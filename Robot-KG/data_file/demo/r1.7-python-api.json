{"index": {"_index": "r1.7-python-api", "_id": "mindspore.boost.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.boost.html", "text_entry": "['mindspore.boost\\n', 'Boost能够自动加速网络，如减少BN/梯度冻结/累积梯度等。\\n', '\\n', '注：此特性为测试版本，我们仍在改进其功能。\\n', '\\n', 'classmindspore.boost.AutoBoost(level=\"O0\", boost_config_dict=\"\")[源代码]\\n', 'MindSpore自动优化算法库。\\n', '\\n', '参数：\\n', '\\n', 'level (str) – Boost的配置级别，默认值：”O0”。\\n', '\\n', '“O0”： 不变化。\\n', '\\n', '“O1”： 启用boost模式, 性能将提升约20%, 准确率保持不变。\\n', '\\n', '“O2”： 启用boost模式, 性能将提升约30%, 准确率下降小于3%。\\n', '\\n', 'boost_config_dict (dict) – 用户可配置的超参字典，建议的格式如下：\\n', '\\n', '{\\n', '    \"boost\": {\\n', '        \"mode\": \"auto\",\\n', '        \"less_bn\": False,\\n', '        \"grad_freeze\": False,\\n', '        \"adasum\": False,\\n', '        \"grad_accumulation\": False,\\n', '        \"dim_reduce\": False},\\n', '\\n', '    \"common\": {\\n', '        \"gradient_split_groups\": [50, 100],\\n', '        \"device_number\": 8},\\n', '\\n', '    \"less_bn\": {\\n', '        \"fn_flag\": True,\\n', '        \"gc_flag\": True},\\n', '\\n', '    \"grad_freeze\": {\\n', '        \"param_groups\": 10,\\n', '        \"freeze_type\": 1,\\n', '        \"freeze_p\": 0.7,\\n', '        \"total_steps\": 65536},\\n', '\\n', '    \"grad_accumulation\": {\\n', '        \"grad_accumulation_step\": 1},\\n', '\\n', '    \"dim_reduce\": {\\n', '        \"rho\": 0.55,\\n', '        \"gamma\": 0.9,\\n', '        \"alpha\": 0.001,\\n', '        \"sigma\": 0.4,\\n', '        \"n_components\": 32,\\n', '        \"pca_mat_path\": None,\\n', '        \"weight_load_dir\": None,\\n', '        \"timeout\": 1800}\\n', '\\n', '}\\n', 'boost：\\n', '\\n', 'mode (str)： Boost配置模式，支持 [“auto”, “manual”, “enable_all”, “disable_all”]。默认值： “auto”。\\n', '\\n', 'auto： 自动配置，取决于Model类中的 boost_level 参数配置。\\n', '\\n', 'manual： 在 boost_config_dict 中人工配置。\\n', '\\n', 'enable_all： 开启所有boost算法。\\n', '\\n', 'disable_all： 关闭所有boost算法。\\n', '\\n', 'less_bn (bool)： 是否开启LessBN算法，默认：False\\n', '\\n', 'grad_freeze (bool)： 是否开启梯度冻结算法，默认：False。\\n', '\\n', 'adasum (bool)： 是否开启自适应求和算法，默认：False。\\n', '\\n', 'grad_accumulation (bool)： 是否开启梯度累加算法，默认：False。\\n', '\\n', 'dim_reduce (bool)： 是否开启降维训练算法，默认：False。\\n', '\\n', '如果开启dim_reduce算法，其他算法会失效。 如果开启grad_freeze算法，同时关闭dim_reduce，其他算法会失效。\\n', '\\n', 'common：\\n', '\\n', 'gradient_split_groups (list)： 网络的梯度分割点，默认： [50, 100]。\\n', '\\n', 'device_number (int)： 设备数，默认： 8。\\n', '\\n', 'less_bn：\\n', '\\n', 'fn_flag (bool)： 是否采用fn替换fc，默认： 替换。\\n', '\\n', 'gc_flag (bool)： 是否启用gc，默认： 启用gc。\\n', '\\n', 'grad_freeze：\\n', '\\n', 'param_groups (int)： 参数分组数量，默认值： 10。\\n', '\\n', 'freeze_type (int)： 梯度冻结策略，参数选择[0, 1]，默认值： 1。\\n', '\\n', 'freeze_p (float)： 梯度冻结概率，默认值： 0.7。\\n', '\\n', 'total_steps (int)： 总训练步数，默认值： 65536。\\n', '\\n', 'grad_accumulation：\\n', '\\n', 'grad_accumulation_step (int)： 累加梯度的步数，默认值： 1。\\n', '\\n', 'dim_reduce：\\n', '\\n', 'dim_reduce主要原理：\\n', '\\n', 'grad_kdkskdelta_loss=pca_mat⋅grad=−bk⋅grad_k=rhom⋅dk=sigma⋅grad_k.T⋅sk\\n', '其中：\\n', '\\n', 'pca_mat (array)： 维度(k*n)，k是 n_components 的大小，n是权重的大小。\\n', '\\n', 'bk (array)： 维度(k*k)，bk是拟牛顿法中的对称正定矩阵。\\n', '\\n', '我们需要找到满足以下条件的m：\\n', '\\n', 'new_loss<old_loss+delta_loss\\n', '然后使用 delta_grad 去更新模型的权重：\\n', '\\n', 'grad_k_projnew_grad_momentumdelta_grad=pca_mat.T⋅grad_k=gamma⋅old_grad_momentum+grad−grad_k_proj=alpha⋅new_grad_momentum−pca_mat.T⋅sk\\n', 'rho (float)： 超参，一般无需调整，默认值： 0.55。\\n', '\\n', 'gamma (float)： 超参，一般无需调整，默认值： 0.9。\\n', '\\n', 'alpha (float)： 超参，一般无需调整，默认值： 0.001。\\n', '\\n', 'sigma (float)： 超参，一般无需调整，默认值： 0.4。\\n', '\\n', 'n_components (int)： PCA后的维度，默认值： 32。\\n', '\\n', 'pca_mat_path (str)： PCA矩阵的加载路径，使用绝对路径，默认值： None。\\n', '\\n', 'weight_load_dir (str)： 以checkpoint形式保存的权重加载路径，用于计算PCA矩阵，默认值： None。\\n', '\\n', 'timeout (int)： 加载PCA矩阵的最长等待时间，默认值： 1800(s)。\\n', '\\n', '用户可以通过加载JSON文件或者直接使用字典来配置 boost_config_dict。 未配置的参数会使用默认值。\\n', '\\n', '异常：\\n', '\\n', 'ValueError – Boost的模式不在[“auto”, “manual”, “enable_all”, “disable_all”]这个列表中。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.boost import AutoBoost\\n', '#1) when configuring the dict directly:\\n', 'boost_config_dict = {\"boost\": {\"mode\": \"auto\"}}\\n', 'boost = AutoBoost(\"O1\", boost_config_dict)\\n', '\\n', '#2) when loading the dict from a json file:\\n', 'import json\\n', 'boost_json = \"/path/boost_config.json\"\\n', \"with open(boost_json, 'r') as fp:\\n\", '    boost_config_dict = json.load(fp)\\n', 'boost = AutoBoost(\"O1\", boost_config_dict)\\n', 'network_auto_process_eval(network)[源代码]\\n', '使用Boost算法推理。\\n', '\\n', '参数：\\n', '\\n', 'network (Cell) - 推理网络。\\n', '\\n', 'network_auto_process_train(network, optimizer)[源代码]\\n', '使用Boost算法训练。\\n', '\\n', '参数：\\n', '\\n', 'network (Cell) - 训练网络。\\n', '\\n', 'optimizer (Union[Cell]) - 用于更新权重的优化器。\\n', '\\n', 'classmindspore.boost.OptimizerProcess(opt)[源代码]\\n', '处理Boost的优化器，目前支持给优化器添加梯度中心化和创建新的优化器。\\n', '\\n', '参数：\\n', '\\n', 'opt (Cell) – 使用的优化器。\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import Tensor, Parameter, nn\\n', 'from mindspore import ops\\n', 'from mindspore.boost import OptimizerProcess\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self, in_features, out_features):\\n', '        super(Net, self).__init__()\\n', '        self.weight = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight')\\n\", '        self.matmul = ops.MatMul()\\n', '\\n', '    def construct(self, x):\\n', '        output = self.matmul(x, self.weight)\\n', '        return output\\n', '\\n', 'size, in_features, out_features = 16, 16, 10\\n', 'network = Net(in_features, out_features)\\n', 'optimizer = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', 'optimizer_process = OptimizerProcess(optimizer)\\n', 'optimizer_process.add_grad_centralization(network)\\n', 'optimizer = optimizer_process.generate_new_optimizer()\\n', 'add_grad_centralization(network)[源代码]\\n', '添加梯度中心化。\\n', '\\n', '参数：\\n', '\\n', 'network (Cell) – 训练网络。\\n', '\\n', 'build_gc_params_group(params_dict, parameters)[源代码]\\n', '构建梯度中心化的分组权重。\\n', '\\n', '参数：\\n', '\\n', 'params_dict (dict) – 训练权重的字典。\\n', '\\n', 'parameters (list) – 训练权重的列表。\\n', '\\n', 'build_params_dict(network)[源代码]\\n', '构建网络权重的字典。\\n', '\\n', '参数：\\n', '\\n', 'network (Cell) – 训练网络。\\n', '\\n', 'generate_new_optimizer()[源代码]\\n', '生成新的优化器。\\n', '\\n', 'classmindspore.boost.ParameterProcess[源代码]\\n', '处理Boost网络的权重。当前支持创建分组参数和自动设置网络梯度切分点。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import Tensor, Parameter, nn\\n', 'import mindspore.ops as ops\\n', 'from mindspore.boost import OptimizerProcess\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self, in_features, out_features):\\n', '        super(Net, self).__init__()\\n', '        self.weight = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight')\\n\", '        self.weight2 = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight2')\\n\", '        self.matmul = ops.MatMul()\\n', '        self.matmul2 = ops.MatMul()\\n', '\\n', '    def construct(self, x):\\n', '        output = self.matmul(x, self.weight)\\n', '        output2 = self.matmul2(x, self.weight2)\\n', '        return output + output2\\n', '\\n', 'size, in_features, out_features = 16, 16, 10\\n', 'network = Net(in_features, out_features)\\n', 'new_parameter = net.trainable_params()[:1]\\n', 'parameter_process = ParameterProcess()\\n', 'group_params = parameter_process.generate_group_params(new_parameter, net.trainable_params())\\n', 'assign_parameter_group(parameters, split_point=None)[源代码]\\n', '设置分组权重。\\n', '\\n', '参数：\\n', '\\n', 'parameters (list) – 训练网络的权重。\\n', '\\n', 'split_point (list) – 网络梯度切分点。默认为None。\\n', '\\n', 'generate_group_params(parameters, origin_params)[源代码]\\n', '创建分组权重。\\n', '\\n', '参数：\\n', '\\n', 'parameters (list) – 训练网络的新权重。\\n', '\\n', 'origin_params (list) – 训练网络的初始权重。\\n', '\\n', 'classmindspore.boost.BoostTrainOneStepCell(network, optimizer, sens=1.0)[源代码]\\n', 'Boost网络训练封装类。\\n', '\\n', '用优化器封装网络，使用输入训练网络来获取结果。反向图在 construct 函数中自动创建，并且支持多种不同的并行模式。\\n', '\\n', '参数：\\n', '\\n', 'network (Cell) – 训练网络，当前网络只支持单个输出。\\n', '\\n', 'optimizer (Union[Cell]) – 用于更新网络参数的优化器。\\n', '\\n', 'sens (numbers.Number) – 作为反向传播输入要填充的缩放数，默认值为1.0。\\n', '\\n', '输入：\\n', '\\n', '(*inputs) (Tuple(Tensor)) – 网络的所有输入组成的元组。\\n', '\\n', '输出：\\n', '\\n', 'Tuple，包含三个Tensor，分别为损失函数值、溢出状态和当前损失缩放系数。\\n', '\\n', 'loss(Tensor)，标量Tensor。\\n', '\\n', 'overflow(Tensor)，标量Tensor，类型为bool。\\n', '\\n', 'loss scaling value(Tensor)，标量Tensor。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 如果 sens 不是一个数字。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import boost\\n', 'net = Net()\\n', 'loss_fn = nn.SoftmaxCrossEntropyWithLogits()\\n', 'optim = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', '#1) Using the WithLossCell existing provide\\n', 'loss_net = nn.WithLossCell(net, loss_fn)\\n', 'train_net = boost.BoostTrainOneStepCell(loss_net, optim)\\n', '\\n', '#2) Using user-defined WithLossCell\\n', 'class MyWithLossCell(Cell):\\n', '   def __init__(self, backbone, loss_fn):\\n', '       super(MyWithLossCell, self).__init__(auto_prefix=False)\\n', '       self._backbone = backbone\\n', '       self._loss_fn = loss_fn\\n', '\\n', '   def construct(self, x, y, label):\\n', '       out = self._backbone(x, y)\\n', '       return self._loss_fn(out, label)\\n', '\\n', '   @property\\n', '   def backbone_network(self):\\n', '       return self._backbone\\n', '\\n', 'loss_net = MyWithLossCell(net, loss_fn)\\n', 'train_net = boost.BoostTrainOneStepCell(loss_net, optim)\\n', 'adasum_process(loss, grads)[源代码]\\n', '使用Adasum算法训练。\\n', '\\n', '参数：\\n', '\\n', 'loss (Tensor) – 网络训练的loss值。\\n', '\\n', 'grads (Tuple(Tensor)) – 网络训练过程中的梯度。\\n', '\\n', '返回：\\n', '\\n', 'Tensor，网络训练过程中得到的loss值。\\n', '\\n', 'check_adasum_enable()[源代码]\\n', 'Adasum算法仅在多卡或者多机场景生效，并且要求卡数符合2的n次方，该函数用来判断adasum算法能否生效。\\n', '\\n', '返回：\\n', '\\n', 'enable_adasum (bool)，Adasum算法是否生效。\\n', '\\n', 'check_dim_reduce_enable()[源代码]\\n', '获取当前是否使用降维二阶训练算法训练。\\n', '\\n', '返回：\\n', '\\n', 'enable_dim_reduce (bool)，降维二阶训练算法是否生效。\\n', '\\n', 'gradient_accumulation_process(loss, grads, sens, *inputs)[源代码]\\n', '使用梯度累积算法训练。\\n', '\\n', '参数：\\n', '\\n', 'loss (Tensor) – 网络训练的loss值。\\n', '\\n', 'grads (Tuple(Tensor)) – 网络训练过程中的梯度。\\n', '\\n', 'sens (Tensor) – 作为反向传播输入要填充的缩放数。\\n', '\\n', 'inputs (Tuple(Tensor)) – 网络训练的输入。\\n', '\\n', '返回：\\n', '\\n', 'Tensor，网络训练过程中得到的loss值。\\n', '\\n', 'gradient_freeze_process(*inputs)[源代码]\\n', '使用梯度冻结算法训练。\\n', '\\n', '参数：\\n', '\\n', 'inputs (Tuple(Tensor)) – 网络训练的输入。\\n', '\\n', '返回：\\n', '\\n', 'Tensor，网络训练过程中得到的loss值。\\n', '\\n', 'classmindspore.boost.BoostTrainOneStepWithLossScaleCell(network, optimizer, scale_sense)[源代码]\\n', '使用混合精度功能的Boost训练网络。\\n', '\\n', '实现了包含损失缩放（loss scale）的单次训练。它使用网络、优化器和用于更新损失缩放系数（loss scale）的Cell(或一个Tensor)作为参数。可在host侧或device侧更新损失缩放系数。 如果需要在host侧更新，使用Tensor作为 scale_sense ，否则，使用可更新损失缩放系数的Cell实例作为 scale_sense 。\\n', '\\n', '参数：\\n', '\\n', 'network (Cell) – 训练网络，当前网络只支持单个输出。\\n', '\\n', 'optimizer (Union[Cell]) – 用于更新网络参数的优化器。\\n', '\\n', 'scale_sense (Union[Tensor, Cell]) - 如果此值为Cell类型，BoostTrainOneStepWithLossScaleCell 会调用它来更新损失缩放系数。如果此值为Tensor类型，可调用 set_sense_scale 来更新损失缩放系数，shape为 () 或 (1,) 。\\n', '\\n', '输入：\\n', '\\n', '(*inputs) (Tuple(Tensor)) - 网络的所有输入组成的元组。\\n', '\\n', '输出：\\n', '\\n', 'Tuple，包含三个Tensor，分别为损失函数值、溢出状态和当前损失缩放系数。\\n', '\\n', 'loss(Tensor)，标量Tensor。\\n', '\\n', 'overflow(Tensor)，标量Tensor，类型为bool。\\n', '\\n', 'loss scaling value(Tensor)，标量Tensor。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - scale_sense 既不是Cell，也不是Tensor。\\n', '\\n', 'ValueError - scale_sense 的shape既不是(1,)也不是()。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import Tensor, Parameter, nn\\n', 'import mindspore.ops as ops\\n', 'from mindspore.nn import WithLossCell\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore import boost\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self, in_features, out_features):\\n', '        super(Net, self).__init__()\\n', '        self.weight = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight')\\n\", '        self.matmul = ops.MatMul()\\n', '\\n', '    def construct(self, x):\\n', '        output = self.matmul(x, self.weight)\\n', '        return output\\n', '\\n', 'size, in_features, out_features = 16, 16, 10\\n', '#1) when the type of scale_sense is Cell:\\n', 'net = Net(in_features, out_features)\\n', 'loss = nn.MSELoss()\\n', 'optimizer = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', 'net_with_loss = WithLossCell(net, loss)\\n', 'manager = nn.DynamicLossScaleUpdateCell(loss_scale_value=2**12, scale_factor=2, scale_window=1000)\\n', 'train_network = boost.BoostTrainOneStepWithLossScaleCell(net_with_loss, optimizer, scale_sense=manager)\\n', 'input = Tensor(np.ones([out_features, in_features]), mstype.float32)\\n', 'labels = Tensor(np.ones([out_features,]), mstype.float32)\\n', 'output = train_network(input, labels)\\n', '\\n', '#2) when the type of scale_sense is Tensor:\\n', 'net = Net(in_features, out_features)\\n', 'loss = nn.MSELoss()\\n', 'optimizer = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', 'net_with_loss = WithLossCell(net, loss)\\n', 'inputs = Tensor(np.ones([size, in_features]).astype(np.float32))\\n', 'label = Tensor(np.zeros([size, out_features]).astype(np.float32))\\n', 'scaling_sens = Tensor(np.full((1), np.finfo(np.float32).max), dtype=mstype.float32)\\n', 'train_network = boost.BoostTrainOneStepWithLossScaleCell(net_with_loss, optimizer, scale_sense=scaling_sens)\\n', 'output = train_network(inputs, label)\\n', 'classmindspore.boost.LessBN(network, fn_flag=False)[源代码]\\n', 'LessBN算法，可以在不损失网络精度的前提下，自动减少网络中批归一化（Batch Normalization）的数量，来提升网络性能。\\n', '\\n', '参数：\\n', '\\n', 'network (Cell) – 待训练的网络模型。\\n', '\\n', 'fn_flag (bool) – 是否将网络中最后一个全连接层替换为全归一化层。默认值：False。\\n', '\\n', '样例：\\n', '\\n', 'network = boost.LessBN(network)\\n', 'classmindspore.boost.GradientFreeze(param_groups, freeze_type, freeze_p, total_steps)[源代码]\\n', '梯度冻结算法，根据指定策略随机冻结某些层的梯度，来提升网络训练性能。 冻结的层数和冻结的概率均可由用户配置。\\n', '\\n', '参数：\\n', '\\n', 'param_groups (Union[tuple, list]) – 梯度冻结训练的权重。\\n', '\\n', 'freeze_type (int) – 梯度冻结训练的策略。\\n', '\\n', 'freeze_p (float) – 梯度冻结训练的概率。\\n', '\\n', 'total_steps (int) – 整个训练过程的总的步数。\\n', '\\n', '样例：\\n', '\\n', 'gradient_freeze_class = boost.GradientFreeze(10, 1, 0.5, 2000)\\n', 'network, optimizer = gradient_freeze_class.freeze_generate(network, optimizer)\\n', 'freeze_generate(network, optimizer)[源代码]\\n', '生成梯度冻结的网络与优化器。\\n', '\\n', '参数：\\n', '\\n', 'network (Cell) – 训练网络。\\n', '\\n', 'optimizer (Union[Cell]) – 用于更新权重的优化器。\\n', '\\n', 'generate_freeze_index_sequence(parameter_groups_number, freeze_strategy, freeze_p, total_steps)[源代码]\\n', '生成梯度冻结每一步需要冻结的层数。\\n', '\\n', '参数：\\n', '\\n', 'parameter_groups_number (numbers.Number) – 梯度冻结训练的权重个数。\\n', '\\n', 'freeze_strategy (int) – 梯度冻结训练的策略。\\n', '\\n', 'freeze_p (float) – 梯度冻结训练的概率。\\n', '\\n', 'total_steps (numbers.Number) – 整个训练过程的总的步数。\\n', '\\n', 'split_parameters_groups(net, freeze_para_groups_number)[源代码]\\n', '拆分用于梯度冻结训练的权重。\\n', '\\n', '参数：\\n', '\\n', 'net (Cell) – 训练网络。\\n', '\\n', 'freeze_para_groups_number (int) – 梯度冻结训练的权重个数。\\n', '\\n', 'classmindspore.boost.FreezeOpt(opt, train_parameter_groups=None, train_strategy=None)[源代码]\\n', '支持梯度冻结训练的优化器。\\n', '\\n', '参数：\\n', '\\n', 'opt (Cell) – 非冻结优化器实例，如 Momentum，SGD。\\n', '\\n', 'train_parameter_groups (Union[tuple, list]) – 梯度冻结训练的权重。\\n', '\\n', 'train_strategy (Union[tuple(int), list(int), Tensor]) – 梯度冻结训练的策略。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.boost.freeze_cell(reducer_flag, network, optimizer, sens, grad, use_grad_accumulation, mean=None, degree=None, max_accumulation_step=1)[源代码]\\n', '提供带梯度冻结的网络Cell。\\n', '\\n', '参数：\\n', '\\n', 'reducer_flag (bool): 是否分布式训练。\\n', '\\n', 'network (Cell): 训练网络。\\n', '\\n', 'optimizer (Cell): 优化器。\\n', '\\n', 'sens (numbers.Number): 损失缩放系数。\\n', '\\n', 'grad (tuple(Tensor)): 网络梯度。\\n', '\\n', 'use_grad_accumulation (bool): 是否使用梯度累积。\\n', '\\n', 'mean (bool): 可选参数，梯度是否求平均，仅分布式训练时生效。默认值为None。\\n', '\\n', 'degree (int): 可选参数，device卡数，仅分布式训练时生效。默认值为None。\\n', '\\n', 'max_accumulation_step (int): 可选参数，梯度累积步数。默认值为1。\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import Tensor, Parameter, nn\\n', 'import mindspore.ops as ops\\n', 'from mindspore.boost.grad_freeze import freeze_cell\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self, in_features, out_features):\\n', '        super(Net, self).__init__()\\n', '        self.weight = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight')\\n\", '        self.matmul = ops.MatMul()\\n', '\\n', '    def construct(self, x):\\n', '        output = self.matmul(x, self.weight)\\n', '        return output\\n', '\\n', 'in_features, out_features = 16, 10\\n', 'network = Net(in_features, out_features)\\n', 'optimizer = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', 'grad = ops.GradOperation(get_by_list=True, sens_param=True)\\n', 'freeze_nets = freeze_cell(False, network, optimizer, 1.0, grad, False, None, None, 1)\\n', 'classmindspore.boost.GradientAccumulation(max_accumulation_step, optimizer)[源代码]\\n', '梯度累积算法，在累积多个step的梯度之后，再用来更新网络权重，可以提高训练效率。\\n', '\\n', '参数：\\n', '\\n', 'max_accumulation_step (int) – 累积梯度的步数。\\n', '\\n', 'optimizer (Cell) – 网络训练使用的优化器。\\n', '\\n', 'classmindspore.boost.AdaSum(rank, device_number, group_number, parameter_tuple)[源代码]\\n', 'Adaptive Summation(AdaSum)是一种优化深度学习模型并行训练的算法，它可以提升不同规模集群训练的精度，减小不同规模集群调参难度。\\n', '\\n', '参数：\\n', '\\n', 'rank (int) – 总的训练的卡数。\\n', '\\n', 'device_number (int) – 单机的卡数。\\n', '\\n', 'group_number (int) – 分组的数量。\\n', '\\n', 'parameter_tuple (Tuple(Parameter)) – 网络训练权重组成的元组。\\n', '\\n', '输入：\\n', '\\n', 'delta_weights (Tuple(Tensor)) – 梯度tuple。\\n', '\\n', 'parameters (Tuple(Parameter)) – 当前权重组成的元组。\\n', '\\n', 'old_parameters (Tuple(Parameter)) – 旧的权重组成的元组。\\n', '\\n', '输出：\\n', '\\n', 'adasum_parameters (Tuple(Tensor)) - adasum处理后更新的权重。\\n', '\\n', 'classmindspore.boost.DimReduce(network, optimizer, weight, pca_mat_local, n_components, rho, gamma, alpha, sigma, rank, rank_size)[源代码]\\n', '降维训练(dimension reduce training)是一种优化深度学习模型训练的算法，它可以加速模型的收敛。\\n', '\\n', '算法主要原理：\\n', '\\n', 'grad_kdkskdelta_loss=pca_mat⋅grad=−bk⋅grad_k=rhom⋅dk=sigma⋅grad_k.T⋅sk\\n', '其中:\\n', '\\n', 'pca_mat (array): PCA矩阵，维度(k*n)，k是 n_components 的大小，n是权重的大小。\\n', '\\n', 'bk (array): 维度(k*k)，bk是拟牛顿法中的对称正定矩阵。\\n', '\\n', '我们需要找到满足以下条件的m:\\n', '\\n', 'new_loss<old_loss+delta_loss\\n', '然后使用 delta_grad 去更新模型的权重:\\n', '\\n', 'grad_k_projnew_grad_momentumdelta_grad=pca_mat.T⋅grad_k=gamma⋅old_grad_momentum+grad−grad_k_proj=alpha⋅new_grad_momentum−pca_mat.T⋅sk\\n', '参数：\\n', '\\n', 'network (Cell) - 训练网络，只支持单输出。\\n', '\\n', 'optimizer (Union[Cell]) - 更新权重的优化器。\\n', '\\n', 'weight (Tuple(Parameter)) - 网络权重组成的元组。\\n', '\\n', 'pca_mat_local (numpy.ndarray) - 用于PCA操作的，经过切分的PCA转换矩阵，维度为k*n，k是切分的 n_components 的大小，n是权重的大小。\\n', '\\n', 'n_components (int) - PCA的主成分维度 components。\\n', '\\n', 'rho (float) - 超参。\\n', '\\n', 'gamma (float) - 超参。\\n', '\\n', 'alpha (float) - 超参。\\n', '\\n', 'sigma (float) - 超参。\\n', '\\n', 'rank (int) - Rank编号。\\n', '\\n', 'rank_size (int) - Rank总数。\\n', '\\n', '输入：\\n', '\\n', 'loss (Tensor) - 网络loss，标量Tensor。\\n', '\\n', 'old_grad (Tuple(Tensor)) - 网络权重提取组成的元组。\\n', '\\n', 'weight (Tuple(Tensor)) - 网络权重组成的元组。\\n', '\\n', 'weight_clone (Tuple(Tensor)) - 网络权重的副本。\\n', '\\n', '(*inputs) (Tuple(Tensor)) - 网络的所有输入组成的元组。\\n', '\\n', '输出：\\n', '\\n', 'loss (Tensor) - 网络loss，标量Tensor。']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.common.initializer.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.common.initializer.html", "text_entry": "['mindspore.common.initializer\\n', '初始化神经元参数。\\n', '\\n', 'classmindspore.common.initializer.Initializer(**kwargs)[源代码]\\n', '初始化器的抽象基类。\\n', '\\n', '参数：\\n', '\\n', 'kwargs (dict) – Initializer 的关键字参数。\\n', '\\n', 'mindspore.common.initializer.initializer(init, shape=None, dtype=mstype.float32)[源代码]\\n', '创建并初始化一个Tensor。\\n', '\\n', '参数：\\n', '\\n', 'init (Union[Tensor, str, Initializer, numbers.Number]) – 初始化方式。\\n', '\\n', 'str - init 是继承自 Initializer 的类的别名，实际使用时会调用相应的类。init 的值可以是”normal”、”ones”或”zeros”等。\\n', '\\n', 'Initializer - init 是继承自 Initializer ，用于初始化Tensor的类。\\n', '\\n', 'numbers.Number - 用于初始化Tensor的常量。\\n', '\\n', 'Tensor - 用于初始化Tensor的Tensor。\\n', '\\n', 'shape (Union[tuple, list, int]) - 被初始化的Tensor的shape，默认值为None。\\n', '\\n', 'dtype (mindspore.dtype) – 被初始化的Tensor的数据类型，默认值为 mindspore.float32 。\\n', '\\n', '返回：\\n', '\\n', 'Tensor。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - 参数 init 的类型不正确。\\n', '\\n', 'ValueError - 当 init 传入Tensor对象时， init 的shape与形参 shape 内的数值不一致。\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'import mindspore\\n', 'from mindspore import Tensor\\n', 'from mindspore.common.initializer import initializer, One\\n', 'data = Tensor(np.zeros([1, 2, 3]), mindspore.float32)\\n', 'tensor1 = initializer(data, [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('ones', [1, 2, 3], mindspore.float32)\\n\", 'tensor3 = initializer(One(), [1, 2, 3], mindspore.float32)\\n', 'tensor4 = initializer(0, [1, 2, 3], mindspore.float32)\\n', 'classmindspore.common.initializer.TruncatedNormal(sigma=0.01)[源代码]\\n', '生成一个服从截断正态（高斯）分布的随机数组用于初始化Tensor。\\n', '\\n', '参数：\\n', '\\n', 'sigma (float) - 截断正态分布的标准差，默认值为0.01。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, TruncatedNormal\\n', 'tensor1 = initializer(TruncatedNormal(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('truncatedNormal', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Normal(sigma=0.01, mean=0.0)[源代码]\\n', '生成一个服从正态分布 N(sigma,mean) 的随机数组用于初始化Tensor。\\n', '\\n', 'f(x)=12∗π−−−−√∗sigmaexp(−(x−mean)22∗sigma2)\\n', '参数：\\n', '\\n', 'sigma (float) - 正态分布的标准差，默认值为0.01。\\n', '\\n', 'mean (float) - 正态分布的均值，默认值为0.0。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Normal\\n', 'tensor1 = initializer(Normal(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('normal', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Uniform(scale=0.07)[源代码]\\n', '生成一个服从均匀分布 U(−scale,scale) 的随机数组用于初始化Tensor。\\n', '\\n', '参数：\\n', '\\n', 'scale (float) - 均匀分布的边界，默认值为0.07。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Uniform\\n', 'tensor1 = initializer(Uniform(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('uniform', [1, 2, 3], mindspore.float32)\\n\", \"classmindspore.common.initializer.HeUniform(negative_slope=0, mode='fan_in', nonlinearity='leaky_relu')[源代码]\\n\", '生成一个服从HeKaiming均匀分布 U(−boundary,boundary) 的随机数组用于初始化Tensor，其中：\\n', '\\n', 'boundary=gain×3fan_mode−−−−−−−−−√\\n', 'gain 是一个可选的缩放因子。 fan_mode 是权重Tensor中输入或输出单元的数量，取决于 mode 是’fan_in’或是’fan_out’。\\n', '\\n', '参数：\\n', '\\n', 'negative_slope (int, float, bool) - 本层激活函数的负数区间斜率（仅适用于非线性激活函数’leaky_relu’），默认值为0。\\n', '\\n', 'mode (str) - 可选’fan_in’或’fan_out’，’fan_in’会保留前向传递中权重方差的量级，’fan_out’会保留反向传递的量级，默认为’fan_in’。\\n', '\\n', 'nonlinearity (str) - 非线性激活函数，推荐使用’relu’或’leaky_relu’，默认为’leaky_relu’。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, HeUniform\\n', 'tensor1 = initializer(HeUniform(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('he_uniform', [1, 2, 3], mindspore.float32)\\n\", \"classmindspore.common.initializer.HeNormal(negative_slope=0, mode='fan_in', nonlinearity='leaky_relu')[源代码]\\n\", '生成一个服从HeKaiming正态分布 N(0,sigma2) 的随机数组用于初始化Tensor，其中：\\n', '\\n', 'sigma=gainfan_mode−−−−−−−−−√\\n', '其中， gain 是一个可选的缩放因子。如果 mode 是’fan_in’，则 fan_mode 是权重Tensor中输入单元的数量，如果 mode 是’fan_out’， fan_mode 是权重Tensor中输出单元的数量。\\n', '\\n', 'HeUniform 算法的详细信息，请查看 https://arxiv.org/abs/1502.01852。\\n', '\\n', '参数：\\n', '\\n', 'negative_slope (int, float, bool) - 本层激活函数的负数区间斜率（仅适用于非线性激活函数’leaky_relu’），默认值为0。\\n', '\\n', 'mode (str) - 可选’fan_in’或’fan_out’，’fan_in’会保留前向传递中权重方差的量级，’fan_out’会保留反向传递的量级，默认为’fan_in’。\\n', '\\n', 'nonlinearity (str) - 非线性激活函数，推荐使用’relu’或’leaky_relu’，默认为’leaky_relu’。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, HeNormal\\n', 'tensor1 = initializer(HeNormal(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('he_normal', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.XavierUniform(gain=1)[源代码]\\n', '生成一个服从Xarvier均匀分布U(-boundary, boundary)的随机数组用于初始化Tensor，均匀分布的取值范围为[-boundary, boundary]，其中：\\n', '\\n', 'boundary=gain∗6nin+nout−−−−−−−−−√\\n', 'gain 是一个可选的缩放因子。nin 为权重Tensor中输入单元的数量。nout 为权重Tensor中输出单元的数量。\\n', '\\n', '有关 XavierUniform 算法的详细信息，请查看 http://proceedings.mlr.press/v9/glorot10a.html。\\n', '\\n', '参数：\\n', '\\n', 'gain (float) - 可选的缩放因子，默认值为1。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, XavierUniform\\n', 'tensor1 = initializer(XavierUniform(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('xavier_uniform', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.One(**kwargs)[源代码]\\n', '生成一个值全为1的常量数组用于初始化Tensor。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, One\\n', 'tensor1 = initializer(One(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('ones', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Zero(**kwargs)[源代码]\\n', '生成一个值全为0的常量数组用于初始化Tensor。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Zero\\n', 'tensor1 = initializer(Zero(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('zeros', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Constant(value)[源代码]\\n', '生成一个常量数组用于初始化Tensor。\\n', '\\n', '参数：\\n', '\\n', 'value (Union[int, numpy.ndarray]) - 用于初始化的常数值或者数组。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer\\n', 'tensor1 = initializer(0, [1, 2, 3], mindspore.float32)\\n', 'tensor2 = initializer(5, [1, 2, 3], mindspore.float32)\\n', 'classmindspore.common.initializer.Identity(**kwargs)[源代码]\\n', '生成一个2维的单位矩阵用于初始化Tensor。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 被初始化的Tensor的维度不等于2。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Identity\\n', 'tensor1 = initializer(Identity(), [2, 3], mindspore.float32)\\n', \"tensor2 = initializer('identity', [2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Sparse(sparsity, sigma=0.01)[源代码]\\n', '生成一个2维的稀疏矩阵用于初始化Tensor。矩阵非0的位置的值服从正态分布 N(0,0.01) 。\\n', '\\n', '参数：\\n', '\\n', 'sparsity (float) - 矩阵每列中元素被置0的比例。\\n', '\\n', 'sigma (float) - 正态分布的标准差，默认值为0.01。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 被初始化的Tensor的维度不等于2。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Sparse\\n', 'tensor1 = initializer(Sparse(sparsity=0.1, sigma=0.01), [5, 8], mindspore.float32)\\n', 'classmindspore.common.initializer.Dirac(groups=1)[源代码]\\n', '利用Dirac delta函数生成一个矩阵用于初始化Tensor。这种初始化方式将会保留卷积层的输入。对于group 卷积，通道的每个分组会被分别保留。\\n', '\\n', '参数：\\n', '\\n', 'groups (int) - 卷积层中的分组，默认值为1。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 被初始化的Tensor的维度不在[3, 4, 5]的范围内。\\n', '\\n', 'ValueError - 初始化的Tensor的第一个维度不能被groups整除。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Dirac\\n', 'tensor1 = initializer(Dirac(groups=2), [6, 4, 3, 3], mindspore.float32)\\n', 'tensor2 = initializer(\"dirac\", [6, 4, 3, 3], mindspore.float32)\\n', 'classmindspore.common.initializer.Orthogonal(gain=1.)[源代码]\\n', '生成一个正交或半正交矩阵用于初始化Tensor。被初始化的Tensor的维度至少为2。 如果维度大于2，多余的维度将会被展平。\\n', '\\n', '参数：\\n', '\\n', 'gain (float) - 可选的比例因子，默认值为1。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 被初始化的Tensor的维度小于2。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Orthogonal\\n', 'tensor1 = initializer(Orthogonal(gain=2.), [2, 3, 4], mindspore.float32)\\n', \"tensor2 = initializer('orthogonal', [2, 3, 4], mindspore.float32)\\n\", \"classmindspore.common.initializer.VarianceScaling(scale=1.0, mode='fan_in', distribution='truncated_normal')[源代码]\\n\", '生成一个随机的矩阵用于初始化Tensor。 当 distribution 是’truncated_normal’或者’untruncated_normal’时，矩阵中的值将服从均值为0，标准差 为 stddev=scalen−−−−√ 的截断或者非截断正太分布。如果 mode 是’fan_in’， n 是输入单元的数量； 如果 mode 是’fan_out’， n 是输出单元的数量；如果 mode 是’fan_avg’， n 是输入输出单元数量的均值。 当 distribution 是’uniform’时，矩阵中的值将服从均匀分布 [−3∗scalen−−−−−√,3∗scalen−−−−−√]。\\n', '\\n', '参数：\\n', '\\n', 'scale (float) - 比例因子，默认值为1.0。\\n', '\\n', 'mode (str) - 其值应为’fan_in’，’fan_out’或者’fan_avg’，默认值为’fan_in’。\\n', '\\n', 'distribution (str) - 用于采样的分布类型。它可以是 ‘uniform’，’truncated_normal’或’untruncated_normal’，默认值为’truncated_normal’。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - scale 小于等于0。\\n', '\\n', 'ValueError - mode 不是’fan_in’，’fan_out’或者’fan_avg’。\\n', '\\n', 'ValueError - distribution 不是’truncated_normal’，’untruncated_normal’或者’uniform’。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, VarianceScaling\\n', \"tensor1 = initializer(VarianceScaling(scale=1.0, mode='fan_out',\\n\", \"                                      distribution='untruncated_normal'), [2, 3], mindspore.float32)\\n\", \"tensor2 = initializer('varianceScaling', [2, 3], mindspore.float32)\"]"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.communication.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.communication.html", "text_entry": "['mindspore.communication\\n', '集合通信接口。\\n', '\\n', '注意，集合通信接口需要预先设置环境变量。对于Ascend，用户需要配置rank_table，设置rank_id和device_id，相关教程可参考： Ascend指导文档。 对于GPU，用户需要预先配置host_file以及mpi，相关教程参考： GPU指导文档。\\n', '\\n', '目前尚不支持CPU。\\n', '\\n', 'classmindspore.communication.GlobalComm[源代码]\\n', 'GlobalComm 是一个储存通信信息的全局类。 成员包含：BACKEND、WORLD_COMM_GROUP。\\n', '\\n', 'BACKEND：使用的通信库，HCCL或者NCCL。\\n', '\\n', 'WORLD_COMM_GROUP：全局通信域。\\n', '\\n', 'mindspore.communication.init(backend_name=None)[源代码]\\n', '初始化通信服务需要的分布式后端，例如 HCCL 或 NCCL 服务。\\n', '\\n', 'Note\\n', '\\n', 'HCCL的全称是华为集合通信库（Huawei Collective Communication Library），NCCL的全称是英伟达集合通信库（NVIDIA Collective Communication Library）。 init 方法应该在 set_context 方法之后使用。\\n', '\\n', '参数：\\n', '\\n', 'backend_name (str) – 分布式后端的名称，可选HCCL或NCCL。如果未设置则根据硬件平台类型（device_target）进行推断，默认值为None。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 参数 backend_name 不是字符串。\\n', '\\n', 'RuntimeError – 1）硬件设备类型无效；2）后台服务无效；3）分布式计算初始化失败；4）未设置环境变量 RANK_ID 或 MINDSPORE_HCCL_CONFIG_PATH 的情况下初始化HCCL服务。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.communication import init\\n', 'init()\\n', 'classmindspore.communication.release[源代码]\\n', '释放分布式资源，例如 HCCL 或 NCCL 服务。\\n', '\\n', 'Note\\n', '\\n', 'release 方法应该在 init 方法之后使用。\\n', '\\n', '异常：\\n', '\\n', 'RuntimeError - 在释放分布式资源失败时抛出。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.communication import init, release\\n', 'init()\\n', 'release()\\n', 'classmindspore.communication.get_rank(group=GlobalComm.WORLD_COMM_GROUP)[源代码]\\n', '在指定通信组中获取当前的设备序号。\\n', '\\n', '参数：\\n', '\\n', 'group (str) - 通信组名称，通常由 create_group 方法创建，否则将使用默认组。默认值： GlobalComm.WORLD_COMM_GROUP 。\\n', '\\n', '返回：\\n', '\\n', 'int, 调用该方法的进程对应的组内序号。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 在参数 group 不是字符串时抛出。\\n', '\\n', 'ValueError – 在后台不可用时抛出。\\n', '\\n', 'RuntimeError – 在 HCCL 或 NCCL 服务不可用时抛出。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.communication import init, get_rank\\n', 'init()\\n', 'rank_id = get_rank()\\n', 'print(rank_id)\\n', '# the result is the rank_id in world_group\\n', 'classmindspore.communication.get_group_size(group=GlobalComm.WORLD_COMM_GROUP)[源代码]\\n', '获取指定通信组实例的rank_size。\\n', '\\n', 'Note\\n', '\\n', 'get_group_size 方法应该在 init 方法之后使用。在跑用例之前用户需要预先配置通信相关的环境变量。\\n', '\\n', '参数：\\n', '\\n', 'group (str) - 指定工作组实例（由 create_group 方法创建）的名称，支持数据类型为str，默认值为 WORLD_COMM_GROUP 。\\n', '\\n', '返回：\\n', '\\n', '指定通信组实例的rank_size，数据类型为int。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 在参数 group 不是字符串时抛出。\\n', '\\n', 'ValueError – 在后台不可用时抛出。\\n', '\\n', 'RuntimeError – 在 HCCL 或 NCCL 服务不可用时抛出。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.context import set_context, set_auto_parallel_context\\n', 'from mindspore.communication.management import init, get_group_size\\n', 'set_context(device_target=\"Ascend\")\\n', 'set_auto_parallel_context(device_num=8)\\n', 'init()\\n', 'group_size = get_group_size()\\n', 'print(\"group_size is: \", group_size)\\n', '\\n', 'classmindspore.communication.get_world_rank_from_group_rank(group, group_rank_id)[源代码]\\n', '由指定通信组中的设备序号获取通信集群中的全局设备序号。\\n', '\\n', 'Note\\n', '\\n', 'GPU 版本的MindSpore不支持此方法；\\n', '\\n', '参数 group 不能是 hccl_world_group；\\n', '\\n', 'get_world_rank_from_group_rank 方法应该在 init 方法之后使用。\\n', '\\n', '参数：\\n', '\\n', 'group (str) - 传入的通信组名称，通常由 create_group 方法创建。\\n', '\\n', 'group_rank_id (int) - 通信组内的设备序号。\\n', '\\n', '返回：\\n', '\\n', 'int, 通信集群中的全局设备序号。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 参数 group 不是字符串或参数 group_rank_id 不是数字。\\n', '\\n', 'ValueError – 参数 group 是 hccl_world_group 或后台不可用。\\n', '\\n', 'RuntimeError – HCCL 或 NCCL 服务不可用，以及使用CPU版本的MindSpore。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.context import set_context\\n', 'from mindspore.communication.management import init, create_group, get_world_rank_from_group_rank\\n', 'set_context(device_target=\"Ascend\")\\n', 'init()\\n', 'group = \"0-4\"\\n', 'rank_ids = [0,4]\\n', 'create_group(group, rank_ids)\\n', 'world_rank_id = get_world_rank_from_group_rank(group, 1)\\n', 'print(\"world_rank_id is: \", world_rank_id)\\n', '\\n', 'classmindspore.communication.get_group_rank_from_world_rank(world_rank_id, group)[源代码]\\n', '由通信集群中的全局设备序号获取指定用户通信组中的rank ID。\\n', '\\n', 'Note\\n', '\\n', 'GPU 版本的MindSpore不支持此方法；\\n', '\\n', '参数 group 不能是 hccl_world_group；\\n', '\\n', 'get_group_rank_from_world_rank 方法应该在 init 方法之后使用。\\n', '\\n', '参数：\\n', '\\n', 'world_rank_id (int) - 通信集群内的全局rank ID。\\n', '\\n', 'group (str) - 指定通信组实例（由 create_group 方法创建）的名称。\\n', '\\n', '返回：\\n', '\\n', '当前通信组内的rank_ID，数据类型为int。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 在参数 group_rank_id 不是数字或参数 group 不是字符串时抛出。\\n', '\\n', 'ValueError – 在参数 group 是 hccl_world_group 或后台不可用时抛出。\\n', '\\n', 'RuntimeError – 在 HCCL 或 NCCL 服务不可用，以及使用GPU版本的MindSpore时抛出。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.context import set_context\\n', 'from mindspore.communication.management import init, create_group, get_group_rank_from_world_rank\\n', 'set_context(device_target=\"Ascend\")\\n', 'init()\\n', 'group = \"0-4\"\\n', 'rank_ids = [0,4]\\n', 'create_group(group, rank_ids)\\n', 'group_rank_id = get_group_rank_from_world_rank(4, group)\\n', 'print(\"group_rank_id is: \", group_rank_id)\\n', '\\n', 'classmindspore.communication.create_group(group, rank_ids)[源代码]\\n', '创建用户自定义的通信组实例。\\n', '\\n', 'Note\\n', '\\n', 'GPU 版本的MindSpore不支持此方法；\\n', '\\n', '列表rank_ids的长度应大于1；\\n', '\\n', '列表rank_ids内不能有重复数据；\\n', '\\n', 'create_group 方法应该在 init 方法之后使用。\\n', '\\n', '参数：\\n', '\\n', 'group (str) - 输入用户自定义的通信组实例名称，支持数据类型为str。\\n', '\\n', 'rank_ids (list) - 设备编号列表。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 参数 group_rank_id 不是数字或参数 group 不是字符串。\\n', '\\n', 'ValueError – 列表rank_ids的长度小于1，或列表rank_ids内有重复数据，以及后台无效。\\n', '\\n', 'RuntimeError – 在 HCCL 或 NCCL 服务不可用，以及使用CPU版本的MindSpore。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.context import set_context\\n', 'from mindspore.ops import operations as ops\\n', 'from mindspore.communication.management import init, create_group\\n', 'set_context(device_target=\"Ascend\")\\n', 'init()\\n', 'group = \"0-8\"\\n', 'rank_ids = [0,8]\\n', 'create_group(group, rank_ids)\\n', 'allreduce = ops.AllReduce(group)\\n', 'classmindspore.communication.get_local_rank(group=GlobalComm.WORLD_COMM_GROUP)[源代码]\\n', '获取指定通信组中当前设备的本地设备序号。\\n', '\\n', 'Note\\n', '\\n', 'GPU 版本的MindSpore不支持此方法；\\n', '\\n', 'get_local_rank 方法应该在 init 方法之后使用。\\n', '\\n', '参数：\\n', '\\n', 'group (str) - 通信组名称，通常由 create_group 方法创建，否则将使用默认组名称。默认值： WORLD_COMM_GROUP 。\\n', '\\n', '返回：\\n', '\\n', 'int, 调用该方法的进程对应的通信组内本地设备序号。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 在参数 group 不是字符串时抛出。\\n', '\\n', 'ValueError – 在后台不可用时抛出。\\n', '\\n', 'RuntimeError – 在 HCCL 或 NCCL 服务不可用时抛出。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.context import set_context, set_auto_parallel_context\\n', 'from mindspore.communication.management import init, get_rank, get_local_rank\\n', 'set_context(device_target=\"Ascend\")\\n', 'set_auto_parallel_context(device_num=16) # 2 server, each server with 8 NPU.\\n', 'init()\\n', 'world_rank = get_rank() # rank_id is 9.\\n', 'local_rank = get_local_rank()\\n', 'print(\"local_rank is: {}, world_rank is {}\".format(local_rank, world_rank))\\n', '\\n', 'classmindspore.communication.get_local_rank_size(group=GlobalComm.WORLD_COMM_GROUP)[源代码]\\n', '获取指定通信组的本地设备总数。\\n', '\\n', 'Note\\n', '\\n', 'GPU 版本的MindSpore不支持此方法；\\n', '\\n', 'get_local_rank_size 方法应该在 init 方法之后使用。\\n', '\\n', '参数：\\n', '\\n', 'group (str) - 传入的通信组名称，通常由 create_group 方法创建，或默认使用 WORLD_COMM_GROUP 。\\n', '\\n', '返回：\\n', '\\n', 'int, 调用该方法的进程对应的通信组设备总数。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 在参数 group 不是字符串时抛出。\\n', '\\n', 'ValueError – 在后台不可用时抛出。\\n', '\\n', 'RuntimeError – 在 HCCL 或 NCCL 服务不可用时抛出。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.context import set_context, set_auto_parallel_context\\n', 'from mindspore.communication.management import init, get_local_rank_size\\n', 'set_context(device_target=\"Ascend\")\\n', 'set_auto_parallel_context(device_num=16) # 2 server, each server with 8 NPU.\\n', 'init()\\n', 'local_rank_size = get_local_rank_size()\\n', 'print(\"local_rank_size is: \", local_rank_size)\\n', '\\n', 'classmindspore.communication.destroy_group(group)[源代码]\\n', '注销用户通信组。\\n', '\\n', 'Note\\n', '\\n', 'GPU 版本的MindSpore不支持此方法；\\n', '\\n', '参数 group 不能是 hccl_world_group；\\n', '\\n', 'destroy_group 方法应该在 init 方法之后使用。\\n', '\\n', '参数：\\n', '\\n', 'group (str) - 被注销通信组实例（通常由 create_group 方法创建）的名称。\\n', '\\n', '异常：\\n', '\\n', 'TypeError – 在参数 group 不是字符串时抛出。\\n', '\\n', 'ValueError – 在参数 group 是 hccl_world_group 或后台不可用时抛出。\\n', '\\n', 'RuntimeError – 在 HCCL 或 NCCL 服务不可用时抛出。\\n', '\\n', 'mindspore.communication.HCCL_WORLD_COMM_GROUP\\n', '“hccl_world_group”字符串，指的是由HCCL创建的默认通信组。\\n', '\\n', 'mindspore.communication.NCCL_WORLD_COMM_GROUP\\n', '“nccl_world_group”字符串，指的是由NCCL创建的默认通信组。\\n']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.context.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.context.html", "text_entry": "['mindspore.context\\n', 'MindSpore context，用于配置当前执行环境，包括执行模式、执行后端和其他特性开关。\\n', '\\n', 'mindspore.context.set_context(**kwargs)[源代码]\\n', '设置运行环境的context。\\n', '\\n', '在运行程序之前，应配置context。如果没有配置，默认情况下将根据设备目标进行自动设置。\\n', '\\n', 'Note\\n', '\\n', '设置属性时，必须输入属性名称。\\n', '\\n', '某些配置适用于特定的设备，有关详细信息，请参见下表：\\n', '\\n', '功能分类\\n', '\\n', '配置参数\\n', '\\n', '硬件平台支持\\n', '\\n', '系统配置\\n', '\\n', 'device_id\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'device_target\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'max_device_memory\\n', '\\n', 'GPU/Ascend\\n', '\\n', 'variable_memory_max_size\\n', '\\n', 'Ascend\\n', '\\n', 'mempool_block_size\\n', '\\n', 'GPU/Ascend\\n', '\\n', '调试配置\\n', '\\n', 'save_graphs\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'save_graphs_path\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'enable_dump\\n', '\\n', 'Ascend\\n', '\\n', 'save_dump_path\\n', '\\n', 'Ascend\\n', '\\n', 'enable_profiling\\n', '\\n', 'Ascend\\n', '\\n', 'profiling_options\\n', '\\n', 'Ascend\\n', '\\n', 'print_file_path\\n', '\\n', 'Ascend\\n', '\\n', 'env_config_path\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'precompile_only\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'reserve_class_name_in_scope\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'pynative_synchronize\\n', '\\n', 'GPU/Ascend\\n', '\\n', '执行控制\\n', '\\n', 'mode\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'enable_graph_kernel\\n', '\\n', 'Ascend/GPU\\n', '\\n', 'graph_kernel_flags\\n', '\\n', 'Ascend/GPU\\n', '\\n', 'enable_reduce_precision\\n', '\\n', 'Ascend\\n', '\\n', 'auto_tune_mode\\n', '\\n', 'Ascend\\n', '\\n', 'check_bprop\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'max_call_depth\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'enable_sparse\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'grad_for_scalar\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'enable_compile_cache\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'runtime_num_threads\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'compile_cache_path\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', '参数：\\n', '\\n', 'device_id (int) - 表示目标设备的ID，其值必须在[0, device_num_per_host-1]范围中，且 device_num_per_host 的值不应超过4096。默认值：0。\\n', '\\n', 'device_target (str) - 表示待运行的目标设备，支持’Ascend’、’GPU’和’CPU’。如果未设置此参数，则使用MindSpore包对应的后端设备。\\n', '\\n', 'max_device_memory (str) - 设置设备可用的最大内存。目前，仅在GPU上支持。格式为“xxGB”。默认值：1024GB。实际使用的内存大小是设备的可用内存和 max_device_memory 值中的最小值。\\n', '\\n', 'variable_memory_max_size (str) - 设置可变内存的最大值。默认值：30GB。\\n', '\\n', 'mempool_block_size (str) - 设置PyNative模式下设备内存池的块大小。格式为“xxGB”。默认值：1GB。最小值是1GB。实际使用的内存池块大小是设备的可用内存和 mempool_block_size 值中的最小值。\\n', '\\n', 'save_graphs (bool) - 表示是否保存计算图。默认值：False。当 save_graphs 属性设为True时， save_graphs_path 属性用于设置中间编译图的存储路径。默认情况下，计算图保存在当前目录下。\\n', '\\n', 'save_graphs_path (str) - 表示保存计算图的路径。默认值：”.”。如果指定的目录不存在，系统将自动创建该目录。在分布式训练中，图形将被保存到 save_graphs_path/rank_${rank_id}/ 目录下。 rank_id 为集群中当前设备的ID。\\n', '\\n', 'enable_dump (bool) - 此参数已弃用，将在下一版本中删除。\\n', '\\n', 'save_dump_path (str) - 此参数已弃用，将在下一版本中删除。\\n', '\\n', 'enable_profiling (bool) - 此参数已弃用，将在下一版本中删除。请使用mindspore.profiler.Profiler API。\\n', '\\n', 'profiling_options (str) - 此参数已弃用，将在下一版本中删除。请使用mindspore.profiler.Profiler API。\\n', '\\n', 'print_file_path (str)：该路径用于保存打印数据。使用时 mindspore.ops.print 可以打印输入的张量或字符串信息，使用方法 mindspore.parse_print() 解析保存的文件。如果设置了此参数，打印数据保存到文件，未设置将显示到屏幕。如果保存的文件已经存在，则将添加时间戳后缀到文件中。将数据保存到文件解决了屏幕打印中的数据丢失问题, 如果未设置，将报告错误:”prompt to set the upper absolute path”。\\n', '\\n', 'env_config_path (str) - 通过 context.set_context(env_config_path=”./mindspore_config.json”) 来设置MindSpore环境配置文件路径。\\n', '\\n', '配置Running Data Recorder：\\n', '\\n', 'enable：表示在发生故障时是否启用Running Data Recorder去收集和保存训练中的关键数据。设置为True时，将打开Running Data Recorder。设置为False时，将关闭Running Data Recorder。\\n', '\\n', 'mode：指定在GRAPH_MODE(0)还是PYNATIVE_MODE(1)下运行，两种模式均支持所有后端。默认值：GRAPH_MODE(0)。\\n', '\\n', 'path：设置Running Data Recorder保存数据的路径。当前路径必须是一个绝对路径。\\n', '\\n', '内存重用：\\n', '\\n', 'mem_Reuse：表示内存复用功能是否打开。设置为True时，将打开内存复用功能。设置为False时，将关闭内存复用功能。 有关running data recoder和内存复用配置详细信息，请查看 配置RDR和内存复用。\\n', '\\n', 'precompile_only (bool) - 表示是否仅预编译网络。默认值：False。设置为True时，仅编译网络，而不执行网络。\\n', '\\n', 'reserve_class_name_in_scope (bool) - 表示是否将网络类名称保存到所属ScopeName中。默认值：True。每个节点都有一个ScopeName。子节点的ScopeName是其父节点。如果 reserve_class_name_in_scope 设置为True，则类名将保存在ScopeName中的关键字“net-”之后。例如：\\n', '\\n', 'Default/net-Net1/net-Net2 (reserve_class_name_in_scope=True)\\n', '\\n', 'Default/net/net (reserve_class_name_in_scope=False)\\n', '\\n', 'pynative_synchronize (bool) - 表示是否在PyNative模式下启动设备同步执行。默认值：False。设置为False时，将在设备上异步执行算子。当算子执行出错时，将无法定位特定错误脚本代码的位置。当设置为True时，将在设备上同步执行算子。这将降低程序的执行性能。此时，当算子执行出错时，可以根据错误的调用栈来定位错误脚本代码的位置。\\n', '\\n', 'mode (int) - 表示在GRAPH_MODE(0)或PYNATIVE_MODE(1)模式中的运行。默认值：GRAPH_MODE(0)。GRAPH_MODE或PYNATIVE_MODE可以通过 mode 属性设置，两种模式都支持所有后端。默认模式为GRAPH_MODE。\\n', '\\n', 'enable_graph_kernel (bool) - 表示开启图算融合去优化网络执行性能。默认值：False。如果 enable_graph_kernel 设置为True，则可以启用加速。有关图算融合的详细信息，请查看 使能图算融合 。\\n', '\\n', 'graph_kernel_flags (str) - 图算融合的优化选项，当与enable_graph_kernel冲突时，它的优先级更高。其仅适用于有经验的用户。例如，context.set_context(graph_kernel_flags=”–opt_level=2 –dump_as_text”)。一些常用选项：\\n', '\\n', 'opt_level：设置优化级别。默认值：2。当opt_level的值大于0时，启动图算融合。可选值包括：\\n', '\\n', '0：关闭图算融合。\\n', '\\n', '1：启动算子的基本融合。\\n', '\\n', '2：包括级别1的所有优化，并打开更多的优化，如CSE优化算法、算术简化等。\\n', '\\n', '3：包括级别2的所有优化，并打开更多的优化，如SitchingFusion、ParallelFusion等。在某些场景下，该级别的优化激进且不稳定。使用此级别时要小心。\\n', '\\n', 'dump_as_text：将关键过程的详细信息生成文本文件保存到”graph_kernel_dump”目录里。默认值：False。\\n', '\\n', '有关更多选项，可以参考实现代码。\\n', '\\n', 'enable_reduce_precision (bool) - 表示是否开启降低精度计算。默认值：True。设置为True时，不支持用户指定的精度，且精度将自动更改。设置为False时，如果未指定用例的精度，则会报错并退出。\\n', '\\n', 'auto_tune_mode (str) - 表示算子构建时的自动调整模式，以获得最佳的切分性能。默认值：NO_TUNE。其值必须在[‘RL’, ‘GA’, ‘RL,GA’]范围中。\\n', '\\n', 'RL：强化学习调优。\\n', '\\n', 'GA：遗传算法调优。\\n', '\\n', 'RL，GA：当RL和GA优化同时打开时，工具会根据网络模型中的不同算子类型自动选择RL或GA。RL和GA的顺序没有区别。（自动选择）。\\n', '\\n', '有关启用算子调优工具设置的更多信息，请查看 使能算子调优工具。\\n', '\\n', 'check_bprop (bool) - 表示是否检查反向传播节点，以确保反向传播节点输出的形状(shape)和数据类型与输入参数相同。默认值：False。\\n', '\\n', 'max_call_depth (int) - 指定函数调用的最大深度。其值必须为正整数。默认值：1000。当嵌套Cell太深或子图数量太多时，需要设置 max_call_depth 参数。系统最大堆栈深度应随着 max_call_depth 的调整而设置为更大的值，否则可能会因为系统堆栈溢出而引发 “core dumped” 异常。\\n', '\\n', 'enable_sparse (bool) - 表示是否启用稀疏特征。默认值：False。有关稀疏特征和稀疏张量的详细信息，请查看 稀疏张量。\\n', '\\n', 'grad_for_scalar (bool)： 表示是否获取标量梯度。默认值：False。当 grad_for_scalar 设置为True时，则可以导出函数的标量输入。由于后端目前不支持伸缩操作，所以该接口只支持在前端可推演的简单操作。\\n', '\\n', 'enable_compile_cache (bool) - 表示是否加载或者保存前端编译的图。当 enable_compile_cache 被设置为True时，在第一次执行的过程中，一个硬件无关的编译缓存会被生成并且导出为一个MINDIR文件。当该网络被再次执行时，如果 enable_compile_cache 仍然为True并且网络脚本没有被更改，那么这个编译缓存会被加载。注意目前只支持有限的Python脚本更改的自动检测，这意味着可能有正确性风险。默认值：False。这是一个实验特性，可能会被更改或者删除。\\n', '\\n', 'compile_cache_path (str) - 保存前端图编译缓存的路径。默认值：”.”。如果目录不存在，系统会自动创建这个目录。缓存会被保存到如下目录： compile_cache_path/rank_${rank_id}/ 。 rank_id 是集群上当前设备的ID。\\n', '\\n', 'runtime_num_threads (int) - 运行时线程池的线程数控制。 默认值为30。\\n', '\\n', '异常：\\n', '\\n', 'ValueError：输入key不是上下文中的属性。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import context\\n', 'context.set_context(mode=context.PYNATIVE_MODE)\\n', 'context.set_context(precompile_only=True)\\n', 'context.set_context(device_target=\"Ascend\")\\n', 'context.set_context(device_id=0)\\n', 'context.set_context(save_graphs=True, save_graphs_path=\"./model.ms\")\\n', 'context.set_context(enable_reduce_precision=True)\\n', 'context.set_context(enable_dump=True, save_dump_path=\".\")\\n', 'context.set_context(enable_graph_kernel=True)\\n', 'context.set_context(graph_kernel_flags=\"--opt_level=2 --dump_as_text\")\\n', 'context.set_context(reserve_class_name_in_scope=True)\\n', 'context.set_context(variable_memory_max_size=\"6GB\")\\n', 'context.set_context(enable_profiling=True,\\n', '                    profiling_options=\\'{\"output\":\"/home/data/output\",\"training_trace\":\"on\"}\\')\\n', 'context.set_context(check_bprop=True)\\n', 'context.set_context(max_device_memory=\"3.5GB\")\\n', 'context.set_context(mempool_block_size=\"1GB\")\\n', 'context.set_context(print_file_path=\"print.pb\")\\n', 'context.set_context(enable_sparse=True)\\n', 'context.set_context(max_call_depth=80)\\n', 'context.set_context(env_config_path=\"./env_config.json\")\\n', 'context.set_context(auto_tune_mode=\"GA,RL\")\\n', 'context.set_context(grad_for_scalar=True)\\n', 'context.set_context(enable_compile_cache=True, compile_cache_path=\"./cache.ms\")\\n', 'context.set_context(pynative_synchronize=True)\\n', 'context.set_context(runtime_num_threads=10)\\n', 'mindspore.context.get_context(attr_key)[源代码]\\n', '根据输入key获取context中的属性值。如果该key没有设置，则会获取它们这些的默认值。\\n', '\\n', '参数：\\n', '\\n', 'attr_key (str) - 属性的key。\\n', '\\n', '返回：\\n', '\\n', 'Object，表示给定属性key的值。\\n', '\\n', '异常：\\n', '\\n', 'ValueError：输入key不是context中的属性。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import context\\n', 'context.get_context(\"device_target\")\\n', 'context.get_context(\"device_id\")\\n', 'mindspore.context.set_auto_parallel_context(**kwargs)[源代码]\\n', '配置自动并行，仅在Ascend和GPU上有效。\\n', '\\n', '应在mindspore.communication.init之前配置自动并行。\\n', '\\n', 'Note\\n', '\\n', '配置时，必须输入配置的名称。如果某个程序具有不同并行模式下的任务，需要提前调用reset_auto_parallel_context()为下一个任务设置新的并行模式。若要设置或更改并行模式，必须在创建任何Initializer之前调用接口，否则，在编译网络时，可能会出现RuntimeError。\\n', '\\n', '某些配置适用于特定的并行模式，有关详细信息，请参见下表：\\n', '\\n', 'Common\\n', '\\n', 'AUTO_PARALLEL\\n', '\\n', 'device_num\\n', '\\n', 'gradient_fp32_sync\\n', '\\n', 'global_rank\\n', '\\n', 'loss_repeated_mean\\n', '\\n', 'gradients_mean\\n', '\\n', 'auto_parallel_search_mode\\n', '\\n', 'parallel_mode\\n', '\\n', 'strategy_ckpt_load_file\\n', '\\n', 'all_reduce_fusion_config\\n', '\\n', 'strategy_ckpt_save_file\\n', '\\n', 'enable_parallel_optimizer\\n', '\\n', 'dataset_strategy\\n', '\\n', 'enable_alltoall\\n', '\\n', 'pipeline_stages\\n', '\\n', 'grad_accumulation_step\\n', '\\n', '参数：\\n', '\\n', 'device_num (int) - 表示可用设备的编号，必须在[1,4096]范围中。默认值：1。\\n', '\\n', 'global_rank (int) - 表示全局RANK的ID，必须在[0,4095]范围中。默认值：0。\\n', '\\n', 'gradients_mean (bool) - 表示是否在梯度的 AllReduce后执行平均算子。stand_alone不支持gradients_mean。默认值：False。\\n', '\\n', 'gradient_fp32_sync (bool)：在FP32中运行梯度的 AllReduce。stand_alone、data_parallel和hybrid_parallel不支持gradient_fp32_sync。默认值：True。\\n', '\\n', 'parallel_mode (str) - 有五种并行模式，分别是stand_alone、data_parallel、hybrid_parallel、semi_auto_parallel和auto_parallel。默认值：stand_alone。\\n', '\\n', 'stand_alone：单卡模式。\\n', '\\n', 'data_parallel：数据并行模式。\\n', '\\n', 'hybrid_parallel：手动实现数据并行和模型并行。\\n', '\\n', 'semi_auto_parallel：半自动并行模式。\\n', '\\n', 'auto_parallel：自动并行模式。\\n', '\\n', 'search_mode (str) - 表示有三种策略搜索模式，分别是recursive_programming，dynamic_programming和sharding_propagation。默认值：dynamic_programming。\\n', '\\n', 'recursive_programming：表示双递归搜索模式。\\n', '\\n', 'dynamic_programming：表示动态规划搜索模式。\\n', '\\n', 'sharding_propagation：表示从已配置算子的切分策略传播到所有算子。\\n', '\\n', 'auto_parallel_search_mode (str) - search_modes参数的兼容接口。将在后续的版本中删除。\\n', '\\n', 'parameter_broadcast (bool) - 表示在训练前是否广播参数。在训练之前，为了使所有设备的网络初始化参数值相同，请将设备0上的参数广播到其他设备。不同并行模式下的参数广播不同。在data_parallel模式下，除layerwise_parallel属性为True的参数外，所有参数都会被广播。在hybrid_parallel、semi_auto_parallel和auto_parallel模式下，分段参数不参与广播。默认值：False。\\n', '\\n', 'strategy_ckpt_load_file (str) - 表示用于加载并行策略checkpoint的路径。默认值：’’。\\n', '\\n', 'strategy_ckpt_save_file (str) - 表示用于保存并行策略checkpoint的路径。默认值：’’。\\n', '\\n', 'full_batch (bool) - 如果在auto_parallel模式下加载整个batch数据集，则此参数应设置为True。默认值：False。目前不建议使用该接口，建议使用dataset_strategy来替换它。\\n', '\\n', 'dataset_strategy (Union[str, tuple]) - 表示数据集分片策略。默认值：data_parallel。dataset_strategy=”data_parallel”等于full_batch=False，dataset_strategy=”full_batch”等于full_batch=True。对于通过模型并列策略加载到网络的数据集，如ds_stra ((1, 8)、(1, 8))，需要使用set_auto_parallel_context(dataset_strategy=ds_stra)。\\n', '\\n', 'enable_parallel_optimizer (bool) - 这是一个开发中的特性，它可以为数据并行训练对权重更新计算进行分片，以节省时间和内存。目前，自动和半自动并行模式支持Ascend和GPU中的所有优化器。数据并行模式仅支持Ascend中的 Lamb 和 AdamWeightDecay 。默认值：False。\\n', '\\n', 'enable_alltoall (bool) - 允许在通信期间生成 AllToAll 通信算子的开关。 如果其值为 False，则将由 AllGather 、 Split 和 Concat 等通信算子的组合来代替 AllToAll 。 默认值：False。\\n', '\\n', 'all_reduce_fusion_config (list) - 通过参数索引设置 AllReduce 融合策略。仅支持ReduceOp.SUM和HCCL_WORLD_GROUP/NCCL_WORLD_GROUP。没有默认值。如果不设置，则关闭算子融合。\\n', '\\n', 'pipeline_stages (int) - 设置pipeline并行的阶段信息。这表明了设备如何单独分布在pipeline上。所有的设备将被划分为pipeline_stags个阶段。目前，这只能在启动semi_auto_parallel模式的情况下使用。默认值：1。\\n', '\\n', 'grad_accumulation_step (int) - 在自动和半自动并行模式下设置梯度的累积step。其值应为正整数。默认值：1。\\n', '\\n', 'parallel_optimizer_config (dict) - 用于开启优化器并行后的行为配置。仅在enable_parallel_optimizer=True的时候生效。目前，它支持关键字如下的关键字：\\n', '\\n', 'gradient_accumulation_shard(bool)：设置累积梯度变量是否在数据并行维度上进行切分。开启后，将进一步减小模型的显存占用，但是会在反向计算梯度时引入额外的通信算子（ReduceScatter）。此配置仅在流水线并行训练和梯度累积模式下生效。默认值：True。\\n', '\\n', 'parallel_optimizer_threshold(int)：设置参数切分的阈值。占用内存小于该阈值的参数不做切分。占用内存大小 = shape[0] * … * shape[n] * size(dtype)。该阈值非负。单位： KB。默认值：64。\\n', '\\n', 'comm_fusion (dict) - 用于设置通信算子的融合配置。可以同一类型的通信算子按梯度张量的大小或者顺序分块传输。输入格式为{“通信类型”: {“mode”:str, “config”: None int 或者 list}},每种通信算子的融合配置有两个键：”mode”和”config”。支持以下通信类型的融合类型和配置：\\n', '\\n', 'allreduce: 进行AllReduce算子的通信融合。”mode”包含：”auto”、”size”和”index”。在”auto”模式下，融合的是梯度变量的大小，默认值阈值为”64”MB，”config”对应的值为None。在”size”模式下，需要用户在config的字典中指定梯度大小阈值，这个值必须大于”0”MB。在”mode”为”index”时，它与”all_reduce_fusion_config”相同，用户需要给”config”传入一个列表，里面每个值表示梯度的索引。\\n', '\\n', 'allgather: 进行AllGather算子的通信融合。”mode”包含：”auto”、”size”。”auto” 和 “size”模式的配置方式与AllReduce相同。\\n', '\\n', 'reducescatter: 进行ReduceScatter算子的通信融合。”mode”包含：”auto”、”size”。”auto” 和 “size”模式的配置方式与AllReduce相同。\\n', '\\n', '异常：\\n', '\\n', 'ValueError：输入key不是自动并行上下文中的属性。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import context\\n', 'context.set_auto_parallel_context(device_num=8)\\n', 'context.set_auto_parallel_context(global_rank=0)\\n', 'context.set_auto_parallel_context(gradients_mean=True)\\n', 'context.set_auto_parallel_context(gradient_fp32_sync=False)\\n', 'context.set_auto_parallel_context(parallel_mode=\"auto_parallel\")\\n', 'context.set_auto_parallel_context(search_mode=\"dynamic_programming\")\\n', 'context.set_auto_parallel_context(auto_parallel_search_mode=\"dynamic_programming\")\\n', 'context.set_auto_parallel_context(parameter_broadcast=False)\\n', 'context.set_auto_parallel_context(strategy_ckpt_load_file=\"./strategy_stage1.ckpt\")\\n', 'context.set_auto_parallel_context(strategy_ckpt_save_file=\"./strategy_stage1.ckpt\")\\n', 'context.set_auto_parallel_context(dataset_strategy=((1, 8), (1, 8)))\\n', 'context.set_auto_parallel_context(enable_parallel_optimizer=False)\\n', 'context.set_auto_parallel_context(enable_alltoall=False)\\n', 'context.set_auto_parallel_context(all_reduce_fusion_config=[8, 160])\\n', 'context.set_auto_parallel_context(pipeline_stages=2)\\n', 'parallel_config = {\"gradient_accumulation_shard\": True, \"parallel_optimizer_threshold\": 24}\\n', 'context.set_auto_parallel_context(parallel_optimizer_config=parallel_config, enable_parallel_optimizer=True)\\n', 'config = {\"allreduce\": {\"mode\": \"size\", \"config\": 32}, \"allgather\": {\"mode\": \"size\", \"config\": 32}}\\n', 'context.set_auto_parallel_context(comm_fusion=config)\\n', 'mindspore.context.get_auto_parallel_context(attr_key)[源代码]\\n', '根据key获取自动并行的配置。\\n', '\\n', '参数：\\n', '\\n', 'attr_key (str) - 配置的key。\\n', '\\n', '返回：\\n', '\\n', '根据key返回配置的值。\\n', '\\n', '异常：\\n', '\\n', 'ValueError：输入key不在自动并行的配置列表中。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import context\\n', 'parallel_mode = context.get_auto_parallel_context(\"parallel_mode\")\\n', 'dataset_strategy = context.get_auto_parallel_context(\"dataset_strategy\")\\n', 'mindspore.context.reset_auto_parallel_context()[源代码]\\n', '重置自动并行的配置为默认值。\\n', '\\n', 'device_num：1。\\n', '\\n', 'global_rank：0。\\n', '\\n', 'gradients_mean：False。\\n', '\\n', 'gradient_fp32_sync：True。\\n', '\\n', 'parallel_mode：’stand_alone’。\\n', '\\n', 'auto_parallel_search_mode：’dynamic_programming’。\\n', '\\n', 'parameter_broadcast：False。\\n', '\\n', 'strategy_ckpt_load_file：’’。\\n', '\\n', 'strategy_ckpt_save_file：’’。\\n', '\\n', 'full_batch：False。\\n', '\\n', 'enable_parallel_optimizer：False。\\n', '\\n', 'enable_alltoall: False。\\n', '\\n', 'pipeline_stages：1。\\n', '\\n', 'classmindspore.context.ParallelMode[源代码]\\n', '并行模式。\\n', '\\n', '有五种并行模式，分别是STAND_ALONE、DATA_PARALLEL、HYBRID_PARALLEL、SEMI_AUTO_PARALLEL和AUTO_PARALLEL。默认值：STAND_ALONE。\\n', '\\n', 'STAND_ALONE：单卡模式。\\n', '\\n', 'DATA_PARALLEL：数据并行模式。\\n', '\\n', 'HYBRID_PARALLEL：手动实现数据并行和模型并行。\\n', '\\n', 'SEMI_AUTO_PARALLEL：半自动并行模式。\\n', '\\n', 'AUTO_PARALLEL：自动并行模式。\\n', '\\n', 'mindspore.context.set_ps_context(**kwargs)[源代码]\\n', '设置参数服务器训练模式的上下文。\\n', '\\n', 'Note\\n', '\\n', '需要给参数服务器训练模式设置其他的环境变量。些环境变量如下所示：\\n', '\\n', 'MS_SERVER_NUM：表示参数服务器数量。\\n', '\\n', 'MS_WORKER_NUM：表示工作进程数量。\\n', '\\n', 'MS_SCHED_HOST：表示调度器IP地址。\\n', '\\n', 'MS_SCHED_PORT：表示调度器开启的监听端口。\\n', '\\n', 'MS_ROLE：表示进程角色，角色列表如下：\\n', '\\n', 'MS_SCHED：表示调度器。\\n', '\\n', 'MS_WORKER：表示工作进程。\\n', '\\n', 'MS_PSERVER/MS_SERVER：表示参数服务器。\\n', '\\n', '参数：\\n', '\\n', 'enable_ps (bool) - 表示是否启用参数服务器训练模式。只有在enable_ps设置为True后，环境变量才会生效。默认值：False。\\n', '\\n', 'config_file_path (string) - 配置文件路径，用于容灾恢复等, 目前参数服务器训练模式仅支持Server容灾。默认值：’’。\\n', '\\n', 'scheduler_manage_port (int) - 调度器HTTP端口，对外开放用于接收和处理用户扩容/缩容等请求。默认值：11202。\\n', '\\n', 'enable_ssl (bool) - 设置是否打开SSL认证。默认值：True。\\n', '\\n', 'client_password (str) - 用于解密客户端证书密钥的密码。默认值：’’。\\n', '\\n', 'server_password (str) - 用于解密服务端证书密钥的密码。默认值：’’。\\n', '\\n', '异常：\\n', '\\n', 'ValueError：输入key不是参数服务器训练模式上下文中的属性。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import context\\n', \"context.set_ps_context(enable_ps=True, enable_ssl=True, client_password='123456', server_password='123456')\\n\", 'mindspore.context.get_ps_context(attr_key)[源代码]\\n', '根据key获取参数服务器训练模式上下文中的属性值。\\n', '\\n', '参数：\\n', '\\n', 'attr_key (str) - 属性的key。\\n', '\\n', 'enable_ps (bool)：表示是否启用参数服务器训练模式。默认值：False。\\n', '\\n', 'config_file_path (string)：配置文件路径，用于容灾恢复等。默认值：’’。\\n', '\\n', 'scheduler_manage_port (int)：调度器HTTP端口，对外开放用于接收和处理用户扩容/缩容等请求。默认值：11202。\\n', '\\n', 'enable_ssl (bool)：设置是否打开SSL认证。默认值：False。\\n', '\\n', 'client_password (str)：用于解密客户端证书密钥的密码。默认值：’’。\\n', '\\n', 'server_password (str)：用于解密服务端证书密钥的密码。默认值：’’。\\n', '\\n', '返回：\\n', '\\n', '根据key返回属性值。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 输入key不是参数服务器训练模式上下文中的属性。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import context\\n', 'context.get_ps_context(\"enable_ps\")\\n', 'mindspore.context.reset_ps_context()[源代码]\\n', '将参数服务器训练模式上下文中的属性重置为默认值。各字段的含义及其默认值见’set_ps_context’接口。']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.dataset.audio.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.dataset.audio.html", "text_entry": "['mindspore.dataset.audio\\n', '此模块用于音频数据增强，包括 transforms 和 utils 两个子模块。 transforms 是一个高性能音频数据增强模块，支持常见的音频数据增强操作。 utils 提供了一些音频处理的工具方法。\\n', '\\n', 'API样例中常用的导入模块如下：\\n', '\\n', 'import mindspore.dataset as ds\\n', 'import mindspore.dataset.audio.transforms as audio\\n', '常用数据处理术语说明如下：\\n', '\\n', 'TensorOperation，所有C++实现的数据处理操作的基类。\\n', '\\n', 'AudioTensorOperation，所有音频数据处理操作的基类，派生自TensorOperation。\\n', '\\n', 'mindspore.dataset.audio.transforms\\n', 'mindspore.dataset.audio.transforms.AllpassBiquad\\n', '\\n', '给音频波形施加双极点全通滤波器，其中心频率和带宽由入参指定。\\n', '\\n', 'mindspore.dataset.audio.transforms.AmplitudeToDB\\n', '\\n', '将输入音频从振幅/功率标度转换为分贝标度。\\n', '\\n', 'mindspore.dataset.audio.transforms.Angle\\n', '\\n', '计算复数序列的角度。\\n', '\\n', 'mindspore.dataset.audio.transforms.BandBiquad\\n', '\\n', '给音频波形施加双极点带通滤波器。\\n', '\\n', 'mindspore.dataset.audio.transforms.BandpassBiquad\\n', '\\n', '给音频波形施加双极点巴特沃斯（Butterworth）带通滤波器。\\n', '\\n', 'mindspore.dataset.audio.transforms.BandrejectBiquad\\n', '\\n', '给音频波形施加双极点巴特沃斯（Butterworth）带阻滤波器。\\n', '\\n', 'mindspore.dataset.audio.transforms.BassBiquad\\n', '\\n', '给音频波形施加低音控制效果，即双极点低频搁架滤波器。\\n', '\\n', 'mindspore.dataset.audio.transforms.ComplexNorm\\n', '\\n', '计算复数序列的范数。\\n', '\\n', 'mindspore.dataset.audio.transforms.Contrast\\n', '\\n', '给音频波形施加对比度增强效果。\\n', '\\n', 'mindspore.dataset.audio.transforms.FrequencyMasking\\n', '\\n', '给音频波形施加频域掩码。\\n', '\\n', 'mindspore.dataset.audio.transforms.LowpassBiquad\\n', '\\n', '给音频波形施加双极点低通滤波器。\\n', '\\n', 'mindspore.dataset.audio.transforms.TimeMasking\\n', '\\n', '给音频波形施加时域掩码。\\n', '\\n', 'mindspore.dataset.audio.transforms.TimeStretch\\n', '\\n', '以给定的比例拉伸音频短时傅里叶（Short Time Fourier Transform, STFT）频谱的时域，但不改变音频的音高。\\n', '\\n', 'mindspore.dataset.audio.utils\\n', 'mindspore.dataset.audio.utils.ScaleType\\n', '\\n', '音频标度枚举类。']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.dataset.config.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.dataset.config.html", "text_entry": "['mindspore.dataset.config\\n', 'config模块能够设置或获取数据处理的全局配置参数。\\n', '\\n', 'API示例所需模块的导入代码如下：\\n', '\\n', 'import mindspore.dataset as ds\\n', 'mindspore.dataset.config.set_sending_batches(batch_num)\\n', '在昇腾设备中使用sink_mode=True进行训练时，设置默认的发送批次。\\n', '\\n', '参数：\\n', '\\n', 'batch_num (int) - 表示总的发送批次。当设置了 batch_num 时，它将会等待，除非增加发送批次。默认值为0，表示将发送数据集中的所有批次。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - batch_num 不是int类型。\\n', '\\n', '样例：\\n', '\\n', '# Set a new global configuration value for the sending batches\\n', 'ds.config.set_sending_batches(10)\\n', 'mindspore.dataset.config.load(file)\\n', '根据文件内容加载项目配置文件。\\n', '\\n', '参数：\\n', '\\n', 'file (str) - 表示待加载的配置文件的路径。\\n', '\\n', '异常：\\n', '\\n', 'RuntimeError - 文件无效，解析失败。\\n', '\\n', '样例：\\n', '\\n', '# Set new default configuration according to values in the configuration file.\\n', '# example config file:\\n', '# {\\n', '#     \"logFilePath\": \"/tmp\",\\n', '#     \"numParallelWorkers\": 4,\\n', '#     \"seed\": 5489,\\n', '#     \"monitorSamplingInterval\": 30\\n', '# }\\n', 'config_file = \"/path/to/config/file\"\\n', 'ds.config.load(config_file)\\n', 'mindspore.dataset.config.set_seed(seed)\\n', '设置随机种子，产生固定的随机数来达到确定的结果。\\n', '\\n', 'Note\\n', '\\n', '此函数在Python随机库和numpy.random库中设置种子，以便随机进行确定性Python增强。此函数应与创建的每个迭代器一起调用，以重置随机种子。\\n', '\\n', '参数：\\n', '\\n', 'seed (int) - 表示随机数量的种子。该参数用于生成确定性随机数。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - seed 不是int类型。\\n', '\\n', 'ValueError - seed 小于0或 seed 大于 UINT32_MAX(4294967295) 时， seed 无效。\\n', '\\n', '样例：\\n', '\\n', '# Set a new global configuration value for the seed value.\\n', '# Operations with randomness will use the seed value to generate random values.\\n', 'ds.config.set_seed(1000)\\n', 'mindspore.dataset.config.get_seed()\\n', '获取随机数的种子。如果随机数的种子已设置，则返回设置的值，否则将返回 std::mt19937::default_seed 这个默认种子值。\\n', '\\n', '返回：\\n', '\\n', 'int，表示种子的随机数量。\\n', '\\n', '样例：\\n', '\\n', '# Get the global configuration of seed.\\n', '# If set_seed() is never called before, the default value(std::mt19937::default_seed) will be returned.\\n', 'seed = ds.config.get_seed()\\n', 'mindspore.dataset.config.set_prefetch_size(size)\\n', '设置管道中线程的队列容量。\\n', '\\n', '参数：\\n', '\\n', 'size (int) - 表示缓存队列的长度。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - size 不是int类型。\\n', '\\n', 'ValueError - size 小于等于0或 size 大于 INT32_MAX(2147483647) 时，线程的队列容量无效。\\n', '\\n', 'Note\\n', '\\n', '用于预取的总内存可能会随着工作线程数量的增加而快速增长，所以当工作线程数量大于4时，每个工作线程的预取大小将减少。 每个工作线程在运行时预取大小将是 prefetchsize * (4 / num_parallel_workers )。\\n', '\\n', '样例：\\n', '\\n', '# Set a new global configuration value for the prefetch size.\\n', 'ds.config.set_prefetch_size(1000)\\n', 'mindspore.dataset.config.get_prefetch_size()\\n', '获取数据处理管道的输出缓存队列长度。 如果 set_prefetch_size 方法未被调用，那么将会返回默认值16。\\n', '\\n', '返回：\\n', '\\n', 'int，表示预取的总行数。\\n', '\\n', '样例：\\n', '\\n', '# Get the global configuration of prefetch size.\\n', '# If set_prefetch_size() is never called before, the default value(16) will be returned.\\n', 'prefetch_size = ds.config.get_prefetch_size()\\n', 'mindspore.dataset.config.set_num_parallel_workers(num)\\n', '为并行工作线程数量设置新的全局配置默认值。 此设置会影响所有数据集操作的并行性。\\n', '\\n', '参数：\\n', '\\n', 'num (int) - 表示并行工作线程的数量，用作为每个数据集操作的默认值。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - num 不是int类型。\\n', '\\n', 'ValueError - num 小于等于0或 num 大于 INT32_MAX(2147483647) 时，并行工作线程数量设置无效。\\n', '\\n', '样例：\\n', '\\n', '# Set a new global configuration value for the number of parallel workers.\\n', '# Now parallel dataset operators will run with 8 workers.\\n', 'ds.config.set_num_parallel_workers(8)\\n', 'mindspore.dataset.config.get_num_parallel_workers()\\n', '获取并行工作线程数量的全局配置。 这是作用于每个操作的并行工作线程数量的值。\\n', '\\n', '返回：\\n', '\\n', 'int，表示每个操作中默认的并行工作线程的数量。\\n', '\\n', '样例：\\n', '\\n', '# Get the global configuration of parallel workers.\\n', '# If set_num_parallel_workers() is never called before, the default value(8) will be returned.\\n', 'num_parallel_workers = ds.config.get_num_parallel_workers()\\n', 'mindspore.dataset.config.set_numa_enable(numa_enable)\\n', '设置NUMA的默认状态为启动状态。如果 numa_enable 为True，则需要确保安装了 NUMA库 。\\n', '\\n', '参数：\\n', '\\n', 'numa_enable (bool) - 表示是否使用NUMA绑定功能。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - numa_enable 不是bool类型。\\n', '\\n', '样例：\\n', '\\n', '# Set a new global configuration value for the state of numa enabled.\\n', '# Now parallel dataset operators will run with numa bind function\\n', 'ds.config.set_numa_enable(True)\\n', 'mindspore.dataset.config.get_numa_enable()\\n', '获取NUMA的启动/禁用状态。 该状态将用于所有进程。\\n', '\\n', '返回：\\n', '\\n', 'bool，表示NUMA的启动状态。\\n', '\\n', '样例：\\n', '\\n', '# Get the global configuration of numa.\\n', 'numa_state = ds.config.get_numa_enable()\\n', 'mindspore.dataset.config.set_monitor_sampling_interval(interval)\\n', '设置监测采样的默认间隔时间（毫秒）。\\n', '\\n', '参数：\\n', '\\n', 'interval (int) - 表示用于性能监测采样的间隔时间（毫秒）。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - interval 不是int类型。\\n', '\\n', 'ValueError - interval 小于等于0或 interval 大于 INT32_MAX(2147483647) 时， interval 无效。\\n', '\\n', '样例：\\n', '\\n', '# Set a new global configuration value for the monitor sampling interval.\\n', 'ds.config.set_monitor_sampling_interval(100)\\n', 'mindspore.dataset.config.get_monitor_sampling_interval()\\n', '获取性能监控采样时间间隔的全局配置。 如果 set_monitor_sampling_interval 方法未被调用，那么将会返回默认值1000。\\n', '\\n', '返回：\\n', '\\n', 'int，表示性能监控采样间隔时间（毫秒）。\\n', '\\n', '样例：\\n', '\\n', '# Get the global configuration of monitor sampling interval.\\n', '# If set_monitor_sampling_interval() is never called before, the default value(1000) will be returned.\\n', 'sampling_interval = ds.config.get_monitor_sampling_interval()\\n', 'mindspore.dataset.config.set_callback_timeout(timeout)\\n', '为 mindspore.dataset.WaitedDSCallback 设置的默认超时时间（秒）。\\n', '\\n', '参数：\\n', '\\n', 'timeout (int) - 表示在出现死锁情况下，用于结束 mindspore.dataset.WaitedDSCallback 中等待的超时时间（秒）。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - timeout 不是int类型。\\n', '\\n', 'ValueError - timeout 小于等于0或 timeout 大于 INT32_MAX(2147483647) 时 timeout 无效。\\n', '\\n', '样例：\\n', '\\n', '# Set a new global configuration value for the timeout value.\\n', 'ds.config.set_callback_timeout(100)\\n', 'mindspore.dataset.config.get_callback_timeout()\\n', '获取 mindspore.dataset.WaitedDSCallback 的默认超时时间。 如果出现死锁，等待的函数将在超时时间结束后退出。\\n', '\\n', '返回：\\n', '\\n', 'int，表示在出现死锁情况下，用于结束 mindspore.dataset.WaitedDSCallback 中的等待函数的超时时间（秒）。\\n', '\\n', '样例：\\n', '\\n', '# Get the global configuration of callback timeout.\\n', '# If set_callback_timeout() is never called before, the default value(60) will be returned.\\n', 'callback_timeout = ds.config.get_callback_timeout()\\n', 'mindspore.dataset.config.set_auto_num_workers(enable)\\n', '自动为每个数据集操作设置并行线程数量（默认情况下，此功能关闭）。\\n', '\\n', '如果启用该功能，将自动调整每个数据集操作中的并行线程数量，这可能会覆盖用户通过脚本定义的并行线程数量或通过ds.config.set_num_parallel_workers()设置的默认值（如果用户未传递任何内容）。\\n', '\\n', '目前，此函数仅针对具有per_batch_map（batch中的运行映射）的YOLOv3数据集进行了优化。 此功能旨在为每个操作的优化线程数量分配一个基础值。 并行线程数有所调整的数据集操作将会被记录。\\n', '\\n', '参数：\\n', '\\n', 'enable (bool) - 表示是否启用自动设置线程数量的特性。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - enable 不是bool类型。\\n', '\\n', '样例：\\n', '\\n', '# Enable auto_num_worker feature, this might override the num_parallel_workers passed in by user\\n', 'ds.config.set_auto_num_workers(True)\\n', 'mindspore.dataset.config.get_auto_num_workers()\\n', '获取当前是否开启自动线程调整。\\n', '\\n', '返回：\\n', '\\n', 'bool，表示是否开启自动线程调整。\\n', '\\n', '样例：\\n', '\\n', '# Get the global configuration of auto number worker feature.\\n', 'flag = ds.config.get_auto_num_workers()\\n', 'mindspore.dataset.config.set_enable_shared_mem(enable)\\n', '设置共享内存标志的是否启用。如果 shared_mem_enable 为True，则使用共享内存队列将数据传递给为数据集操作而创建的进程，而这些数据集操作将设置 python_multiprocessing 为True。\\n', '\\n', 'Note\\n', '\\n', 'Windows和MacOS平台尚不支持 set_enable_shared_mem 。\\n', '\\n', '参数：\\n', '\\n', 'enable (bool) - 表示当 python_multiprocessing 为True时，是否在数据集操作中使用共享内存。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - enable 不是bool类型。\\n', '\\n', '样例：\\n', '\\n', '# Enable shared memory feature to improve the performance of Python multiprocessing.\\n', 'ds.config.set_enable_shared_mem(True)\\n', 'mindspore.dataset.config.get_enable_shared_mem()\\n', '获取当前是否开启共享内存。\\n', '\\n', 'Note\\n', '\\n', 'Windows和MacOS平台尚不支持 get_enable_shared_mem 。\\n', '\\n', '返回：\\n', '\\n', 'bool，表示是否启用共享内存。\\n', '\\n', '样例：\\n', '\\n', '# Get the flag of shared memory feature.\\n', 'shared_mem_flag = ds.config.get_enable_shared_mem()\\n', 'mindspore.dataset.config.set_enable_autotune(enable, filepath_prefix=None)\\n', '设置是否开启自动数据加速。默认情况下不开启自动数据加速。\\n', '\\n', '自动数据加速用于在训练过程中根据环境资源的负载，自动调整数据处理管道全局配置，提高数据处理的速度。\\n', '\\n', '可以通过设置 json_filepath 将优化后的全局配置保存为JSON文件，以便后续复用。\\n', '\\n', '参数：\\n', '\\n', 'enable (bool) - 是否开启自动数据加速。\\n', '\\n', 'filepath_prefix (str，可选) - 优化后的全局配置的保存路径+文件前缀。多卡环境时，设备ID号与JSON扩展名会自动添加到 filepath_prefix 参数后面作为完整的文件路径，单卡默认设备ID号为0。例如，设置 filepath_prefix=”/path/to/some/dir/prefixname” ，设备ID为1的训练进程 生成的调优文件将被命名为 /path/to/some/dir/prefixname_1.json 。默认值：None，表示不保存配置文件，但可以通过INFO日志查看调优配置。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - 当 enable 的类型不为bool。\\n', '\\n', 'TypeError - 当 json_filepath 的类型不为str。\\n', '\\n', 'RuntimeError - 当 json_filepath 字符长度为0。\\n', '\\n', 'RuntimeError - 当 json_filepath 为目录。\\n', '\\n', 'RuntimeError - 当 json_filepath 路径不存在。\\n', '\\n', 'RuntimeError - 当 json_filepath 没有写入权限。\\n', '\\n', 'Note\\n', '\\n', '当 enable 为 False 时，json_filepath 值将会被忽略。\\n', '\\n', '生成的JSON文件可以通过 mindspore.dataset.deserialize 进行加载，得到调优后的数据处理管道。\\n', '\\n', '生成的JSON文件内容示例如下，”remark”字段将给出结论表明数据处理管道是否进行了调整，”summary”字段将展示数据处理管道的调优配置。 用户可以根据调优结果修改代码脚本。\\n', '\\n', '{\\n', '    \"remark\": \"The following file has been auto-generated by the Dataset AutoTune.\",\\n', '    \"summary\": [\\n', '        \"CifarOp(ID:5)       (num_parallel_workers: 2, prefetch_size:64)\",\\n', '        \"MapOp(ID:4)         (num_parallel_workers: 2, prefetch_size:64)\",\\n', '        \"MapOp(ID:3)         (num_parallel_workers: 2, prefetch_size:64)\",\\n', '        \"BatchOp(ID:2)       (num_parallel_workers: 8, prefetch_size:64)\"\\n', '    ],\\n', '    \"tree\": {\\n', '        ...\\n', '    }\\n', '}\\n', '样例：\\n', '\\n', '# enable AutoTune and save optimized data pipeline configuration\\n', 'ds.config.set_enable_autotune(True, \"/path/to/autotune_out.json\")\\n', '\\n', '# enable AutoTune\\n', 'ds.config.set_enable_autotune(True)\\n', 'mindspore.dataset.config.get_enable_autotune()\\n', '获取当前是否开启自动数据加速。\\n', '\\n', '返回：\\n', '\\n', 'bool，表示是否开启自动数据加速。\\n', '\\n', '样例：\\n', '\\n', '# get the state of AutoTune\\n', 'autotune_flag = ds.config.get_enable_autotune()\\n', 'mindspore.dataset.config.set_autotune_interval(interval)\\n', '设置自动数据加速的配置调整step间隔。\\n', '\\n', '默认设置为0，将在每个epoch结束后调整配置；否则，将每隔 interval 个step调整一次配置。\\n', '\\n', '参数：\\n', '\\n', 'interval (int) - 配置调整的step间隔。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - 当 interval 类型不为int。\\n', '\\n', 'ValueError - 当 interval 的值小于零。\\n', '\\n', '样例：\\n', '\\n', '# set a new interval for AutoTune\\n', 'ds.config.set_autotune_interval(30)\\n', 'mindspore.dataset.config.get_autotune_interval()\\n', '获取当前自动数据加速的配置调整step间隔。\\n', '\\n', '返回：\\n', '\\n', 'int，自动数据加速的配置调整step间隔。\\n', '\\n', '样例：\\n', '\\n', '# get the global configuration of the autotuning interval\\n', 'autotune_interval = ds.config.get_autotune_interval()\\n', 'mindspore.dataset.config.set_auto_offload(offload)\\n', '设置是否开启数据异构加速。\\n', '\\n', '数据异构加速可以自动将数据处理的部分运算分配到不同的异构硬件（GPU或Ascend）上，以提高数据处理的速度。\\n', '\\n', '参数：\\n', '\\n', 'offload (bool) - 是否开启数据异构加速。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - 当 offload 的类型不为bool。\\n', '\\n', '样例：\\n', '\\n', '# Enable automatic offload feature\\n', 'ds.config.set_auto_offload(True)\\n', 'mindspore.dataset.config.get_auto_offload()\\n', '获取当前是否开启数据异构加速。\\n', '\\n', '返回：\\n', '\\n', 'bool，表示是否开启数据异构加速。\\n', '\\n', 'mindspore.dataset.config.set_enable_watchdog(enable)\\n', '设置watchdog Python线程是否启用。默认情况下，watchdog Python线程是启用的。watchdog Python线程负责清理卡死或假死的子进程。\\n', '\\n', '参数：\\n', '\\n', 'enable (bool) - 是否开启watchdog Python线程。默认情况下，watchdog Python线程是启用的。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - enable 不是bool类型。\\n', '\\n', '样例：\\n', '\\n', '# Set a new global configuration value for the state of watchdog Python thread as enabled.\\n', 'ds.config.set_enable_watchdog(True)\\n', 'mindspore.dataset.config.get_enable_watchdog()\\n', '获取当前是否开启watchdog Python线程。默认初始状态是开启。\\n', '\\n', '返回：\\n', '\\n', 'bool，表示是否开启watchdog Python线程。\\n', '\\n', '样例：\\n', '\\n', '# Get the global configuration of watchdog Python thread.\\n', 'watchdog_state = ds.config.get_enable_watchdog()\\n', 'mindspore.dataset.config.set_multiprocessing_timeout_interval(interval)\\n', '设置在多进程/多线程下，主进程/主线程获取数据超时时，告警日志打印的默认时间间隔（秒）。\\n', '\\n', '参数：\\n', '\\n', 'interval (int) - 表示多进程/多线程下，主进程/主线程获取数据超时时，告警日志打印的时间间隔（秒）。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - interval 不是int类型。\\n', '\\n', 'ValueError - interval 小于等于0或 interval 大于 INT32_MAX(2147483647) 时， interval 无效。\\n', '\\n', '样例：\\n', '\\n', '# Set a new global configuration value for multiprocessing/multithreading timeout when getting data.\\n', 'ds.config.set_multiprocessing_timeout_interval(300)\\n', 'mindspore.dataset.config.get_multiprocessing_timeout_interval()\\n', '获取在多进程/多线程下，主进程/主线程获取数据超时时，告警日志打印的时间间隔的全局配置。\\n', '\\n', '返回：\\n', '\\n', 'int，表示多进程/多线程下，主进程/主线程获取数据超时时，告警日志打印的时间间隔（默认300秒）。\\n', '\\n', '样例：\\n', '\\n', '# Get the global configuration of multiprocessing/multithreading timeout when main process/thread gets data\\n', '# from subprocesses/child threads. If set_multiprocessing_timeout_interval() is never called before, the\\n', '# default value(300) will be returned.\\n', 'multiprocessing_timeout_interval = ds.config.get_multiprocessing_timeout_interval()']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.dataset.text.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.dataset.text.html", "text_entry": "['mindspore.dataset.text\\n', '此模块用于文本数据增强，包括 transforms 和 utils 两个子模块。\\n', '\\n', 'transforms 是一个高性能文本数据增强模块，支持常见的文本数据增强处理。\\n', '\\n', 'utils 提供了一些文本处理的工具方法。\\n', '\\n', '在API示例中，常用的模块导入方法如下：\\n', '\\n', 'import mindspore.dataset as ds\\n', 'from mindspore.dataset import text\\n', '常用数据处理术语说明如下：\\n', '\\n', 'TensorOperation，所有C++实现的数据处理操作的基类。\\n', '\\n', 'TextTensorOperation，所有文本数据处理操作的基类，派生自TensorOperation。\\n', '\\n', 'mindspore.dataset.text.transforms\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '说明\\n', '\\n', 'mindspore.dataset.text.transforms.BasicTokenizer\\n', '\\n', '按照指定规则对输入的UTF-8编码字符串进行分词。\\n', '\\n', 'Windows平台尚不支持 BasicTokenizer\\n', '\\n', 'mindspore.dataset.text.transforms.BertTokenizer\\n', '\\n', '使用Bert分词器对字符串进行分词。\\n', '\\n', 'Windows平台尚不支持 BertTokenizer\\n', '\\n', 'mindspore.dataset.text.transforms.CaseFold\\n', '\\n', '将UTF-8编码字符串中的字符规范化为小写，相比 str.lower() 支持更多字符。\\n', '\\n', 'Windows平台尚不支持 CaseFold\\n', '\\n', 'mindspore.dataset.text.transforms.JiebaTokenizer\\n', '\\n', '使用Jieba分词器对中文字符串进行分词。\\n', '\\n', '必须保证隐式马尔科夫模型分词（HMMSEgment）和最大概率法分词（MPSegment）所使用的词典文件的完整性\\n', '\\n', 'mindspore.dataset.text.transforms.Lookup\\n', '\\n', '根据词表，将分词标记(token)映射到其索引值(id)。\\n', '\\n', 'mindspore.dataset.text.transforms.Ngram\\n', '\\n', '从1-D的字符串生成N-gram。\\n', '\\n', 'mindspore.dataset.text.transforms.NormalizeUTF8\\n', '\\n', '对UTF-8编码的字符串进行规范化处理。\\n', '\\n', 'Windows平台尚不支持 NormalizeUTF8\\n', '\\n', 'mindspore.dataset.text.transforms.PythonTokenizer\\n', '\\n', '使用用户自定义的分词器对输入字符串进行分词。\\n', '\\n', 'mindspore.dataset.text.transforms.RegexReplace\\n', '\\n', '根据正则表达式对UTF-8编码格式的字符串内容进行正则替换。\\n', '\\n', 'Windows平台尚不支持 RegexReplace\\n', '\\n', 'mindspore.dataset.text.transforms.RegexTokenizer\\n', '\\n', '根据正则表达式对字符串进行分词。\\n', '\\n', 'Windows平台尚不支持 RegexTokenizer\\n', '\\n', 'mindspore.dataset.text.transforms.SentencePieceTokenizer\\n', '\\n', '使用SentencePiece分词器对字符串进行分词。\\n', '\\n', 'mindspore.dataset.text.transforms.SlidingWindow\\n', '\\n', '在输入数据的某个维度上进行滑窗切分处理，当前仅支持处理1-D的Tensor。\\n', '\\n', 'mindspore.dataset.text.transforms.ToNumber\\n', '\\n', '将字符串的每个元素转换为数字。\\n', '\\n', 'mindspore.dataset.text.transforms.TruncateSequencePair\\n', '\\n', '截断一对 1-D 字符串的内容，使其总长度小于给定长度。\\n', '\\n', 'mindspore.dataset.text.transforms.UnicodeCharTokenizer\\n', '\\n', '使用Unicode分词器将字符串分词为Unicode字符。\\n', '\\n', 'mindspore.dataset.text.transforms.UnicodeScriptTokenizer\\n', '\\n', '使用UnicodeScript分词器对UTF-8编码的字符串进行分词。\\n', '\\n', 'Windows平台尚不支持 UnicodeScriptTokenizer\\n', '\\n', 'mindspore.dataset.text.transforms.WhitespaceTokenizer\\n', '\\n', '基于ICU4C定义的空白字符（’ ‘, ‘\\\\t’, ‘\\\\r’, ‘\\\\n’）对输入的UTF-8字符串进行分词。\\n', '\\n', 'Windows平台尚不支持 WhitespaceTokenizer\\n', '\\n', 'mindspore.dataset.text.transforms.WordpieceTokenizer\\n', '\\n', '将输入的字符串切分为子词。\\n', '\\n', 'mindspore.dataset.text.utils\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '说明\\n', '\\n', 'mindspore.dataset.text.JiebaMode\\n', '\\n', 'mindspore.dataset.text.transforms.JiebaTokenizer 的枚举值。\\n', '\\n', 'mindspore.dataset.text.NormalizeForm\\n', '\\n', 'Unicode规范化模式 枚举类。\\n', '\\n', 'mindspore.dataset.text.SentencePieceModel\\n', '\\n', 'SentencePiece分词方法的枚举类。\\n', '\\n', 'mindspore.dataset.text.SentencePieceVocab\\n', '\\n', '用于执行分词的SentencePiece对象。\\n', '\\n', 'mindspore.dataset.text.SPieceTokenizerLoadType\\n', '\\n', 'mindspore.dataset.text.transforms.SentencePieceTokenizer 加载类型的枚举值。\\n', '\\n', 'mindspore.dataset.text.SPieceTokenizerOutType\\n', '\\n', 'mindspore.dataset.text.transforms.SentencePieceTokenizer 输出类型的枚举值。\\n', '\\n', 'mindspore.dataset.text.to_str\\n', '\\n', '基于 encoding 字符集对每个元素进行解码，借此将 bytes 的NumPy数组转换为 string 的数组。\\n', '\\n', 'mindspore.dataset.text.to_bytes\\n', '\\n', '基于 encoding 字符集对每个元素进行编码，将 string 的NumPy数组转换为 bytes 的数组。\\n', '\\n', 'mindspore.dataset.text.Vocab\\n', '\\n', '用于查找单词的Vocab对象。']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.dataset.transforms.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.dataset.transforms.html", "text_entry": "['mindspore.dataset.transforms\\n', '此模块用于通用数据增强，包括 c_transforms 和 py_transforms 两个子模块。\\n', '\\n', 'c_transforms 是一个高性能数据增强模块，基于C++实现。\\n', '\\n', '而 py_transforms 提供了一种基于Python和NumPy的实现方式。\\n', '\\n', '在API示例中，常用的模块导入方法如下：\\n', '\\n', 'import mindspore.dataset as ds\\n', 'import mindspore.dataset.vision.c_transforms as c_vision\\n', 'import mindspore.dataset.vision.py_transforms as py_vision\\n', 'from mindspore.dataset.transforms import c_transforms\\n', 'from mindspore.dataset.transforms import py_transforms\\n', '常用数据处理术语说明如下：\\n', '\\n', 'TensorOperation，所有C++实现的数据处理操作的基类。\\n', '\\n', 'PyTensorOperation，所有Python实现的数据处理操作的基类。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms\\n', 'mindspore.dataset.transforms.c_transforms.Compose\\n', '\\n', '将多个数据增强算子组合使用。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Concatenate\\n', '\\n', '在Tensor的某一个轴上进行元素拼接。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Duplicate\\n', '\\n', '将输入的数据列复制得到新的数据列，每次仅可以输入1个数据列进行复制。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Fill\\n', '\\n', '将Tensor的所有元素都赋值为指定的值，输出Tensor将与输入Tensor具有与具有相同的shape和数据类型。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Mask\\n', '\\n', '用给条件判断输入Tensor的内容，并返回一个掩码Tensor。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.OneHot\\n', '\\n', '将Tensor进行OneHot编码。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.PadEnd\\n', '\\n', '对输入Tensor进行填充，要求 pad_shape 与输入Tensor的维度保持一致。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.RandomApply\\n', '\\n', '指定一组数据增强处理及其被应用的概率，在运算时按概率随机应用其中的增强处理。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.RandomChoice\\n', '\\n', '在一组数据增强中随机选择部分增强处理进行应用。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Relational\\n', '\\n', '关系操作符，可以取值为Relational.EQ、Relational.NE、Relational.GT、Relational.GE、Relational.LT、Relational.LE。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Slice\\n', '\\n', '对Tensor进行切片操作，功能类似于NumPy的索引(目前只支持1D形状的Tensor)。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.TypeCast\\n', '\\n', '将输入的Tensor转换为指定的数据类型。\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Unique\\n', '\\n', '对输入张量进行唯一运算，每次只支持对一个数据列进行变换。\\n', '\\n', 'mindspore.dataset.transforms.py_transforms\\n', 'mindspore.dataset.transforms.py_transforms.Compose\\n', '\\n', '将多个数据增强算子组合使用。\\n', '\\n', 'mindspore.dataset.transforms.py_transforms.OneHotOp\\n', '\\n', '将Tensor进行OneHot编码，可以进一步对标签进行平滑处理。\\n', '\\n', 'mindspore.dataset.transforms.py_transforms.RandomApply\\n', '\\n', '指定一组数据增强处理及其被应用的概率，在运算时按概率随机应用其中的增强处理。\\n', '\\n', 'mindspore.dataset.transforms.py_transforms.RandomChoice\\n', '\\n', '在一组数据增强中随机选择部分增强处理进行应用。\\n', '\\n', 'mindspore.dataset.transforms.py_transforms.RandomOrder\\n', '\\n', '给一个数据增强的列表，随机打乱数据增强处理的顺序。']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.dataset.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.dataset.html", "text_entry": "['mindspore.dataset\\n', '该模块提供了加载和处理各种通用数据集的API，如MNIST、CIFAR-10、CIFAR-100、VOC、COCO、ImageNet、CelebA、CLUE等， 也支持加载业界标准格式的数据集，包括MindRecord、TFRecord、Manifest等。此外，用户还可以使用此模块定义和加载自己的数据集。\\n', '\\n', '该模块还提供了在加载时进行数据采样的API，如SequentialSample、RandomSampler、DistributedSampler等。\\n', '\\n', '大多数数据集可以通过指定参数 cache 启用缓存服务，以提升整体数据处理效率。 请注意Windows平台上还不支持缓存服务，因此在Windows上加载和处理数据时，请勿使用。更多介绍和限制， 请参考 Single-Node Tensor Cache。\\n', '\\n', '在API示例中，常用的模块导入方法如下：\\n', '\\n', 'import mindspore.dataset as ds\\n', 'from mindspore.dataset.transforms import c_transforms\\n', '常用数据集术语说明如下：\\n', '\\n', 'Dataset，所有数据集的基类，提供了数据处理方法来帮助预处理数据。\\n', '\\n', 'SourceDataset，一个抽象类，表示数据集管道的来源，从文件和数据库等数据源生成数据。\\n', '\\n', 'MappableDataset，一个抽象类，表示支持随机访问的源数据集。\\n', '\\n', 'Iterator，用于枚举元素的数据集迭代器的基类。\\n', '\\n', '视觉\\n', 'mindspore.dataset.Caltech101Dataset\\n', '\\n', '读取和解析Caltech101数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.Caltech256Dataset\\n', '\\n', '读取和解析Caltech256数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.CelebADataset\\n', '\\n', '读取和解析CelebA数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.Cifar10Dataset\\n', '\\n', '读取和解析CIFAR-10数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.Cifar100Dataset\\n', '\\n', '读取和解析CIFAR-100数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.CityscapesDataset\\n', '\\n', '读取和解析Cityscapes数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.CocoDataset\\n', '\\n', '读取和解析COCO数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.DIV2KDataset\\n', '\\n', '读取和解析DIV2K数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.EMnistDataset\\n', '\\n', 'A source dataset that reads and parses the EMNIST dataset.\\n', '\\n', 'mindspore.dataset.FakeImageDataset\\n', '\\n', 'A source dataset for generating fake images.\\n', '\\n', 'mindspore.dataset.FashionMnistDataset\\n', '\\n', 'A source dataset that reads and parses the FASHION-MNIST dataset.\\n', '\\n', 'mindspore.dataset.FlickrDataset\\n', '\\n', 'A source dataset that reads and parses Flickr8k and Flickr30k dataset.\\n', '\\n', 'mindspore.dataset.Flowers102Dataset\\n', '\\n', 'A source dataset that reads and parses Flowers102 dataset.\\n', '\\n', 'mindspore.dataset.ImageFolderDataset\\n', '\\n', '从树状结构的文件目录中读取图片构建源数据集，同一个文件夹中的所有图片将被分配相同的label。\\n', '\\n', 'mindspore.dataset.KMnistDataset\\n', '\\n', 'A source dataset that reads and parses the KMNIST dataset.\\n', '\\n', 'mindspore.dataset.ManifestDataset\\n', '\\n', '读取和解析Manifest数据文件构建数据集。\\n', '\\n', 'mindspore.dataset.MnistDataset\\n', '\\n', '读取和解析MNIST数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.PhotoTourDataset\\n', '\\n', 'A source dataset that reads and parses the PhotoTour dataset.\\n', '\\n', 'mindspore.dataset.Places365Dataset\\n', '\\n', 'A source dataset that reads and parses the Places365 dataset.\\n', '\\n', 'mindspore.dataset.QMnistDataset\\n', '\\n', 'A source dataset that reads and parses the QMNIST dataset.\\n', '\\n', 'mindspore.dataset.SBDataset\\n', '\\n', 'A source dataset that reads and parses Semantic Boundaries Dataset.\\n', '\\n', 'mindspore.dataset.SBUDataset\\n', '\\n', 'A source dataset that reads and parses the SBU dataset.\\n', '\\n', 'mindspore.dataset.SemeionDataset\\n', '\\n', 'A source dataset that reads and parses Semeion dataset.\\n', '\\n', 'mindspore.dataset.STL10Dataset\\n', '\\n', 'A source dataset that reads and parses STL10 dataset.\\n', '\\n', 'mindspore.dataset.SVHNDataset\\n', '\\n', 'A source dataset that reads and parses SVHN dataset.\\n', '\\n', 'mindspore.dataset.USPSDataset\\n', '\\n', 'A source dataset that reads and parses the USPS dataset.\\n', '\\n', 'mindspore.dataset.VOCDataset\\n', '\\n', '读取和解析VOC数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.WIDERFaceDataset\\n', '\\n', 'A source dataset that reads and parses WIDERFace dataset.\\n', '\\n', '文本\\n', 'mindspore.dataset.AGNewsDataset\\n', '\\n', 'A source dataset that reads and parses AG News datasets.\\n', '\\n', 'mindspore.dataset.AmazonReviewDataset\\n', '\\n', 'A source dataset that reads and parses Amazon Review Polarity and Amazon Review Full datasets.\\n', '\\n', 'mindspore.dataset.CLUEDataset\\n', '\\n', '读取和解析CLUE数据集的源文件构建数据集。\\n', '\\n', 'mindspore.dataset.CoNLL2000Dataset\\n', '\\n', 'A source dataset that reads and parses CoNLL2000 dataset.\\n', '\\n', 'mindspore.dataset.DBpediaDataset\\n', '\\n', 'A source dataset that reads and parses the DBpedia dataset.\\n', '\\n', 'mindspore.dataset.EnWik9Dataset\\n', '\\n', 'A source dataset that reads and parses EnWik9 dataset.\\n', '\\n', 'mindspore.dataset.IMDBDataset\\n', '\\n', 'A source dataset that reads and parses Internet Movie Database (IMDb).\\n', '\\n', 'mindspore.dataset.IWSLT2016Dataset\\n', '\\n', 'A source dataset that reads and parses IWSLT2016 datasets.\\n', '\\n', 'mindspore.dataset.IWSLT2017Dataset\\n', '\\n', 'A source dataset that reads and parses IWSLT2017 datasets.\\n', '\\n', 'mindspore.dataset.PennTreebankDataset\\n', '\\n', 'A source dataset that reads and parses PennTreebank datasets.\\n', '\\n', 'mindspore.dataset.SogouNewsDataset\\n', '\\n', 'A source dataset that reads and parses Sogou News dataset.\\n', '\\n', 'mindspore.dataset.TextFileDataset\\n', '\\n', '读取和解析文本文件构建数据集。\\n', '\\n', 'mindspore.dataset.UDPOSDataset\\n', '\\n', 'A source dataset that reads and parses UDPOS dataset.\\n', '\\n', 'mindspore.dataset.WikiTextDataset\\n', '\\n', 'A source dataset that reads and parses WikiText2 and WikiText103 datasets.\\n', '\\n', 'mindspore.dataset.YahooAnswersDataset\\n', '\\n', 'A source dataset that reads and parses the YahooAnswers dataset.\\n', '\\n', 'mindspore.dataset.YelpReviewDataset\\n', '\\n', 'A source dataset that reads and parses Yelp Review Polarity and Yelp Review Full dataset.\\n', '\\n', '音频\\n', 'mindspore.dataset.LJSpeechDataset\\n', '\\n', 'A source dataset that reads and parses LJSpeech dataset.\\n', '\\n', 'mindspore.dataset.SpeechCommandsDataset\\n', '\\n', 'A source dataset that reads and parses the SpeechCommands dataset.\\n', '\\n', 'mindspore.dataset.TedliumDataset\\n', '\\n', 'A source dataset that reads and parses Tedlium dataset.\\n', '\\n', 'mindspore.dataset.YesNoDataset\\n', '\\n', 'A source dataset that reads and parses the YesNo dataset.\\n', '\\n', '标准格式\\n', 'mindspore.dataset.CSVDataset\\n', '\\n', '读取和解析CSV数据文件构建数据集。\\n', '\\n', 'mindspore.dataset.MindDataset\\n', '\\n', '读取和解析MindRecord数据文件构建数据集。\\n', '\\n', 'mindspore.dataset.OBSMindDataset\\n', '\\n', '读取和解析存放在华为云OBS、Minio以及AWS S3等云存储上的MindRecord格式数据集。\\n', '\\n', 'mindspore.dataset.TFRecordDataset\\n', '\\n', '读取和解析TFData格式的数据文件构建数据集。\\n', '\\n', '用户自定义\\n', 'mindspore.dataset.GeneratorDataset\\n', '\\n', '自定义Python数据源，通过迭代该数据源构造数据集。\\n', '\\n', 'mindspore.dataset.NumpySlicesDataset\\n', '\\n', '由Python数据构建数据集。\\n', '\\n', 'mindspore.dataset.PaddedDataset\\n', '\\n', '由用户提供的填充数据构建数据集。\\n', '\\n', 'mindspore.dataset.RandomDataset\\n', '\\n', 'A source dataset that generates random data.\\n', '\\n', '图\\n', 'mindspore.dataset.GraphData\\n', '\\n', '从共享文件或数据库中读取用于GNN训练的图数据集。\\n', '\\n', '采样器\\n', 'mindspore.dataset.DistributedSampler\\n', '\\n', '分布式采样器，将数据集进行分片用于分布式训练。\\n', '\\n', 'mindspore.dataset.PKSampler\\n', '\\n', '为数据集中每P个类别各采样K个样本。\\n', '\\n', 'mindspore.dataset.RandomSampler\\n', '\\n', '随机采样器。\\n', '\\n', 'mindspore.dataset.SequentialSampler\\n', '\\n', '按数据集的读取顺序采样数据集样本，相当于不使用采样器。\\n', '\\n', 'mindspore.dataset.SubsetRandomSampler\\n', '\\n', '给定样本的索引序列，从序列中随机获取索引对数据集进行采样。\\n', '\\n', 'mindspore.dataset.SubsetSampler\\n', '\\n', '给定样本的索引序列，对数据集采样指定索引的样本。\\n', '\\n', 'mindspore.dataset.WeightedRandomSampler\\n', '\\n', '给定样本的权重列表，根据权重决定样本的采样概率，随机采样[0，len(weights) - 1]中的样本。\\n', '\\n', '其他\\n', 'mindspore.dataset.BatchInfo\\n', '\\n', '此类提供了两种方法获取数据集的批处理数量（batch size）和迭代数（epoch）属性。\\n', '\\n', 'mindspore.dataset.DatasetCache\\n', '\\n', '创建数据缓存客户端实例。\\n', '\\n', 'mindspore.dataset.DSCallback\\n', '\\n', '数据处理回调类的抽象基类，用户可以基于此类实现自己的回调操作。\\n', '\\n', 'mindspore.dataset.SamplingStrategy\\n', '\\n', '指定图数据采样策略的枚举类。\\n', '\\n', 'mindspore.dataset.Schema\\n', '\\n', '用于解析和存储数据列属性的类。\\n', '\\n', 'mindspore.dataset.Shuffle\\n', '\\n', '指定混洗模式的枚举类。\\n', '\\n', 'mindspore.dataset.WaitedDSCallback\\n', '\\n', '阻塞式数据处理回调类的抽象基类，用于与训练回调类 mindspore.train.callback 的同步。\\n', '\\n', 'mindspore.dataset.OutputFormat\\n', '\\n', '通过API get_all_neighbors 获取所有相邻节点时，指定节点的存储格式。\\n', '\\n', 'mindspore.dataset.compare\\n', '\\n', '比较两个数据处理管道是否相同。\\n', '\\n', 'mindspore.dataset.deserialize\\n', '\\n', '数据处理管道反序列化，支持输入Python字典或使用 mindspore.dataset.serialize() 接口生成的JSON文件。\\n', '\\n', 'mindspore.dataset.serialize\\n', '\\n', '将数据处理管道序列化成JSON文件。\\n', '\\n', 'mindspore.dataset.show\\n', '\\n', '将数据处理管道图写入MindSpore的INFO级别日志文件。\\n', '\\n', 'mindspore.dataset.sync_wait_for_dataset\\n', '\\n', '等待所有的卡需要的数据集文件下载完成。\\n', '\\n', 'mindspore.dataset.utils.imshow_det_bbox\\n', '\\n', '使用给定的边界框和类别置信度绘制图像。\\n', '\\n', 'mindspore.dataset.zip\\n', '\\n', '将多个dataset对象按列进行合并压缩。']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.dataset.vision.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.dataset.vision.html", "text_entry": "['mindspore.dataset.vision\\n', '此模块用于图像数据增强，包括 c_transforms 和 py_transforms 两个子模块。 c_transforms 是使用 C++ OpenCv 开发的高性能图像增强模块。 py_transforms 是使用 Python Pillow 开发的图像增强模块。\\n', '\\n', 'API样例中常用的导入模块如下：\\n', '\\n', 'import mindspore.dataset.vision.c_transforms as c_vision\\n', 'import mindspore.dataset.vision.py_transforms as py_vision\\n', 'from mindspore.dataset.transforms import c_transforms\\n', '常用数据处理术语说明如下：\\n', '\\n', 'TensorOperation，所有C++实现的数据处理操作的基类。\\n', '\\n', 'PyTensorOperation，所有Python实现的数据处理操作的基类。\\n', '\\n', 'ImageTensorOperation，所有图像数据处理操作的基类，派生自TensorOperation。\\n', '\\n', 'mindspore.dataset.vision.c_transforms\\n', 'mindspore.dataset.vision.c_transforms.AutoContrast\\n', '\\n', '在输入图像上应用自动对比度。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.BoundingBoxAugment\\n', '\\n', '对图像的随机标注边界框区域，应用给定的图像变换处理。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.CenterCrop\\n', '\\n', '对输入图像应用中心区域裁剪。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.ConvertColor\\n', '\\n', '更改图像的色彩空间。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Crop\\n', '\\n', '在输入图像上裁剪出指定区域。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.CutMixBatch\\n', '\\n', '对输入批次的图像和标注应用剪切混合转换。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.CutOut\\n', '\\n', '从输入图像数组中随机裁剪出给定数量的正方形区域。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Decode\\n', '\\n', '对输入图像进行解码。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Equalize\\n', '\\n', '对输入图像进行直方图均衡化。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.GaussianBlur\\n', '\\n', '使用指定的高斯核对输入图像进行模糊处理。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.HorizontalFlip\\n', '\\n', '水平翻转输入图像。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.HWC2CHW\\n', '\\n', '将输入图像的shape从 <H, W, C> 转换为 <C, H, W>。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Invert\\n', '\\n', '在 RGB 模式下对输入图像应用像素反转，计算方式为（255 - pixel）。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.MixUpBatch\\n', '\\n', '对输入批次的图像和标注应用混合转换。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Normalize\\n', '\\n', '根据均值和标准差对输入图像进行归一化。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.NormalizePad\\n', '\\n', '根据均值和标准差对输入图像进行归一化，然后填充一个全零的额外通道。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Pad\\n', '\\n', '填充图像。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomAffine\\n', '\\n', '对输入图像应用随机仿射变换。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomColor\\n', '\\n', '随机调整输入图像的颜色。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomColorAdjust\\n', '\\n', '随机调整输入图像的亮度、对比度、饱和度和色调。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomCrop\\n', '\\n', '对输入图像进行随机区域的裁剪。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomCropDecodeResize\\n', '\\n', '“裁剪”、”解码”和”调整尺寸大小”的组合处理。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomCropWithBBox\\n', '\\n', '在输入图像的随机位置进行裁剪并相应地调整边界框。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomHorizontalFlip\\n', '\\n', '对输入图像按给定的概率进行水平随机翻转。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomHorizontalFlipWithBBox\\n', '\\n', '对输入图像按给定的概率进行水平随机翻转并相应地调整边界框。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomPosterize\\n', '\\n', '随机减少输入图像每个颜色通道的位数。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomResize\\n', '\\n', '对输入图像使用随机选择的 mindspore.dataset.vision.Inter 插值方式去调整它的尺寸大小。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomResizedCrop\\n', '\\n', '对输入图像进行随机裁剪，并使用指定的 mindspore.dataset.vision.Inter 插值方式去调整为指定的尺寸大小。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomResizedCropWithBBox\\n', '\\n', '对输入图像进行随机裁剪且随机调整纵横比，并将处理后的图像调整为指定的尺寸大小，并相应地调整边界框。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomResizeWithBBox\\n', '\\n', '对输入图像使用随机选择的 mindspore.dataset.vision.Inter 插值方式去调整它的尺寸大小，并相应地调整边界框的尺寸大小。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomRotation\\n', '\\n', '在指定的角度范围内，随机旋转输入图像。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomSelectSubpolicy\\n', '\\n', '从策略列表中随机选择一个子策略以应用于输入图像。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomSharpness\\n', '\\n', '在固定或随机的范围调整输入图像的锐度。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomSolarize\\n', '\\n', '从给定阈值范围内随机选择一个子范围，对位于给定子范围内的像素，将其像素值设置为(255 - 原本像素值)。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomVerticalFlip\\n', '\\n', '以给定的概率对输入图像在垂直方向进行随机翻转。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomVerticalFlipWithBBox\\n', '\\n', '以给定的概率对输入图像和边界框在垂直方向进行随机翻转。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Rescale\\n', '\\n', '基于给定的缩放和平移因子调整图像的尺寸大小。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Resize\\n', '\\n', '对输入图像使用给定的 mindspore.dataset.vision.Inter 插值方式去调整为给定的尺寸大小。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.ResizeWithBBox\\n', '\\n', '将输入图像调整为给定的尺寸大小并相应地调整边界框的大小。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Rotate\\n', '\\n', '将输入图像旋转指定的度数。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.SlicePatches\\n', '\\n', '在水平和垂直方向上将Tensor切片为多个块。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.SoftDvppDecodeRandomCropResizeJpeg\\n', '\\n', '使用Ascend系列芯片DVPP模块的模拟算法对JPEG图像进行裁剪、解码和缩放。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.SoftDvppDecodeResizeJpeg\\n', '\\n', '使用Ascend系列芯片DVPP模块的模拟算法对JPEG图像进行解码和缩放。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.UniformAugment\\n', '\\n', '对输入图像执行随机选取的数据增强操作。\\n', '\\n', 'mindspore.dataset.vision.c_transforms.VerticalFlip\\n', '\\n', '对输入图像进行垂直翻转。\\n', '\\n', 'mindspore.dataset.vision.py_transforms\\n', 'mindspore.dataset.vision.py_transforms.AutoContrast\\n', '\\n', '最大化（标准化）输入PIL图像的对比度。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.CenterCrop\\n', '\\n', '以输入PIL图像的中心为裁剪中心，裁剪指定尺寸大小的子图。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Cutout\\n', '\\n', '随机去除输入numpy.ndarray图像上一定数量的正方形区域，将区域内像素值置为0。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Decode\\n', '\\n', '将输入原始图像字节解码为RGB格式PIL图像。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Equalize\\n', '\\n', '对输入PIL图像进行直方图均衡。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.FiveCrop\\n', '\\n', '在输入PIL图像的中心与四个角处分别裁剪指定尺寸大小的子图。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Grayscale\\n', '\\n', '将输入PIL图像转换为灰度图。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.HsvToRgb\\n', '\\n', '将输入的HSV格式numpy.ndarray图像转换为RGB格式。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.HWC2CHW\\n', '\\n', '将输入的numpy.ndarray图像的shape从(H, W, C)转换为(C, H, W)。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Invert\\n', '\\n', '反转输入PIL图像的颜色。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.LinearTransformation\\n', '\\n', '使用指定的变换方阵和均值向量对输入numpy.ndarray图像进行线性变换。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.MixUp\\n', '\\n', '随机混合一批输入的numpy.ndarray图像及其标签。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Normalize\\n', '\\n', '使用指定的均值和标准差，标准化shape为(C, H, W)的输入numpy.ndarray图像。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.NormalizePad\\n', '\\n', '使用指定的均值和标准差，标准化shape为(C, H, W)的输入numpy.ndarray图像，并填充一个全零的额外通道。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Pad\\n', '\\n', '对输入PIL图像的各边进行填充。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomAffine\\n', '\\n', '对输入PIL图像进行随机仿射变换。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomColor\\n', '\\n', '随机调整输入PIL图像的色彩平衡。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomColorAdjust\\n', '\\n', '随机调整输入PIL图像的亮度、对比度、饱和度和色调。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomCrop\\n', '\\n', '在输入PIL图像上的随机位置，裁剪指定尺寸大小的子图。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomErasing\\n', '\\n', '按照指定的概率擦除输入numpy.ndarray图像上随机矩形区域内的像素。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomGrayscale\\n', '\\n', '按照指定的概率将输入PIL图像转换为灰度图。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomHorizontalFlip\\n', '\\n', '按照指定的概率随机水平翻转输入的PIL图像。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomPerspective\\n', '\\n', '按照指定的概率对输入PIL图像进行透视变换。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomResizedCrop\\n', '\\n', '在输入PIL图像上的随机位置裁剪子图，并放缩到指定尺寸大小。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomRotation\\n', '\\n', '将输入PIL图像旋转随机角度。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomSharpness\\n', '\\n', '随机调整输入PIL图像的锐度。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomVerticalFlip\\n', '\\n', '按照指定的概率随机垂直翻转输入的PIL图像。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Resize\\n', '\\n', '将输入PIL图像放缩为指定尺寸大小。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RgbToHsv\\n', '\\n', '将输入的RGB格式numpy.ndarray图像转换为HSV格式。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.TenCrop\\n', '\\n', '在输入PIL图像的中心与四个角处分别裁剪指定尺寸大小的子图，并将其翻转图一并返回。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.ToPIL\\n', '\\n', '将已解码的numpy.ndarray图像转换为PIL图像。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.ToTensor\\n', '\\n', '将输入的PIL或numpy.ndarray图像转换为指定数据类型的numpy.ndarray图像，此时像素值取值将由[0, 255]变为[0.0, 1.0]，图像的shape将由(H, W, C)变为(C, H, W)。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.ToType\\n', '\\n', '将输入的numpy.ndarray图像转换为指定数据类型。\\n', '\\n', 'mindspore.dataset.vision.py_transforms.UniformAugment\\n', '\\n', '从指定序列中均匀采样一批数据处理操作，并按顺序随机执行，即采样出的操作也可能不被执行。\\n', '\\n', 'mindspore.dataset.vision.utils\\n', 'mindspore.dataset.vision.Border\\n', '\\n', '边界填充方式枚举类。\\n', '\\n', 'mindspore.dataset.vision.ConvertMode\\n', '\\n', '图像色彩空间转换模式枚举类。\\n', '\\n', 'mindspore.dataset.vision.ImageBatchFormat\\n', '\\n', '图像批处理输出格式枚举类。\\n', '\\n', 'mindspore.dataset.vision.Inter\\n', '\\n', '图像插值方式枚举类。\\n', '\\n', 'mindspore.dataset.vision.SliceMode\\n', '\\n', 'Tensor切片方式枚举类。']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.mindrecord.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.mindrecord.html", "text_entry": "['mindspore.mindrecord\\n', 'MindRecord是MindSpore开发的一种高效数据格式，此模块提供了一些方法帮助用户将不同数据集转换为MindRecord格式， 也提供了一些操作MindRecord数据文件的方法如读取、写入、检索等。 用户可以使用FileWriter API生成MindRecord格式数据集，并使用MindDataset API加载MindRecord格式数据集。\\n', '\\n', '用户还可以通过相应的子模块将其他格式数据集转换为MindRecord格式数据集。\\n', '\\n', 'classmindspore.mindrecord.FileWriter(file_name, shard_num=1, overwrite=False)[源代码]\\n', '将用户自定义的数据转为MindRecord格式数据集的类。\\n', '\\n', 'Note\\n', '\\n', '生成MindRecord文件后，如果修改文件名，可能会导致读取文件失败。\\n', '\\n', '参数：\\n', '\\n', 'file_name (str) - 转换生成的MindRecord文件路径。\\n', '\\n', 'shard_num (int，可选) - 生成MindRecord的文件个数。取值范围为[1, 1000]。默认值：1。\\n', '\\n', 'overwrite (bool，可选) - 当指定目录存在同名文件时是否覆盖写。默认值：False。\\n', '\\n', '异常：\\n', '\\n', 'ParamValueError - file_name 或 shard_num 无效。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.mindrecord import FileWriter\\n', 'schema_json = {\"file_name\": {\"type\": \"string\"}, \"label\": {\"type\": \"int32\"}, \"data\": {\"type\": \"bytes\"}}\\n', 'indexes = [\"file_name\", \"label\"]\\n', 'data = [{\"file_name\": \"1.jpg\", \"label\": 0,\\n', '         \"data\": b\"\\\\x10c\\\\xb3w\\\\xa8\\\\xee$o&<q\\\\x8c\\\\x8e(\\\\xa2\\\\x90\\\\x90\\\\x96\\\\xbc\\\\xb1\\\\x1e\\\\xd4QER\\\\x13?\\\\xff\"},\\n', '        {\"file_name\": \"2.jpg\", \"label\": 56,\\n', '         \"data\": b\"\\\\xe6\\\\xda\\\\xd1\\\\xae\\\\x07\\\\xb8>\\\\xd4\\\\x00\\\\xf8\\\\x129\\\\x15\\\\xd9\\\\xf2q\\\\xc0\\\\xa2\\\\x91YFUO\\\\x1dsE1\"},\\n', '        {\"file_name\": \"3.jpg\", \"label\": 99,\\n', '         \"data\": b\"\\\\xaf\\\\xafU<\\\\xb8|6\\\\xbd}\\\\xc1\\\\x99[\\\\xeaj+\\\\x8f\\\\x84\\\\xd3\\\\xcc\\\\xa0,i\\\\xbb\\\\xb9-\\\\xcdz\\\\xecp{T\\\\xb1\"}]\\n', 'writer = FileWriter(file_name=\"test.mindrecord\", shard_num=1, overwrite=True)\\n', 'writer.add_schema(schema_json, \"test_schema\")\\n', '\\n', 'writer.add_index(indexes)\\n', '\\n', 'writer.write_raw_data(data)\\n', '\\n', 'writer.commit()\\n', '\\n', 'add_index(index_fields)[源代码]\\n', '指定schema中的字段作为索引来加速MindRecord文件的读取。schema可以通过 add_schema 来添加。\\n', '\\n', 'Note\\n', '\\n', '索引字段应为Primitive类型，例如 int 、float 、str 。\\n', '\\n', '如果不调用该函数，则默认将schema中所有的Primitive类型的字段设置为索引。 请参考类的示例 mindspore.mindrecord.FileWriter 。\\n', '\\n', '参数：\\n', '\\n', 'index_fields (list[str]) - schema中的字段。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', '异常：\\n', '\\n', 'ParamTypeError - 索引字段无效。\\n', '\\n', 'MRMDefineIndexError - 索引字段不是Primitive类型。\\n', '\\n', 'MRMAddIndexError - 无法添加索引字段。\\n', '\\n', 'MRMGetMetaError - 未设置schema或无法获取schema。\\n', '\\n', 'add_schema(content, desc=None)[源代码]\\n', '增加描述用户自定义数据的schema。\\n', '\\n', 'Note\\n', '\\n', '请参考类的示例 mindspore.mindrecord.FileWriter 。\\n', '\\n', '参数：\\n', '\\n', 'content (dict) - schema内容的字典。\\n', '\\n', 'desc (str，可选) - schema的描述。默认值：None。\\n', '\\n', '返回：\\n', '\\n', 'int，schema ID。\\n', '\\n', '异常：\\n', '\\n', 'MRMInvalidSchemaError - schema无效。\\n', '\\n', 'MRMBuildSchemaError - 构建schema失败。\\n', '\\n', 'MRMAddSchemaError - 添加schema失败。\\n', '\\n', 'commit()[源代码]\\n', '将内存中的数据同步到磁盘，并生成相应的数据库文件。\\n', '\\n', 'Note\\n', '\\n', '请参考类的示例 mindspore.mindrecord.FileWriter 。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', '异常：\\n', '\\n', 'MRMOpenError - 打开MindRecord文件失败。\\n', '\\n', 'MRMSetHeaderError - 设置MindRecord文件的header失败。\\n', '\\n', 'MRMIndexGeneratorError - 创建索引Generator失败。\\n', '\\n', 'MRMGenerateIndexError - 写入数据库失败。\\n', '\\n', 'MRMCommitError - 数据同步到磁盘失败。\\n', '\\n', 'open_and_set_header()[源代码]\\n', '打开MindRecord文件准备写入并且设置描述其meta信息的头部，该函数仅用于并行写入，并在 write_raw_data 函数之前调用。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', '异常：\\n', '\\n', 'MRMOpenError - 打开MindRecord文件失败。\\n', '\\n', 'MRMSetHeaderError - 设置MindRecord文件的header失败。\\n', '\\n', 'open_for_append(file_name)[源代码]\\n', '打开MindRecord文件，准备追加数据。\\n', '\\n', '参数：\\n', '\\n', 'file_name (str) - MindRecord格式的数据集文件的路径。\\n', '\\n', '返回：\\n', '\\n', 'FileWriter，MindRecord文件的写对象。\\n', '\\n', '异常：\\n', '\\n', 'ParamValueError - file_name 无效。\\n', '\\n', 'FileNameError - MindRecord文件路径中包含无效字符。\\n', '\\n', 'MRMOpenError - 打开MindRecord文件失败。\\n', '\\n', 'MRMOpenForAppendError - 打开MindRecord文件追加数据失败。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.mindrecord import FileWriter\\n', 'schema_json = {\"file_name\": {\"type\": \"string\"}, \"label\": {\"type\": \"int32\"}, \"data\": {\"type\": \"bytes\"}}\\n', 'data = [{\"file_name\": \"1.jpg\", \"label\": 0,\\n', '         \"data\": b\"\\\\x10c\\\\xb3w\\\\xa8\\\\xee$o&<q\\\\x8c\\\\x8e(\\\\xa2\\\\x90\\\\x90\\\\x96\\\\xbc\\\\xb1\\\\x1e\\\\xd4QER\\\\x13?\\\\xff\"}]\\n', 'writer = FileWriter(file_name=\"test.mindrecord\", shard_num=1, overwrite=True)\\n', 'writer.add_schema(schema_json, \"test_schema\")\\n', '\\n', 'writer.write_raw_data(data)\\n', '\\n', 'writer.commit()\\n', '\\n', 'write_append = FileWriter.open_for_append(\"test.mindrecord\")\\n', 'write_append.write_raw_data(data)\\n', '\\n', 'write_append.commit()\\n', '\\n', 'set_header_size(header_size)[源代码]\\n', '设置MindRecord文件的header，其中包含shard信息、schema信息、page的元信息等。 header越大，MindRecord文件可以存储更多的元信息。如果header大于默认大小（16MB），需要调用本函数来设置合适的大小。\\n', '\\n', '参数：\\n', '\\n', 'header_size (int) - header大小，可设置范围为16*1024(16KB)到128*1024*1024(128MB)。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', '异常：\\n', '\\n', 'MRMInvalidHeaderSizeError - 设置header大小失败。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.mindrecord import FileWriter\\n', 'writer = FileWriter(file_name=\"test.mindrecord\", shard_num=1)\\n', 'writer.set_header_size(1 << 25) # 32MB\\n', '\\n', 'set_page_size(page_size)[源代码]\\n', '设置存储数据的page大小，page分为两种类型：raw page和blob page。 page越大，page可以存储更多的数据。如果单个样本大于默认大小（32MB），需要调用本函数来设置合适的大小。\\n', '\\n', '参数：\\n', '\\n', 'page_size (int) - page大小，可设置范围为32*1024(32KB)到256*1024*1024(256MB)。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', '异常：\\n', '\\n', 'MRMInvalidPageSizeError - 设置page大小失败。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.mindrecord import FileWriter\\n', 'writer = FileWriter(file_name=\"test.mindrecord\", shard_num=1)\\n', 'writer.set_page_size(1 << 26) # 128MB\\n', '\\n', 'write_raw_data(raw_data, parallel_writer=False)[源代码]\\n', '根据schema校验用户自定义数据后，将数据转换为一系列连续的MindRecord格式的数据集文件。\\n', '\\n', 'Note\\n', '\\n', '请参考类的示例 mindspore.mindrecord.FileWriter 。\\n', '\\n', '参数：\\n', '\\n', 'raw_data (list[dict]) - 用户自定义数据的列表。\\n', '\\n', 'parallel_writer (bool，可选) - 如果为True，则并行写入用户自定义数据。默认值：False。。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', '异常：\\n', '\\n', 'ParamTypeError - 索引字段无效。\\n', '\\n', 'MRMOpenError - 打开MindRecord文件失败。\\n', '\\n', 'MRMValidateDataError - 数据校验失败。\\n', '\\n', 'MRMSetHeaderError - 设置MindRecord文件的header失败。\\n', '\\n', 'MRMWriteDatasetError - 写入MindRecord格式的数据集失败。\\n', '\\n', 'classmindspore.mindrecord.FileReader(file_name, num_consumer=4, columns=None, operator=None)[源代码]\\n', '读取MindRecord格式数据集。\\n', '\\n', 'Note\\n', '\\n', '如果 file_name 是文件路径的字符串，则会尝试加载同一批转换生成的所有MindRecord文件，如果缺少其中某个MindRecord文件，则会引发异常。\\n', '\\n', '如果 file_name 是文件路径组成的列表，则只加载列表中指定的MindRecord文件。\\n', '\\n', '参数：\\n', '\\n', 'file_name (str, list[str]) - MindRecord格式的数据集文件路径或文件路径组成的列表。\\n', '\\n', 'num_consumer (int，可选) - 加载数据的并发数。默认值：4。不应小于1或大于处理器的核数。\\n', '\\n', 'columns (list[str]，可选) - MindRecord中待读取数据列的列表。默认值：None，读取所有的数据列。\\n', '\\n', 'operator (int，可选) - 保留参数。默认值：None。\\n', '\\n', '异常：\\n', '\\n', 'ParamValueError - file_name 、num_consumer 或 columns 无效。\\n', '\\n', 'close()[源代码]\\n', '停止数据集加载并且关闭文件句柄。\\n', '\\n', 'get_next()[源代码]\\n', '按列名一次返回下一批的数据。\\n', '\\n', '返回：\\n', '\\n', 'dict，下一批数据，键值与数据列名相同。\\n', '\\n', '异常：\\n', '\\n', 'MRMUnsupportedSchemaError - 当schema无效。\\n', '\\n', 'classmindspore.mindrecord.MindPage(file_name, num_consumer=4)[源代码]\\n', '以分页方式读取MindRecord文件的类。\\n', '\\n', '参数：\\n', '\\n', 'file_name (Union[str, list[str]]) - MindRecord格式的数据集文件或文件列表。\\n', '\\n', 'num_consumer (int，可选) - 加载数据的并发数。默认值：4。不应小于1或大于处理器的核数。\\n', '\\n', '异常：\\n', '\\n', 'ParamValueError - file_name 、num_consumer 或 columns 无效。\\n', '\\n', 'MRMInitSegmentError - 初始化ShardSegment失败。\\n', '\\n', 'get_category_fields()[源代码]\\n', '返回用于数据分组的候选category字段。\\n', '\\n', '返回：\\n', '\\n', 'list[str]，候选category字段。\\n', '\\n', 'read_at_page_by_id(category_id, page, num_row)[源代码]\\n', '以分页方式按category ID进行查询。\\n', '\\n', '参数：\\n', '\\n', 'category_id (int) - category ID，参考 read_category_info 函数的返回值。\\n', '\\n', 'page (int) - 分页的索引。\\n', '\\n', 'num_row (int) - 每个分页的行数。\\n', '\\n', '返回：\\n', '\\n', 'list[dict]，根据category ID查询的数据。\\n', '\\n', '异常：\\n', '\\n', 'ParamValueError - 参数无效。\\n', '\\n', 'MRMFetchDataError - 无法按category ID获取数据。\\n', '\\n', 'MRMUnsupportedSchemaError - schema无效。\\n', '\\n', 'read_at_page_by_name(category_name, page, num_row)[源代码]\\n', '以分页方式按category字段进行查询。\\n', '\\n', '参数：\\n', '\\n', 'category_name (str) - category字段对应的字符，参考 read_category_info 函数的返回值。\\n', '\\n', 'page (int) - 分页的索引。\\n', '\\n', 'num_row (int) - 每个分页的行数。\\n', '\\n', '返回：\\n', '\\n', 'list[dict]，根据category字段查询的数据。\\n', '\\n', 'read_category_info()[源代码]\\n', '当数据按指定的category字段进行分组时，返回category信息。\\n', '\\n', '返回：\\n', '\\n', 'str，分组信息的描述。\\n', '\\n', '异常：\\n', '\\n', 'MRMReadCategoryInfoError - 读取category信息失败。\\n', '\\n', 'set_category_field(category_field)[源代码]\\n', '设置category字段。\\n', '\\n', 'Note\\n', '\\n', '必须是候选category字段。\\n', '\\n', '参数：\\n', '\\n', 'category_field (str) - category字段名称。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED\\n', '\\n', 'classmindspore.mindrecord.Cifar10ToMR(source, destination)[源代码]\\n', '将CIFAR-10数据集转换为MindRecord格式数据集。\\n', '\\n', 'Note\\n', '\\n', '示例的详细信息，请参见 转换CIFAR-10数据集。\\n', '\\n', '参数：\\n', '\\n', 'source (str) - 待转换的CIFAR-10数据集文件所在目录的路径。\\n', '\\n', 'destination (str) - 转换生成的MindRecord文件路径，需提前创建目录并且目录下不能存在同名文件。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - source 或 destination 无效。\\n', '\\n', 'run(fields=None)[源代码]\\n', '执行从CIFAR-10数据集到MindRecord格式数据集的转换。\\n', '\\n', '参数：\\n', '\\n', 'fields (list[str]，可选) - 索引字段的列表。默认值：None。 索引字段的设置请参考函数 mindspore.mindrecord.FileWriter.add_index() 。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'transform(fields=None)[源代码]\\n', 'mindspore.mindrecord.Cifar10ToMR.run() 的包装函数来保证异常时正常退出。\\n', '\\n', '参数：\\n', '\\n', 'fields (list[str]，可选) - 索引字段的列表。默认值：None。 索引字段的设置请参考函数 mindspore.mindrecord.FileWriter.add_index() 。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'classmindspore.mindrecord.Cifar100ToMR(source, destination)[源代码]\\n', '将CIFAR-100数据集转换为MindRecord格式数据集。\\n', '\\n', 'Note\\n', '\\n', '示例的详细信息，请参见 转换CIFAR-10数据集。\\n', '\\n', '参数：\\n', '\\n', 'source (str) - 待转换的CIFAR-100数据集文件所在目录的路径。\\n', '\\n', 'destination (str) - 转换生成的MindRecord文件路径，需提前创建目录并且目录下不能存在同名文件。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 参数 source 或 destination 无效。\\n', '\\n', 'run(fields=None)[源代码]\\n', '执行从CIFAR-100数据集到MindRecord格式数据集的转换。\\n', '\\n', '参数：\\n', '\\n', 'fields (list[str]，可选) - 索引字段的列表，例如[‘fine_label’, ‘coarse_label’]。默认值：None。 索引字段的设置请参考函数 mindspore.mindrecord.FileWriter.add_index() 。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'transform(fields=None)[源代码]\\n', 'mindspore.mindrecord.Cifar100ToMR.run() 的包装函数来保证异常时正常退出。\\n', '\\n', '参数：\\n', '\\n', 'fields (list[str]，可选) - 索引字段的列表，例如[‘fine_label’, ‘coarse_label’]。默认值：None。 索引字段的设置请参考函数 mindspore.mindrecord.FileWriter.add_index() 。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'classmindspore.mindrecord.CsvToMR(source, destination, columns_list=None, partition_number=1)[源代码]\\n', '将CSV格式数据集转换为MindRecord格式数据集。\\n', '\\n', 'Note\\n', '\\n', '示例的详细信息，请参见 转换CSV数据集。\\n', '\\n', '参数：\\n', '\\n', 'source (str) - 待转换的CSV文件路径。\\n', '\\n', 'destination (str) - 转换生成的MindRecord文件路径，需提前创建目录并且目录下不能存在同名文件。\\n', '\\n', 'columns_list (list[str]，可选) - CSV中待读取数据列的列表。默认值：None，读取所有的数据列。\\n', '\\n', 'partition_number (int，可选) - 生成MindRecord的文件个数。默认值：1。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 参数 source 、destination 、partition_number 无效。\\n', '\\n', 'RuntimeError - 参数 columns_list 无效。\\n', '\\n', 'run()[源代码]\\n', '执行从CSV格式数据集到MindRecord格式数据集的转换。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'transform()[源代码]\\n', 'mindspore.mindrecord.CsvToMR.run() 的包装函数来保证异常时正常退出。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'classmindspore.mindrecord.ImageNetToMR(map_file, image_dir, destination, partition_number=1)[源代码]\\n', '将ImageNet数据集转换为MindRecord格式数据集。\\n', '\\n', '参数：\\n', '\\n', 'map_file (str) - 标签映射文件的路径。映射文件内容如下：\\n', '\\n', 'n02119789 0\\n', 'n02100735 1\\n', 'n02110185 2\\n', 'n02096294 3\\n', 'image_dir (str) - ImageNet数据集的目录路径，目录中包含类似n02119789、n02100735、n02110185和n02096294的子目录。\\n', '\\n', 'destination (str) - 转换生成的MindRecord文件路径，需提前创建目录并且目录下不能存在同名文件。\\n', '\\n', 'partition_number (int，可选) - 生成MindRecord的文件个数。默认值：1。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 参数 map_file 、image_dir 或 destination 无效。\\n', '\\n', 'run()[源代码]\\n', '执行从ImageNet数据集到MindRecord格式数据集的转换。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'transform()[源代码]\\n', 'mindspore.mindrecord.ImageNetToMR.run() 的包装函数来保证异常时正常退出。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'classmindspore.mindrecord.MnistToMR(source, destination, partition_number=1)[源代码]\\n', '将MNIST数据集转换为MindRecord格式数据集。\\n', '\\n', '参数：\\n', '\\n', 'source (str) - 数据集目录路径，其包含t10k-images-idx3-ubyte.gz、train-images-idx3-ubyte.gz、t10k-labels-idx1-ubyte.gz和train-labels-idx1-ubyte.gz数据集文件。\\n', '\\n', 'destination (str) - 转换生成的MindRecord文件路径，需提前创建目录并且目录下不能存在同名文件。\\n', '\\n', 'partition_number (int，可选) - 生成MindRecord的文件个数。默认值：1。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 参数 source 、 destination 、 partition_number 无效。\\n', '\\n', 'run()[源代码]\\n', '执行从MNIST数据集到MindRecord格式数据集的转换。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，MNIST数据集是否成功转换为MindRecord格式数据集。\\n', '\\n', 'transform()[源代码]\\n', 'mindspore.mindrecord.MnistToMR.run() 函数的包装函数来保证异常时正常退出。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'classmindspore.mindrecord.TFRecordToMR(source, destination, feature_dict, bytes_fields=None)[源代码]\\n', '将TFRecord格式数据集转换为MindRecord格式数据集。\\n', '\\n', 'Note\\n', '\\n', '示例的详细信息，请参见 转换TFRecord数据集。\\n', '\\n', '参数：\\n', '\\n', 'source (str) - 待转换的TFRecord文件路径。\\n', '\\n', 'destination (str) - 转换生成的MindRecord文件路径，需提前创建目录并且目录下不能存在同名文件。\\n', '\\n', 'feature_dict (dict[str, FixedLenFeature]) - TFRecord的feature类别的字典，当前支持 FixedLenFeature 类型。\\n', '\\n', 'bytes_fields (list[str]，可选) - feature_dict 中的字节字段，可以为字节类型的图像字段。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 无效参数。\\n', '\\n', 'Exception - 找不到TensorFlow模块或其版本不正确。\\n', '\\n', 'run()[源代码]\\n', '执行从TFRecord格式数据集到MindRecord格式数据集的转换。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。\\n', '\\n', 'tfrecord_iterator()[源代码]\\n', '生成一个字典，其key是schema中的字段，value是数据。\\n', '\\n', '返回：\\n', '\\n', 'Dict，key与schema中字段名相同的数据字典。\\n', '\\n', 'tfrecord_iterator_oldversion()[源代码]\\n', '生成一个字典，其中key是schema中的字段，value是数据。该函数适用于早于2.1.0版本的TensorFlow。\\n', '\\n', '返回：\\n', '\\n', 'Dict，key与schema中字段名相同的数据字典。\\n', '\\n', 'transform()[源代码]\\n', 'mindspore.mindrecord.TFRecordToMR.run() 的包装函数来保证异常时正常退出。\\n', '\\n', '返回：\\n', '\\n', 'MSRStatus，SUCCESS或FAILED。']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.nn.probability.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.nn.probability.html", "text_entry": "['mindspore.nn.probability\\n', '用于构造概率网络的高级组件。\\n', '\\n', 'Bijectors\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.probability.bijector.Bijector\\n', '\\n', 'Bijector类。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.Exp\\n', '\\n', '指数Bijector（Exponential Bijector）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.GumbelCDF\\n', '\\n', 'GumbelCDF Bijector。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.Invert\\n', '\\n', '逆映射Bijector（Invert Bijector）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.PowerTransform\\n', '\\n', '乘方Bijector（PowerTransform Bijector）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.ScalarAffine\\n', '\\n', '标量仿射Bijector（Scalar Affine Bijector）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.Softplus\\n', '\\n', 'Softplus Bijector。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'Distributions\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.probability.distribution.Bernoulli\\n', '\\n', '伯努利分布（Bernoulli Distribution）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Beta\\n', '\\n', 'Beta 分布（Beta Distribution）。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.probability.distribution.Categorical\\n', '\\n', '分类分布。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Cauchy\\n', '\\n', '柯西分布（Cauchy distribution）。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.probability.distribution.Distribution\\n', '\\n', '所有分布的基类。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Exponential\\n', '\\n', '指数分布（Exponential Distribution）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Gamma\\n', '\\n', '伽马分布（Gamma distribution）。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.probability.distribution.Geometric\\n', '\\n', '几何分布（Geometric Distribution）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Gumbel\\n', '\\n', 'Gumbel分布（Gumbel distribution）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Logistic\\n', '\\n', 'Logistic分布（Logistic distribution）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.LogNormal\\n', '\\n', '对数正态分布（LogNormal distribution）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Normal\\n', '\\n', '正态分布（Normal distribution）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Poisson\\n', '\\n', '泊松分布（Poisson Distribution）。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.probability.distribution.TransformedDistribution\\n', '\\n', '转换分布（Transformed Distribution）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Uniform\\n', '\\n', '均匀分布（Uniform Distribution）。\\n', '\\n', 'Ascend GPU\\n', '\\n']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.nn.transformer.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.nn.transformer.html", "text_entry": "['mindspore.nn.transformer\\n', 'Note\\n', '\\n', 'Transformer网络。这些是实验性接口，可能会修改或删除。\\n', '\\n', 'classmindspore.nn.transformer.AttentionMask(seq_length, parallel_config=default_dpmp_config)[源代码]\\n', '从输入掩码中获取下三角矩阵。输入掩码是值为1或0的二维Tensor (batch_size, seq_length)。1表示当前位置是一个有效的标记，0则表示当前位置不是一个有效的标记。\\n', '\\n', '参数：\\n', '\\n', 'seq_length (int) - 表示输入Tensor的序列长度。\\n', '\\n', 'parallel_config (OpParallelConfig) - 表示并行配置。默认值为 default_dpmp_config ，表示一个带有默认参数的 OpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'input_mask (Tensor) - 掩码矩阵，shape为(batch_size, seq_length)，表示每个位置是否为有效输入。\\n', '\\n', '输出：\\n', '\\n', 'Tensor，表示shape为(batch_size, seq_length, seq_length)的注意力掩码矩阵。\\n', '\\n', '异常：\\n', '\\n', 'TypeError - seq_length 不是整数。\\n', '\\n', 'ValueError - seq_length 不是正数。\\n', '\\n', 'TypeError - parallel_config 不是OpParallelConfig的子类。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore.nn.transformer import AttentionMask\\n', 'from mindspore import Tensor\\n', 'mask = AttentionMask(seq_length=4)\\n', 'mask_array = np.array([[1, 1, 1, 0]], np.float32)\\n', 'inputs = Tensor(mask_array)\\n', 'res = mask(inputs)\\n', 'print(res)\\n', '\\n', '\\n', '\\n', '\\n', 'classmindspore.nn.transformer.VocabEmbedding(vocab_size, embedding_size, parallel_config=default_embedding_parallel_config, param_init=\"normal\")[源代码]\\n', '根据输入的索引查找参数表中的行作为返回值。当设置并行模式为 AUTO_PARALLEL_MODE 时，如果parallel_config.vocab_emb_dp为True时，那么embedding lookup表采用数据并行的方式，数据并行度为 parallel_config.data_parallel ，否则按 parallel_config.model_parallel 对embedding表中的第0维度进行切分。\\n', '\\n', 'Note\\n', '\\n', '启用 AUTO_PARALLEL / SEMI_AUTO_PARALLEL 模式时，此层仅支持2维度的输入，因为策略是为2D输入而配置的。\\n', '\\n', '参数：\\n', '\\n', 'vocab_size （int) - 表示查找表的大小。\\n', '\\n', 'embedding_size （int）- 表示查找表中每个嵌入向量的大小。\\n', '\\n', 'param_init （Union[Tensor, str, Initializer, numbers.Number]）- 表示embedding_table的Initializer。当指定字符串时，请参见 initializer 类了解字符串的值。默认值：’normal’。\\n', '\\n', 'parallel_config (EmbeddingOpParallelConfig) - 表示网络的并行配置。默认值为 default_embedding_parallel_config ，表示带有默认参数的 EmbeddingOpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'input_ids (Tensor) - shape为(batch_size, seq_length)的输入，其数据类型为int32。\\n', '\\n', '输出：\\n', '\\n', 'Tuple，表示一个包含(output, embedding_table)的元组。\\n', '\\n', 'output (Tensor) - shape为(batch_size, seq_length, embedding_size)嵌入向量查找结果。\\n', '\\n', 'weight (Tensor) - shape为(vocab_size, embedding_size)的嵌入表。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - parallel_config.vocab_emb_dp为True时，词典的大小不是parallel_config.model_parallel的倍数。\\n', '\\n', 'ValueError - vocab_size 不是正值。\\n', '\\n', 'ValueError - embedding_size 不是正值。\\n', '\\n', 'TypeError - parallel_config 不是OpParallelConfig的子类。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore.nn.transformer import VocabEmbedding\\n', 'from mindspore import Tensor\\n', 'from mindspore import dtype as mstype\\n', 'model = VocabEmbedding(vocab_size=30, embedding_size=30)\\n', 'tensor = Tensor(np.ones((20, 15)), mstype.int32)\\n', 'output, table = model(tensor)\\n', 'print(output.shape)\\n', '\\n', 'print(table.shape)\\n', '\\n', 'classmindspore.nn.transformer.MultiHeadAttention(batch_size, src_seq_length, tgt_seq_length, hidden_size, num_heads, hidden_dropout_rate=0.1, attention_dropout_rate=0.1, compute_dtype=mstype.float16, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, use_past=False, parallel_config=default_dpmp_config)[源代码]\\n', '论文 Attention Is All You Need 中所述的多头注意力的实现。给定src_seq_length长度的query向量，tgt_seq_length长度的key向量和value，注意力计算流程如下：\\n', '\\n', 'MultiHeadAttention(query,key,vector)=Dropout(Concat(head1,…,headh)WO)\\n', '其中， head_i = Attention(QW_i^Q, KW_i^K, VW_i^V) 。注意：输出层的投影计算中带有偏置参数。\\n', '\\n', '如果query tensor、key tensor和value tensor相同，则上述即为自注意力机制的计算过程。\\n', '\\n', '参数：\\n', '\\n', 'batch_size (int) - 表示训练批次的大小。\\n', '\\n', 'src_seq_length (int) - 表示query向量的序列长度。\\n', '\\n', 'tgt_seq_length (int) - 表示key向量和value向量的序列长度。\\n', '\\n', 'hidden_size (int) - 表示输入的向量大小。\\n', '\\n', 'num_heads (int) - 表示注意力机制中头的数量。\\n', '\\n', 'hidden_dropout_rate (float) - 表示最后dense输出的丢弃率。默认值：0.1\\n', '\\n', 'attention_dropout_rate (float) - 表示注意力score的丢弃率。默认值：0.1\\n', '\\n', 'compute_dtype (dtype.Number) - 表示dense中矩阵乘法的计算类型。默认值：dtype.float16。其值应为dtype.float32或dtype.float16。\\n', '\\n', 'param_init_type (dtype.Number) - 表示模块的参数初始化类型。默认值：dtype.float32。其值应为dtype.float32或dtype.float16。\\n', '\\n', 'softmax_compute_type (dtype.Number) - 表示softmax计算模块的类型。默认值：dtype.float32。 其值应为dtype.float32或dtype.float16。\\n', '\\n', 'use_past (bool) - 使用过去状态进行计算，用于增量预测。例如，如果我们有两个单词，想生成十个或以上单词。我们只需要计算一次这两个单词的状态，然后逐个生成下一个单词。当use_past为True时，有两个步骤可以执行预测。 第一步是通过 model.add_flags_recursive(is_first_iteration=True) 将is_first_iteration设为True，并传递完整的输入。然后，通过 model.add_flags_recursive(is_first_iteration=False) 将is_first_iteration设为False。此时，传递step的输入tensor，并对其进行循环。默认值：False\\n', '\\n', 'parallel_config (OpParallelConfig) - 表示并行配置。默认值为 default_dpmp_config ，表示一个带有参数的 OpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'query_tensor (Tensor) - use_past为False或is_first_iteration为True时，表示shape为(batch_size, src_seq_length, hidden_size)或(batch_size * src_seq_length, hidden_size)的query向量。否则，shape必须为(batch_size, 1, hidden_size)。\\n', '\\n', 'key_tensor (Tensor) - use_past为False或is_first_iteration为True时，表示shape为(batch_size, tgt_seq_length, hidden_size)或(batch_size * tgt_seq_length, hidden_size)的key向量。否则，shape必须为(batch_size, 1, hidden_size)。\\n', '\\n', 'value_tensor (Tensor) - use_past为False或is_first_iteration为True时，表示shape为(batch_size, tgt_seq_length, hidden_size)或(batch_size * tgt_seq_length, hidden_size)的value向量。否则，shape必须为(batch_size, 1, hidden_size)。\\n', '\\n', 'attention_mask (Tensor) - use_past为False或is_first_iteration为True时，表示shape为(batch_size, src_seq_length, tgt_seq_length)的注意力掩码矩阵。否则，shape必须为(batch_size, 1, tgt_seq_length)。\\n', '\\n', 'key_past (Tensor) - shape为(batch_size, num_heads, size_per_head, tgt_seq_length)的Float16 tensor， 表示过去所计算的key向量。 当use_past为True时，需要传入非None值用于增量预测。默认值为None。\\n', '\\n', 'value_past (Tensor) - shape为(batch_size, num_heads, tgt_seq_length, size_per_head)的Float16 tensor，表示过去所计算的value向量。 当use_past为True时，需要传入非None值用于增量预测。默认值为None。\\n', '\\n', 'batch_valid_length (Tensor) - shape为(batch_size,)的Int32 tensor，表示已经计算的token索引。 当use_past为True时，需要传入非None值用于增量预测。默认值为None。\\n', '\\n', '输出：\\n', '\\n', 'Tuple，表示一个包含(output, layer_present)的元组。\\n', '\\n', 'output (Tensor) - Tensor。use_past为False或is_first_iteration为True时，表示shape为(batch_size, src_seq_length, hidden_size)或(batch_size * src_seq_length, hidden_size)的层输出的float tensor。否则，shape将为(batch_size, 1, hidden_size)。\\n', '\\n', 'layer_present (Tuple) - 表示shape为((batch_size, num_heads, size_per_head, tgt_seq_length)或(batch_size, num_heads, tgt_seq_length, size_per_head))的投影key向量和value向量的Tensor的元组。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore.nn.transformer import MultiHeadAttention\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore import Tensor\\n', 'model = MultiHeadAttention(batch_size=2, hidden_size=15, src_seq_length=20, tgt_seq_length=20,\\n', '                           num_heads=3)\\n', 'from_tensor = Tensor(np.ones((2, 20, 15)), mstype.float32)\\n', 'to_tensor = Tensor(np.ones((2, 20, 15)), mstype.float16)\\n', 'attention_mask = Tensor(np.ones((2, 20, 20)), mstype.float16)\\n', 'attn_out, past = model(from_tensor, to_tensor, to_tensor, attention_mask)\\n', 'print(attn_out.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', '# When use use_past=True, it includes two steps to implement the incremental prediction.\\n', \"# Step 1: set is_first_iteration=True, and input the full sequence length's state.\\n\", '# We need to prepare the memory parameters for saving key and value states firstly.\\n', 'model = MultiHeadAttention(batch_size=2, hidden_size=15, src_seq_length=20, tgt_seq_length=20,\\n', '                           num_heads=3, use_past=True)\\n', 'key_past = Tensor(np.zeros(shape=(2, 3, 5, 20)), mstype.float16)\\n', 'value_past = Tensor(np.zeros(shape=(2, 3, 20, 5)), mstype.float16)\\n', 'batch_valid_length = Tensor(np.ones((2,)), mstype.int32)\\n', '# Set is_first_iteration=True to generate the full memory states\\n', 'model.add_flags_recursive(is_first_iteration=True)\\n', 'attn_out, past = model(from_tensor, to_tensor, to_tensor, attention_mask, key_past, value_past,\\n', '                       batch_valid_length)\\n', 'print(attn_out.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'from_tensor = Tensor(np.ones((2, 1, 15)), mstype.float32)\\n', 'to_tensor = Tensor(np.ones((2, 1, 15)), mstype.float16)\\n', 'attention_mask = Tensor(np.ones((2, 1, 20)), mstype.float16)\\n', '# Step 2: set is_first_iteration=False, and pass the single word to run the prediction rather than the\\n', '# full sequence.\\n', 'model.add_flags_recursive(is_first_iteration=False)\\n', 'attn_out, past = model(from_tensor, to_tensor, to_tensor, attention_mask, key_past, value_past,\\n', '                       batch_valid_length)\\n', 'print(attn_out.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'classmindspore.nn.transformer.FeedForward(hidden_size, ffn_hidden_size, dropout_rate, hidden_act=\"gelu\", expert_num=1, param_init_type=mstype.float32, parallel_config=default_dpmp_config)[源代码]\\n', '具有两层线性层的多层感知器，并在最终输出上使用Dropout。第一个线性层将输入维度从hidden_size投影到ffn_hidden_size，并在中间应用激活层。第二个线性层将该维度从ffn_hidden_size投影到hidden_size。配置parallel_config之后， 第一个线性层的权重将在输入维度上被分片，第二个线性层在输出维度上进行切分。总体过程如下\\n', '\\n', '其中 W1,W2,b1 和 b2 为可训练参数。\\n', '\\n', '参数：\\n', '\\n', 'hidden_size (int) - 表示输入的维度。\\n', '\\n', 'ffn_hidden_size (int) - 表示中间隐藏大小。\\n', '\\n', 'dropout_rate (float) - 表示第二个线性层输出的丢弃率。\\n', '\\n', 'hidden_act (str) - 表示第一个线性层的激活。其值可为’relu’、’relu6’、’tanh’、’gelu’、’fast_gelu’、’elu’、’sigmoid’、’prelu’、’leakyrelu’、’hswish’、’hsigmoid’、’logsigmoid’等等。默认值：’gelu’。\\n', '\\n', 'expert_num (int) - 表示线性层中使用的专家数量。对于expert_num > 1用例，使用BatchMatMul。BatchMatMul中的第一个维度表示expert_num。默认值：1\\n', '\\n', 'param_init_type (dtype.Number) - 表示参数初始化类型。其值应为dtype.float32或dtype.float16。默认值：dtype.float32\\n', '\\n', 'parallel_config (OpParallelConfig) - 表示并行配置。更多详情，请参见 OpParallelConfig 。默认值为 default_dpmp_config ，表示一个带有默认参数的 OpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'x (Tensor) - 应为 [batch, seq_length, hidden_size]或[batch * seq_length, hidden_size] 。表示浮点Tensor。\\n', '\\n', '输出：\\n', '\\n', 'Tensor，表示映射后该层的输出。shape为 [batch, seq_length, hidden_size] 或 [batch * seq_length, hidden_size] 。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - hidden_act 不是字符串。\\n', '\\n', 'TypeError - parallel_config 不是OpParallelConfig的子类。\\n', '\\n', 'ValueError - ffn_hidden_size 不是parallel_config中model_parallel的倍数。\\n', '\\n', 'ValueError - hidden_size 不是parallel_config中model_parallel的倍数。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore.nn.transformer import FeedForward\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore import Tensor\\n', 'model = FeedForward(hidden_size=15, ffn_hidden_size=30, dropout_rate=0.1)\\n', 'tensor = Tensor(np.ones((2, 20, 15)), mstype.float32)\\n', 'output = model(tensor)\\n', 'print(output.shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerEncoder(batch_size, num_layers, hidden_size, ffn_hidden_size, seq_length, num_heads, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, hidden_act=\"gelu\", post_layernorm_residual=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, lambda_func=None, offset=0, use_past=False, moe_config=default_moe_config, parallel_config=default_transformer_config)[源代码]\\n', 'Transformer中的编码器模块，具有多层堆叠的 TransformerEncoderLayer ，包括多头自注意力层和前馈层。\\n', '\\n', '参数：\\n', '\\n', 'batch_size (int) - 表示输入tensor的批次大小。\\n', '\\n', 'num_layers (int) - 表示 TransformerEncoderLayer 的层。\\n', '\\n', 'hidden_size (int) - 表示输入的隐藏大小。\\n', '\\n', 'ffn_hidden_size (int) - 表示前馈层中bottleneck的隐藏大小。\\n', '\\n', 'seq_length (int) - 表示输入序列长度。\\n', '\\n', 'num_heads (int) - 表示注意力头的数量。\\n', '\\n', 'hidden_dropout_rate (float) - 表示作用在隐藏层输出的丢弃率。默认值：0.1\\n', '\\n', 'attention_dropout_rate (float) - 表示注意力score的丢弃率。默认值：0.1\\n', '\\n', 'post_layernorm_residual (bool) - 表示是否在LayerNorm之前使用残差，即是否选择残差为Post-LayerNorm或者Pre-LayerNorm。默认值：False\\n', '\\n', 'hidden_act (str) - 表示内部前馈层的激活函数。其值可为’relu’、’relu6’、’tanh’、’gelu’、’fast_gelu’、’elu’、’sigmoid’、’prelu’、’leakyrelu’、’hswish’、’hsigmoid’、’logsigmoid’等等。默认值：gelu。\\n', '\\n', 'layernorm_compute_type (dtype.Number) - 表示LayerNorm的计算类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'softmax_compute_type (dtype.Number) - 表示注意力中softmax的计算类型。其值应为dtype.float32或dtype.float16。默认值为mstype.float32。\\n', '\\n', 'param_init_type (dtype.Number) - 表示模块的参数初始化类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'use_past (bool) - 使用过去状态进行计算，用于增量预测。例如，如果我们有两个单词，想生成十个或以上单词。我们只需要计算一次这两个单词的状态，然后逐个生成下一个单词。当use_past为True时，有两个步骤可以运行预测。第一步是通过 model.add_flags_recursive(is_first_iteration=True) 将is_first_iteration设为True，并传递完整的输入。然后，通过 model.add_flags_recursive(is_first_iteration=False) 将is_first_iteration设为False。此时，传递step的输入tensor，并对其进行环回。默认值：False\\n', '\\n', 'lambda_func - 表示设置融合索引、pipeline阶段和重计算属性的函数。如果用户想确定pipeline阶段和梯度聚合融合，用户可以传递一个接受 network 、 layer_id 、 offset 、 parallel_config 和 layers 的函数。 network(Cell) 表示transformer块， layer_id(int) 表示当前模块的层索引，从零开始计数， offset(int) 表示如果网络中还有其他模块，则layer_index需要一个偏置。pipeline的默认设置为： (layer_id + offset) // (layers / pipeline_stage) 。\\n', '\\n', 'offset (int) - 表示 decoder 的初始层索引。其用于设置梯度聚合的融合值和流水线并行的stage值。\\n', '\\n', 'moe_config (MoEConfig) - 表示MoE (Mixture of Expert)的配置。\\n', '\\n', 'parallel_config (TransformerOpParallelConfig) - 表示并行配置。默认值为 default_transformer_config ，表示带有默认参数的 TransformerOpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'hidden_states (Tensor) - Tensor。如果use_past为False或者is_first_iteration为True，shape为[batch_size, seq_length, hidden_size]或者[batch_size * seq_length, hidden_size]。否则，shape应为[batch_size, 1, hidden_size]。\\n', '\\n', 'attention_mask (Tensor) - Tensor，表示shape为[[batch_size, seq_length, seq_length]的注意力掩码。\\n', '\\n', 'init_reset (Tensor) - shape为[1]的bool tensor，用于清除增量预测中使用的past key参数和past value参数。仅当use_past为True时有效。默认值为True。\\n', '\\n', 'batch_valid_length (Tensor) - shape为[batch_size]的Int32 tensor，表示过去所计算的索引。当use_past为True时，它用于增量预测。默认值为None。\\n', '\\n', '输出：\\n', '\\n', 'Tuple，表示一个包含(output, layer_present)的元组。\\n', '\\n', 'output (Tensor) - use_past为False或is_first_iteration为True时，表示shape为(batch_size, seq_length, hidden_size)或(batch_size * seq_length, hidden_size)的层输出的float tensor。否则，shape将为(batch_size, 1, hidden_size)。\\n', '\\n', 'layer_present (Tuple) - 大小为num_layers的元组，其中每个元组都包含shape为((batch_size, num_heads, size_per_head, seq_length)或(batch_size, num_heads, seq_length, size_per_head))的投影key向量和value向量的Tensor的元组。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import TransformerEncoder\\n', 'from mindspore import Tensor\\n', 'model = TransformerEncoder(batch_size=2, num_layers=2, hidden_size=8, ffn_hidden_size=64,\\n', '                           seq_length=16, num_heads=2)\\n', 'encoder_input_value = Tensor(np.ones((2, 16, 8)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 16, 16)), mstype.float16)\\n', 'output, past = model(encoder_input_value, encoder_input_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(len(past))\\n', '\\n', 'print(past[0][0].shape)\\n', '\\n', 'print(past[0][1].shape)\\n', '\\n', '# When use use_past=True, it includes two steps to implement the incremental prediction.\\n', \"# Step 1: set is_first_iteration=True, and input the full sequence length's state.\\n\", 'batch_valid_length = Tensor(np.ones((2,)), mstype.int32)\\n', 'init_reset = Tensor([True], mstype.bool_)\\n', '# Set is_first_iteration=True to generate the full memory states\\n', 'model = TransformerEncoder(batch_size=2, hidden_size=8, ffn_hidden_size=64, seq_length=16,\\n', '                           num_heads=2, num_layers=2, use_past=True)\\n', 'model.add_flags_recursive(is_first_iteration=True)\\n', 'hidden, past = model(encoder_input_value, encoder_input_mask, init_reset, batch_valid_length)\\n', 'print(hidden.shape)\\n', '\\n', 'print(past[0][0].shape)\\n', '\\n', 'print(past[0][1].shape)\\n', '\\n', 'encoder_input_value = Tensor(np.ones((2, 1, 8)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 1, 16)), mstype.float16)\\n', 'init_reset = Tensor([False], mstype.bool_)\\n', '# Step 2: set is_first_iteration=False, and pass the single word to run the prediction rather than\\n', '# the full sequence.\\n', 'model.add_flags_recursive(is_first_iteration=False)\\n', 'hidden, past = model(encoder_input_value, encoder_input_mask, init_reset, batch_valid_length)\\n', 'print(hidden.shape)\\n', '\\n', 'print(past[0][0].shape)\\n', '\\n', 'print(past[0][1].shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerDecoder(num_layers, batch_size, hidden_size, ffn_hidden_size, src_seq_length, tgt_seq_length, num_heads, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, post_layernorm_residual=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, hidden_act=\"gelu\", lambda_func=None, use_past=False, offset=0, moe_config=default_moe_config, parallel_config=default_transformer_config)[源代码]\\n', 'Transformer中的解码器模块，为多层堆叠的 TransformerDecoderLayer ，包括多头自注意力层、交叉注意力层和前馈层。\\n', '\\n', '参数：\\n', '\\n', 'batch_size (int) - 表示输入Tensor的批次大小。\\n', '\\n', 'num_layers (int) - 表示 TransformerDecoderLayer 的层数。\\n', '\\n', 'hidden_size (int) - 表示输入的隐藏大小。\\n', '\\n', 'ffn_hidden_size (int) - 表示前馈层中bottleneck的隐藏大小。\\n', '\\n', 'src_seq_length (int) - 表示输入源序列长度。\\n', '\\n', 'tgt_seq_length (int) - 表示输入目标序列长度。\\n', '\\n', 'num_heads (int) - 表示注意力头的数量。\\n', '\\n', 'hidden_dropout_rate (float) - 表示作用在隐藏层输出的丢弃率。默认值：0.1\\n', '\\n', 'attention_dropout_rate (float) - 表示注意力score的丢弃率。默认值：0.1\\n', '\\n', 'post_layernorm_residual (bool) - 表示是否在LayerNorm之前使用残差，即是否选择残差为Post-LayerNorm或者Pre-LayerNorm。默认值：False\\n', '\\n', 'hidden_act (str) - 表示内部前馈层的激活函数。其值可为’relu’、’relu6’、’tanh’、’gelu’、’fast_gelu’、’elu’、’sigmoid’、’prelu’、’leakyrelu’、’hswish’、’hsigmoid’、’logsigmoid’等等。默认值：gelu。\\n', '\\n', 'layernorm_compute_type (dtype.Number) - 表示LayerNorm的计算类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'use_past (bool) - 表示是否开启增量推理。在推理中会缓存注意力机制计算结果，避免冗余计算。默认值为False。\\n', '\\n', 'softmax_compute_type (dtype.Number) - 表示注意力中softmax的计算类型。其值应为dtype.float32或dtype.float16。默认值为mstype.float32。\\n', '\\n', 'param_init_type (dtype.Number) - 表示模块的参数初始化类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'offset (int) - 表示 decoder 的初始层索引偏移值。其用于设置梯度聚合的融合值和流水线并行的stage值，使其不与编码器层的相关属性重叠。\\n', '\\n', 'lambda_func - 表示确定梯度融合索引、pipeline阶段和重计算属性的函数。如果用户想确定pipeline阶段和梯度聚合融合，用户可以传递一个接受 network 、 layer_id 、 offset 、 parallel_config 和 layers 的函数。 network(Cell) 表示transformer块， layer_id(int) 表示当前模块的层索引，从零开始计数， offset(int) 表示如果网络中还有其他模块，则layer_index需要一个偏置。pipeline的默认设置为： (layer_id + offset) // (layers / pipeline_stage) 。默认值：None\\n', '\\n', 'moe_config (MoEConfig) - 表示MoE (Mixture of Expert)的配置。\\n', '\\n', 'parallel_config (TransformerOpParallelConfig) - 表示并行配置。默认值为 default_transformer_config ，表示带有默认参数的 TransformerOpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'hidden_stats (Tensor) - shape为[batch_size, seq_length, hidden_size]或[batch_size * seq_length, hidden_size]的输入tensor。\\n', '\\n', 'attention_mask (Tensor) - shape为[batch_size, seq_length, seq_length]的解码器的注意力掩码。\\n', '\\n', 'encoder_output (Tensor) - shape为[batch_size, seq_length, hidden_size]或[batch_size * seq_length, hidden_size]的编码器的输出。\\n', '\\n', 'memory_mask (Tensor) - shape为[batch, tgt_seq_length, src_seq_length]的交叉注意力的memory掩码，其中tgt_seq_length表示解码器的长度。注：当网络位于最外层时，此参数不能通过None传递。默认值为None。\\n', '\\n', 'init_reset (Tensor) - shape为[1]的bool tensor，用于清除增量预测中使用的past key参数和past value参数。仅当use_past为True时有效。默认值为True。\\n', '\\n', 'batch_valid_length (Tensor) - shape为[batch_size]的Int32 tensor，表示过去所计算的索引。当use_past为True时，它用于增量预测。默认值为None。\\n', '\\n', '输出：\\n', '\\n', 'Tuple，表示一个包含(output, layer_present)的元组。\\n', '\\n', 'output (Tensor) - 输出的logit。shape为[batch, tgt_seq_length, hidden_size]或[batch * tgt_seq_length, hidden_size]。\\n', '\\n', 'layer_present (Tuple) - 大小为层数的元组，其中每个元组都是shape为((batch_size, num_heads, size_per_head, tgt_seq_length)或(batch_size, num_heads, tgt_seq_length, size_per_head)的自注意力中的投影key向量和value向量的tensor的元组，或者是shape为(batch_size, num_heads, size_per_head, src_seq_length)或(batch_size, num_heads, src_seq_length, size_per_head))的交叉注意力中的投影key向量和value向量的tensor的元组。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import TransformerDecoder\\n', 'from mindspore import Tensor\\n', 'model = TransformerDecoder(batch_size=2, num_layers=1, hidden_size=64, ffn_hidden_size=64,\\n', '                           num_heads=2, src_seq_length=20, tgt_seq_length=10)\\n', 'encoder_input_value = Tensor(np.ones((2, 20, 64)), mstype.float32)\\n', 'decoder_input_value = Tensor(np.ones((2, 10, 64)), mstype.float32)\\n', 'decoder_input_mask = Tensor(np.ones((2, 10, 10)), mstype.float16)\\n', 'memory_mask = Tensor(np.ones((2, 10, 20)), mstype.float16)\\n', 'output, past = model(decoder_input_value, decoder_input_mask, encoder_input_value, memory_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(len(past))\\n', '\\n', 'print(past[0][0].shape)\\n', '\\n', 'print(past[0][1].shape)\\n', '\\n', 'print(past[0][2].shape)\\n', '\\n', 'print(past[0][3].shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerEncoderLayer(batch_size, hidden_size, ffn_hidden_size, num_heads, seq_length, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, post_layernorm_residual=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, hidden_act=\"gelu\", use_past=False, moe_config=default_moe_config, parallel_config=default_dpmp_config)[源代码]\\n', 'Transformer的编码器层。Transformer的编码器层上的单层的实现，包括多头注意力层和前馈层。\\n', '\\n', '参数：\\n', '\\n', 'batch_size (int) - 表示输入Tensor的批次大小。\\n', '\\n', 'hidden_size (int) - 表示输入的隐藏大小。\\n', '\\n', 'seq_length (int) - 表示输入序列长度。\\n', '\\n', 'ffn_hidden_size (int) - 表示前馈层中bottleneck的隐藏大小。\\n', '\\n', 'num_heads (int) - 表示注意力头的数量。\\n', '\\n', 'hidden_dropout_rate (float) - 表示作用在隐藏层输出的丢弃率。默认值：0.1\\n', '\\n', 'attention_dropout_rate (float) - 表示注意力score的丢弃率。默认值：0.1\\n', '\\n', 'post_layernorm_residual (bool) - 表示是否在LayerNorm之前使用残差，即是否选择残差为Post-LayerNorm或者Pre-LayerNorm。默认值：False\\n', '\\n', 'hidden_act (str) - 表示内部前馈层的激活函数。其值可为’relu’、’relu6’、’tanh’、’gelu’、’fast_gelu’、’elu’、’sigmoid’、’prelu’、’leakyrelu’、’hswish’、’hsigmoid’、’logsigmoid’等等。默认值：gelu。\\n', '\\n', 'layernorm_compute_type (dtype.Number) - 表示LayerNorm的计算类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'softmax_compute_type (dtype.Number) - 表示注意力中softmax的计算类型。其值应为dtype.float32或dtype.float16。默认值为mstype.float32。\\n', '\\n', 'param_init_type (dtype.Number) - 表示模块的参数初始化类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'use_past (bool) - 使用过去状态进行计算，用于增量预测。例如，如果我们有两个单词，想生成十个或以上单词。我们只需要计算一次这两个单词的状态，然后逐个生成下一个单词。当use_past为True时，有两个步骤可以运行预测。第一步是通过 model.add_flags_recursive(is_first_iteration=True) 将is_first_iteration设为True，并传递完整的输入。然后，通过 model.add_flags_recursive(is_first_iteration=False) 将is_first_iteration设为False。此时，传递step的输入tensor，并对其进行环回。默认值：False\\n', '\\n', 'moe_config (MoEConfig) - 表示MoE (Mixture of Expert)的配置。\\n', '\\n', 'parallel_config (OpParallelConfig) - 表示并行配置。默认值为 default_dpmp_config ，表示一个带有默认参数的 OpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'x (Tensor) - Float Tensor。如果use_past为False或者is_first_iteration为True，shape应为[batch_size, seq_length, hidden_size]或者[batch_size * seq_length, hidden_size]。否则，shape应为[batch_size, 1, hidden_size]。\\n', '\\n', 'input_mask (Tensor) - Float tensor。use_past为False或者is_first_iteration为True时，表示shape为[batch_size, seq_length, seq_length]的注意力掩码。否则，shape应为[batch_size, 1, hidden_size]。\\n', '\\n', 'init_reset (Tensor) - shape为[1]的bool tensor，用于清除增量预测中使用的past key参数和past value参数。仅当use_past为True时有效。默认值为True。\\n', '\\n', 'batch_valid_length (Tensor) - shape为[batch_size]的Int32 tensor，表示过去所计算的索引。当use_past为True时，它用于增量预测。默认值为None。\\n', '\\n', '输出：\\n', '\\n', 'Tuple，表示一个包含(output, layer_present)的元组。\\n', '\\n', 'output (Tensor) - use_past为False或is_first_iteration为True时，表示shape为(batch_size, seq_length, hidden_size)或(batch_size * seq_length, hidden_size)的层输出的float tensor。否则，shape将为(batch_size, 1, hidden_size)。\\n', '\\n', 'layer_present (Tuple) - 表示shape为((batch_size, num_heads, size_per_head, seq_length)或(batch_size, num_heads, seq_length, size_per_head))的投影key向量和value向量的Tensor的元组。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import TransformerEncoderLayer\\n', 'from mindspore import Tensor\\n', 'model = TransformerEncoderLayer(batch_size=2, hidden_size=8, ffn_hidden_size=64, seq_length=16,\\n', '                                num_heads=2)\\n', 'encoder_input_value = Tensor(np.ones((2, 16, 8)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 16, 16)), mstype.float16)\\n', 'output, past = model(encoder_input_value, encoder_input_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', '# When use use_past=True, it includes two steps to implement the incremental prediction.\\n', \"# Step 1: set is_first_iteration=True, and input the full sequence length's state.\\n\", 'batch_valid_length = Tensor(np.ones((2,)), mstype.int32)\\n', 'init_reset = Tensor([True], mstype.bool_)\\n', '# Set is_first_iteration=True to generate the full memory states\\n', 'model = TransformerEncoderLayer(batch_size=2, hidden_size=8, ffn_hidden_size=64, seq_length=16,\\n', '                                num_heads=2, use_past=True)\\n', 'model.add_flags_recursive(is_first_iteration=True)\\n', 'hidden, past = model(encoder_input_value, encoder_input_mask, init_reset, batch_valid_length)\\n', 'print(hidden.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'encoder_input_value = Tensor(np.ones((2, 1, 8)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 1, 16)), mstype.float16)\\n', 'init_reset = Tensor([False], mstype.bool_)\\n', '# Step 2: set is_first_iteration=False, and pass the single word to run the prediction rather than\\n', '# the full sequence.\\n', 'model.add_flags_recursive(is_first_iteration=False)\\n', 'hidden, past = model(encoder_input_value, encoder_input_mask, init_reset, batch_valid_length)\\n', 'print(hidden.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerDecoderLayer(hidden_size, ffn_hidden_size, num_heads, batch_size, src_seq_length, tgt_seq_length, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, post_layernorm_residual=False, use_past=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, hidden_act=\"gelu\", moe_config=default_moe_config, parallel_config=default_dpmp_config)[源代码]\\n', 'Transformer的解码器层。Transformer的解码器层上的单层的实现，包括自注意力层、交叉注意力层和前馈层。当encoder_output为None时，交叉注意力将无效。\\n', '\\n', '参数：\\n', '\\n', 'batch_size (int) - 表示输入Tensor的批次大小。\\n', '\\n', 'hidden_size (int)：表示输入的隐藏大小。\\n', '\\n', 'src_seq_length (int) - 表示输入源序列长度。\\n', '\\n', 'tgt_seq_length (int) - 表示输入目标序列长度。\\n', '\\n', 'ffn_hidden_size (int) - 表示前馈层中bottleneck的隐藏大小。\\n', '\\n', 'num_heads (int) - 表示注意力头的数量。\\n', '\\n', 'hidden_dropout_rate (float) - 表示作用在隐藏层输出的丢弃率。默认值：0.1\\n', '\\n', 'attention_dropout_rate (float) - 表示注意力score的丢弃率。默认值：0.1\\n', '\\n', 'post_layernorm_residual (bool) - 表示是否在LayerNorm之前使用残差，即是否选择残差为Post-LayerNorm或者Pre-LayerNorm。默认值：False\\n', '\\n', 'hidden_act (str) - 表示内部前馈层的激活函数。其值可为’relu’、’relu6’、’tanh’、’gelu’、’fast_gelu’、’elu’、’sigmoid’、’prelu’、’leakyrelu’、’hswish’、’hsigmoid’、’logsigmoid’等等。默认值：gelu。\\n', '\\n', 'layernorm_compute_type (dtype.Number) - 表示LayerNorm的计算类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'softmax_compute_type (dtype.Number) - 表示注意力中softmax的计算类型。其值应为dtype.float32或dtype.float16。默认值为mstype.float32。\\n', '\\n', 'param_init_type (dtype.Number) - 表示模块的参数初始化类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'use_past (bool) - 使用过去状态进行计算，用于增量预测。默认值：False\\n', '\\n', 'moe_config (MoEConfig) - 表示MoE (Mixture of Expert)的配置。\\n', '\\n', 'parallel_config (OpParallelConfig) - 表示并行配置。默认值为 default_dpmp_config ，表示一个带有默认参数的 OpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'hidden_stats (Tensor) - shape为[batch_size, tgt_seq_length, hidden_size]或[batch_size * tgt_seq_length, hidden_size]的输入tensor。\\n', '\\n', 'decoder_mask (Tensor) - shape为[batch_size, src_seq_length, seq_length]的解码器的注意力掩码。\\n', '\\n', 'encoder_output (Tensor) - shape为[batch_size, seq_length, hidden_size]或[batch_size * seq_length, hidden_size]的编码器的输出。注：当网络位于最外层时，此参数不能通过None传递。默认值为None。\\n', '\\n', 'memory_mask (Tensor) - shape为[batch, tgt_seq_length, src_seq_length]的交叉注意力的memory掩码，其中tgt_seq_length表示解码器的长度。注：当网络位于最外层时，此参数不能通过None传递。默认值为None。\\n', '\\n', 'init_reset (Tensor) - shape为[1]的bool tensor，用于清除增量预测中使用的past key参数和past value参数。仅当use_past为True时有效。默认值为True。\\n', '\\n', 'batch_valid_length (Tensor) - shape为[batch_size]的Int32 tensor，表示过去所计算的索引。当use_past为True时，它用于增量预测。默认值为None。\\n', '\\n', '输出：\\n', '\\n', 'Tuple，表示一个包含(output, layer_present)的元组。\\n', '\\n', 'output (Tensor) - 此层的输出logit。shape为[batch, seq_length, hidden_size]或[batch * seq_length, hidden_size]。\\n', '\\n', 'layer_present (Tuple) - 元组，其中每个元组都是shape为((batch_size, num_heads, size_per_head, tgt_seq_length)或(batch_size, num_heads, tgt_seq_length, size_per_head)的自注意力中的投影key向量和value向量的tensor的元组，或者是shape为(batch_size, num_heads, size_per_head, src_seq_length)或(batch_size, num_heads, src_seq_length, size_per_head))的交叉注意力中的投影key向量和value向量的tensor的元组。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import TransformerDecoderLayer\\n', 'from mindspore import Tensor\\n', 'model = TransformerDecoderLayer(batch_size=2, hidden_size=64, ffn_hidden_size=64, num_heads=2,\\n', '                                src_seq_length=20, tgt_seq_length=10)\\n', 'encoder_input_value = Tensor(np.ones((2, 20, 64)), mstype.float32)\\n', 'decoder_input_value = Tensor(np.ones((2, 10, 64)), mstype.float32)\\n', 'decoder_input_mask = Tensor(np.ones((2, 10, 10)), mstype.float16)\\n', 'memory_mask = Tensor(np.ones((2, 10, 20)), mstype.float16)\\n', 'output, past = model(decoder_input_value, decoder_input_mask, encoder_input_value, memory_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'print(past[2].shape)\\n', '\\n', 'print(past[3].shape)\\n', '\\n', 'classmindspore.nn.transformer.Transformer(hidden_size, batch_size, ffn_hidden_size, src_seq_length, tgt_seq_length, encoder_layers=3, decoder_layers=3, num_heads=2, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, hidden_act=\"gelu\", post_layernorm_residual=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, lambda_func=None, use_past=False, moe_config=default_moe_config, parallel_config=default_transformer_config)[源代码]\\n', 'Transformer模块，包括编码器和解码器。与原始的实现方式的区别在于该模块在实行层归一化之前使用了残差加法。默认的激活层为 gelu 。 详细信息可参考 Attention Is All You Need 。\\n', '\\n', 'Note\\n', '\\n', '这是一个实验接口，可能会被更改或者删除。\\n', '\\n', '参数：\\n', '\\n', 'batch_size (int) - 表示输入的批次大小。\\n', '\\n', 'encoder_layers (int) - 表示 TransformerEncoderLayer 的层数。\\n', '\\n', 'decoder_layers (int) - 表示 TransformerDecoderLayer 的层数。\\n', '\\n', 'hidden_size (int) - 表示输入向量的大小。\\n', '\\n', 'ffn_hidden_size (int) - 表示前馈层中bottleneck的隐藏大小。\\n', '\\n', 'src_seq_length (int) - 表示编码器的输入Tensor的seq_length。\\n', '\\n', 'tgt_seq_length (int) - 表示解码器的输入Tensor的seq_length。\\n', '\\n', 'num_heads (int) - 表示注意力头的数量。默认值：2\\n', '\\n', 'hidden_dropout_rate (float) - 表示作用在隐藏层输出的丢弃率。默认值：0.1\\n', '\\n', 'attention_dropout_rate (float) - 表示注意力score的丢弃率。默认值：0.1\\n', '\\n', 'post_layernorm_residual (bool) - 表示是否在LayerNorm之前使用残差，即是否选择残差为Post-LayerNorm或者Pre-LayerNorm。默认值：False\\n', '\\n', 'use_past (bool) - 表示是否开启增量推理。在推理中会缓存注意力机制计算结果，避免冗余计算。默认值为False。\\n', '\\n', 'layernorm_compute_type (dtype.Number) - 表示LayerNorm的计算类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'softmax_compute_type (dtype.Number) - 表示注意力机制中softmax的计算类型。其值应为dtype.float32或dtype.float16。默认值为mstype.float32。\\n', '\\n', 'param_init_type (dtype.Number) - 表示模块的参数初始化类型。其值应为dtype.float32或dtype.float16。默认值为dtype.float32。\\n', '\\n', 'hidden_act (str) - 表示前馈层的激活行为。其值可为’relu’、’relu6’、’tanh’、’gelu’、’fast_gelu’、’elu’、’sigmoid’、’prelu’、’leakyrelu’、’hswish’、’hsigmoid’、’logsigmoid’等等。默认值：gelu。\\n', '\\n', 'moe_config (MoEConfig) - 表示MoE (Mixture of Expert)的配置。\\n', '\\n', 'lambda_func - 表示设置融合索引、pipeline阶段和重计算属性的函数。如果用户想确定pipeline阶段和梯度融合，用户可以传递一个接受 network 、 layer_id 、 offset 、 parallel_config 和 layers 的函数。 network(Cell) 表示transformer块， layer_id(int) 表示当前模块的层索引，从零开始计数， offset(int) 表示如果网络中还有其他模块，则layer_id需要一个偏移。pipeline的默认设置为： (layer_id + offset) // ((encoder_layers + decoder_length) / pipeline_stage) 。\\n', '\\n', 'parallel_config (TransformerOpParallelConfig) - 表示并行配置。默认值为 default_transformer_config ，表示带有默认参数的 TransformerOpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'encoder_inputs (Tensor) - shape为[batch_size, seq_length, hidden_size]或[batch_size * seq_length, hidden_size]的输入Tensor。\\n', '\\n', 'encoder_masks (Tensor) - shape为[batch_size, seq_length, seq_length]的解码器的注意力掩码。\\n', '\\n', 'decoder_inputs (Tensor) - shape为[batch_size, seq_length, hidden_size]或[batch_size * seq_length, hidden_size]的编码器的输出。如果解码器层数为0，则此值应为None。\\n', '\\n', 'decoder_masks (Tensor) - shape为[batch_size, seq_length, seq_length]的解码器的注意力掩码。\\n', '\\n', 'memory_mask (Tensor) - shape为[batch, tgt_seq_length, src_seq_length]的交叉注意力的memory掩码，其中tgt_seq_length表示解码器的长度。如果解码器层为0，则shape为[batch_size, seq_length, hidden_size]的编码器的输出应为None。\\n', '\\n', 'init_reset (Tensor) - shape为[1]的bool tensor，用于清除增量预测中使用的past key参数和past value参数。仅当use_past为True时有效。默认值为True。\\n', '\\n', 'batch_valid_length (Tensor) - shape为[batch_size]的Int32 tensor，表示过去所计算的索引。当use_past为True时，它用于增量预测。默认值为None。\\n', '\\n', '输出：\\n', '\\n', 'Tuple，表示包含(output, encoder_layer_present, encoder_layer_present, accum_loss)的元组。\\n', '\\n', 'output (Tensor) - 如果只有编码器，则表示编码器层的输出logit。shape为[batch, src_seq_length, hidden_size] or [batch * src_seq_length, hidden_size]。如果有编码器和解码器，则输出来自于解码器层。shape为[batch, tgt_seq_length, hidden_size]或[batch * tgt_seq_length, hidden_size]。\\n', '\\n', 'encoder_layer_present (Tuple) - 大小为num_layers的元组，其中每个元组都是shape为((batch_size, num_heads, size_per_head, src_seq_length)或(batch_size, num_heads, src_seq_length, size_per_head))的自注意力中的投影key向量和value向量的tensor的元组。\\n', '\\n', 'decoder_layer_present (Tuple) - 大小为num_layers的元组，其中每个元组都是shape为((batch_size, num_heads, size_per_head, tgt_seq_length)或(batch_size, num_heads, tgt_seq_length, size_per_head))的self attention中的投影key向量和value向量的tensor的元组，或者是shape为(batch_size, num_heads, size_per_head, src_seq_length)或(batch_size, num_heads, src_seq_length, size_per_head))的交叉注意力中的投影key向量和value向量的tensor的元组。如果未设置解码器，返回值将为None。\\n', '\\n', 'accum_loss (Tensor) - 表示一个辅助损失来最小化路由到每个专家的数据部分的均方，且仅仅在专家数大于1时才会返回。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import Transformer\\n', 'from mindspore import Tensor\\n', 'model = Transformer(batch_size=2, encoder_layers=1, decoder_layers=2, hidden_size=64,\\n', '                    ffn_hidden_size=64, src_seq_length=20, tgt_seq_length=10)\\n', 'encoder_input_value = Tensor(np.ones((2, 20, 64)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 20, 20)), mstype.float16)\\n', 'decoder_input_value = Tensor(np.ones((2, 10, 64)), mstype.float32)\\n', 'decoder_input_mask = Tensor(np.ones((2, 10, 10)), mstype.float16)\\n', 'memory_mask = Tensor(np.ones((2, 10, 20)), mstype.float16)\\n', 'output, en_past, de_past = model(encoder_input_value, encoder_input_mask, decoder_input_value,\\n', '                                 decoder_input_mask, memory_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(len(en_past))\\n', '\\n', 'print(len(de_past))\\n', '\\n', 'print(en_past[0][0].shape)\\n', '\\n', 'print(en_past[0][1].shape)\\n', '\\n', 'print(de_past[0][0].shape)\\n', '\\n', 'print(de_past[0][1].shape)\\n', '\\n', 'print(de_past[0][2].shape)\\n', '\\n', 'print(de_past[0][3].shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerOpParallelConfig(data_parallel=1, model_parallel=1, expert_parallel=1, pipeline_stage=1, micro_batch_num=1, recompute=default_transformer_recompute_config, optimizer_shard=False, gradient_aggregation_group=4, vocab_emb_dp=True)[源代码]\\n', '用于设置数据并行、模型并行等等并行配置的TransformerOpParallelConfig。\\n', '\\n', 'Note\\n', '\\n', '除recompute参数外，当用户未将auto_parallel_context设为 SEMI_AUTO_PARALLEL 或 AUTO_PARALLEL 时，其他参数将无效。 在训练时，micro_batch_num的值必须大于或等于equal to pipeline_stage的值。data_parallel*model_parallel *pipeline_stage的值必须等于或小于总设备的数量。设置pipeline_stage和optimizer_shard时，其配置将覆盖auto_parallel_context的配置。\\n', '\\n', '参数：\\n', '\\n', 'data_parallel (int) - 表示数据并行数。默认值：1。\\n', '\\n', 'model_parallel (int) - 表示模型并行数。默认值：1。\\n', '\\n', 'expert_parallel (int) - 表示专家并行数，只有在应用混合专家结构（MoE，Mixture of Experts）时才会生效。默认值：1.\\n', '\\n', 'pipeline_stage (int) - 表示将Transformer切分成的stage数目。其值应为正数。默认值：1。\\n', '\\n', 'micro_batch_num (int) - 表示用于pipeline训练的batch的微型大小。默认值：1。\\n', '\\n', 'optimizer_shard (bool) - 表示是否使能优化器切分。默认值：False。\\n', '\\n', 'gradient_aggregation_group (int) - 表示优化器切分的融合组大小。默认值：4。\\n', '\\n', 'recompute (bool) - 表示是否启用transformer每层的的重计算。默认值：False。\\n', '\\n', 'vocab_emb_dp (bool) - 表示Embedding表是否为数据并行，否则将在查找表中的第0维度根据模型并行度进行切分。默认值：True。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.nn.transformer import TransformerRecomputeConfig\\n', 'recompute_config=TransformerRecomputeConfig(recompute=True, parallel_optimizer_comm_recompute=True, \\\\\\n', '                                            mp_comm_recompute=True, recompute_slice_activation=True)\\n', 'config=TransformerOpParallelConfig(data_parallel=1, model_parallel=1, recompute=recompute_config)\\n', 'dp_mp_config()\\n', '获取包含数据并行、模型并行度的DPMPlConfig。\\n', '\\n', 'embedding_dp_mp_config()\\n', '获取包含数据并行、模型并行和embedding并行度的EmbeddingParallelConfig。\\n', '\\n', 'classmindspore.nn.transformer.EmbeddingOpParallelConfig(data_parallel=1, model_parallel=1, vocab_emb_dp=True)[源代码]\\n', 'VocabEmbedding 类中的并行配置。当vocab_emb_dp为True时，设置Embedding查找为数据并行，其中model_parallel参数会被忽略。当vocab_emb_dp为False时，在Embedding表的第0轴进行按model_parallel的大小进行切分。\\n', '\\n', '参数：\\n', '\\n', 'data_parallel (int) - 表示数据并行度。默认值：1。\\n', '\\n', 'model_parallel (int) - 表示模型平行度。默认值：1。\\n', '\\n', 'vocab_emb_dp (bool) - 表示模型并行或数据并行中的Shard embedding。默认值：True。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.nn.transformer import EmbeddingOpParallelConfig\\n', 'config=EmbeddingOpParallelConfig(data_parallel=1, model_parallel=1, vocab_emb_dp=True)\\n', 'dp_mp_config()\\n', '获取包含有data_parallel和model_parallel属性的DPMPlConfig类。\\n', '\\n', 'classmindspore.nn.transformer.TransformerRecomputeConfig(recompute=False, parallel_optimizer_comm_recompute=False, mp_comm_recompute=True, recompute_slice_activation=False)[源代码]\\n', 'Transformer的重计算配置接口。\\n', '\\n', '参数：\\n', '\\n', 'recompute (bool) - 是否使能重计算。默认值为False。\\n', '\\n', 'parallel_optimizer_comm_recompute (bool) - 指定由优化器切分产生的AllGather算子是否进行重计算。默认值为False。\\n', '\\n', 'mp_comm_recompute (bool) - 指定由模型并行成分产生的通信算子是否进行重计算。默认值为False。\\n', '\\n', 'recompute_slice_activation (bool) - 指定激活层是否切片保存。默认值为False。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.nn.transformer import TransformerRecomputeConfig\\n', 'config=TransformerRecomputeConfig(recompute=True, parallel_optimizer_comm_recompute=True, \\\\\\n', '                                  mp_comm_recompute=True, recompute_slice_activation=True)\\n', 'classmindspore.nn.transformer.CrossEntropyLoss(parallel_config=default_dpmp_config)[源代码]\\n', '计算输入和输出之间的交叉熵损失。\\n', '\\n', '参数：\\n', '\\n', 'parallel_config (OpParallelConfig, MoEParallelConfig) - 表示并行配置。默认值为 default_dpmp_config ，表示一个带有默认参数的 OpParallelConfig 实例。\\n', '\\n', '输入：\\n', '\\n', 'logits (Tensor) - shape为(N, C)的Tensor。表示的输出logits。其中N表示任意大小的维度，C表示类别个数。数据类型必须为float16或float32。\\n', '\\n', 'labels (Tensor) - shape为(N, )的Tensor。表示样本的真实标签，其中每个元素的取值区间为[0,C)。\\n', '\\n', 'input_mask (Tensor) - shape为(N, )的Tensor。input_mask表示是否有填充输入。1表示有效，0表示无效，其中元素值为0的位置不会计算进损失值。\\n', '\\n', '输出：\\n', '\\n', 'Tensor，表示对应的交叉熵损失。\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import CrossEntropyLoss\\n', 'from mindspore import Tensor\\n', 'loss = CrossEntropyLoss()\\n', 'logits = Tensor(np.array([[3, 5, 6, 9, 12, 33, 42, 12, 32, 72]]), mstype.float32)\\n', 'labels_np = np.array([1]).astype(np.int32)\\n', 'input_mask = Tensor(np.ones(1).astype(np.float32))\\n', 'labels = Tensor(labels_np)\\n', 'output = loss(logits, labels, input_mask)\\n', 'print(output.shape)\\n', '\\n', 'classmindspore.nn.transformer.OpParallelConfig(data_parallel=1, model_parallel=1)[源代码]\\n', '用于设置数据并行和模型并行的OpParallelConfig。\\n', '\\n', '参数：\\n', '\\n', 'data_parallel (int) - 表示数据并行度。默认值：1\\n', '\\n', 'model_parallel (int) - 表示模型并行度。默认值：1\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.nn.transformer import OpParallelConfig\\n', 'config=OpParallelConfig(data_parallel=1, model_parallel=1)\\n', 'classmindspore.nn.transformer.FixedSparseAttention(batch_size, num_heads, size_per_head, block_size, seq_length=1024, num_different_global_patterns=4, parallel_config=default_dpmp_config)[源代码]\\n', '固定稀疏注意力层。\\n', '\\n', '此接口实现了Sparse Transformer中使用的稀疏注意力原语。更多详情，请见论文（https://arxiv.org/abs/1904.10509）。\\n', '\\n', '具体来说，它包括以下内容：\\n', '\\n', '正常注意力的更快实现（不计算上三角，并且融合了许多操作）。\\n', '\\n', '如论文Sparse Transformers所述，“分散”和“固定”注意力的实现。\\n', '\\n', '参数：\\n', '\\n', 'batch_size (int) - 表示输入batch size的数量。\\n', '\\n', 'num_heads (int) - 表示注意力头数。\\n', '\\n', 'block_size (int) - 表示用来确定block size的整数。目前稀疏自注意力的实现基于稀疏块矩阵。此参数定义了稀疏矩阵块的大小。目前仅支持64。\\n', '\\n', 'seq_length (int) - 表示输入序列的长度。目前只支持1024。\\n', '\\n', 'num_different_global_patterns (int) - 表示用于确定不同的全局注意力数量。虽然全局注意力由局部的代表性的块决定， 但由于有多个头，所以每个头都可以使用不同的全局代表。目前只支持4。\\n', '\\n', 'size_per_head (int) - 表示每个注意力头的向量大小。目前仅支持64和128。\\n', '\\n', 'parallel_config (OpParallelConfig) - 并行设置，内容请参阅 OpParallelConfig 的定义。默认值为 default_dpmp_config ，一个用默认参数初始化的 OpParallelConfig 的实例。\\n', '\\n', '输入：\\n', '\\n', 'q (Tensor) - Tensor query (mstype.fp16 [batch_size, seq_length, hidden_size])：表示上下文的query向量。\\n', '\\n', 'k (Tensor) - Tensor key (mstype.fp16 [batch_size, seq_length, hidden_size])：表示上下文的key向量。\\n', '\\n', 'v (Tensor) - Tensor value (mstype.fp16 [批次大小, seq_length, hidden_size])：表示上下文的value向量。\\n', '\\n', 'attention_mask (Tensor) - Float Tensor the mask of (mstype.fp32 , mstype.fp16 [batch_size, seq_length, seq_length])： 表示掩码的下三角形矩阵。\\n', '\\n', '输出：\\n', '\\n', 'Tensor，shape为[batch_size, seq_length, hidden_size]。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import FixedSparseAttention\\n', 'from mindspore import Tensor\\n', 'model = FixedSparseAttention(batch_size=2,\\n', '                             num_heads=8,\\n', '                             size_per_head=64,\\n', '                             block_size=64)\\n', 'q = Tensor(np.ones((2, 1024, 8*64)), mstype.float16)\\n', 'k = Tensor(np.ones((2, 1024, 8*64)), mstype.float16)\\n', 'v = Tensor(np.ones((2, 1024, 8*64)), mstype.float16)\\n', 'attention_mask = Tensor(np.ones((2, 1024, 1024)), mstype.float32)\\n', 'output = model(q, k, v, attention_mask)\\n', 'print(output.shape)\\n', '\\n', 'classmindspore.nn.transformer.MoEConfig(expert_num=1, capacity_factor=1.1, aux_loss_factor=0.05, num_experts_chosen=1)[源代码]\\n', 'MoE (Mixture of Expert)的配置。\\n', '\\n', '参数：\\n', '\\n', 'expert_num (int) - 表示使用的专家数量。默认值：1。\\n', '\\n', 'capacity_factor (float) - 表示专家处理的容量关系，其值大于等于1.0。默认值：1.1。\\n', '\\n', 'aux_loss_factor (float) - 表示负载均衡损失（由路由器产生）的平衡系数。相乘的结果会加到总损失函数中。此系数的值小于1.0。默认值：0.05。\\n', '\\n', 'num_experts_chosen (int) - 表示每个标识选择的专家数量，其值小于等于专家数量。默认值：1。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.nn.transformer import MoEConfig\\n', 'moe_config = MoEConfig(expert_num=4, capacity_factor=5.0, aux_loss_factor=0.05, num_experts_chosen=1)']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.nn.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.nn.html", "text_entry": "['mindspore.nn\\n', '神经网络Cell。\\n', '\\n', '用于构建神经网络中的预定义构建块或计算单元。\\n', '\\n', 'MindSpore中 mindspore.nn 接口与上一版本相比，新增、删除和支持平台的变化信息请参考 API Updates。\\n', '\\n', '基本构成单元\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.Cell\\n', '\\n', 'MindSpore中神经网络的基本构成单元。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.GraphCell\\n', '\\n', '运行从MindIR加载的计算图。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.LossBase\\n', '\\n', '损失函数的基类。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Optimizer\\n', '\\n', '用于参数更新的优化器基类。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '容器\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.CellList\\n', '\\n', '构造Cell列表。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SequentialCell\\n', '\\n', '构造Cell顺序容器。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '封装层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.DistributedGradReducer\\n', '\\n', '分布式优化器。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.DynamicLossScaleUpdateCell\\n', '\\n', '用于动态更新损失缩放系数(loss scale)的神经元。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.FixedLossScaleUpdateCell\\n', '\\n', '固定损失缩放系数的神经元。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.ForwardValueAndGrad\\n', '\\n', '训练网络的封装。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.GetNextSingleOp\\n', '\\n', '用于获取下一条数据的Cell。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.MicroBatchInterleaved\\n', '\\n', 'Wrap the network with Batch Size.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.ParameterUpdate\\n', '\\n', '更新参数的Cell。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.PipelineCell\\n', '\\n', '将MiniBatch切分成更细粒度的MicroBatch，用于流水线并行的训练中。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.TimeDistributed\\n', '\\n', 'The time distributed layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.TrainOneStepCell\\n', '\\n', '训练网络封装类。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.TrainOneStepWithLossScaleCell\\n', '\\n', '使用混合精度功能的训练网络。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.WithEvalCell\\n', '\\n', '封装前向网络和损失函数，返回用于计算评估指标的损失函数值、前向输出和标签。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.WithGradCell\\n', '\\n', 'Cell that returns the gradients.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.WithLossCell\\n', '\\n', '包含损失函数的Cell。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '卷积神经网络层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.Conv1d\\n', '\\n', '一维卷积层。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv1dTranspose\\n', '\\n', '一维转置卷积层。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv2d\\n', '\\n', '二维卷积层。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv2dTranspose\\n', '\\n', '二维转置卷积层。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv3d\\n', '\\n', '三维卷积层。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv3dTranspose\\n', '\\n', '三维转置卷积层。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.Unfold\\n', '\\n', '从图像中提取滑窗的区域块。\\n', '\\n', 'Ascend GPU\\n', '\\n', '循环神经网络层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.RNN\\n', '\\n', '循环神经网络（RNN）层，其使用的激活函数为tanh或relu。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.RNNCell\\n', '\\n', '循环神经网络单元，激活函数是tanh或relu。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.GRU\\n', '\\n', 'GRU（Gate Recurrent Unit）称为门控循环单元网络，是循环神经网络（Recurrent Neural Network, RNN）的一种。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.GRUCell\\n', '\\n', 'GRU（Gate Recurrent Unit）称为门控循环单元。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.LSTM\\n', '\\n', '长短期记忆（LSTM）网络，根据输出序列和给定的初始状态计算输出序列和最终状态。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.LSTMCell\\n', '\\n', '长短期记忆网络单元（LSTMCell）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '嵌入层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.Embedding\\n', '\\n', '嵌入层。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.EmbeddingLookup\\n', '\\n', '嵌入查找层。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MultiFieldEmbeddingLookup\\n', '\\n', 'Returns a slice of input tensor based on the specified indices and the field ids.\\n', '\\n', 'Ascend GPU\\n', '\\n', '非线性激活函数层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.CELU\\n', '\\n', 'Continuously differentiable exponential linear units activation function.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.ELU\\n', '\\n', '指数线性单元激活函数（Exponential Linear Unit activation function）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.FastGelu\\n', '\\n', '快速高斯误差线性单元激活函数（Fast Gaussian Error Linear Units activation function）。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.GELU\\n', '\\n', '高斯误差线性单元激活函数（Gaussian error linear unit activation function）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.HShrink\\n', '\\n', 'Hard Shrink激活函数，按输入元素计算输出，公式定义如下：。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.HSigmoid\\n', '\\n', 'Hard Sigmoid激活函数，按元素计算输出。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.HSwish\\n', '\\n', 'Hard Swish激活函数。\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.nn.LeakyReLU\\n', '\\n', 'Leaky ReLU激活函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.LogSigmoid\\n', '\\n', 'Log Sigmoid激活函数。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.LogSoftmax\\n', '\\n', 'Log Softmax激活函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.PReLU\\n', '\\n', 'PReLU激活层（PReLU Activation Operator）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.ReLU\\n', '\\n', '修正线性单元激活函数（Rectified Linear Unit activation function）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ReLU6\\n', '\\n', 'ReLU6激活函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Sigmoid\\n', '\\n', 'Sigmoid激活函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Softmax\\n', '\\n', 'Softmax函数，它是二分类函数 mindspore.nn.Sigmoid 在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SoftShrink\\n', '\\n', 'Applies the SoftShrink function element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.Tanh\\n', '\\n', 'Tanh激活函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '线性层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.Dense\\n', '\\n', '全连接层。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Dropout层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.Dropout\\n', '\\n', '随机丢弃层。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '归一化层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.BatchNorm1d\\n', '\\n', '对输入的二维数据进行批归一化(Batch Normalization Layer)。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.BatchNorm2d\\n', '\\n', '对输入的四维数据进行批归一化(Batch Normalization Layer)。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.BatchNorm3d\\n', '\\n', '对输入的五维数据进行批归一化(Batch Normalization Layer)。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.GlobalBatchNorm\\n', '\\n', 'The GlobalBatchNorm interface is deprecated, please use the mindspore.nn.SyncBatchNorm instead.\\n', '\\n', '弃用\\n', '\\n', 'mindspore.nn.GroupNorm\\n', '\\n', '在mini-batch输入上进行组归一化。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.InstanceNorm2d\\n', '\\n', '对四维输入实现实例归一化（Instance Normalization Layer）。\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.nn.LayerNorm\\n', '\\n', '在mini-batch输入上应用层归一化（Layer Normalization）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SyncBatchNorm\\n', '\\n', 'Sync Batch Normalization layer over a N-dimension input.\\n', '\\n', 'Ascend\\n', '\\n', '池化层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.AvgPool1d\\n', '\\n', '对输入的多维数据进行一维平面上的平均池化运算。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.AvgPool2d\\n', '\\n', '对输入的多维数据进行二维的平均池化运算。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MaxPool1d\\n', '\\n', '对输入的多维数据进行一维平面上的最大池化运算。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MaxPool2d\\n', '\\n', '对输入的多维数据进行二维的最大池化运算。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '填充层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.Pad\\n', '\\n', '根据 paddings 和 mode 对输入进行填充。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '损失函数\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.BCELoss\\n', '\\n', '计算目标值和预测值之间的二值交叉熵损失值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.BCEWithLogitsLoss\\n', '\\n', '输入经过sigmoid激活函数后作为预测值，BCEWithLogitsLoss计算预测值和目标值之间的二值交叉熵损失。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.CosineEmbeddingLoss\\n', '\\n', 'CosineEmbeddingLoss creates a criterion to measure the similarity between two tensors using cosine distance.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.DiceLoss\\n', '\\n', 'Dice系数是一个集合相似性loss,用于计算两个样本之间的相似性。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.FocalLoss\\n', '\\n', 'FocalLoss函数。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.L1Loss\\n', '\\n', 'L1Loss用于计算预测值和目标值之间的平均绝对误差。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MSELoss\\n', '\\n', '用于计算预测值与标签值之间的均方误差。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MultiClassDiceLoss\\n', '\\n', 'When there are multiple classifications, label is transformed into multiple binary classifications by one hot.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.RMSELoss\\n', '\\n', 'RMSELoss用来测量 x 和 y 元素之间的均方根误差，其中 x 是输入Tensor， y 是目标值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SampledSoftmaxLoss\\n', '\\n', '抽样交叉熵损失函数。\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.nn.SmoothL1Loss\\n', '\\n', 'SmoothL1损失函数，如果预测值和目标值的逐个元素绝对误差小于设定阈值 beta 则用平方项，否则用绝对误差项。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SoftMarginLoss\\n', '\\n', '针对二分类问题的损失函数。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.SoftmaxCrossEntropyWithLogits\\n', '\\n', '计算预测值与真实值之间的交叉熵。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '优化器\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.Adagrad\\n', '\\n', 'Adagrad算法的实现。\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.nn.Adam\\n', '\\n', 'Adaptive Moment Estimation (Adam)算法的实现。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.AdamOffload\\n', '\\n', '此优化器在主机CPU上运行Adam优化算法，设备上仅执行网络参数的更新，最大限度地降低内存成本。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.AdamWeightDecay\\n', '\\n', '权重衰减Adam算法的实现。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.AdaSumByDeltaWeightWrapCell\\n', '\\n', 'Adaptive Summation (AdaSum)算法的实现，根据更新前后的参数差计算。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.AdaSumByGradWrapCell\\n', '\\n', 'Adaptive Summation (AdaSum)算法的实现，根据梯度计算。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.ASGD\\n', '\\n', 'Implements Average Stochastic Gradient Descent.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.FTRL\\n', '\\n', 'FTRL算法实现。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.Lamb\\n', '\\n', 'LAMB（Layer-wise Adaptive Moments optimizer for Batching training，用于批训练的分层自适应矩优化器）算法的实现。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.LARS\\n', '\\n', 'LARS算法的实现。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.LazyAdam\\n', '\\n', 'Adaptive Moment Estimation (Adam)算法的实现。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Momentum\\n', '\\n', 'Momentum算法的实现。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ProximalAdagrad\\n', '\\n', 'ProximalAdagrad算法的实现。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.RMSProp\\n', '\\n', '均方根传播（RMSProp）算法的实现。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Rprop\\n', '\\n', 'Implements Resilient backpropagation.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SGD\\n', '\\n', '随机梯度下降的实现。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.thor\\n', '\\n', '通过二阶算法THOR更新参数。\\n', '\\n', 'Ascend GPU\\n', '\\n', '评价指标\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.Accuracy\\n', '\\n', '计算数据分类的正确率，包括二分类和多分类。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.auc\\n', '\\n', '使用梯形法则计算曲线下面积AUC（Area Under the Curve，AUC）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.BleuScore\\n', '\\n', '计算具有一个或多个引用的机器翻译文本的BLEU分数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ConfusionMatrix\\n', '\\n', '计算混淆矩阵(confusion matrix)，通常用于评估分类模型的性能，包括二分类和多分类场景。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ConfusionMatrixMetric\\n', '\\n', '计算与混淆矩阵相关的度量。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.CosineSimilarity\\n', '\\n', '计算余弦相似度。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Dice\\n', '\\n', '集合相似性度量。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.F1\\n', '\\n', '计算F1 score。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Fbeta\\n', '\\n', '计算Fbeta评分。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.HausdorffDistance\\n', '\\n', '计算Hausdorff距离。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.get_metric_fn\\n', '\\n', '根据输入的 name 获取metric的方法。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Loss\\n', '\\n', '计算loss的平均值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MAE\\n', '\\n', '计算平均绝对误差MAE（Mean Absolute Error）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MeanSurfaceDistance\\n', '\\n', '计算从 y_pred 到 y 的平均表面距离。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Metric\\n', '\\n', '用于计算评估指标的基类。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MSE\\n', '\\n', '测量均方差MSE（Mean Squared Error）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.names\\n', '\\n', '获取所有metric的名称。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.OcclusionSensitivity\\n', '\\n', '用于计算神经网络对给定图像的遮挡灵敏度（Occlusion Sensitivity），表示了图像的哪些部分对神经网络的分类决策最重要。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Perplexity\\n', '\\n', '计算困惑度（perplexity）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Precision\\n', '\\n', '计算数据分类的精度，包括单标签场景和多标签场景。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Recall\\n', '\\n', '计算数据分类的召回率，包括单标签场景和多标签场景。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ROC\\n', '\\n', '计算ROC曲线。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.RootMeanSquareDistance\\n', '\\n', '计算从 y_pred 到 y 的均方根表面距离。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.rearrange_inputs\\n', '\\n', '此装饰器用于根据类的 indexes 属性对输入重新排列。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Top1CategoricalAccuracy\\n', '\\n', '计算top-1分类正确率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Top5CategoricalAccuracy\\n', '\\n', '计算top-5分类正确率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.TopKCategoricalAccuracy\\n', '\\n', '计算top-k分类正确率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '动态学习率\\n', 'LearningRateSchedule类\\n', '本模块中的动态学习率都是LearningRateSchedule的子类，将LearningRateSchedule的实例传递给优化器。在训练过程中，优化器以当前step为输入调用该实例，得到当前的学习率。\\n', '\\n', 'import mindspore.nn as nn\\n', '\\n', 'min_lr = 0.01\\n', 'max_lr = 0.1\\n', 'decay_steps = 4\\n', 'cosine_decay_lr = nn.CosineDecayLR(min_lr, max_lr, decay_steps)\\n', '\\n', 'net = Net()\\n', 'optim = nn.Momentum(net.trainable_params(), learning_rate=cosine_decay_lr, momentum=0.9)\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.CosineDecayLR\\n', '\\n', '基于余弦衰减函数计算学习率。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.ExponentialDecayLR\\n', '\\n', '基于指数衰减函数计算学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.InverseDecayLR\\n', '\\n', '基于逆时衰减函数计算学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.NaturalExpDecayLR\\n', '\\n', '基于自然指数衰减函数计算学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.PolynomialDecayLR\\n', '\\n', '基于多项式衰减函数计算学习率。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.WarmUpLR\\n', '\\n', '预热学习率。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'Dynamic LR函数\\n', '本模块中的动态学习率都是function，调用function并将结果传递给优化器。在训练过程中，优化器将result[current step]作为当前学习率。\\n', '\\n', 'import mindspore.nn as nn\\n', '\\n', 'min_lr = 0.01\\n', 'max_lr = 0.1\\n', 'total_step = 6\\n', 'step_per_epoch = 1\\n', 'decay_epoch = 4\\n', '\\n', 'lr= nn.cosine_decay_lr(min_lr, max_lr, total_step, step_per_epoch, decay_epoch)\\n', '\\n', 'net = Net()\\n', 'optim = nn.Momentum(net.trainable_params(), learning_rate=lr, momentum=0.9)\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.cosine_decay_lr\\n', '\\n', '基于余弦衰减函数计算学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.exponential_decay_lr\\n', '\\n', '基于指数衰减函数计算学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.inverse_decay_lr\\n', '\\n', '基于逆时衰减函数计算学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.natural_exp_decay_lr\\n', '\\n', '基于自然指数衰减函数计算学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.piecewise_constant_lr\\n', '\\n', '获取分段常量学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.polynomial_decay_lr\\n', '\\n', '基于多项式衰减函数计算学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.warmup_lr\\n', '\\n', '预热学习率。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '稀疏层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.SparseTensorDenseMatmul\\n', '\\n', 'Multiplies sparse matrix a and dense matrix b.\\n', '\\n', 'CPU\\n', '\\n', 'mindspore.nn.SparseToDense\\n', '\\n', 'Converts a sparse tensor(COOTensor) into dense.\\n', '\\n', 'CPU\\n', '\\n', '图像处理层\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.CentralCrop\\n', '\\n', 'Crops the central region of the images with the central_fraction.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ImageGradients\\n', '\\n', 'Returns two tensors, the first is along the height dimension and the second is along the width dimension.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MSSSIM\\n', '\\n', 'Returns MS-SSIM index between two images.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.PSNR\\n', '\\n', 'Returns Peak Signal-to-Noise Ratio of two image batches.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ResizeBilinear\\n', '\\n', '使用双线性插值调整输入Tensor为指定的大小。\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.nn.SSIM\\n', '\\n', 'Returns SSIM index between two images.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '矩阵处理\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.MatrixDiag\\n', '\\n', 'Returns a batched diagonal tensor with a given batched diagonal values.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.MatrixDiagPart\\n', '\\n', 'Returns the batched diagonal part of a batched tensor.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.MatrixSetDiag\\n', '\\n', 'Modifies the batched diagonal part of a batched tensor.\\n', '\\n', 'Ascend\\n', '\\n', '工具\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.ClipByNorm\\n', '\\n', '对输入Tensor的值进行裁剪，使用 L2 范数控制梯度。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Flatten\\n', '\\n', '对输入Tensor的第0维之外的维度进行展平操作。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.get_activation\\n', '\\n', '获取激活函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.L1Regularizer\\n', '\\n', '对权重计算L1正则化。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Norm\\n', '\\n', 'Computes the norm of vectors, currently including Euclidean norm, i.e., L2-norm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.OneHot\\n', '\\n', '对输入进行one-hot编码并返回。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Range\\n', '\\n', 'Creates a sequence of numbers in range [start, limit) with step size delta.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Roll\\n', '\\n', 'Rolls the elements of a tensor along an axis.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.Tril\\n', '\\n', '返回一个Tensor，指定主对角线以上的元素被置为零。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Triu\\n', '\\n', '返回一个Tensor，指定主对角线以下的元素被置为0。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '数学运算\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.MatMul\\n', '\\n', 'The nn.MatMul interface is deprecated, please use the mindspore.ops.matmul instead.\\n', '\\n', '弃用\\n', '\\n', 'mindspore.nn.Moments\\n', '\\n', '沿指定轴 axis 计算输入 x 的均值和方差。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ReduceLogSumExp\\n', '\\n', 'Reduces a dimension of a tensor by calculating exponential for all elements in the dimension, then calculate logarithm of the sum.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '梯度\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.nn.Jvp\\n', '\\n', '计算给定网络的雅可比向量积(Jacobian-vector product, JVP)。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Vjp\\n', '\\n', '计算给定网络的向量雅可比积(vector-Jacobian product, VJP)。\\n', '\\n', 'Ascend GPU CPU']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.numpy.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.numpy.html", "text_entry": "['mindspore.numpy\\n', 'MindSpore NumPy工具包提供了一系列类NumPy接口。用户可以使用类NumPy语法在MindSpore上进行模型的搭建。\\n', '\\n', 'MindSpore Numpy具有四大功能模块：Array生成、Array操作、逻辑运算和数学运算。\\n', '\\n', '在API示例中，常用的模块导入方法如下：\\n', '\\n', 'import mindspore.numpy as np\\n', 'Array生成\\n', '生成类算子用来生成和构建具有指定数值、类型和形状的数组(Tensor)。\\n', '\\n', '构建数组代码示例：\\n', '\\n', 'import mindspore.numpy as np\\n', 'import mindspore.ops as ops\\n', 'input_x = np.array([1, 2, 3], np.float32)\\n', 'print(\"input_x =\", input_x)\\n', 'print(\"type of input_x =\", ops.typeof(input_x))\\n', '运行结果如下：\\n', '\\n', 'input_x = [1. 2. 3.]\\n', 'type of input_x = Tensor[Float32]\\n', '除了使用上述方法来创建外，也可以通过以下几种方式创建。\\n', '\\n', '生成具有相同元素的数组\\n', '\\n', '生成具有相同元素的数组代码示例：\\n', '\\n', 'input_x = np.full((2, 3), 6, np.float32)\\n', 'print(input_x)\\n', '运行结果如下：\\n', '\\n', '[[6. 6. 6.]\\n', ' [6. 6. 6.]]\\n', '生成指定形状的全1数组，示例：\\n', '\\n', 'input_x = np.ones((2, 3), np.float32)\\n', 'print(input_x)\\n', '运行结果如下：\\n', '\\n', '[[1. 1. 1.]\\n', ' [1. 1. 1.]]\\n', '生成具有某个范围内的数值的数组\\n', '\\n', '生成指定范围内的等差数组代码示例：\\n', '\\n', 'input_x = np.arange(0, 5, 1)\\n', 'print(input_x)\\n', '运行结果如下：\\n', '\\n', '[0 1 2 3 4]\\n', '生成特殊类型的数组\\n', '\\n', '生成给定对角线处下方元素为1，上方元素为0的矩阵，示例：\\n', '\\n', 'input_x = np.tri(3, 3, 1)\\n', 'print(input_x)\\n', '运行结果如下：\\n', '\\n', '[[1. 1. 0.]\\n', ' [1. 1. 1.]\\n', ' [1. 1. 1.]]\\n', '生成对角线为1，其他元素为0的二维矩阵，示例：\\n', '\\n', 'input_x = np.eye(2, 2)\\n', 'print(input_x)\\n', '运行结果如下：\\n', '\\n', '[[1. 0.]\\n', ' [0. 1.]]\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.numpy.arange\\n', '\\n', 'Returns evenly spaced values within a given interval.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.array\\n', '\\n', 'Creates a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.asarray\\n', '\\n', 'Converts the input to tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.asfarray\\n', '\\n', 'Similar to asarray, converts the input to a float tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.bartlett\\n', '\\n', 'Returns the Bartlett window.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.blackman\\n', '\\n', 'Returns the Blackman window.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.copy\\n', '\\n', 'Returns a tensor copy of the given object.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diag\\n', '\\n', 'Extracts a diagonal or construct a diagonal array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diag_indices\\n', '\\n', 'Returns the indices to access the main diagonal of an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diagflat\\n', '\\n', 'Creates a two-dimensional array with the flattened input as a diagonal.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diagonal\\n', '\\n', 'Returns specified diagonals.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.empty\\n', '\\n', 'Returns a new array of given shape and type, without initializing entries.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.empty_like\\n', '\\n', 'Returns a new array with the same shape and type as a given array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.eye\\n', '\\n', 'Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.full\\n', '\\n', 'Returns a new tensor of given shape and type, filled with fill_value.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.full_like\\n', '\\n', 'Returns a full array with the same shape and type as a given array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.geomspace\\n', '\\n', 'Returns numbers spaced evenly on a log scale (a geometric progression).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.hamming\\n', '\\n', 'Returns the Hamming window.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.hanning\\n', '\\n', 'Returns the Hanning window.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.histogram_bin_edges\\n', '\\n', 'Function to calculate only the edges of the bins used by the histogram function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.identity\\n', '\\n', 'Returns the identity tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.indices\\n', '\\n', 'Returns an array representing the indices of a grid.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ix_\\n', '\\n', 'Constructs an open mesh from multiple sequences.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.linspace\\n', '\\n', 'Returns evenly spaced values within a given interval.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logspace\\n', '\\n', 'Returns numbers spaced evenly on a log scale.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.meshgrid\\n', '\\n', 'Returns coordinate matrices from coordinate vectors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.mgrid\\n', '\\n', 'mgrid is an NdGrid instance with sparse=False.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ogrid\\n', '\\n', 'ogrid is an NdGrid instance with sparse=True.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ones\\n', '\\n', 'Returns a new tensor of given shape and type, filled with ones.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ones_like\\n', '\\n', 'Returns an array of ones with the same shape and type as a given array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.pad\\n', '\\n', 'Pads an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.rand\\n', '\\n', 'Returns a new Tensor with given shape and dtype, filled with random numbers from the uniform distribution on the interval [0,1).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.randint\\n', '\\n', 'Return random integers from minval (inclusive) to maxval (exclusive).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.randn\\n', '\\n', 'Returns a new Tensor with given shape and dtype, filled with a sample (or samples) from the standard normal distribution.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.trace\\n', '\\n', 'Returns the sum along diagonals of the array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tri\\n', '\\n', 'Returns a tensor with ones at and below the given diagonal and zeros elsewhere.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tril\\n', '\\n', 'Returns a lower triangle of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tril_indices\\n', '\\n', 'Returns the indices for the lower-triangle of an (n, m) array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tril_indices_from\\n', '\\n', 'Returns the indices for the lower-triangle of arr.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.triu\\n', '\\n', 'Returns an upper triangle of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.triu_indices\\n', '\\n', 'Returns the indices for the upper-triangle of an (n, m) array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.triu_indices_from\\n', '\\n', 'Returns the indices for the upper-triangle of arr.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.vander\\n', '\\n', 'Generates a Vandermonde matrix.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.zeros\\n', '\\n', 'Returns a new tensor of given shape and type, filled with zeros.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.zeros_like\\n', '\\n', 'Returns an array of zeros with the same shape and type as a given array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Array操作\\n', '操作类算子主要进行数组的维度变换，分割和拼接等。\\n', '\\n', '数组维度变换\\n', '\\n', '矩阵转置，代码示例：\\n', '\\n', 'input_x = np.arange(10).reshape(5, 2)\\n', 'output = np.transpose(input_x)\\n', 'print(output)\\n', '运行结果如下：\\n', '\\n', '[[0 2 4 6 8]\\n', ' [1 3 5 7 9]]\\n', '交换指定轴，代码示例：\\n', '\\n', 'input_x = np.ones((1, 2, 3))\\n', 'output = np.swapaxes(input_x, 0, 1)\\n', 'print(output.shape)\\n', '运行结果如下：\\n', '\\n', '(2, 1, 3)\\n', '数组分割\\n', '\\n', '将输入数组平均切分为多个数组，代码示例：\\n', '\\n', 'input_x = np.arange(9)\\n', 'output = np.split(input_x, 3)\\n', 'print(output)\\n', '运行结果如下：\\n', '\\n', '(Tensor(shape=[3], dtype=Int32, value= [0, 1, 2]), Tensor(shape=[3], dtype=Int32, value= [3, 4, 5]), Tensor(shape=[3], dtype=Int32, value= [6, 7, 8]))\\n', '数组拼接\\n', '\\n', '将两个数组按照指定轴进行拼接，代码示例：\\n', '\\n', 'input_x = np.arange(0, 5)\\n', 'input_y = np.arange(10, 15)\\n', 'output = np.concatenate((input_x, input_y), axis=0)\\n', 'print(output)\\n', '运行结果如下：\\n', '\\n', '[ 0  1  2  3  4 10 11 12 13 14]\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.numpy.append\\n', '\\n', 'Appends values to the end of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.apply_along_axis\\n', '\\n', 'Applies a function to 1-D slices along the given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.apply_over_axes\\n', '\\n', 'Applies a function repeatedly over multiple axes.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.array_split\\n', '\\n', 'Splits a tensor into multiple sub-tensors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.array_str\\n', '\\n', 'Returns a string representation of the data in an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.atleast_1d\\n', '\\n', 'Converts inputs to arrays with at least one dimension.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.atleast_2d\\n', '\\n', 'Reshapes inputs as arrays with at least two dimensions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.atleast_3d\\n', '\\n', 'Reshapes inputs as arrays with at least three dimensions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.broadcast_arrays\\n', '\\n', 'Broadcasts any number of arrays against each other.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.broadcast_to\\n', '\\n', 'Broadcasts an array to a new shape.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.choose\\n', '\\n', 'Construct an array from an index array and a list of arrays to choose from.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.column_stack\\n', '\\n', 'Stacks 1-D tensors as columns into a 2-D tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.concatenate\\n', '\\n', 'Joins a sequence of tensors along an existing axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.dsplit\\n', '\\n', 'Splits a tensor into multiple sub-tensors along the 3rd axis (depth).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.dstack\\n', '\\n', 'Stacks tensors in sequence depth wise (along the third axis).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.expand_dims\\n', '\\n', 'Expands the shape of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.flip\\n', '\\n', 'Reverses the order of elements in an array along the given axis.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.fliplr\\n', '\\n', 'Flips the entries in each row in the left/right direction.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.flipud\\n', '\\n', 'Flips the entries in each column in the up/down direction.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.hsplit\\n', '\\n', 'Splits a tensor into multiple sub-tensors horizontally (column-wise).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.hstack\\n', '\\n', 'Stacks tensors in sequence horizontally.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.moveaxis\\n', '\\n', 'Moves axes of an array to new positions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.piecewise\\n', '\\n', 'Evaluates a piecewise-defined function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ravel\\n', '\\n', 'Returns a contiguous flattened tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.repeat\\n', '\\n', 'Repeats elements of an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.reshape\\n', '\\n', 'Reshapes a tensor without changing its data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.roll\\n', '\\n', 'Rolls a tensor along given axes.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.rollaxis\\n', '\\n', 'Rolls the specified axis backwards, until it lies in the given position.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.rot90\\n', '\\n', 'Rotates a tensor by 90 degrees in the plane specified by axes.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.numpy.select\\n', '\\n', 'Returns an array drawn from elements in choicelist, depending on conditions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.size\\n', '\\n', 'Returns the number of elements along a given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.split\\n', '\\n', 'Splits a tensor into multiple sub-tensors along the given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.squeeze\\n', '\\n', 'Removes single-dimensional entries from the shape of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.stack\\n', '\\n', 'Joins a sequence of arrays along a new axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.swapaxes\\n', '\\n', 'Interchanges two axes of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.take\\n', '\\n', 'Takes elements from an array along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.take_along_axis\\n', '\\n', 'Takes values from the input array by matching 1d index and data slices.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tile\\n', '\\n', 'Constructs an array by repeating a the number of times given by reps.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.transpose\\n', '\\n', 'Reverses or permutes the axes of a tensor; returns the modified tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.unique\\n', '\\n', 'Finds the unique elements of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.unravel_index\\n', '\\n', 'Converts a flat index or array of flat indices into a tuple of coordinate arrays.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.vsplit\\n', '\\n', 'Splits a tensor into multiple sub-tensors vertically (row-wise).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.vstack\\n', '\\n', 'Stacks tensors in sequence vertically.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.where\\n', '\\n', 'Returns elements chosen from x or y depending on condition.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '逻辑运算\\n', '逻辑运算类算子主要进行各类逻辑相关的运算。\\n', '\\n', '相等（equal）和小于（less）计算代码示例如下：\\n', '\\n', 'input_x = np.arange(0, 5)\\n', 'input_y = np.arange(0, 10, 2)\\n', 'output = np.equal(input_x, input_y)\\n', 'print(\"output of equal:\", output)\\n', 'output = np.less(input_x, input_y)\\n', 'print(\"output of less:\", output)\\n', '运行结果如下：\\n', '\\n', 'output of equal: [ True False False False False]\\n', 'output of less: [False  True  True  True  True]\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.numpy.array_equal\\n', '\\n', 'Returns True if input arrays have same shapes and all elements equal.\\n', '\\n', 'GPU CPU Ascend\\n', '\\n', 'mindspore.numpy.array_equiv\\n', '\\n', 'Returns True if input arrays are shape consistent and all elements equal.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.equal\\n', '\\n', 'Returns the truth value of (x1 == x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.greater\\n', '\\n', 'Returns the truth value of (x1 > x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.greater_equal\\n', '\\n', 'Returns the truth value of (x1 >= x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.in1d\\n', '\\n', 'Tests whether each element of a 1-D array is also present in a second array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.isclose\\n', '\\n', 'Returns a boolean tensor where two tensors are element-wise equal within a tolerance.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.isfinite\\n', '\\n', 'Tests element-wise for finiteness (not infinity or not Not a Number).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.isin\\n', '\\n', 'Calculates element in test_elements, broadcasting over element only.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.isinf\\n', '\\n', 'Tests element-wise for positive or negative infinity.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.isnan\\n', '\\n', 'Tests element-wise for NaN and return result as a boolean array.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.isneginf\\n', '\\n', 'Tests element-wise for negative infinity, returns result as bool array.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.isposinf\\n', '\\n', 'Tests element-wise for positive infinity, returns result as bool array.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.isscalar\\n', '\\n', 'Returns True if the type of element is a scalar type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.less\\n', '\\n', 'Returns the truth value of (x1 < x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.less_equal\\n', '\\n', 'Returns the truth value of (x1 <= x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logical_and\\n', '\\n', 'Computes the truth value of x1 AND x2 element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logical_not\\n', '\\n', 'Computes the truth value of NOT a element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logical_or\\n', '\\n', 'Computes the truth value of x1 OR x2 element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logical_xor\\n', '\\n', 'Computes the truth value of x1 XOR x2, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.not_equal\\n', '\\n', 'Returns (x1 != x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.signbit\\n', '\\n', 'Returns element-wise True where signbit is set (less than zero).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sometrue\\n', '\\n', 'Tests whether any array element along a given axis evaluates to True.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '数学运算\\n', '数学运算类算子包括各类数学相关的运算：加减乘除乘方，以及指数、对数等常见函数等。\\n', '\\n', '数学计算支持类似NumPy的广播特性。\\n', '\\n', '加法\\n', '\\n', '以下代码实现了 input_x 和 input_y 两数组相加的操作：\\n', '\\n', 'input_x = np.full((3, 2), [1, 2])\\n', 'input_y = np.full((3, 2), [3, 4])\\n', 'output = np.add(input_x, input_y)\\n', 'print(output)\\n', '运行结果如下：\\n', '\\n', '[[4 6]\\n', ' [4 6]\\n', ' [4 6]]\\n', '矩阵乘法\\n', '\\n', '以下代码实现了 input_x 和 input_y 两矩阵相乘的操作：\\n', '\\n', \"input_x = np.arange(2*3).reshape(2, 3).astype('float32')\\n\", \"input_y = np.arange(3*4).reshape(3, 4).astype('float32')\\n\", 'output = np.matmul(input_x, input_y)\\n', 'print(output)\\n', '运行结果如下：\\n', '\\n', '[[20. 23. 26. 29.]\\n', ' [56. 68. 80. 92.]]\\n', '求平均值\\n', '\\n', '以下代码实现了求 input_x 所有元素的平均值的操作：\\n', '\\n', \"input_x = np.arange(6).astype('float32')\\n\", 'output = np.mean(input_x)\\n', 'print(output)\\n', '运行结果如下：\\n', '\\n', '2.5\\n', '指数\\n', '\\n', '以下代码实现了自然常数 e 的 input_x 次方的操作：\\n', '\\n', \"input_x = np.arange(5).astype('float32')\\n\", 'output = np.exp(input_x)\\n', 'print(output)\\n', '运行结果如下：\\n', '\\n', '[ 1.         2.7182817  7.389056  20.085537  54.59815  ]\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.numpy.absolute\\n', '\\n', 'Calculates the absolute value element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.add\\n', '\\n', 'Adds arguments element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.amax\\n', '\\n', 'Returns the maximum of an array or maximum along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.amin\\n', '\\n', 'Returns the minimum of an array or minimum along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arccos\\n', '\\n', 'Trigonometric inverse cosine, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arccosh\\n', '\\n', 'Inverse hyperbolic cosine, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arcsin\\n', '\\n', 'Inverse sine, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arcsinh\\n', '\\n', 'Inverse hyperbolic sine element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arctan\\n', '\\n', 'Trigonometric inverse tangent, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arctan2\\n', '\\n', 'Element-wise arc tangent of x1/x2 choosing the quadrant correctly.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.numpy.arctanh\\n', '\\n', 'Inverse hyperbolic tangent element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.numpy.argmax\\n', '\\n', 'Returns the indices of the maximum values along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.argmin\\n', '\\n', 'Returns the indices of the minimum values along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.around\\n', '\\n', 'Evenly round to the given number of decimals.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.average\\n', '\\n', 'Computes the weighted average along the specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.bincount\\n', '\\n', 'Count number of occurrences of each value in array of non-negative ints.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.bitwise_and\\n', '\\n', 'Computes the bit-wise AND of two arrays element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.numpy.bitwise_or\\n', '\\n', 'Computes the bit-wise OR of two arrays element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.numpy.bitwise_xor\\n', '\\n', 'Computes the bit-wise XOR of two arrays element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.numpy.cbrt\\n', '\\n', 'Returns the cube-root of a tensor, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ceil\\n', '\\n', 'Returns the ceiling of the input, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.clip\\n', '\\n', 'Clips (limits) the values in an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.convolve\\n', '\\n', 'Returns the discrete, linear convolution of two one-dimensional sequences.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.copysign\\n', '\\n', 'Changes the sign of x1 to that of x2, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.corrcoef\\n', '\\n', 'Returns Pearson product-moment correlation coefficients.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.correlate\\n', '\\n', 'Cross-correlation of two 1-dimensional sequences.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.numpy.cos\\n', '\\n', 'Cosine element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.cosh\\n', '\\n', 'Hyperbolic cosine, element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.numpy.count_nonzero\\n', '\\n', 'Counts the number of non-zero values in the tensor x.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.cov\\n', '\\n', 'Estimates a covariance matrix, given data and weights.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.cross\\n', '\\n', 'Returns the cross product of two (arrays of) vectors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.cumprod\\n', '\\n', 'Returns the cumulative product of elements along a given axis.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.numpy.cumsum\\n', '\\n', 'Returns the cumulative sum of the elements along a given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.deg2rad\\n', '\\n', 'Converts angles from degrees to radians.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diff\\n', '\\n', 'Calculates the n-th discrete difference along the given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.digitize\\n', '\\n', 'Returns the indices of the bins to which each value in input array belongs.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.divide\\n', '\\n', 'Returns a true division of the inputs, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.divmod\\n', '\\n', 'Returns element-wise quotient and remainder simultaneously.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.dot\\n', '\\n', 'Returns the dot product of two arrays.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ediff1d\\n', '\\n', 'The differences between consecutive elements of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.exp\\n', '\\n', 'Calculates the exponential of all elements in the input array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.exp2\\n', '\\n', 'Calculates 2**p for all p in the input array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.expm1\\n', '\\n', 'Calculates exp(x) - 1 for all elements in the array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.fix\\n', '\\n', 'Rounds to nearest integer towards zero.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.float_power\\n', '\\n', 'First array elements raised to powers from second array, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.floor\\n', '\\n', 'Returns the floor of the input, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.floor_divide\\n', '\\n', 'Returns the largest integer smaller or equal to the division of the inputs.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.fmod\\n', '\\n', 'Returns the element-wise remainder of division.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.gcd\\n', '\\n', 'Returns the greatest common divisor of |x1| and |x2|.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.gradient\\n', '\\n', 'Returns the gradient of a N-dimensional array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.heaviside\\n', '\\n', 'Computes the Heaviside step function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.histogram\\n', '\\n', 'Computes the histogram of a dataset.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.histogram2d\\n', '\\n', 'Computes the multidimensional histogram of some data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.histogramdd\\n', '\\n', 'Computes the multidimensional histogram of some data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.hypot\\n', '\\n', 'Given the “legs” of a right triangle, returns its hypotenuse.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.inner\\n', '\\n', 'Returns the inner product of two tensors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.interp\\n', '\\n', 'One-dimensional linear interpolation for monotonically increasing sample points.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.invert\\n', '\\n', 'Computes bit-wise inversion, or bit-wise NOT, element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.numpy.kron\\n', '\\n', 'Kronecker product of two arrays.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.lcm\\n', '\\n', 'Returns the lowest common multiple of |x1| and |x2|.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.log\\n', '\\n', 'Returns the natural logarithm, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.log10\\n', '\\n', 'Base-10 logarithm of x.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.log1p\\n', '\\n', 'Returns the natural logarithm of one plus the input array, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.log2\\n', '\\n', 'Base-2 logarithm of x.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logaddexp\\n', '\\n', 'Logarithm of the sum of exponentiations of the inputs.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logaddexp2\\n', '\\n', 'Logarithm of the sum of exponentiations of the inputs in base of 2.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.matmul\\n', '\\n', 'Returns the matrix product of two arrays.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.matrix_power\\n', '\\n', 'Raises a square matrix to the (integer) power n.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.maximum\\n', '\\n', 'Returns the element-wise maximum of array elements.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.mean\\n', '\\n', 'Computes the arithmetic mean along the specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.minimum\\n', '\\n', 'Element-wise minimum of tensor elements.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.multi_dot\\n', '\\n', 'Computes the dot product of two or more arrays in a single function call, while automatically selecting the fastest evaluation order.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.multiply\\n', '\\n', 'Multiplies arguments element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.nancumsum\\n', '\\n', 'Return the cumulative sum of array elements over a given axis treating Not a Numbers (NaNs) as zero.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanmax\\n', '\\n', 'Return the maximum of an array or maximum along an axis, ignoring any NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanmean\\n', '\\n', 'Computes the arithmetic mean along the specified axis, ignoring NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanmin\\n', '\\n', 'Returns the minimum of array elements over a given axis, ignoring any NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanstd\\n', '\\n', 'Computes the standard deviation along the specified axis, while ignoring NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nansum\\n', '\\n', 'Returns the sum of array elements over a given axis treating Not a Numbers (NaNs) as zero.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanvar\\n', '\\n', 'Computes the variance along the specified axis, while ignoring NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.negative\\n', '\\n', 'Numerical negative, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.norm\\n', '\\n', 'Matrix or vector norm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.outer\\n', '\\n', 'Computes the outer product of two vectors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polyadd\\n', '\\n', 'Finds the sum of two polynomials.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polyder\\n', '\\n', 'Returns the derivative of the specified order of a polynomial.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polyint\\n', '\\n', 'Returns an antiderivative (indefinite integral) of a polynomial.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polymul\\n', '\\n', 'Finds the product of two polynomials.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.numpy.polysub\\n', '\\n', 'Difference (subtraction) of two polynomials.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polyval\\n', '\\n', 'Evaluates a polynomial at specific values.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.positive\\n', '\\n', 'Numerical positive, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.power\\n', '\\n', 'First array elements raised to powers from second array, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.promote_types\\n', '\\n', 'Returns the data type with the smallest size and smallest scalar kind.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ptp\\n', '\\n', 'Range of values (maximum - minimum) along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.rad2deg\\n', '\\n', 'Converts angles from radians to degrees.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.radians\\n', '\\n', 'Converts angles from degrees to radians.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ravel_multi_index\\n', '\\n', 'Converts a tuple of index arrays into an array of flat indices, applying boundary modes to the multi-index.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.numpy.reciprocal\\n', '\\n', 'Returns the reciprocal of the argument, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.remainder\\n', '\\n', 'Returns element-wise remainder of division.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.result_type\\n', '\\n', 'Returns the type that results from applying the type promotion rules to the arguments.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.rint\\n', '\\n', 'Rounds elements of the array to the nearest integer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.searchsorted\\n', '\\n', 'Finds indices where elements should be inserted to maintain order.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sign\\n', '\\n', 'Returns an element-wise indication of the sign of a number.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sin\\n', '\\n', 'Trigonometric sine, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sinh\\n', '\\n', 'Hyperbolic sine, element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.numpy.sqrt\\n', '\\n', 'Returns the non-negative square-root of an array, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.square\\n', '\\n', 'Returns the element-wise square of the input.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.std\\n', '\\n', 'Computes the standard deviation along the specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.subtract\\n', '\\n', 'Subtracts arguments, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sum\\n', '\\n', 'Returns sum of array elements over a given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tan\\n', '\\n', 'Computes tangent element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.numpy.tanh\\n', '\\n', 'Computes hyperbolic tangent element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tensordot\\n', '\\n', 'Computes tensor dot product along specified axes.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.trapz\\n', '\\n', 'Integrates along the given axis using the composite trapezoidal rule.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.true_divide\\n', '\\n', 'Returns a true division of the inputs, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.trunc\\n', '\\n', 'Returns the truncated value of the input, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.unwrap\\n', '\\n', 'Unwraps by changing deltas between values to 2*pi complement.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.var\\n', '\\n', 'Computes the variance along the specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'MindSpore Numpy与MindSpore特性结合\\n', 'mindspore.numpy能够充分利用MindSpore的强大功能，实现算子的自动微分，并使用图模式加速运算，帮助用户快速构建高效的模型。同时，MindSpore还支持多种后端设备，包括Ascend、GPU和CPU等，用户可以根据自己的需求灵活设置。以下提供了几种常用方法：\\n', '\\n', 'ms_function: 将代码包裹进图模式，用于提高代码运行效率。\\n', '\\n', 'GradOperation: 用于自动求导。\\n', '\\n', 'mindspore.context: 用于设置运行模式和后端设备等。\\n', '\\n', 'mindspore.nn.Cell: 用于建立深度学习模型。\\n', '\\n', '使用示例如下：\\n', '\\n', 'ms_function使用示例\\n', '\\n', '首先，以神经网络里经常使用到的矩阵乘与矩阵加算子为例：\\n', '\\n', 'import mindspore.numpy as np\\n', '\\n', \"x = np.arange(8).reshape(2, 4).astype('float32')\\n\", 'w1 = np.ones((4, 8))\\n', 'b1 = np.zeros((8,))\\n', 'w2 = np.ones((8, 16))\\n', 'b2 = np.zeros((16,))\\n', 'w3 = np.ones((16, 4))\\n', 'b3 = np.zeros((4,))\\n', '\\n', 'def forward(x, w1, b1, w2, b2, w3, b3):\\n', '    x = np.dot(x, w1) + b1\\n', '    x = np.dot(x, w2) + b2\\n', '    x = np.dot(x, w3) + b3\\n', '    return x\\n', '\\n', 'print(forward(x, w1, b1, w2, b2, w3, b3))\\n', '运行结果如下：\\n', '\\n', '[[ 768.  768.  768.  768.]\\n', ' [2816. 2816. 2816. 2816.]]\\n', '对上述示例，我们可以借助 ms_function 将所有算子编译到一张静态图里以加快运行效率，示例如下：\\n', '\\n', 'from mindspore import ms_function\\n', '\\n', 'forward_compiled = ms_function(forward)\\n', 'print(forward(x, w1, b1, w2, b2, w3, b3))\\n', '运行结果如下：\\n', '\\n', '[[ 768.  768.  768.  768.]\\n', ' [2816. 2816. 2816. 2816.]]\\n', 'Note\\n', '\\n', '目前静态图不支持在Python交互式模式下运行，并且有部分语法限制。ms_function 的更多信息可参考 API ms_function 。\\n', '\\n', 'GradOperation使用示例\\n', '\\n', 'GradOperation 可以实现自动求导。以下示例可以实现对上述没有用 ms_function 修饰的 forward 函数定义的计算求导。\\n', '\\n', 'from mindspore import ops\\n', '\\n', 'grad_all = ops.composite.GradOperation(get_all=True)\\n', 'print(grad_all(forward)(x, w1, b1, w2, b2, w3, b3))\\n', '运行结果如下：\\n', '\\n', '(Tensor(shape=[2, 4], dtype=Float32, value=\\n', ' [[ 5.12000000e+02,  5.12000000e+02,  5.12000000e+02,  5.12000000e+02],\\n', '  [ 5.12000000e+02,  5.12000000e+02,  5.12000000e+02,  5.12000000e+02]]),\\n', ' Tensor(shape=[4, 8], dtype=Float32, value=\\n', ' [[ 2.56000000e+02,  2.56000000e+02,  2.56000000e+02 ...  2.56000000e+02,  2.56000000e+02,  2.56000000e+02],\\n', '  [ 3.84000000e+02,  3.84000000e+02,  3.84000000e+02 ...  3.84000000e+02,  3.84000000e+02,  3.84000000e+02],\\n', '  [ 5.12000000e+02,  5.12000000e+02,  5.12000000e+02 ...  5.12000000e+02,  5.12000000e+02,  5.12000000e+02]\\n', '  [ 6.40000000e+02,  6.40000000e+02,  6.40000000e+02 ...  6.40000000e+02,  6.40000000e+02,  6.40000000e+02]]),\\n', '  ...\\n', ' Tensor(shape=[4], dtype=Float32, value= [ 2.00000000e+00,  2.00000000e+00,  2.00000000e+00,  2.00000000e+00]))\\n', '如果要对 ms_function 修饰的 forward 计算求导，需要提前使用 context 设置运算模式为图模式，示例如下：\\n', '\\n', 'from mindspore import ms_function, context\\n', '\\n', 'context.set_context(mode=context.GRAPH_MODE)\\n', 'grad_all = ops.composite.GradOperation(get_all=True)\\n', 'print(grad_all(ms_function(forward))(x, w1, b1, w2, b2, w3, b3))\\n', '运行结果如下：\\n', '\\n', '(Tensor(shape=[2, 4], dtype=Float32, value=\\n', ' [[ 5.12000000e+02,  5.12000000e+02,  5.12000000e+02,  5.12000000e+02],\\n', '  [ 5.12000000e+02,  5.12000000e+02,  5.12000000e+02,  5.12000000e+02]]),\\n', ' Tensor(shape=[4, 8], dtype=Float32, value=\\n', ' [[ 2.56000000e+02,  2.56000000e+02,  2.56000000e+02 ...  2.56000000e+02,  2.56000000e+02,  2.56000000e+02],\\n', '  [ 3.84000000e+02,  3.84000000e+02,  3.84000000e+02 ...  3.84000000e+02,  3.84000000e+02,  3.84000000e+02],\\n', '  [ 5.12000000e+02,  5.12000000e+02,  5.12000000e+02 ...  5.12000000e+02,  5.12000000e+02,  5.12000000e+02]\\n', '  [ 6.40000000e+02,  6.40000000e+02,  6.40000000e+02 ...  6.40000000e+02,  6.40000000e+02,  6.40000000e+02]]),\\n', '  ...\\n', ' Tensor(shape=[4], dtype=Float32, value= [ 2.00000000e+00,  2.00000000e+00,  2.00000000e+00,  2.00000000e+00]))\\n', '更多细节可参考 API GradOperation 。\\n', '\\n', 'mindspore.context使用示例\\n', '\\n', 'MindSpore支持多后端运算，可以通过 mindspore.context 进行设置。mindspore.numpy 的多数算子可以使用图模式或者PyNative模式运行，也可以运行在CPU，CPU或者Ascend等多种后端设备上。\\n', '\\n', 'from mindspore import context\\n', '\\n', '# Execucation in static graph mode\\n', 'context.set_context(mode=context.GRAPH_MODE)\\n', '\\n', '# Execucation in PyNative mode\\n', 'context.set_context(mode=context.PYNATIVE_MODE)\\n', '\\n', '# Execucation on CPU backend\\n', 'context.set_context(device_target=\"CPU\")\\n', '\\n', '# Execucation on GPU backend\\n', 'context.set_context(device_target=\"GPU\")\\n', '\\n', '# Execucation on Ascend backend\\n', 'context.set_context(device_target=\"Ascend\")\\n', '...\\n', '更多细节可参考 API mindspore.context 。\\n', '\\n', 'mindspore.numpy使用示例\\n', '\\n', '这里提供一个使用 mindspore.numpy 构建网络模型的示例。\\n', '\\n', 'mindspore.numpy 接口可以定义在 nn.Cell 代码块内进行网络的构建，示例如下：\\n', '\\n', 'import mindspore.numpy as np\\n', 'from mindspore import context\\n', 'from mindspore.nn import Cell\\n', '\\n', 'context.set_context(mode=context.GRAPH_MODE)\\n', '\\n', \"x = np.arange(8).reshape(2, 4).astype('float32')\\n\", 'w1 = np.ones((4, 8))\\n', 'b1 = np.zeros((8,))\\n', 'w2 = np.ones((8, 16))\\n', 'b2 = np.zeros((16,))\\n', 'w3 = np.ones((16, 4))\\n', 'b3 = np.zeros((4,))\\n', '\\n', 'class NeuralNetwork(Cell):\\n', '    def construct(self, x, w1, b1, w2, b2, w3, b3):\\n', '        x = np.dot(x, w1) + b1\\n', '        x = np.dot(x, w2) + b2\\n', '        x = np.dot(x, w3) + b3\\n', '        return x\\n', '\\n', 'net = NeuralNetwork()\\n', '\\n', 'print(net(x, w1, b1, w2, b2, w3, b3))\\n', '运行结果如下：\\n', '\\n', '[[ 768.  768.  768.  768.]\\n', ' [2816. 2816. 2816. 2816.]]']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.ops.functional.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.ops.functional.html", "text_entry": "['mindspore.ops.functional\\n', 'functional算子是经过初始化后的Primitive，可以直接作为函数使用。functional算子的使用示例如下：\\n', '\\n', 'from mindspore import Tensor, ops\\n', 'from mindspore import dtype as mstype\\n', '\\n', 'input_x = Tensor(-1, mstype.int32)\\n', \"input_dict = {'x':1, 'y':2}\\n\", '\\n', 'result_abs = ops.absolute(input_x)\\n', 'print(result_abs)\\n', '\\n', \"result_in_dict = ops.in_dict('x', input_dict)\\n\", 'print(result_in_dict)\\n', '\\n', \"result_not_in_dict = ops.not_in_dict('x', input_dict)\\n\", 'print(result_not_in_dict)\\n', '\\n', 'result_isconstant = ops.isconstant(input_x)\\n', 'print(result_isconstant)\\n', '\\n', 'result_typeof = ops.typeof(input_x)\\n', 'print(result_typeof)\\n', '\\n', '# outputs:\\n', '# 1\\n', '# True\\n', '# False\\n', '# True\\n', '# Tensor[Int32]\\n', '神经网络层算子\\n', '激活函数\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.tanh\\n', '\\n', 'Refer to mindspore.ops.Tanh.\\n', '\\n', '数学运算算子\\n', '逐元素运算\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.absolute\\n', '\\n', 'Refer to mindspore.ops.Abs.\\n', '\\n', 'mindspore.ops.acos\\n', '\\n', 'Refer to mindspore.ops.ACos.\\n', '\\n', 'mindspore.ops.acosh\\n', '\\n', 'Refer to mindspore.ops.Acosh.\\n', '\\n', 'mindspore.ops.add\\n', '\\n', 'Refer to mindspore.ops.Add.\\n', '\\n', 'mindspore.ops.addn\\n', '\\n', 'Refer to mindspore.ops.AddN.\\n', '\\n', 'mindspore.ops.asin\\n', '\\n', 'Refer to mindspore.ops.Asin.\\n', '\\n', 'mindspore.ops.asinh\\n', '\\n', 'Refer to mindspore.ops.Asinh.\\n', '\\n', 'mindspore.ops.atan\\n', '\\n', 'Refer to mindspore.ops.Atan.\\n', '\\n', 'mindspore.ops.atan2\\n', '\\n', 'Refer to mindspore.ops.Atan2.\\n', '\\n', 'mindspore.ops.atanh\\n', '\\n', 'Refer to mindspore.ops.Atanh.\\n', '\\n', 'mindspore.ops.bitwise_and\\n', '\\n', 'Refer to mindspore.ops.BitwiseAnd.\\n', '\\n', 'mindspore.ops.bitwise_or\\n', '\\n', 'Refer to mindspore.ops.BitwiseOr.\\n', '\\n', 'mindspore.ops.bitwise_xor\\n', '\\n', 'Refer to mindspore.ops.BitwiseXor.\\n', '\\n', 'mindspore.ops.cos\\n', '\\n', 'Refer to mindspore.ops.Cos.\\n', '\\n', 'mindspore.ops.cosh\\n', '\\n', 'Refer to mindspore.ops.Cosh.\\n', '\\n', 'mindspore.ops.div\\n', '\\n', 'Refer to mindspore.ops.RealDiv.\\n', '\\n', 'mindspore.ops.erf\\n', '\\n', 'Refer to mindspore.ops.Erf.\\n', '\\n', 'mindspore.ops.erfc\\n', '\\n', 'Refer to mindspore.ops.Erfc.\\n', '\\n', 'mindspore.ops.exp\\n', '\\n', 'Refer to mindspore.ops.Exp.\\n', '\\n', 'mindspore.ops.floor\\n', '\\n', 'Refer to mindspore.ops.Floor.\\n', '\\n', 'mindspore.ops.floordiv\\n', '\\n', 'Refer to mindspore.ops.FloorDiv.\\n', '\\n', 'mindspore.ops.floormod\\n', '\\n', 'Refer to mindspore.ops.FloorMod.\\n', '\\n', 'mindspore.ops.log\\n', '\\n', 'Refer to mindspore.ops.Log.\\n', '\\n', 'mindspore.ops.logical_and\\n', '\\n', 'Refer to mindspore.ops.LogicalAnd.\\n', '\\n', 'mindspore.ops.logical_not\\n', '\\n', 'Refer to mindspore.ops.LogicalNot.\\n', '\\n', 'mindspore.ops.logical_or\\n', '\\n', 'Refer to mindspore.ops.LogicalOr.\\n', '\\n', 'mindspore.ops.invert\\n', '\\n', 'Refer to mindspore.ops.Invert.\\n', '\\n', 'mindspore.ops.mul\\n', '\\n', 'Refer to mindspore.ops.Mul.\\n', '\\n', 'mindspore.ops.neg_tensor\\n', '\\n', 'Refer to mindspore.ops.Neg.\\n', '\\n', 'mindspore.ops.pows\\n', '\\n', 'Refer to mindspore.ops.Pow.\\n', '\\n', 'mindspore.ops.sin\\n', '\\n', 'Refer to mindspore.ops.Sin.\\n', '\\n', 'mindspore.ops.sinh\\n', '\\n', 'Refer to mindspore.ops.Sinh.\\n', '\\n', 'mindspore.ops.sqrt\\n', '\\n', 'Refer to mindspore.ops.Sqrt.\\n', '\\n', 'mindspore.ops.square\\n', '\\n', 'Refer to mindspore.ops.Square.\\n', '\\n', 'mindspore.ops.sub\\n', '\\n', 'Refer to mindspore.ops.Sub.\\n', '\\n', 'mindspore.ops.tan\\n', '\\n', 'Refer to mindspore.ops.Tan.\\n', '\\n', 'mindspore.ops.tensor_add\\n', '\\n', 'Refer to mindspore.ops.Add.\\n', '\\n', 'mindspore.ops.tensor_div\\n', '\\n', 'Refer to mindspore.ops.RealDiv.\\n', '\\n', 'mindspore.ops.tensor_exp\\n', '\\n', 'Refer to mindspore.ops.Exp.\\n', '\\n', 'mindspore.ops.tensor_expm1\\n', '\\n', 'Refer to mindspore.ops.Expm1.\\n', '\\n', 'mindspore.ops.tensor_floordiv\\n', '\\n', 'Refer to mindspore.ops.FloorDiv.\\n', '\\n', 'mindspore.ops.tensor_mod\\n', '\\n', 'Refer to mindspore.ops.FloorMod.\\n', '\\n', 'mindspore.ops.tensor_mul\\n', '\\n', 'Refer to mindspore.ops.Mul.\\n', '\\n', 'mindspore.ops.tensor_pow\\n', '\\n', 'Refer to mindspore.ops.Pow.\\n', '\\n', 'mindspore.ops.tensor_sub\\n', '\\n', 'Refer to mindspore.ops.Sub.\\n', '\\n', 'Reduction算子\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.reduce_max\\n', '\\n', 'Refer to mindspore.ops.ReduceMax.\\n', '\\n', 'mindspore.ops.reduce_mean\\n', '\\n', 'Refer to mindspore.ops.ReduceMean.\\n', '\\n', 'mindspore.ops.reduce_min\\n', '\\n', 'Refer to mindspore.ops.ReduceMin.\\n', '\\n', 'mindspore.ops.reduce_prod\\n', '\\n', 'Refer to mindspore.ops.ReduceProd.\\n', '\\n', 'mindspore.ops.reduce_sum\\n', '\\n', 'Refer to mindspore.ops.ReduceSum.\\n', '\\n', '比较算子\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.check_bprop\\n', '\\n', 'Refer to mindspore.ops.CheckBprop.\\n', '\\n', 'mindspore.ops.equal\\n', '\\n', 'Refer to mindspore.ops.Equal.\\n', '\\n', 'mindspore.ops.ge\\n', '\\n', 'Refer to mindspore.ops.GreaterEqual.\\n', '\\n', 'mindspore.ops.gt\\n', '\\n', 'Refer to mindspore.ops.Greater.\\n', '\\n', 'mindspore.ops.le\\n', '\\n', 'Refer to mindspore.ops.LessEqual.\\n', '\\n', 'mindspore.ops.less\\n', '\\n', 'Refer to mindspore.ops.Less.\\n', '\\n', 'mindspore.ops.isfinite\\n', '\\n', 'Refer to mindspore.ops.IsFinite.\\n', '\\n', 'mindspore.ops.isinstance_\\n', '\\n', 'Refer to mindspore.ops.IsInstance.\\n', '\\n', 'mindspore.ops.isnan\\n', '\\n', 'Refer to mindspore.ops.IsNan.\\n', '\\n', 'mindspore.ops.issubclass_\\n', '\\n', 'Refer to mindspore.ops.IsSubClass.\\n', '\\n', 'mindspore.ops.maximum\\n', '\\n', 'Refer to mindspore.ops.Maximum.\\n', '\\n', 'mindspore.ops.minimum\\n', '\\n', 'Refer to mindspore.ops.Minimum.\\n', '\\n', 'mindspore.ops.not_equal\\n', '\\n', 'Refer to mindspore.ops.NotEqual.\\n', '\\n', 'mindspore.ops.same_type_shape\\n', '\\n', 'Refer to mindspore.ops.SameTypeShape.\\n', '\\n', 'mindspore.ops.tensor_ge\\n', '\\n', 'Refer to mindspore.ops.GreaterEqual.\\n', '\\n', 'mindspore.ops.tensor_gt\\n', '\\n', 'Refer to mindspore.ops.Greater.\\n', '\\n', 'mindspore.ops.tensor_le\\n', '\\n', 'Refer to mindspore.ops.LessEqual.\\n', '\\n', 'mindspore.ops.tensor_lt\\n', '\\n', 'Refer to mindspore.ops.Less.\\n', '\\n', '线性代数算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.matmul\\n', '\\n', '计算两个数组的乘积。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Tensor操作算子\\n', 'Tensor创建\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.eye\\n', '\\n', 'Refer to mindspore.ops.Eye.\\n', '\\n', 'mindspore.ops.fill\\n', '\\n', 'Refer to mindspore.ops.Fill.\\n', '\\n', 'mindspore.ops.ones_like\\n', '\\n', 'Refer to mindspore.ops.OnesLike.\\n', '\\n', 'mindspore.ops.zeros_like\\n', '\\n', 'Refer to mindspore.ops.ZerosLike.\\n', '\\n', '随机生成算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.gamma\\n', '\\n', 'Generates random numbers according to the Gamma random number distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.multinomial\\n', '\\n', 'Returns a tensor sampled from the multinomial probability distribution located in the corresponding row of the input tensor.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.poisson\\n', '\\n', 'Generates random numbers according to the Poisson random number distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'Array操作\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.cast\\n', '\\n', 'Refer to mindspore.ops.Cast.\\n', '\\n', 'mindspore.ops.cumprod\\n', '\\n', 'Refer to mindspore.ops.CumProd.\\n', '\\n', 'mindspore.ops.cumsum\\n', '\\n', 'Refer to mindspore.ops.CumSum.\\n', '\\n', 'mindspore.ops.dtype\\n', '\\n', 'Refer to mindspore.ops.DType.\\n', '\\n', 'mindspore.ops.expand_dims\\n', '\\n', 'Refer to mindspore.ops.ExpandDims.\\n', '\\n', 'mindspore.ops.gather\\n', '\\n', 'Refer to mindspore.ops.Gather.\\n', '\\n', 'mindspore.ops.gather_d\\n', '\\n', 'Refer to mindspore.ops.GatherD.\\n', '\\n', 'mindspore.ops.gather_nd\\n', '\\n', 'Refer to mindspore.ops.GatherNd.\\n', '\\n', 'mindspore.ops.rank\\n', '\\n', 'Refer to mindspore.ops.Rank.\\n', '\\n', 'mindspore.ops.reshape\\n', '\\n', 'Refer to mindspore.ops.Reshape.\\n', '\\n', 'mindspore.ops.scatter_nd\\n', '\\n', 'Refer to mindspore.ops.ScatterNd.\\n', '\\n', 'mindspore.ops.shape\\n', '\\n', 'Refer to mindspore.ops.Shape.\\n', '\\n', 'mindspore.ops.size\\n', '\\n', 'Refer to mindspore.ops.Size.\\n', '\\n', 'mindspore.ops.sort\\n', '\\n', 'Refer to mindspore.ops.Sort.\\n', '\\n', 'mindspore.ops.squeeze\\n', '\\n', 'Refer to mindspore.ops.Squeeze.\\n', '\\n', 'mindspore.ops.stack\\n', '\\n', 'Refer to mindspore.ops.Stack.\\n', '\\n', 'mindspore.ops.strided_slice\\n', '\\n', 'Refer to mindspore.ops.StridedSlice.\\n', '\\n', 'mindspore.ops.tensor_scatter_add\\n', '\\n', 'Refer to mindspore.ops.TensorScatterAdd.\\n', '\\n', 'mindspore.ops.tensor_scatter_update\\n', '\\n', 'Refer to mindspore.ops.TensorScatterUpdate.\\n', '\\n', 'mindspore.ops.tensor_slice\\n', '\\n', 'Refer to mindspore.ops.Slice.\\n', '\\n', 'mindspore.ops.tile\\n', '\\n', 'Refer to mindspore.ops.Tile.\\n', '\\n', 'mindspore.ops.transpose\\n', '\\n', 'Refer to mindspore.ops.Transpose.\\n', '\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.select\\n', '\\n', 'Returns the selected elements, either from input x or input y, depending on the condition cond.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.unique\\n', '\\n', 'Returns the unique elements of input tensor and also return a tensor containing the index of each value of input tensor corresponding to the output unique tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '类型转换\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.scalar_cast\\n', '\\n', 'Refer to mindspore.ops.ScalarCast.\\n', '\\n', 'mindspore.ops.scalar_to_array\\n', '\\n', 'Refer to mindspore.ops.ScalarToArray.\\n', '\\n', 'mindspore.ops.scalar_to_tensor\\n', '\\n', 'Refer to mindspore.ops.ScalarToTensor.\\n', '\\n', 'mindspore.ops.tuple_to_array\\n', '\\n', 'Refer to mindspore.ops.TupleToArray.\\n', '\\n', 'Parameter操作算子\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.assign\\n', '\\n', 'Refer to mindspore.ops.Assign.\\n', '\\n', 'mindspore.ops.assign_add\\n', '\\n', 'Refer to mindspore.ops.AssignAdd.\\n', '\\n', 'mindspore.ops.assign_sub\\n', '\\n', 'Refer to mindspore.ops.AssignSub.\\n', '\\n', 'mindspore.ops.scatter_nd_update\\n', '\\n', 'Refer to mindspore.ops.ScatterNdUpdate.\\n', '\\n', 'mindspore.ops.scatter_update\\n', '\\n', 'Refer to mindspore.ops.ScatterUpdate.\\n', '\\n', '调试算子\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.print_\\n', '\\n', 'Refer to mindspore.ops.Print.\\n', '\\n', '其他算子\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.bool_and\\n', '\\n', 'Calculate the result of logical AND operation. (Usage is the same as “and” in Python)\\n', '\\n', 'mindspore.ops.bool_eq\\n', '\\n', 'Determine whether the Boolean values are equal. (Usage is the same as “==” in Python)\\n', '\\n', 'mindspore.ops.bool_not\\n', '\\n', 'Calculate the result of logical NOT operation. (Usage is the same as “not” in Python)\\n', '\\n', 'mindspore.ops.bool_or\\n', '\\n', 'Calculate the result of logical OR operation. (Usage is the same as “or” in Python)\\n', '\\n', 'mindspore.ops.depend\\n', '\\n', 'Refer to mindspore.ops.Depend.\\n', '\\n', 'mindspore.ops.in_dict\\n', '\\n', 'Determine if a str in dict.\\n', '\\n', 'mindspore.ops.is_not\\n', '\\n', 'Determine whether the input is not the same as the other one. (Usage is the same as “is not” in Python)\\n', '\\n', 'mindspore.ops.is_\\n', '\\n', 'Determine whether the input is the same as the other one. (Usage is the same as “is” in Python)\\n', '\\n', 'mindspore.ops.isconstant\\n', '\\n', 'Determine whether the object is constant.\\n', '\\n', 'mindspore.ops.not_in_dict\\n', '\\n', 'Determine whether the object is not in the dict.\\n', '\\n', 'mindspore.ops.partial\\n', '\\n', 'Refer to mindspore.ops.Partial.\\n', '\\n', 'mindspore.ops.scalar_add\\n', '\\n', 'Get the sum of two numbers. (Usage is the same as “+” in Python)\\n', '\\n', 'mindspore.ops.scalar_div\\n', '\\n', 'Get the quotient of dividing the first input number by the second input number. (Usage is the same as “/” in Python)\\n', '\\n', 'mindspore.ops.scalar_eq\\n', '\\n', 'Determine whether two numbers are equal. (Usage is the same as “==” in Python)\\n', '\\n', 'mindspore.ops.scalar_floordiv\\n', '\\n', 'Divide the first input number by the second input number and round down to the closest integer. (Usage is the same as “//” in Python)\\n', '\\n', 'mindspore.ops.scalar_ge\\n', '\\n', 'Determine whether the number is greater than or equal to another number. (Usage is the same as “>=” in Python)\\n', '\\n', 'mindspore.ops.scalar_gt\\n', '\\n', 'Determine whether the number is greater than another number. (Usage is the same as “>” in Python)\\n', '\\n', 'mindspore.ops.scalar_le\\n', '\\n', 'Determine whether the number is less than or equal to another number. (Usage is the same as “<=” in Python)\\n', '\\n', 'mindspore.ops.scalar_log\\n', '\\n', 'Get the natural logarithm of the input number.\\n', '\\n', 'mindspore.ops.scalar_lt\\n', '\\n', 'Determine whether the number is less than another number. (Usage is the same as “<” in Python)\\n', '\\n', 'mindspore.ops.scalar_mod\\n', '\\n', 'Get the remainder of dividing the first input number by the second input number. (Usage is the same as “%” in Python)\\n', '\\n', 'mindspore.ops.scalar_mul\\n', '\\n', 'Get the product of the input two numbers. (Usage is the same as “*” in Python)\\n', '\\n', 'mindspore.ops.scalar_ne\\n', '\\n', 'Determine whether two numbers are not equal. (Usage is the same as “!=” in Python)\\n', '\\n', 'mindspore.ops.scalar_pow\\n', '\\n', 'Compute a number to the power of the second input number.\\n', '\\n', 'mindspore.ops.scalar_sub\\n', '\\n', 'Subtract the second input number from the first input number. (Usage is the same as “-” in Python)\\n', '\\n', 'mindspore.ops.scalar_uadd\\n', '\\n', 'Get the positive value of the input number.\\n', '\\n', 'mindspore.ops.scalar_usub\\n', '\\n', 'Get the negative value of the input number.\\n', '\\n', 'mindspore.ops.shape_mul\\n', '\\n', 'The input of shape_mul must be shape multiply elements in tuple(shape).\\n', '\\n', 'mindspore.ops.stop_gradient\\n', '\\n', 'Disable update during back propagation. (stop_gradient)\\n', '\\n', 'mindspore.ops.string_concat\\n', '\\n', 'Concatenate two strings.\\n', '\\n', 'mindspore.ops.string_eq\\n', '\\n', 'Determine if two strings are equal.\\n', '\\n', 'mindspore.ops.typeof\\n', '\\n', 'Get type of object.\\n', '\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.arange\\n', '\\n', '根据给定的范围返回指定均匀间隔的数据。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.batch_dot\\n', '\\n', '当输入的两个Tensor是批量数据时，对其进行批量点积操作。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.clip_by_global_norm\\n', '\\n', '通过权重梯度总和的比率来裁剪多个Tensor的值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.clip_by_value\\n', '\\n', '将输入Tensor值裁剪到指定的最小值和最大值之间。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.core\\n', '\\n', 'A decorator that adds a flag to the function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.count_nonzero\\n', '\\n', 'Count number of nonzero elements across axis of input tensor\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.cummin\\n', '\\n', 'Computation of the cumulative minimum of elements of ‘x’ in the dimension axis, and the index location of each maximum value found in the dimension ‘axis’.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.dot\\n', '\\n', '两个Tensor之间的点积。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.grad\\n', '\\n', 'A wrapper function to generate the gradient function for the input function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.jvp\\n', '\\n', 'Compute the jacobian-vector-product of the given network.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.laplace\\n', '\\n', 'Generates random numbers according to the Laplace random number distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.narrow\\n', '\\n', 'Returns a narrowed tensor from input tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.normal\\n', '\\n', 'Generates random numbers according to the Normal (or Gaussian) random number distribution.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.repeat_elements\\n', '\\n', '在指定轴上复制输入Tensor的元素，类似 np.repeat 的功能。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.sequence_mask\\n', '\\n', '返回一个表示每个单元的前N个位置的掩码Tensor。\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.tensor_dot\\n', '\\n', '在指定轴上对Tensor a 和 b 进行点乘操作。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.uniform\\n', '\\n', '生成服从均匀分布的随机数。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.vjp\\n', '\\n', 'Compute the vector-jacobian-product of the given network.\\n', '\\n', 'Ascend GPU CPU']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.ops.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.ops.html", "text_entry": "['mindspore.ops\\n', '可用于Cell的构造函数的算子。\\n', '\\n', 'import mindspore.ops as ops\\n', 'MindSpore中 mindspore.ops 接口与上一版本相比，新增、删除和支持平台的变化信息请参考 API Updates 。\\n', '\\n', '算子原语\\n', 'mindspore.ops.Primitive\\n', '\\n', 'Primitive是Python中算子原语的基类。\\n', '\\n', 'mindspore.ops.PrimitiveWithCheck\\n', '\\n', 'PrimitiveWithCheck是Python中原语的基类，定义了检查算子输入参数的函数，但是使用了C++源码中注册的推理方法。\\n', '\\n', 'mindspore.ops.PrimitiveWithInfer\\n', '\\n', 'PrimitiveWithInfer是Python中的原语基类，在python中定义了跟踪推理的函数。\\n', '\\n', '装饰器\\n', 'mindspore.ops.constexpr\\n', '\\n', '创建PrimiveWithInfer算子，用于在编译时推断值。\\n', '\\n', 'mindspore.ops.custom_info_register\\n', '\\n', 'A decorator which is used to bind the registration information to the func parameter of mindspore.ops.Custom.\\n', '\\n', 'mindspore.ops.ms_hybrid\\n', '\\n', '用于MindSpore Hybrid DSL函数书写的装饰器。\\n', '\\n', 'mindspore.ops.op_info_register\\n', '\\n', '用于注册算子的装饰器。\\n', '\\n', 'mindspore.ops.prim_attr_register\\n', '\\n', 'Primitive属性的注册器。\\n', '\\n', '神经网络层算子\\n', '神经网络\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.AvgPool\\n', '\\n', '对输入的多维数据进行二维平均池化运算。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AvgPool3D\\n', '\\n', '对输入的多维数据进行三维的平均池化运算。\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.BasicLSTMCell\\n', '\\n', 'It’s similar to operator mindspore.ops.DynamicRNN.\\n', '\\n', '弃用\\n', '\\n', 'mindspore.ops.BatchNorm\\n', '\\n', '对输入数据进行归一化(Batch Normalization)和更新参数。\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.Conv2D\\n', '\\n', '2D convolution layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Conv2DBackpropInput\\n', '\\n', 'The Conv2DBackpropInput interface is deprecated, please refer to mindspore.ops.Conv2DTranspose if you want to do unsampling.\\n', '\\n', '弃用\\n', '\\n', 'mindspore.ops.Conv2DTranspose\\n', '\\n', 'Compute a 2D transposed convolution, which is also known as a deconvolution (although it is not an actual deconvolution).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Conv3D\\n', '\\n', '3D convolution layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Conv3DTranspose\\n', '\\n', 'Computes a 3D transposed convolution, which is also known as a deconvolution (although it is not an actual deconvolution).\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.CTCGreedyDecoder\\n', '\\n', 'Performs greedy decoding on the logits given in inputs.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.DepthwiseConv2dNative\\n', '\\n', 'DepthwiseConv2dNative will be deprecated in the future.\\n', '\\n', '弃用\\n', '\\n', 'mindspore.ops.Dropout\\n', '\\n', 'Dropout是一种正则化手段，通过在训练中以 1−keep_prob 的概率随机将神经元输出设置为0，起到减少神经元相关性的作用，避免过拟合。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Dropout2D\\n', '\\n', '在训练期间，根据概率 1 - keep_prob ，随机的将一些通道设置为0，且服从伯努利分布。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Dropout3D\\n', '\\n', '随机丢弃层。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.DropoutDoMask\\n', '\\n', 'The DropoutDoMask interface is deprecated, please use the mindspore.ops.Dropout instead.\\n', '\\n', '弃用\\n', '\\n', 'mindspore.ops.DropoutGenMask\\n', '\\n', 'The DropoutGenMask interface is deprecated, please use the mindspore.ops.Dropout instead.\\n', '\\n', '弃用\\n', '\\n', 'mindspore.ops.DynamicGRUV2\\n', '\\n', 'Applies a single-layer gated recurrent unit (GRU) to an input sequence.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.DynamicRNN\\n', '\\n', 'Applies a recurrent neural network to the input.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Flatten\\n', '\\n', '扁平化（Flatten）输入Tensor，不改变0轴的size。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LayerNorm\\n', '\\n', '在输入Tensor上应用层归一化（Layer Normalization）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LRN\\n', '\\n', 'Local Response Normalization.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.LSTM\\n', '\\n', 'Performs the Long Short-Term Memory (LSTM) on the input.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.MaxPool\\n', '\\n', '对输入的多维数据进行二维的最大池化运算。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MaxPool3D\\n', '\\n', '对输入的多维数据进行三维的最大池化运算。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MaxPoolWithArgmax\\n', '\\n', '对输入Tensor执行最大池化运算，并返回最大值和索引。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.MirrorPad\\n', '\\n', 'Pads the input tensor according to the paddings and mode.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Pad\\n', '\\n', '根据参数 paddings 对输入进行填充。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.EmbeddingLookup\\n', '\\n', '根据指定的索引，返回输入Tensor的切片。\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.Padding\\n', '\\n', '将输入Tensor的最后一个维度从1扩展到 pad_dim_size ，其填充值为0。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ResizeNearestNeighbor\\n', '\\n', '使用最近邻插值算法调整输入Tensor为指定大小。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ResizeBilinear\\n', '\\n', '使用双线性插值调整图像大小到指定的大小。\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', '损失函数\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.BCEWithLogitsLoss\\n', '\\n', '输入经过sigmoid激活函数后作为预测值，BCEWithLogitsLoss计算预测值和目标值之间的二值交叉熵损失。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.BinaryCrossEntropy\\n', '\\n', 'Computes the binary cross entropy between the logits and the labels.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.CTCLoss\\n', '\\n', 'Calculates the CTC (Connectionist Temporal Classification) loss and the gradient.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.KLDivLoss\\n', '\\n', 'Computes the Kullback-Leibler divergence between the logits and the labels.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.L2Loss\\n', '\\n', '用于计算L2范数的一半，但不对结果进行开方操作。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.NLLLoss\\n', '\\n', '获取预测值和目标值之间的负对数似然损失。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.RNNTLoss\\n', '\\n', 'Computes the RNNTLoss and its gradient with respect to the softmax outputs.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SigmoidCrossEntropyWithLogits\\n', '\\n', '计算预测值与真实值之间的sigmoid交叉熵。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SmoothL1Loss\\n', '\\n', 'Computes smooth L1 loss, a robust L1 loss.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SoftMarginLoss\\n', '\\n', 'SoftMarginLoss operation.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SoftmaxCrossEntropyWithLogits\\n', '\\n', '使用one-hot编码获取预测值和真实之间的softmax交叉熵。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SparseSoftmaxCrossEntropyWithLogits\\n', '\\n', 'Computes the softmax cross-entropy value between logits and sparse encoding labels.\\n', '\\n', 'GPU CPU\\n', '\\n', '激活函数\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.Elu\\n', '\\n', '指数线性单元激活函数（Exponential Linear Unit activation function）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FastGeLU\\n', '\\n', 'Fast Gaussian Error Linear Units activation function.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.GeLU\\n', '\\n', '高斯误差线性单元激活函数（Gaussian Error Linear Units activation function）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.HShrink\\n', '\\n', 'Applies the hard shrinkage function element-wise, each element complies with the following function:\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.HSigmoid\\n', '\\n', 'Hard sigmoid activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.HSwish\\n', '\\n', 'Hard swish activation function.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.LogSoftmax\\n', '\\n', 'LogSoftmax激活函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Mish\\n', '\\n', 'Computes MISH(A Self Regularized Non-Monotonic Neural Activation Function) of input tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.PReLU\\n', '\\n', '带参数的线性修正单元激活函数（Parametric Rectified Linear Unit activation function）。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ReLU\\n', '\\n', '线性修正单元激活函数（Rectified Linear Unit）。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReLU6\\n', '\\n', 'Computes ReLU (Rectified Linear Unit) upper bounded by 6 of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReLUV2\\n', '\\n', '线性修正单元激活函数（Rectified Linear Unit activation function）。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SeLU\\n', '\\n', '激活函数SeLU（Scaled exponential Linear Unit）。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Sigmoid\\n', '\\n', 'Sigmoid激活函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Softmax\\n', '\\n', 'Softmax函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Softplus\\n', '\\n', 'Softplus activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SoftShrink\\n', '\\n', 'Applies the SoftShrink function element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Softsign\\n', '\\n', 'Softsign activation function.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Tanh\\n', '\\n', 'Tanh激活函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '优化器\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.Adam\\n', '\\n', 'Updates gradients by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AdamNoUpdateParam\\n', '\\n', 'Updates gradients by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'CPU\\n', '\\n', 'mindspore.ops.AdamWeightDecay\\n', '\\n', 'Updates gradients by the Adaptive Moment Estimation algorithm with weight decay (AdamWeightDecay).\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.AdaptiveAvgPool2D\\n', '\\n', 'AdaptiveAvgPool2D operation.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.ApplyAdadelta\\n', '\\n', 'Updates relevant entries according to the adadelta scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyAdagrad\\n', '\\n', 'Updates relevant entries according to the adagrad scheme.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.ApplyAdagradDA\\n', '\\n', 'Update var according to the proximal adagrad scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyAdagradV2\\n', '\\n', 'Updates relevant entries according to the adagradv2 scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyAdaMax\\n', '\\n', 'Updates relevant entries according to the adamax scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyAddSign\\n', '\\n', 'Updates relevant entries according to the AddSign algorithm.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyCenteredRMSProp\\n', '\\n', 'Optimizer that implements the centered RMSProp algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ApplyFtrl\\n', '\\n', 'Updates relevant entries according to the FTRL scheme.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ApplyGradientDescent\\n', '\\n', 'Updates var by subtracting alpha * delta from it.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ApplyMomentum\\n', '\\n', 'Optimizer that implements the Momentum algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ApplyPowerSign\\n', '\\n', 'Updates relevant entries according to the AddSign algorithm.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyProximalAdagrad\\n', '\\n', 'Updates relevant entries according to the proximal adagrad algorithm.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyProximalGradientDescent\\n', '\\n', 'Updates relevant entries according to the FOBOS(Forward Backward Splitting) algorithm.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyRMSProp\\n', '\\n', 'Optimizer that implements the Root Mean Square prop(RMSProp) algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FusedSparseAdam\\n', '\\n', 'Merges the duplicate value of the gradient and then updates parameters by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.FusedSparseFtrl\\n', '\\n', 'Merges the duplicate value of the gradient and then updates relevant entries according to the FTRL-proximal scheme.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.FusedSparseLazyAdam\\n', '\\n', 'Merges the duplicate value of the gradient and then updates parameters by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.FusedSparseProximalAdagrad\\n', '\\n', 'Merges the duplicate value of the gradient and then updates relevant entries according to the proximal adagrad algorithm.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.LARSUpdate\\n', '\\n', 'Conducts LARS (layer-wise adaptive rate scaling) update on the sum of squares of gradient.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SparseApplyAdagrad\\n', '\\n', 'Updates relevant entries according to the adagrad scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SparseApplyAdagradV2\\n', '\\n', 'Updates relevant entries according to the adagrad scheme, one more epsilon attribute than SparseApplyAdagrad.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SparseApplyProximalAdagrad\\n', '\\n', 'Updates relevant entries according to the proximal adagrad algorithm.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.SGD\\n', '\\n', 'Computes the stochastic gradient descent.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SparseApplyFtrl\\n', '\\n', 'Updates relevant entries according to the FTRL-proximal scheme.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.SparseApplyFtrlV2\\n', '\\n', 'Updates relevant entries according to the FTRL-proximal scheme.\\n', '\\n', 'Ascend\\n', '\\n', '距离函数\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.Cdist\\n', '\\n', 'Computes batched the p-norm distance between each pair of the two collections of row vectors.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.EditDistance\\n', '\\n', 'Computes the Levenshtein Edit Distance.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.LpNorm\\n', '\\n', 'Returns the matrix norm or vector norm of a given tensor.\\n', '\\n', 'Ascend\\n', '\\n', '采样算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.ComputeAccidentalHits\\n', '\\n', '计算与目标类完全匹配的抽样样本的位置id。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.LogUniformCandidateSampler\\n', '\\n', '使用log-uniform(Zipfian)分布对一组类别进行采样。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.UniformCandidateSampler\\n', '\\n', '使用均匀分布对一组类别进行采样。\\n', '\\n', 'GPU\\n', '\\n', '图像处理\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.BoundingBoxDecode\\n', '\\n', 'Decodes bounding boxes locations.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.BoundingBoxEncode\\n', '\\n', 'Encodes bounding boxes locations.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.CheckValid\\n', '\\n', 'Checks bounding box.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.CropAndResize\\n', '\\n', 'Extracts crops from the input image tensor and resizes them.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ExtractVolumePatches\\n', '\\n', 'Extract patches from input and put them in the “depth” output dimension.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.IOU\\n', '\\n', '计算矩形的IOU，即真实区域和预测区域的交并比。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.L2Normalize\\n', '\\n', 'L2范数归一化算子。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.NMSWithMask\\n', '\\n', 'When object detection problem is performed in the computer vision field, object detection algorithm generates a plurality of bounding boxes.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ROIAlign\\n', '\\n', 'Computes the Region of Interest (RoI) Align operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '文本处理\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.NoRepeatNGram\\n', '\\n', 'Updates log_probs with repeat n-grams.\\n', '\\n', 'Ascend\\n', '\\n', '数学运算算子\\n', '逐元素运算\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.Abs\\n', '\\n', 'Returns absolute value of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AccumulateNV2\\n', '\\n', 'Computes accumulation of all input tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ACos\\n', '\\n', 'Computes arccosine of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Acosh\\n', '\\n', 'Computes inverse hyperbolic cosine of the inputs element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Add\\n', '\\n', '两个输入Tensor逐元素相加。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Addcdiv\\n', '\\n', 'Performs the element-wise division of tensor x1 by tensor x2, multiply the result by the scalar value and add it to input_data.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Addcmul\\n', '\\n', 'Performs the element-wise product of tensor x1 and tensor x2, multiply the result by the scalar value and add it to input_data.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.AddN\\n', '\\n', '逐元素将所有输入的Tensor相加。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Asin\\n', '\\n', 'Computes arcsine of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Asinh\\n', '\\n', 'Computes inverse hyperbolic sine of the input element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Atan\\n', '\\n', 'Computes the trigonometric inverse tangent of the input element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Atan2\\n', '\\n', 'Returns arctangent of x/y element-wise.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.Atanh\\n', '\\n', 'Computes inverse hyperbolic tangent of the input element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.BesselI0e\\n', '\\n', 'Computes BesselI0e of input element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BesselI1e\\n', '\\n', 'Computes BesselI1e of input element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BitwiseAnd\\n', '\\n', 'Returns bitwise and of two tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BitwiseOr\\n', '\\n', 'Returns bitwise or of two tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BitwiseXor\\n', '\\n', 'Returns bitwise xor of two tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Ceil\\n', '\\n', '向上取整函数。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Conj\\n', '\\n', 'Returns a tensor of complex numbers that are the complex conjugate of each element in input.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.ops.Cos\\n', '\\n', 'Computes cosine of input element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Cosh\\n', '\\n', 'Computes hyperbolic cosine of input element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.Div\\n', '\\n', '逐元素计算第一输入Tensor除以第二输入Tensor的商。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.DivNoNan\\n', '\\n', 'Computes a safe divide and returns 0 if the y is zero.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Einsum\\n', '\\n', 'This operator uses equation to represent a tuple of tensors operations, you can use this operator to perform diagonal/reducesum/transpose/matmul/mul/inner product operations, etc.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.Erf\\n', '\\n', '逐元素计算 x 的高斯误差函数。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Erfc\\n', '\\n', 'Computes the complementary error function of x element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Erfinv\\n', '\\n', 'Computes the inverse error function of input.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Exp\\n', '\\n', 'Returns exponential of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Expm1\\n', '\\n', 'Returns exponential then minus 1 of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Floor\\n', '\\n', '向下取整函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FloorDiv\\n', '\\n', 'Divides the first input tensor by the second input tensor element-wise and round down to the closest integer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FloorMod\\n', '\\n', 'Computes the remainder of division element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Imag\\n', '\\n', 'Returns a new tensor containing imaginary value of the input.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.ops.Inv\\n', '\\n', '按元素计算输入Tensor的倒数。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Invert\\n', '\\n', 'Flips all bits of input tensor element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Lerp\\n', '\\n', 'Does a linear interpolation of two tensors start and end based on a float or tensor weight.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Log\\n', '\\n', '逐元素返回Tensor的自然对数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Log1p\\n', '\\n', 'Returns the natural logarithm of one plus the input tensor element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.LogicalAnd\\n', '\\n', 'Computes the “logical AND” of two tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LogicalNot\\n', '\\n', 'Computes the “logical NOT” of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LogicalOr\\n', '\\n', 'Computes the “logical OR” of two tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Mod\\n', '\\n', 'Computes the remainder of dividing the first input tensor by the second input tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Mul\\n', '\\n', '两个Tensor逐元素相乘。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MulNoNan\\n', '\\n', 'Computes x * y element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.Neg\\n', '\\n', '计算输入x的相反数并返回。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Pow\\n', '\\n', '计算 x 中每个元素的 y 次幂。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Real\\n', '\\n', 'Returns a Tensor that is the real part of the input.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.ops.RealDiv\\n', '\\n', 'Divides the first input tensor by the second input tensor in floating-point type element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Reciprocal\\n', '\\n', 'Returns reciprocal of a tensor element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Rint\\n', '\\n', 'Returns an integer that is closest to x element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Round\\n', '\\n', '对输入数据进行四舍五入到最接近的整数数值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Rsqrt\\n', '\\n', 'Computes reciprocal of square root of input tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Sign\\n', '\\n', 'Performs sign on the tensor element-wise.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.Sin\\n', '\\n', 'Computes sine of the input element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Sinh\\n', '\\n', 'Computes hyperbolic sine of the input element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.Sqrt\\n', '\\n', '计算输入Tensor的平方根。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Square\\n', '\\n', 'Returns square of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SquaredDifference\\n', '\\n', 'Subtracts the second input tensor from the first input tensor element-wise and returns square of it.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SquareSumAll\\n', '\\n', 'Returns the square sum of a tensor element-wise\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Sub\\n', '\\n', '逐元素用第一个输入Tensor减去第二个输入Tensor。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Tan\\n', '\\n', 'Computes tangent of x element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.TruncateDiv\\n', '\\n', 'Divides the first input tensor by the second input tensor element-wise for integer types, negative numbers will round fractional quantities towards zero.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.TruncateMod\\n', '\\n', 'Returns the remainder of division element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Xdivy\\n', '\\n', 'Divides the first input tensor by the second input tensor element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Xlogy\\n', '\\n', 'Computes the first input tensor multiplied by the logarithm of second input tensor element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'Reduction算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.Argmax\\n', '\\n', '返回输入Tensor在指定轴上的最大值索引。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ArgMaxWithValue\\n', '\\n', '根据指定的索引计算最大值，并返回索引和值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Argmin\\n', '\\n', '返回输入Tensor在指定轴上的最小值索引。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ArgMinWithValue\\n', '\\n', '根据指定的索引计算最小值，并返回索引和值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceAll\\n', '\\n', 'Reduces a dimension of a tensor by the “logicalAND” of all elements in the dimension, by default.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceAny\\n', '\\n', 'Reduces a dimension of a tensor by the “logical OR” of all elements in the dimension, by default.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceMax\\n', '\\n', '默认情况下，输出张量各维度上的最大值，以达到对所有维度进行归约的目的。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceMean\\n', '\\n', '默认情况下，输出Tensor各维度上的平均值，以达到对所有维度进行归约的目的。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceMin\\n', '\\n', 'Reduces a dimension of a tensor by the minimum value in the dimension, by default.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceProd\\n', '\\n', 'Reduces a dimension of a tensor by multiplying all elements in the dimension, by default.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ReduceSum\\n', '\\n', '默认情况下，输出Tensor各维度上的和，以达到对所有维度进行归约的目的。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '比较算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.ApproximateEqual\\n', '\\n', 'Returns True if abs(x-y) is smaller than tolerance element-wise, otherwise False.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.CheckBprop\\n', '\\n', 'Checks whether the data type and the shape of corresponding elements from tuples x and y are the same.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Equal\\n', '\\n', '逐元素比较两个输入Tensor是否相等。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.EqualCount\\n', '\\n', 'Computes the number of the same elements of two tensors.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.Greater\\n', '\\n', '按元素比较输入参数 x,y 的值，输出结果为bool值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.GreaterEqual\\n', '\\n', '输入两个数据，逐元素比较第一个数据是否大于等于第二个数据。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.InTopK\\n', '\\n', 'Determines whether the targets are in the top k predictions.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.IsFinite\\n', '\\n', 'Determines which elements are finite for each position.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.IsInf\\n', '\\n', 'Determines which elements are inf or -inf for each position\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.IsInstance\\n', '\\n', 'Checks whether an object is an instance of a target type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.IsNan\\n', '\\n', '判断输入数据每个位置上的值是否是Nan。\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.IsSubClass\\n', '\\n', 'Checks whether this type is a sub-class of another type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Less\\n', '\\n', 'Computes the boolean value of x<y element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LessEqual\\n', '\\n', '逐元素计算 x<=y 的bool值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Maximum\\n', '\\n', '计算输入Tensor的最大值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Minimum\\n', '\\n', 'Computes the minimum of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.NotEqual\\n', '\\n', '计算两个Tensor是否不相等。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SameTypeShape\\n', '\\n', 'Checks whether the data type and shape of two tensors are the same.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.TopK\\n', '\\n', 'Finds values and indices of the k largest entries along the last dimension.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '线性代数算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.BatchMatMul\\n', '\\n', '两个batch后的Tensor之间的矩阵乘法。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.BiasAdd\\n', '\\n', '返回输入Tensor与偏置Tensor之和。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Ger\\n', '\\n', 'Ger product of x1 and x2.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.MatMul\\n', '\\n', '将矩阵 a 和矩阵 b 相乘。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MatrixInverse\\n', '\\n', '计算输入矩阵的逆矩阵，如果输入矩阵不可逆，将产生错误或者返回一个未知结果。\\n', '\\n', 'GPU CPU\\n', '\\n', 'Tensor操作算子\\n', 'Tensor创建\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.Eps\\n', '\\n', '创建一个与输入数据类型和shape都相同的Tensor，元素值为对应数据类型能表达的最小值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Eye\\n', '\\n', '创建一个主对角线上元素为1，其余元素为0的Tensor。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Fill\\n', '\\n', '创建一个指定shape的Tensor，并用指定值填充。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LinSpace\\n', '\\n', 'Returns a Tensor whose value is num evenly spaced in the interval start and stop (including start and stop), and the length of the output Tensor is num.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.OneHot\\n', '\\n', '返回一个one-hot类型的Tensor。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Ones\\n', '\\n', '创建一个值全为1的Tensor。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.OnesLike\\n', '\\n', '返回值为1的Tensor，shape和数据类型与输入相同。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Zeros\\n', '\\n', '创建一个值全为0的Tensor。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ZerosLike\\n', '\\n', '返回值为0的Tensor，其shape和数据类型与输入Tensor相同。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '随机生成算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.Gamma\\n', '\\n', '根据概率密度函数分布生成随机正值浮点数x。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Multinomial\\n', '\\n', 'Returns a tensor sampled from the multinomial probability distribution located in the corresponding row of tensor input.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.Poisson\\n', '\\n', 'Produces random non-negative integer values i, distributed according to discrete probability function:\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.RandomCategorical\\n', '\\n', 'Generates random samples from a given categorical distribution tensor.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.RandomChoiceWithMask\\n', '\\n', 'Generates a random sample as index tensor with a mask tensor from a given tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Randperm\\n', '\\n', 'Generates n random samples from 0 to n-1 without repeating.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.StandardLaplace\\n', '\\n', 'Generates random numbers according to the Laplace random number distribution (mean=0, lambda=1).\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.StandardNormal\\n', '\\n', 'Generates random numbers according to the standard Normal (or Gaussian) random number distribution.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.UniformInt\\n', '\\n', 'Produces random integer values i, uniformly distributed on the closed interval [minval, maxval), that is, distributed according to the discrete probability function:\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.UniformReal\\n', '\\n', '产生随机的浮点数，均匀分布在[0，1)范围内。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Array操作\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.BatchToSpace\\n', '\\n', 'Divides batch dimension with blocks and interleaves these blocks back into spatial dimensions.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.BatchToSpaceND\\n', '\\n', 'Divides batch dimension with blocks and interleaves these blocks back into spatial dimensions.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BroadcastTo\\n', '\\n', '将输入shape广播到目标shape。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Cast\\n', '\\n', '转换输入Tensor的数据类型。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Concat\\n', '\\n', '在指定轴上拼接输入Tensor。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.CumProd\\n', '\\n', 'Computes the cumulative product of the tensor x along axis.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.CumSum\\n', '\\n', '计算输入Tensor在指定轴上的累加和。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.DataFormatDimMap\\n', '\\n', 'Returns the dimension index in the destination data format given in the source data format.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.DepthToSpace\\n', '\\n', 'Rearrange blocks of depth data into spatial dimensions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.DType\\n', '\\n', 'Returns the data type of the input tensor as mindspore.dtype.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.DynamicShape\\n', '\\n', '与 TensorShape 相同， DynamicShape 将会被 TensorShape 替换，请使用 TensorShape 。\\n', '\\n', 'Deprecated\\n', '\\n', 'mindspore.ops.ExpandDims\\n', '\\n', 'Adds an additional dimension to input_x at the given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FloatStatus\\n', '\\n', 'Determines if the elements contain Not a Number(NaN), infinite or negative infinite.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.Gather\\n', '\\n', '返回输入Tensor在指定 axis 上 input_indices 索引对应的元素组成的切片。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.GatherD\\n', '\\n', '获取指定轴的元素。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.GatherNd\\n', '\\n', '根据索引获取输入Tensor指定位置上的元素。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.HistogramFixedWidth\\n', '\\n', 'Returns a rank 1 histogram counting the number of entries in values that fall into every bin.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Identity\\n', '\\n', '返回与输入具有相同shape和值的Tensor。\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.IndexAdd\\n', '\\n', 'Adds tensor y to specified axis and indices of tensor x.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.InplaceAdd\\n', '\\n', 'Adds v into specified rows of x.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.InplaceSub\\n', '\\n', 'Subtracts v into specified rows of x.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.InplaceUpdate\\n', '\\n', 'Updates specified rows with values in v.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.InvertPermutation\\n', '\\n', 'Computes the inverse of an index permutation.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MaskedFill\\n', '\\n', '将掩码位置为True的位置填充指定的值。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.MaskedSelect\\n', '\\n', '使用布尔掩码对输入进行选择得到一个新的一维Tensor。\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.Meshgrid\\n', '\\n', '从给定的Tensor生成网格矩阵。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ParallelConcat\\n', '\\n', 'Concats tensor in the first dimension.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.PopulationCount\\n', '\\n', 'Computes element-wise population count(a.k.a bitsum, bitcount).\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Rank\\n', '\\n', 'Returns the rank of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Reshape\\n', '\\n', '基于给定的shape，对输入Tensor进行重新排列。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReverseSequence\\n', '\\n', '对输入序列进行部分反转。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ReverseV2\\n', '\\n', '对输入Tensor按指定维度反转。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ScatterNd\\n', '\\n', '根据指定的索引将更新值散布到新Tensor上。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Select\\n', '\\n', 'Returns the selected elements, either from input x or input y, depending on the condition.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Shape\\n', '\\n', 'Returns the shape of the input tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Size\\n', '\\n', '返回一个Scalar，类型为整数，表示输入Tensor的大小，即Tensor中元素的总数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Slice\\n', '\\n', '根据指定shape对输入Tensor进行切片。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Sort\\n', '\\n', '根据指定的轴对输入Tensor的元素进行排序。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SpaceToBatch\\n', '\\n', 'SpaceToBatch is deprecated.\\n', '\\n', '弃用\\n', '\\n', 'mindspore.ops.SpaceToBatchND\\n', '\\n', 'Divides spatial dimensions into blocks and combines the block size with the original batch.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SpaceToDepth\\n', '\\n', 'Rearrange blocks of spatial data into depth.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SparseGatherV2\\n', '\\n', 'Returns a slice of input tensor based on the specified indices and axis.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Split\\n', '\\n', '根据指定的轴和分割数量对输入Tensor进行分割。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SplitV\\n', '\\n', 'Splits the input tensor into num_split tensors along the given dimension.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Squeeze\\n', '\\n', '返回删除指定 axis 中大小为1的维度后的Tensor。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Stack\\n', '\\n', '在指定轴上对输入Tensor序列进行堆叠。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.StridedSlice\\n', '\\n', '输入Tensor根据步长和索引进行切片提取。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.TensorScatterAdd\\n', '\\n', '根据指定的更新值和输入索引，通过相加运算更新输入Tensor的值。\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.TensorScatterMax\\n', '\\n', '根据指定的更新值和输入索引，通过最大值运算更新输入Tensor的值。\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.TensorScatterMin\\n', '\\n', '根据指定的更新值和输入索引，通过最小值运算更新输入Tensor的值。\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.TensorScatterSub\\n', '\\n', '根据指定的更新值和输入索引，通过减法运算更新输入Tensor的值。\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.TensorScatterUpdate\\n', '\\n', '根据指定的更新值和输入索引，通过更新操作更新输入Tensor的值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.TensorShape\\n', '\\n', '返回输入Tensor的Shape。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Tile\\n', '\\n', '按照给定的次数复制输入Tensor。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Transpose\\n', '\\n', '根据指定的排列对输入的Tensor进行数据重排。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Unique\\n', '\\n', 'Returns the unique elements of input tensor and also return a tensor containing the index of each value of input tensor corresponding to the output unique tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.UniqueWithPad\\n', '\\n', 'Returns unique elements and relative indexes in 1-D tensor, filled with padding num.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.UnsortedSegmentMax\\n', '\\n', 'Computes the maximum along segments of a tensor.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.UnsortedSegmentMin\\n', '\\n', 'Computes the minimum of a tensor along segments.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.UnsortedSegmentProd\\n', '\\n', 'Computes the product of a tensor along segments.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.UnsortedSegmentSum\\n', '\\n', 'Computes the sum of a tensor along segments.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Unstack\\n', '\\n', '根据指定轴对输入矩阵进行分解。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '类型转换\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.ScalarCast\\n', '\\n', 'Casts the input scalar to another type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScalarToArray\\n', '\\n', '将Scalar转换为 Tensor 。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScalarToTensor\\n', '\\n', '将Scalar转换为指定数据类型的 Tensor 。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.TupleToArray\\n', '\\n', '将tuple转换为Tensor。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Parameter操作算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.Assign\\n', '\\n', 'Assigns Parameter with a value.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AssignAdd\\n', '\\n', 'Updates a Parameter by adding a value to it.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AssignSub\\n', '\\n', 'Updates a Parameter by subtracting a value from it.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ScatterAdd\\n', '\\n', '根据指定更新值和输入索引通过加法运算更新输入数据的值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScatterDiv\\n', '\\n', '根据指定更新值和输入索引通过除法运算更新输入数据的值。\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.ScatterMax\\n', '\\n', '根据指定更新值和输入索引通过最大值运算更新输入数据的值。\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.ScatterMin\\n', '\\n', '根据指定更新值和输入索引通过最小值运算更新输入数据的值。\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.ScatterMul\\n', '\\n', '根据指定更新值和输入索引通过乘法运算更新输入数据的值。\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.ScatterNdAdd\\n', '\\n', '使用给定值通过加法运算和输入索引更新Tensor值。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ScatterNdSub\\n', '\\n', '使用给定值通过减法运算和输入索引更新Tensor值。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ScatterNdUpdate\\n', '\\n', '使用给定值以及输入索引更新输入数据的值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScatterNonAliasingAdd\\n', '\\n', '使用给定值通过加法操作和输入索引来更新Tensor值。\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ScatterSub\\n', '\\n', '使用给定更新值通过减法操作和输入索引来更新Tensor值。\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.ScatterUpdate\\n', '\\n', '使用给定的更新值和输入索引更新输入Tensor的值。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '数据操作算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.GetNext\\n', '\\n', '返回数据集队列中的下一个元素。\\n', '\\n', 'Ascend GPU\\n', '\\n', '通信算子\\n', '注意，以下列表中的接口需要先配置好通信环境变量。\\n', '\\n', '针对Ascend设备，用户需要准备rank表，设置rank_id和device_id，详见 Ascend指导文档 。\\n', '\\n', '针对GPU设备，用户需要准备host文件和mpi，详见 GPU指导文档 。\\n', '\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.AllGather\\n', '\\n', '在指定的通信组中汇聚Tensor。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.AllReduce\\n', '\\n', '使用指定方式对通信组内的所有设备的Tensor数据进行规约操作，所有设备都得到相同的结果。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.AlltoAll\\n', '\\n', 'AlltoAll is a collective operation.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Broadcast\\n', '\\n', '对输入数据整组广播。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.NeighborExchange\\n', '\\n', 'NeighborExchange is a collective operation.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.NeighborExchangeV2\\n', '\\n', 'NeighborExchangeV2 is a collective operation.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ReduceOp\\n', '\\n', 'Operation options for reducing tensors.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ReduceScatter\\n', '\\n', 'Reduces and scatters tensors from the specified communication group.\\n', '\\n', 'Ascend GPU\\n', '\\n', '调试算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.HistogramSummary\\n', '\\n', 'Outputs the tensor to protocol buffer through histogram summary operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ImageSummary\\n', '\\n', 'Outputs the image tensor to protocol buffer through image summary operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScalarSummary\\n', '\\n', 'Outputs a scalar to a protocol buffer through a scalar summary operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.TensorSummary\\n', '\\n', 'Outputs a tensor to a protocol buffer through a tensor summary operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Print\\n', '\\n', '将输入Tensor或string进行打印输出。\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.NPUAllocFloatStatus\\n', '\\n', 'Allocates a flag to store the overflow status.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.NPUClearFloatStatus\\n', '\\n', 'Clears the flag which stores the overflow status.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.NPUGetFloatStatus\\n', '\\n', 'Updates the flag which is the output tensor of NPUAllocFloatStatus with the latest overflow status.\\n', '\\n', 'Ascend\\n', '\\n', '稀疏算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.SparseTensorDenseMatmul\\n', '\\n', 'Multiplies sparse matrix A by dense matrix B.\\n', '\\n', 'CPU\\n', '\\n', 'mindspore.ops.SparseToDense\\n', '\\n', 'Converts a sparse representation into a dense tensor.\\n', '\\n', 'CPU\\n', '\\n', '其他算子\\n', '接口名\\n', '\\n', '概述\\n', '\\n', '支持平台\\n', '\\n', 'mindspore.ops.Depend\\n', '\\n', 'Depend is used for processing dependency operations.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.GradOperation\\n', '\\n', '一个高阶函数，为输入函数生成梯度函数。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.HookBackward\\n', '\\n', 'This operation is used as a tag to hook gradient in intermediate variables.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.HyperMap\\n', '\\n', '对输入序列做集合运算。\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.InsertGradientOf\\n', '\\n', 'Attaches callback to the graph node that will be invoked on the node’s gradient.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Map\\n', '\\n', 'Map will apply the set operation on input sequences.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MultitypeFuncGraph\\n', '\\n', 'Generates overloaded functions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Partial\\n', '\\n', 'Makes a partial function instance.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', '算子信息注册\\n', 'mindspore.ops.AiCPURegOp\\n', '\\n', 'Class for AiCPU operator information register.\\n', '\\n', 'mindspore.ops.CustomRegOp\\n', '\\n', 'Class used for generating the registration information for the func parameter of mindspore.ops.Custom.\\n', '\\n', 'mindspore.ops.DataType\\n', '\\n', 'Ascend算子的dtype和format的多种组合。\\n', '\\n', 'mindspore.ops.TBERegOp\\n', '\\n', 'Class for TBE operator information register.\\n', '\\n', 'mindspore.ops.get_vm_impl_fn\\n', '\\n', '通过Primitive对象或Primitive名称，获取虚拟实现函数。\\n', '\\n', '自定义算子\\n', 'mindspore.ops.Custom\\n', '\\n', 'Custom 算子是MindSpore自定义算子的统一接口。']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.parallel.nn.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.parallel.nn.html", "text_entry": "['mindspore.parallel.nn\\n', 'Transformer接口的导入方式由 mindspore.parallel.nn 修改为 mindspore.nn.transformer ，这些接口的使用方式不变。\\n', '\\n', '原始的导入方式将保留1-2个版本。你可以通过以下样例查看差异：\\n', '\\n', '# r1.5\\n', 'from mindspore.parallel.nn import Transformer\\n', '\\n', '# Current\\n', 'from mindspore.nn.transformer import Transformer']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.parallel.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.parallel.html", "text_entry": "['mindspore.parallel\\n', '并行相关功能的接口。\\n', '\\n', 'mindspore.parallel.set_algo_parameters(**kwargs)[源代码]\\n', '设置并行策略搜索算法中的参数。有关典型用法，请参见 test_auto_parallel_resnet.py 。\\n', '\\n', 'Note\\n', '\\n', '属性名称为必填项。此接口仅在AUTO_PARALLEL模式下工作。\\n', '\\n', '参数：\\n', '\\n', 'fully_use_devices (bool) - 表示是否仅搜索充分利用所有可用设备的策略。默认值：True。例如，如果有8个可用设备，当该参数设为true时，策略(4, 1)将不包括在ReLU的候选策略中，因为策略(4, 1)仅使用4个设备。\\n', '\\n', 'elementwise_op_strategy_follow (bool) - 表示elementwise算子是否具有与后续算子一样的策略。默认值：False。例如，Add的输出给了ReLU，其中ReLU是elementwise算子。如果该参数设置为true，则算法搜索的策略可以保证这两个算子的策略是一致的，例如，ReLU的策略(8, 1)和Add的策略((8, 1), (8, 1))。\\n', '\\n', 'enable_algo_approxi (bool) - 表示是否在算法中启用近似。默认值：False。由于大型DNN模型的并行搜索策略有较大的解空间，该算法在这种情况下耗时较长。为了缓解这种情况，如果该参数设置为true，则会进行近似丢弃一些候选策略，以便缩小解空间。\\n', '\\n', 'algo_approxi_epsilon (float) - 表示近似算法中使用的epsilon值。默认值：0.1 此值描述了近似程度。例如，一个算子的候选策略数量为S，如果 enable_algo_approxi 为true，则剩余策略的大小为min{S, 1/epsilon}。\\n', '\\n', 'tensor_slice_align_enable (bool) - 表示是否检查MatMul的tensor切片的shape。默认值：False 受某些硬件的属性限制，只有shape较大的MatMul内核才能显示出优势。如果该参数为true，则检查MatMul的切片shape以阻断不规则的shape。\\n', '\\n', 'tensor_slice_align_size (int) - 表示MatMul的最小tensor切片的shape，该值必须在[1,1024]范围内。默认值：16。 如果 tensor_slice_align_enable 设为true，则MatMul tensor的最后维度的切片大小应该是该值的倍数。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 无法识别传入的关键字。\\n', '\\n', 'mindspore.parallel.reset_algo_parameters()[源代码]\\n', '重置算法参数属性。\\n', '\\n', 'Note\\n', '\\n', '此接口仅在AUTO_PARALLEL模式下工作。\\n', '\\n', '重置后，属性值为：\\n', '\\n', 'fully_use_devices：True\\n', '\\n', 'elementwise_op_strategy_follow：False\\n', '\\n', 'enable_algo_approxi：False\\n', '\\n', 'algo_approxi_epsilon：0.1\\n', '\\n', 'tensor_slice_align_enable：False\\n', '\\n', 'tensor_slice_align_size：16\\n', '\\n', 'mindspore.parallel.get_algo_parameters(attr_key)[源代码]\\n', '获取算法参数配置属性。\\n', '\\n', 'Note\\n', '\\n', '属性名称为必填项。此接口仅在AUTO_PARALLEL模式下工作。\\n', '\\n', '参数：\\n', '\\n', 'attr_key (str) - 属性的key。key包括”fully_use_devices”、”elementwise_op_strategy_follow”、”enable_algo_approxi”、”algo_approxi_epsilon”、”tensor_slice_align_enable”和”tensor_slice_align_size”。\\n', '\\n', '返回：\\n', '\\n', '根据key返回属性值。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 无法识别传入的关键字。\\n', '\\n']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.Profiler.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.profiler.html", "text_entry": "['mindspore.Profiler\\n', '本模块提供Python API，用于启用MindSpore神经网络性能数据的分析。 用户可以通过导入 mindspore.profiler.Profiler 然后初始化Profiler对象以开始分析，使用 Profiler.analyse() 停止收集和分析。 用户可通过Mindinsight工具可视化分析结果。 目前，Profiler支持AICORE算子、AICPU算子、HostCPU算子、内存、设备通信、集群等数据的分析。\\n', '\\n', 'classmindspore.profiler.Profiler(**kwargs)[源代码]\\n', 'MindSpore用户能够通过该类对神经网络的性能进行采集。\\n', '\\n', '参数：\\n', '\\n', 'output_path (str, 可选) – 表示输出数据的路径。默认值：”./data”。\\n', '\\n', 'profile_communication (bool, 可选) – （仅限Ascend）表示是否在多设备训练中收集通信性能数据。当值为True时，收集这些数据。在单台设备训练中，该参数的设置无效。默认值：False。\\n', '\\n', 'profile_memory (bool, 可选) – （仅限Ascend）表示是否收集Tensor内存数据。当值为True时，收集这些数据。默认值：False。\\n', '\\n', 'start_profile (bool, 可选) – 该参数控制是否在Profiler初始化的时候开启数据采集。默认值：True。\\n', '\\n', '异常：\\n', '\\n', 'RuntimeError – 当CANN的版本与MindSpore版本不匹配时，生成的ascend_job_id目录结构MindSpore无法解析。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import nn, context\\n', 'from mindspore import Model\\n', 'import mindspore.dataset as ds\\n', 'from mindspore.profiler import Profiler\\n', '\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self):\\n', '        super(Net, self).__init__()\\n', '        self.fc = nn.Dense(2,2)\\n', '    def construct(self, x):\\n', '        return self.fc(x)\\n', '\\n', 'def generator():\\n', '    for i in range(2):\\n', '        yield (np.ones([2, 2]).astype(np.float32), np.ones([2]).astype(np.int32))\\n', '\\n', 'def train(net):\\n', '    optimizer = nn.Momentum(net.trainable_params(), 1, 0.9)\\n', '    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\\n', '    data = ds.GeneratorDataset(generator, [\"data\", \"label\"])\\n', '    model = Model(net, loss, optimizer)\\n', '    model.train(1, data)\\n', '\\n', \"if __name__ == '__main__':\\n\", '    # If the device_target is GPU, set the device_target to \"GPU\"\\n', '    context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\")\\n', '\\n', '    # Init Profiler\\n', '    # Note that the Profiler should be initialized after context.set_context and before model.train\\n', '    # If you are running in parallel mode on Ascend, the Profiler should be initialized before HCCL\\n', '    # initialized.\\n', '    profiler = Profiler()\\n', '\\n', '    # Train Model\\n', '    net = Net()\\n', '    train(net)\\n', '\\n', '    # Profiler end\\n', '    profiler.analyse()\\n', 'analyse()[源代码]\\n', '收集和分析训练的性能数据，支持在训练中和训练后调用。样例如上所示。\\n', '\\n', 'start()[源代码]\\n', '开启Profiler数据采集，可以按条件开启Profiler。\\n', '\\n', '异常：\\n', '\\n', 'RuntimeError – profiler已经开启。\\n', '\\n', 'RuntimeError – 停止Minddata采集后，不支持重复开启。\\n', '\\n', 'RuntimeError – 如果start_profile参数未设置或设置为True。\\n', '\\n', '样例：\\n', '\\n', 'class StopAtStep(Callback):\\n', '    def __init__(self, start_step, stop_step):\\n', '        super(StopAtStep, self).__init__()\\n', '        self.start_step = start_step\\n', '        self.stop_step = stop_step\\n', '        self.profiler = Profiler(start_profile=False)\\n', '\\n', '    def step_begin(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        step_num = cb_params.cur_step_num\\n', '        if step_num == self.start_step:\\n', '            self.profiler.start()\\n', '\\n', '    def step_end(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        step_num = cb_params.cur_step_num\\n', '        if step_num == self.stop_step:\\n', '            self.profiler.stop()\\n', '\\n', '    def end(self, run_context):\\n', '        self.profiler.analyse()\\n', 'stop()[源代码]\\n', '停止Profiler，可以按条件停止Profiler。\\n', '\\n', '异常：\\n', '\\n', 'RuntimeError – profiler没有开启。\\n', '\\n', '样例：\\n', '\\n', 'class StopAtEpoch(Callback):\\n', '    def __init__(self, start_epoch, stop_epoch):\\n', '        super(StopAtEpoch, self).__init__()\\n', '        self.start_epoch = start_epoch\\n', '        self.stop_epoch = stop_epoch\\n', '        self.profiler = Profiler(start_profile=False)\\n', '\\n', '    def epoch_begin(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        epoch_num = cb_params.cur_epoch_num\\n', '        if epoch_num == self.start_epoch:\\n', '            self.profiler.start()\\n', '\\n', '    def epoch_end(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        epoch_num = cb_params.cur_epoch_num\\n', '        if epoch_num == self.stop_epoch:\\n', '            self.profiler.stop()\\n', '\\n', '    def end(self, run_context):\\n', '        self.profiler.analyse()\\n']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.scipy.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.scipy.html", "text_entry": "['mindspore.scipy\\n', 'Scipy-like interfaces in mindspore.\\n', '\\n', 'mindspore.scipy.linalg\\n', 'Linear algebra submodule.\\n', '\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.scipy.linalg.block_diag\\n', '\\n', 'Create a block diagonal matrix from provided arrays.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.cho_factor\\n', '\\n', 'Compute the cholesky decomposition of a matrix, to use in cho_solve.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.cholesky\\n', '\\n', 'Compute the cholesky decomposition of a matrix.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.cho_solve\\n', '\\n', 'Given the cholesky factorization of a, solve the linear equation\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.eigh\\n', '\\n', 'Solve a standard or generalized eigenvalue problem for a complex Hermitian or real symmetric matrix.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.inv\\n', '\\n', 'Compute the inverse of a matrix.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.lu\\n', '\\n', 'Compute pivoted LU decomposition of a general matrix.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.lu_factor\\n', '\\n', 'Compute pivoted LU decomposition of a square matrix, and its outputs can be directly used as the inputs of lu_solve.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.solve_triangular\\n', '\\n', 'Assuming a is a batched triangular matrix, solve the equation\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.optimize\\n', 'Optimize submodule.\\n', '\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.scipy.optimize.line_search\\n', '\\n', 'Inexact line search that satisfies strong Wolfe conditions.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.optimize.minimize\\n', '\\n', 'Minimization of scalar function of one or more variables.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.sparse.linalg\\n', 'Sparse linear algebra submodule.\\n', '\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.scipy.sparse.linalg.cg\\n', '\\n', 'Use Conjugate Gradient iteration to solve the linear system:\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.sparse.linalg.gmres\\n', '\\n', 'Given given A and b, GMRES solves the linear system:\\n', '\\n', 'CPU GPU']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.train.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.train.html", "text_entry": "['mindspore.train\\n', 'mindspore.train.summary\\n', '使用SummaryRecord将需要的数据存储为summary文件和lineage文件，使用方法包括自定义回调函数和自定义训练循环。保存的summary文件使用MindInsight进行可视化分析。\\n', '\\n', \"classmindspore.train.summary.SummaryRecord(log_dir, file_prefix='events', file_suffix='_MS', network=None, max_file_size=None, raise_exception=False, export_options=None)[源代码]\\n\", 'SummaryRecord用于记录summary数据和lineage数据。\\n', '\\n', '该方法将在一个指定的目录中创建summary文件和lineage文件，并将数据写入文件。\\n', '\\n', '它通过执行 record 方法将数据写入文件。除了通过 summary算子 记录网络的数据外，SummaryRecord还支持通过 自定义回调函数和自定义训练循环 记录数据。\\n', '\\n', 'Note\\n', '\\n', '使用SummaryRecord时，需要将代码放置到 if __name__ == “__main__” 中运行。\\n', '\\n', '确保在最后关闭SummaryRecord，否则进程不会退出。请参阅下面的示例部分，了解如何用两种方式正确关闭SummaryRecord。\\n', '\\n', '每次训练只允许创建一个SummaryRecord实例，否则会导致数据写入异常。\\n', '\\n', 'SummaryRecord仅支持Linux系统。\\n', '\\n', '编译MindSpore时，设置 -s on 关闭维测功能后，SummaryRecord不可用。\\n', '\\n', '参数：\\n', '\\n', 'log_dir (str) - log_dir 是用来保存summary文件的目录。\\n', '\\n', 'file_prefix (str) - 文件的前缀。默认值：events 。\\n', '\\n', 'file_suffix (str) - 文件的后缀。默认值：_MS 。\\n', '\\n', 'network (Cell) - 表示用于保存计算图的网络。默认值：None。\\n', '\\n', 'max_file_size (int, 可选) - 可写入磁盘的每个文件的最大大小（以字节为单位）。例如，预期写入文件最大不超过4GB，则设置 max_file_size=4*1024**3 。默认值：None，表示无限制。\\n', '\\n', 'raise_exception (bool, 可选) - 设置在记录数据中发生RuntimeError或OSError异常时是否抛出异常。默认值：False，表示打印错误日志，不抛出异常。\\n', '\\n', 'export_options (Union[None, dict]) - 可以将保存在summary中的数据导出，并使用字典自定义所需的数据和文件格式。注：导出的文件大小不受 max_file_size 的限制。例如，您可以设置{‘tensor_format’:’npy’}将Tensor导出为 npy 文件。支持导出的数据类型如下所示。默认值：None，表示不导出数据。\\n', '\\n', 'tensor_format (Union[str, None]) - 自定义导出的Tensor的格式。支持[“npy”, None]。默认值：None，表示不导出Tensor。\\n', '\\n', 'npy：将Tensor导出为NPY文件。\\n', '\\n', '异常：\\n', '\\n', 'TypeError： max_file_size 不是整型，或 file_prefix 和 file_suffix 不是字符串。\\n', '\\n', 'ValueError： 编译MindSpore时，设置 -s on 关闭了维测功能。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    # use in with statement to auto close\\n', '    with SummaryRecord(log_dir=\"./summary_dir\") as summary_record:\\n', '        pass\\n', '\\n', '    # use in try .. finally .. to ensure closing\\n', '    try:\\n', '        summary_record = SummaryRecord(log_dir=\"./summary_dir\")\\n', '    finally:\\n', '        summary_record.close()\\n', 'add_value(plugin, name, value)[源代码]\\n', '添加需要记录的值。\\n', '\\n', '参数：\\n', '\\n', 'plugin (str) - 数据类型标签。\\n', '\\n', 'graph：代表添加的数据为计算图。\\n', '\\n', 'scalar：代表添加的数据为标量。\\n', '\\n', 'image：代表添加的数据为图片。\\n', '\\n', 'tensor：代表添加的数据为张量。\\n', '\\n', 'histogram：代表添加的数据为直方图。\\n', '\\n', 'train_lineage：代表添加的数据为训练阶段的lineage数据。\\n', '\\n', 'eval_lineage：代表添加的数据为评估阶段的lineage数据。\\n', '\\n', 'dataset_graph：代表添加的数据为数据图。\\n', '\\n', 'custom_lineage_data：代表添加的数据为自定义lineage数据。\\n', '\\n', 'LANDSCAPE: 代表添加的数据为地形图。\\n', '\\n', 'name (str) - 数据名称。\\n', '\\n', 'value (Union[Tensor, GraphProto, TrainLineage, EvaluationLineage, DatasetGraph, UserDefinedInfo，LossLandscape])：待存储的值。\\n', '\\n', '当plugin为”graph”时，参数值的数据类型应为”GraphProto”对象。具体详情，请参见 mindspore/ccsrc/anf_ir.proto。\\n', '\\n', '当plugin为”scalar”、”image”、”tensor”或”histogram”时，参数值的数据类型应为”Tensor”对象。\\n', '\\n', '当plugin为”train_lineage”时，参数值的数据类型应为”TrainLineage”对象。具体详情，请参见 mindspore/ccsrc/lineage.proto。\\n', '\\n', '当plugin为”eval_lineage”时，参数值的数据类型应为”EvaluationLineage”对象。具体详情，请参见 mindspore/ccsrc/lineage.proto。\\n', '\\n', '当plugin为”dataset_graph”时，参数值的数据类型应为”DatasetGraph”对象。具体详情，请参见 mindspore/ccsrc/lineage.proto。\\n', '\\n', '当plugin为”custom_lineage_data”时，参数值的数据类型应为”UserDefinedInfo”对象。具体详情，请参见 mindspore/ccsrc/lineage.proto。\\n', '\\n', '当plugin为”LANDSCAPE”时，参数值的数据类型应为”LossLandscape”对象。具体详情，请参见 mindspore/ccsrc/summary.proto。\\n', '\\n', '异常：\\n', '\\n', 'ValueError： plugin 的值不在可选值内。\\n', '\\n', 'TypeError： name 不是非空字符串，或当 plugin 为”scalar”、”image”、”tensor”或”histogram”时，value 的数据类型不是”Tensor”对象。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import Tensor\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', \"        summary_record.add_value('scalar', 'loss', Tensor(0.1))\\n\", 'close()[源代码]\\n', '将缓冲区中的数据立刻写入文件并关闭SummaryRecord。请使用with语句或try…finally语句进行自动关闭。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    try:\\n', '        summary_record = SummaryRecord(log_dir=\"./summary_dir\")\\n', '    finally:\\n', '        summary_record.close()\\n', 'flush()[源代码]\\n', '刷新缓冲区，将缓冲区中的数据写入磁盘。\\n', '\\n', '调用该函数以确保所有挂起事件都已写入到磁盘。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', '        summary_record.flush()\\n', 'propertylog_dir\\n', '获取日志文件的完整路径。\\n', '\\n', '返回：\\n', '\\n', 'str，日志文件的完整路径。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', '        log_dir = summary_record.log_dir\\n', 'record(step, train_network=None, plugin_filter=None)[源代码]\\n', '记录summary。\\n', '\\n', '参数：\\n', '\\n', 'step (int) - 表示当前的step。\\n', '\\n', 'train_network (Cell) - 表示用于保存计算图的训练网络。默认值：None，表示当原始网络的图为None时，不保存计算图。\\n', '\\n', 'plugin_filter (Callable[[str], bool], 可选) - 过滤器函数，用于过滤需要写入的标签项。默认值：None。\\n', '\\n', '返回：\\n', '\\n', 'bool，表示记录是否成功。\\n', '\\n', '异常：\\n', '\\n', 'TypeError： step 不为整型，或 train_network 的类型不为 mindspore.nn.Cell 。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', '        result = summary_record.record(step=2)\\n', '        print(result)\\n', '\\n', '\\n', 'set_mode(mode)[源代码]\\n', '设置模型运行阶段。不同的阶段会影响记录数据的内容。\\n', '\\n', '参数：\\n', '\\n', 'mode (str) - 待设置的网络阶段，可选值为”train”或”eval”。\\n', '\\n', 'train：代表训练阶段。\\n', '\\n', 'eval：代表评估阶段，此时 summary_record 不会记录summary算子的数据。\\n', '\\n', '异常：\\n', '\\n', 'ValueError： mode 的值不在可选值内。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', \"        summary_record.set_mode('eval')\\n\", 'mindspore.train.callback\\n', 'classmindspore.train.callback.Callback[源代码]\\n', '用于构建Callback函数的基类。Callback函数是一个上下文管理器，在运行模型时被调用。 可以使用此机制进行一些自定义操作。\\n', '\\n', 'Callback函数可以在step或epoch开始前或结束后执行一些操作。 要创建自定义Callback，需要继承Callback基类并重载它相应的方法，有关自定义Callback的详细信息，请查看 Callback。\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import Model, nn\\n', 'from mindspore.train.callback import Callback\\n', 'from mindspore import dataset as ds\\n', 'class Print_info(Callback):\\n', '    def step_end(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        print(\"step_num: \", cb_params.cur_step_num)\\n', '\\n', 'print_cb = Print_info()\\n', 'data = {\"x\": np.float32(np.random.rand(64, 10)), \"y\": np.random.randint(0, 5, (64,))}\\n', 'dataset = ds.NumpySlicesDataset(data=data).batch(32)\\n', 'net = nn.Dense(10, 5)\\n', \"loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'optim = nn.Momentum(net.trainable_params(), 0.01, 0.9)\\n', 'model = Model(net, loss_fn=loss, optimizer=optim)\\n', 'model.train(1, dataset, callbacks=print_cb)\\n', '\\n', 'begin(run_context)[源代码]\\n', '在网络执行之前被调用一次。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'end(run_context)[源代码]\\n', '网络执行后被调用一次。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'epoch_begin(run_context)[源代码]\\n', '在每个epoch开始之前被调用。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'epoch_end(run_context)[源代码]\\n', '在每个epoch结束后被调用。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'step_begin(run_context)[源代码]\\n', '在每个step开始之前被调用。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'step_end(run_context)[源代码]\\n', '在每个step完成后被调用。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'classmindspore.train.callback.LossMonitor(per_print_times=1)[源代码]\\n', '监控训练的loss。\\n', '\\n', '如果loss是NAN或INF，则终止训练。\\n', '\\n', 'Note\\n', '\\n', '如果 per_print_times 为0，则不打印loss。\\n', '\\n', '参数：\\n', '\\n', 'per_print_times (int) - 表示每隔多少个step打印一次loss。默认值：1。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 当 per_print_times 不是整数或小于零。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import Model, nn\\n', '\\n', 'net = LeNet5()\\n', \"loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'optim = nn.Momentum(net.trainable_params(), 0.01, 0.9)\\n', 'model = Model(net, loss_fn=loss, optimizer=optim)\\n', \"data_path = './MNIST_Data'\\n\", 'dataset = create_dataset(data_path)\\n', 'loss_monitor = LossMonitor()\\n', 'model.train(10, dataset, callbacks=loss_monitor)\\n', 'step_end(run_context)[源代码]\\n', 'step结束时打印训练loss。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的相关信息。\\n', '\\n', 'classmindspore.train.callback.TimeMonitor(data_size=None)[源代码]\\n', '监控训练时间。\\n', '\\n', '参数：\\n', '\\n', 'data_size (int) - 表示每隔多少个step打印一次信息。如果程序在训练期间获取到Model的 batch_num ，则将把 data_size 设为 batch_num ，否则将使用 data_size 。默认值：None。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - data_size 不是正整数。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import Model, nn\\n', '\\n', 'net = LeNet5()\\n', \"loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'optim = nn.Momentum(net.trainable_params(), 0.01, 0.9)\\n', 'model = Model(net, loss_fn=loss, optimizer=optim)\\n', \"data_path = './MNIST_Data'\\n\", 'dataset = create_dataset(data_path)\\n', 'time_monitor = TimeMonitor()\\n', 'model.train(10, dataset, callbacks=time_monitor)\\n', 'epoch_begin(run_context)[源代码]\\n', '在epoch开始时记录时间。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的相关信息。\\n', '\\n', 'epoch_end(run_context)[源代码]\\n', '在epoch结束时打印epoch的耗时。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的相关信息。\\n', '\\n', \"classmindspore.train.callback.ModelCheckpoint(prefix='CKP', directory=None, config=None)[源代码]\\n\", 'checkpoint的回调函数。\\n', '\\n', '在训练过程中调用该方法可以保存网络参数。\\n', '\\n', 'Note\\n', '\\n', '在分布式训练场景下，请为每个训练进程指定不同的目录来保存checkpoint文件。否则，可能会训练失败。 如果在 model 方法中使用此回调函数，默认将会把优化器中的参数保存到checkpoint文件中。\\n', '\\n', '参数：\\n', '\\n', 'prefix (str) - checkpoint文件的前缀名称。默认值：’CKP’。\\n', '\\n', 'directory (str) - 保存checkpoint文件的文件夹路径。默认情况下，文件保存在当前目录下。默认值：None。\\n', '\\n', 'config (CheckpointConfig) - checkpoint策略配置。默认值：None。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 如果prefix参数不是str类型或包含’/’字符。\\n', '\\n', 'ValueError - 如果directory参数不是str类型。\\n', '\\n', 'TypeError - config不是CheckpointConfig类型。\\n', '\\n', 'end(run_context)[源代码]\\n', '在训练结束后，会保存最后一个step的checkpoint。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'propertylatest_ckpt_file_name\\n', '返回最新的checkpoint路径和文件名。\\n', '\\n', 'step_end(run_context)[源代码]\\n', '在step结束时保存checkpoint。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'classmindspore.train.callback.SummaryCollector(summary_dir, collect_freq=10, collect_specified_data=None, keep_default_action=True, custom_lineage_data=None, collect_tensor_freq=None, max_file_size=None, export_options=None)[源代码]\\n', 'SummaryCollector可以收集一些常用信息。\\n', '\\n', '它可以帮助收集loss、学习率、计算图等。 SummaryCollector还可以允许通过 summary算子 将数据收集到summary文件中。\\n', '\\n', 'Note\\n', '\\n', '使用SummaryCollector时，需要将代码放置到 if __name__ == “__main__” 中运行。\\n', '\\n', '不允许在回调列表中存在多个SummaryCollector实例。\\n', '\\n', '并非所有信息都可以在训练阶段或评估阶段收集。\\n', '\\n', 'SummaryCollector始终记录summary算子收集的数据。\\n', '\\n', 'SummaryCollector仅支持Linux系统。\\n', '\\n', '编译MindSpore时，设置 -s on 关闭维测功能后，SummaryCollector不可用。\\n', '\\n', '参数：\\n', '\\n', 'summary_dir (str) - 收集的数据将存储到此目录。如果目录不存在，将自动创建。\\n', '\\n', 'collect_freq (int) - 设置数据收集的频率，频率应大于零，单位为 step 。如果设置了频率，将在(current steps % freq)=0时收集数据，并且将总是收集第一个step。需要注意的是，如果使用数据下沉模式，单位将变成 epoch 。不建议过于频繁地收集数据，因为这可能会影响性能。默认值：10。\\n', '\\n', 'collect_specified_data (Union[None, dict]) - 对收集的数据进行自定义操作。您可以使用字典自定义需要收集的数据类型。例如，您可以设置{‘collect_metric’:False}不去收集metrics。支持控制的数据如下。默认值：None，收集所有数据。\\n', '\\n', 'collect_metric (bool) - 表示是否收集训练metrics，目前只收集loss。把第一个输出视为loss，并且算出其平均数。默认值：True。\\n', '\\n', 'collect_graph (bool) - 表示是否收集计算图。目前只收集训练计算图。默认值：True。\\n', '\\n', 'collect_train_lineage (bool) - 表示是否收集训练阶段的lineage数据，该字段将显示在MindInsight的 lineage页面 上。默认值：True。\\n', '\\n', 'collect_eval_lineage (bool) - 表示是否收集评估阶段的lineage数据，该字段将显示在MindInsight的lineage页面上。默认值：True。\\n', '\\n', 'collect_input_data (bool) - 表示是否为每次训练收集数据集。目前仅支持图像数据。如果数据集中有多列数据，则第一列应为图像数据。默认值：True。\\n', '\\n', 'collect_dataset_graph (bool) - 表示是否收集训练阶段的数据集图。默认值：True。\\n', '\\n', 'histogram_regular (Union[str, None]) - 收集参数分布页面的权重和偏置，并在MindInsight中展示。此字段允许正则表达式控制要收集的参数。不建议一次收集太多参数，因为这会影响性能。注：如果收集的参数太多并且内存不足，训练将会失败。默认值：None，表示只收集网络的前五个超参。\\n', '\\n', 'collect_landscape (Union[dict, None]) - 表示是否收集创建loss地形图所需要的参数。如果设置None，则不收集任何参数。默认收集所有参数并且将会保存在 {summary_dir}/ckpt_dir/train_metadata.json 文件中。\\n', '\\n', 'landscape_size (int) - 指定生成loss地形图的图像分辨率。例如：如果设置为128，则loss地形图的分辨率是128*128。注意：计算loss地形图的时间随着分辨率的增大而增加。默认值：40。可选值：3-256。\\n', '\\n', 'unit (str) - 指定训练过程中保存checkpoint时，下方参数 intervals 以何种形式收集模型权重。例如：将 intervals 设置为[[1, 2, 3, 4]]，如果 unit 设置为step，则收集模型权重的频率单位为step，将保存1-4个step的模型权重，而 unit 设置为epoch，则将保存1-4个epoch的模型权重。默认值：step。可选值：epoch/step。\\n', '\\n', 'create_landscape (dict) - 选择创建哪种类型的loss地形图，分为训练过程loss地形图（train）和训练结果loss地形图（result）。默认值：{“train”: True, “result”: True}。可选值：True/False。\\n', '\\n', 'num_samples (int) - 创建loss地形图所使用的数据集的大小。例如：在图像数据集中，您可以设置 num_samples 是128，这意味着将有128张图片被用来创建loss地形图。注意：num_samples 越大，计算loss地形图时间越长。默认值：128。\\n', '\\n', 'intervals (List[List[int]]) - 指定loss地形图的区间。例如：如果用户想要创建两张训练过程的loss地形图，分别为1-5epoch和6-10epoch，则用户可以设置[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]。注意：每个区间至少包含3个epoch。\\n', '\\n', 'keep_default_action (bool) - 此字段影响 collect_specified_data 字段的收集行为。True：表示设置指定数据后，其他数据按默认设置收集。False：表示设置指定数据后，只收集指定数据，不收集其他数据。默认值：True。\\n', '\\n', 'custom_lineage_data (Union[dict, None]) - 允许您自定义数据并将数据显示在MindInsight的lineage页面上。在自定义数据中，key支持str类型，value支持str、int和float类型。默认值：None，表示不存在自定义数据。\\n', '\\n', 'collect_tensor_freq (Optional[int]) - 语义与 collect_freq 的相同，但仅控制TensorSummary。由于TensorSummary数据太大，无法与其他summary数据进行比较，因此此参数用于降低收集量。默认情况下，收集TensorSummary数据的最大step数量为20，但不会超过收集其他summary数据的step数量。例如，给定 collect_freq=10 ，当总step数量为600时，TensorSummary将收集20个step，而收集其他summary数据时会收集61个step。但当总step数量为20时，TensorSummary和其他summary将收集3个step。另外请注意，在并行模式下，会平均分配总的step数量，这会影响TensorSummary收集的step的数量。默认值：None，表示要遵循上述规则。\\n', '\\n', 'max_file_size (Optional[int]) - 可写入磁盘的每个文件的最大大小（以字节为单位）。例如，如果不大于4GB，则设置 max_file_size=4*1024**3 。默认值：None，表示无限制。\\n', '\\n', 'export_options (Union[None, dict]) - 表示对导出的数据执行自定义操作。注：导出的文件的大小不受 max_file_size 的限制。您可以使用字典自定义导出的数据。例如，您可以设置{‘tensor_format’:’npy’}将tensor导出为 npy 文件。支持控制的数据如下所示。默认值：None，表示不导出数据。\\n', '\\n', 'tensor_format (Union[str, None]) - 自定义导出的tensor的格式。支持[“npy”, None]。默认值：None，表示不导出tensor。\\n', '\\n', 'npy - 将tensor导出为NPY文件。\\n', '\\n', '异常：\\n', '\\n', 'ValueError： 编译MindSpore时，设置 -s on 关闭了维测功能。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore.nn as nn\\n', 'from mindspore import context\\n', 'from mindspore.train.callback import SummaryCollector\\n', 'from mindspore import Model\\n', 'from mindspore.nn import Accuracy\\n', '\\n', \"if __name__ == '__main__':\\n\", '    # If the device_target is GPU, set the device_target to \"GPU\"\\n', '    context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\")\\n', \"    mnist_dataset_dir = '/path/to/mnist_dataset_directory'\\n\", '    # The detail of create_dataset method shown in model_zoo.official.cv.lenet.src.dataset.py\\n', '    ds_train = create_dataset(mnist_dataset_dir, 32)\\n', '    # The detail of LeNet5 shown in model_zoo.official.cv.lenet.src.lenet.py\\n', '    network = LeNet5(10)\\n', '    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\\n', '    net_opt = nn.Momentum(network.trainable_params(), 0.01, 0.9)\\n', '    model = Model(network, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()}, amp_level=\"O2\")\\n', '\\n', '    # Simple usage:\\n', \"    summary_collector = SummaryCollector(summary_dir='./summary_dir')\\n\", '    model.train(1, ds_train, callbacks=[summary_collector], dataset_sink_mode=False)\\n', '\\n', '    # Do not collect metric and collect the first layer parameter, others are collected by default\\n', \"    specified={'collect_metric': False, 'histogram_regular': '^conv1.*'}\\n\", \"    summary_collector = SummaryCollector(summary_dir='./summary_dir', collect_specified_data=specified)\\n\", '    model.train(1, ds_train, callbacks=[summary_collector], dataset_sink_mode=False)\\n', \"classmindspore.train.callback.CheckpointConfig(save_checkpoint_steps=1, save_checkpoint_seconds=0, keep_checkpoint_max=5, keep_checkpoint_per_n_minutes=0, integrated_save=True, async_save=False, saved_network=None, append_info=None, enc_key=None, enc_mode='AES-GCM', exception_save=False)[源代码]\\n\", '保存checkpoint时的配置策略。\\n', '\\n', 'Note\\n', '\\n', '在训练过程中，如果数据集是通过数据通道传输的，建议将 save_checkpoint_steps 设为循环下沉step数量的整数倍数，否则，保存checkpoint的时机可能会有偏差。建议同时只设置一种触发保存checkpoint策略和一种保留checkpoint文件总数策略。如果同时设置了 save_checkpoint_steps 和 save_checkpoint_seconds ，则 save_checkpoint_seconds 无效。如果同时设置了 keep_checkpoint_max 和 keep_checkpoint_per_n_minutes ，则 keep_checkpoint_per_n_minutes 无效。\\n', '\\n', '参数：\\n', '\\n', 'save_checkpoint_steps (int) - 每隔多少个step保存一次checkpoint。默认值：1。\\n', '\\n', 'save_checkpoint_seconds (int) - 每隔多少秒保存一次checkpoint。不能同时与 save_checkpoint_steps 一起使用。默认值：0。\\n', '\\n', 'keep_checkpoint_max (int) - 最多保存多少个checkpoint文件。默认值：5。\\n', '\\n', 'keep_checkpoint_per_n_minutes (int) - 每隔多少分钟保存一个checkpoint文件。不能同时与 keep_checkpoint_max 一起使用。默认值：0。\\n', '\\n', 'integrated_save (bool) - 在自动并行场景下，是否合并保存拆分后的Tensor。合并保存功能仅支持在自动并行场景中使用，在手动并行场景中不支持。默认值：True。\\n', '\\n', 'async_save (bool) - 是否异步执行保存checkpoint文件。默认值：False。\\n', '\\n', 'saved_network (Cell) - 保存在checkpoint文件中的网络。如果 saved_network 没有被训练，则保存 saved_network 的初始值。默认值：None。\\n', '\\n', 'append_info (list) - 保存在checkpoint文件中的信息。支持”epoch_num”、”step_num”和dict类型。dict的key必须是str，dict的value必须是int、float或bool中的一个。默认值：None。\\n', '\\n', 'enc_key (Union[None, bytes]) - 用于加密的字节类型key。如果值为None，则不需要加密。默认值：None。\\n', '\\n', 'enc_mode (str) - 仅当 enc_key 不设为None时，该参数有效。指定了加密模式，目前支持AES-GCM和AES-CBC。默认值：AES-GCM。\\n', '\\n', 'exception_save (bool) - 当有异常发生时，是否保存当前checkpoint文件。默认值：False。\\n', '\\n', '异常：\\n', '\\n', 'ValueError - 输入参数的类型不正确。\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import Model, nn\\n', 'from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\\n', 'from mindspore.common.initializer import Normal\\n', '\\n', 'class LeNet5(nn.Cell):\\n', '    def __init__(self, num_class=10, num_channel=1):\\n', '        super(LeNet5, self).__init__()\\n', \"        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\\n\", \"        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\\n\", '        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))\\n', '        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\\n', '        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\\n', '        self.relu = nn.ReLU()\\n', '        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\\n', '        self.flatten = nn.Flatten()\\n', '\\n', '    def construct(self, x):\\n', '        x = self.max_pool2d(self.relu(self.conv1(x)))\\n', '        x = self.max_pool2d(self.relu(self.conv2(x)))\\n', '        x = self.flatten(x)\\n', '        x = self.relu(self.fc1(x))\\n', '        x = self.relu(self.fc2(x))\\n', '        x = self.fc3(x)\\n', '        return x\\n', '\\n', 'net = LeNet5()\\n', \"loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'optim = nn.Momentum(net.trainable_params(), 0.01, 0.9)\\n', 'model = Model(net, loss_fn=loss, optimizer=optim)\\n', \"data_path = './MNIST_Data'\\n\", 'dataset = create_dataset(data_path)\\n', 'config = CheckpointConfig(saved_network=net)\\n', \"ckpoint_cb = ModelCheckpoint(prefix='LeNet5', directory='./checkpoint', config=config)\\n\", 'model.train(10, dataset, callbacks=ckpoint_cb)\\n', 'propertyappend_dict\\n', '获取需要额外保存到checkpoint中的字典的值。\\n', '\\n', '返回：\\n', '\\n', 'Dict: 字典中的值。\\n', '\\n', 'propertyasync_save\\n', '获取是否异步保存checkpoint。\\n', '\\n', '返回：\\n', '\\n', 'Bool: 是否异步保存checkpoint。\\n', '\\n', 'propertyenc_key\\n', '获取加密的key值。\\n', '\\n', '返回：\\n', '\\n', '(None, bytes): 加密的key值。\\n', '\\n', 'propertyenc_mode\\n', '获取加密模式。\\n', '\\n', '返回：\\n', '\\n', 'str: 加密模式。\\n', '\\n', 'get_checkpoint_policy()[源代码]\\n', '获取checkpoint的保存策略。\\n', '\\n', '返回：\\n', '\\n', 'Dict: checkpoint的保存策略。\\n', '\\n', 'propertyintegrated_save\\n', '获取是否合并保存拆分后的Tensor。\\n', '\\n', '返回：\\n', '\\n', 'Bool: 获取是否合并保存拆分后的Tensor。\\n', '\\n', 'propertykeep_checkpoint_max\\n', '获取最多保存checkpoint文件的数量。\\n', '\\n', '返回：\\n', '\\n', 'Int: 最多保存checkpoint文件的数量。\\n', '\\n', 'propertykeep_checkpoint_per_n_minutes\\n', '获取每隔多少分钟保存一个checkpoint文件。\\n', '\\n', '返回：\\n', '\\n', 'Int: 每隔多少分钟保存一个checkpoint文件。\\n', '\\n', 'propertysave_checkpoint_seconds\\n', '获取每隔多少秒保存一次checkpoint文件。\\n', '\\n', '返回：\\n', '\\n', 'Int: 每隔多少秒保存一次checkpoint文件。\\n', '\\n', 'propertysave_checkpoint_steps\\n', '获取每隔多少个step保存一次checkpoint文件。\\n', '\\n', '返回：\\n', '\\n', 'Int: 每隔多少个step保存一次checkpoint文件。\\n', '\\n', 'propertysaved_network\\n', '获取需要保存的网络。\\n', '\\n', '返回：\\n', '\\n', 'Cell: 需要保存的网络。\\n', '\\n', 'classmindspore.train.callback.RunContext(original_args)[源代码]\\n', '提供模型的相关信息。\\n', '\\n', '在Model方法里提供模型的相关信息。 回调函数可以调用 request_stop() 方法来停止迭代。\\n', '\\n', '参数：\\n', '\\n', 'original_args (dict) - 模型的相关信息。\\n', '\\n', 'get_stop_requested()[源代码]\\n', '获取是否停止训练的标志。\\n', '\\n', '返回：\\n', '\\n', 'bool，如果为True，则 Model.train() 停止迭代。\\n', '\\n', 'original_args()[源代码]\\n', '获取模型相关信息的对象。\\n', '\\n', '返回：\\n', '\\n', 'dict，含有模型的相关信息的对象。\\n', '\\n', 'request_stop()[源代码]\\n', '在训练期间设置停止请求。\\n', '\\n', '可以使用此函数请求停止训练。 Model.train() 会检查是否调用此函数。\\n', '\\n', 'classmindspore.train.callback.LearningRateScheduler(learning_rate_function)[源代码]\\n', '用于在训练期间更改学习率。\\n', '\\n', '参数：\\n', '\\n', 'learning_rate_function (Function) - 在训练期间更改学习率的函数。\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'from mindspore import Model\\n', 'from mindspore.train.callback import LearningRateScheduler\\n', 'import mindspore.nn as nn\\n', 'from mindspore import dataset as ds\\n', '\\n', 'def learning_rate_function(lr, cur_step_num):\\n', '    if cur_step_num%1000 == 0:\\n', '        lr = lr*0.1\\n', '    return lr\\n', '\\n', 'lr = 0.1\\n', 'momentum = 0.9\\n', 'net = nn.Dense(10, 5)\\n', \"loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'optim = nn.Momentum(net.trainable_params(), learning_rate=lr, momentum=momentum)\\n', 'model = Model(net, loss_fn=loss, optimizer=optim)\\n', '\\n', 'data = {\"x\": np.float32(np.random.rand(64, 10)), \"y\": np.random.randint(0, 5, (64,))}\\n', 'dataset = ds.NumpySlicesDataset(data=data).batch(32)\\n', 'model.train(1, dataset, callbacks=[LearningRateScheduler(learning_rate_function)],\\n', '            dataset_sink_mode=False)\\n', 'step_end(run_context)[源代码]\\n', '在step结束时更改学习率。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'classmindspore.train.callback.SummaryLandscape(summary_dir)[源代码]\\n', 'SummaryLandscape可以帮助您收集loss地形图的信息。通过计算loss，可以在PCA（Principal Component Analysis）方向或者随机方向创建地形图。\\n', '\\n', 'Note\\n', '\\n', '使用SummaryLandscape时，需要将代码放置到 if __name__ == “__main__” 中运行。\\n', '\\n', 'SummaryLandscape仅支持Linux系统。\\n', '\\n', '参数：\\n', '\\n', 'summary_dir (str) - 该路径将被用来保存创建地形图所使用的数据。\\n', '\\n', '样例：\\n', '\\n', 'import mindspore.nn as nn\\n', 'from mindspore import context\\n', 'from mindspore.train.callback import SummaryCollector, SummaryLandscape\\n', 'from mindspore import Model\\n', 'from mindspore.nn import Loss, Accuracy\\n', '\\n', \"if __name__ == '__main__':\\n\", '    # If the device_target is Ascend, set the device_target to \"Ascend\"\\n', '    context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\\n', \"    mnist_dataset_dir = '/path/to/mnist_dataset_directory'\\n\", '    # The detail of create_dataset method shown in model_zoo.official.cv.lenet.src.dataset.py\\n', '    ds_train = create_dataset(mnist_dataset_dir, 32)\\n', '    # The detail of LeNet5 shown in model_zoo.official.cv.lenet.src.lenet.py\\n', '    network = LeNet5(10)\\n', '    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\\n', '    net_opt = nn.Momentum(network.trainable_params(), 0.01, 0.9)\\n', '    model = Model(network, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()})\\n', '    # Simple usage for collect landscape information:\\n', '    interval_1 = [1, 2, 3, 4, 5]\\n', \"    summary_collector = SummaryCollector(summary_dir='./summary/lenet_interval_1',\\n\", '                                         collect_specified_data={\\'collect_landscape\\':{\"landscape_size\": 4,\\n', '                                                                                       \"unit\": \"step\",\\n', '                                                                         \"create_landscape\":{\"train\":True,\\n', '                                                                                            \"result\":False},\\n', '                                                                         \"num_samples\": 2048,\\n', '                                                                         \"intervals\": [interval_1]}\\n', '                                                                   })\\n', '    model.train(1, ds_train, callbacks=[summary_collector], dataset_sink_mode=False)\\n', '\\n', '    # Simple usage for visualization landscape:\\n', '    def callback_fn():\\n', '        network = LeNet5(10)\\n', '        net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\\n', '        metrics = {\"Loss\": Loss()}\\n', '        model = Model(network, net_loss, metrics=metrics)\\n', \"        mnist_dataset_dir = '/path/to/mnist_dataset_directory'\\n\", '        ds_eval = create_dataset(mnist_dataset_dir, 32)\\n', '        return model, network, ds_eval, metrics\\n', '\\n', \"    summary_landscape = SummaryLandscape('./summary/lenet_interval_1')\\n\", '    # parameters of collect_landscape can be modified or unchanged\\n', '    summary_landscape.gen_landscapes_with_multi_process(callback_fn,\\n', '                                                       collect_landscape={\"landscape_size\": 4,\\n', '                                                                        \"create_landscape\":{\"train\":False,\\n', '                                                                                           \"result\":False},\\n', '                                                                         \"num_samples\": 2048,\\n', '                                                                         \"intervals\": [interval_1]},\\n', '                                                        device_ids=[1])\\n', 'clean_ckpt()[源代码]\\n', '清理checkpoint。\\n', '\\n', 'gen_landscapes_with_multi_process(callback_fn, collect_landscape=None, device_ids=None, output=None)[源代码]\\n', '使用多进程来生成地形图。\\n', '\\n', '参数：\\n', '\\n', 'callback_fn (python function) - Python函数对象，用户需要写一个没有输入的函数，返回值要求如下。\\n', '\\n', 'mindspore.train.Model：用户的模型。\\n', '\\n', 'mindspore.nn.Cell：用户的网络。\\n', '\\n', 'mindspore.dataset：创建loss所需要的用户数据集。\\n', '\\n', 'mindspore.nn.Metrics：用户的评估指标。\\n', '\\n', 'collect_landscape (Union[dict, None]) - 创建loss地形图所用的参数含义与SummaryCollector同名字段一致。此处设置的目的是允许用户可以自由修改创建loss地形图参数。默认值：None。\\n', '\\n', 'landscape_size (int) - 指定生成loss地形图的图像分辨率。例如：如果设置为128，则loss地形图的分辨率是128*128。计算loss地形图的时间随着分辨率的增大而增加。默认值：40。可选值：3-256。\\n', '\\n', 'create_landscape (dict) - 选择创建哪种类型的loss地形图，分为训练过程loss地形图（train）和训练结果loss地形图（result）。默认值：{“train”: True, “result”: True}。可选值：True/False。\\n', '\\n', 'num_samples (int) - 创建loss地形图所使用的数据集的大小。例如：在图像数据集中，您可以设置 num_samples 是128，这意味着将有128张图片被用来创建loss地形图。注意：num_samples 越大，计算loss地形图时间越长。默认值：128。\\n', '\\n', 'intervals (List[List[int]]) - 指定创建loss地形图所需要的checkpoint区间。例如：如果用户想要创建两张训练过程的loss地形图，分别为1-5epoch和6-10epoch，则用户可以设置[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]。注意：每个区间至少包含3个epoch。\\n', '\\n', 'device_ids (List(int)) - 指定创建loss地形图所使用的目标设备的ID。例如：[0, 1]表示使用设备0和设备1来创建loss地形图。默认值：None。\\n', '\\n', 'output (str) - 指定保存loss地形图的路径。默认值：None。默认保存路径与summary文件相同。\\n', '\\n', 'classmindspore.train.callback.History[源代码]\\n', '将网络输出的相关信息记录到 History 对象中。\\n', '\\n', '用户不自定义训练网络或评估网络情况下，记录的内容将为损失值；用户自定义了训练网络/评估网络的情况下，如果定义的网络返回 Tensor 或 numpy.ndarray，则记录此返回值均值，如果返回 tuple 或 list，则记录第一个元素。\\n', '\\n', 'Note\\n', '\\n', '通常使用在 mindspore.Model.train 中。\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'import mindspore.dataset as ds\\n', 'from mindspore.train.callback import History\\n', 'from mindspore import Model, nn\\n', 'data = {\"x\": np.float32(np.random.rand(64, 10)), \"y\": np.random.randint(0, 5, (64,))}\\n', 'train_dataset = ds.NumpySlicesDataset(data=data).batch(32)\\n', 'net = nn.Dense(10, 5)\\n', \"crit = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'opt = nn.Momentum(net.trainable_params(), 0.01, 0.9)\\n', 'history_cb = History()\\n', 'model = Model(network=net, optimizer=opt, loss_fn=crit, metrics={\"recall\"})\\n', 'model.train(2, train_dataset, callbacks=[history_cb])\\n', 'print(history_cb.epoch)\\n', 'print(history_cb.history)\\n', '\\n', '\\n', 'begin(run_context)[源代码]\\n', '训练开始时初始化History对象的epoch属性。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'epoch_end(run_context)[源代码]\\n', 'epoch结束时记录网络输出的相关信息。\\n', '\\n', '参数：\\n', '\\n', 'run_context (RunContext) - 包含模型的一些基本信息。\\n', '\\n', 'classmindspore.train.callback.LambdaCallback(epoch_begin=None, epoch_end=None, step_begin=None, step_end=None, begin=None, end=None)[源代码]\\n', '用于自定义简单的callback。\\n', '\\n', '使用匿名函数构建callback，定义的匿名函数将在 mindspore.Model.{train | eval} 的对应阶段被调用。\\n', '\\n', '请注意，callback的每个阶段都需要一个位置参数：run_context。\\n', '\\n', 'Note\\n', '\\n', '这是一个会变更或删除的实验性接口。\\n', '\\n', '参数：\\n', '\\n', 'epoch_begin (Function) - 每个epoch开始时被调用。\\n', '\\n', 'epoch_end (Function) - 每个epoch结束时被调用。\\n', '\\n', 'step_begin (Function) - 每个step开始时被调用。\\n', '\\n', 'step_end (Function) - 每个step结束时被调用。\\n', '\\n', 'begin (Function) - 模型训练、评估开始时被调用。\\n', '\\n', 'end (Function) - 模型训练、评估结束时被调用。\\n', '\\n', '样例：\\n', '\\n', 'import numpy as np\\n', 'import mindspore.dataset as ds\\n', 'from mindspore.train.callback import LambdaCallback\\n', 'from mindspore import Model, nn\\n', 'data = {\"x\": np.float32(np.random.rand(64, 10)), \"y\": np.random.randint(0, 5, (64,))}\\n', 'train_dataset = ds.NumpySlicesDataset(data=data).batch(32)\\n', 'net = nn.Dense(10, 5)\\n', \"crit = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'opt = nn.Momentum(net.trainable_params(), 0.01, 0.9)\\n', 'lambda_callback = LambdaCallback(epoch_end=\\n', 'lambda run_context: print(\"loss: \", run_context.original_args().net_outputs))\\n', 'model = Model(network=net, optimizer=opt, loss_fn=crit, metrics={\"recall\"})\\n', 'model.train(2, train_dataset, callbacks=[lambda_callback])\\n', '\\n', '\\n', 'mindspore.train.train_thor\\n', '转换为二阶相关的类和函数。\\n', '\\n', 'classmindspore.train.train_thor.ConvertNetUtils[源代码]\\n', '将网络转换为thor层网络，用于计算并存储二阶信息矩阵。\\n', '\\n', 'convert_to_thor_net(net)[源代码]\\n', '该接口用于将网络转换为thor层网络，用于计算并存储二阶信息矩阵。\\n', '\\n', 'Note\\n', '\\n', '此接口由二阶优化器thor自动调用。\\n', '\\n', '参数：\\n', '\\n', 'net (Cell) - 由二阶优化器thor训练的网络。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'ConvertNetUtils().convert_to_thor_net(net)\\n', 'classmindspore.train.train_thor.ConvertModelUtils[源代码]\\n', '该接口用于增加计算图，提升二阶算法THOR运行时的性能。\\n', '\\n', \"staticconvert_to_thor_model(model, network, loss_fn=None, optimizer=None, metrics=None, amp_level='O0', loss_scale_manager=None, keep_batchnorm_fp32=False)[源代码]\\n\", '该接口用于增加计算图，提升二阶算法THOR运行时的性能。\\n', '\\n', '参数：\\n', '\\n', 'model (Object) - 用于训练的高级API。 Model 将图层分组到具有训练特征的对象中。\\n', '\\n', 'network (Cell) - 训练网络。\\n', '\\n', 'loss_fn (Cell) - 目标函数。默认值：None。\\n', '\\n', 'optimizer (Cell) - 用于更新权重的优化器。默认值：None。\\n', '\\n', 'metrics (Union[dict, set]) - 在训练期间由模型评估的词典或一组度量。例如：{‘accuracy’, ‘recall’}。默认值：None。\\n', '\\n', 'amp_level (str) - 混合精度训练的级别。支持[“O0”, “O2”, “O3”, “auto”]。默认值：”O0”。\\n', '\\n', 'O0 - 不改变。\\n', '\\n', 'O2 - 将网络转换为float16，使用动态loss scale保持BN在float32中运行。\\n', '\\n', 'O3 - 将网络强制转换为float16，并使用附加属性 keep_batchnorm_fp32=False 。\\n', '\\n', 'auto - 在不同设备中，将级别设置为建议级别。GPU上建议使用O2，Ascend上建议使用O3。建议级别基于专家经验，不能总是一概而论。用户应指定特殊网络的级别。\\n', '\\n', 'loss_scale_manager (Union[None, LossScaleManager]) - 如果为None，则不会按比例缩放loss。否则，通过LossScaleManager和优化器缩放loss不能为None。这是一个关键参数。例如，使用 loss_scale_manager=None 设置值。\\n', '\\n', 'keep_batchnorm_fp32 (bool) - 保持BN在 float32 中运行。如果为True，则将覆盖之前的级别设置。默认值：False。\\n', '\\n', '返回：\\n', '\\n', 'model (Object) - 用于训练的高级API。 Model 将图层分组到具有训练特征的对象中。\\n', '\\n', '支持平台：\\n', '\\n', 'Ascend GPU\\n', '\\n', '样例：\\n', '\\n', 'from mindspore import nn\\n', 'from mindspore import Tensor\\n', 'from mindspore.nn import thor\\n', 'from mindspore import Model\\n', 'from mindspore import FixedLossScaleManager\\n', 'from mindspore.train.callback import LossMonitor\\n', 'from mindspore.train.train_thor import ConvertModelUtils\\n', '\\n', 'net = Net()\\n', 'dataset = create_dataset()\\n', 'temp = Tensor([4e-4, 1e-4, 1e-5, 1e-5], mstype.float32)\\n', 'opt = thor(net, learning_rate=temp, damping=temp, momentum=0.9, loss_scale=128, frequency=4)\\n', \"loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'loss_scale = FixedLossScaleManager(128, drop_overflow_update=False)\\n', \"model = Model(net, loss_fn=loss, optimizer=opt, loss_scale_manager=loss_scale, metrics={'acc'},\\n\", '              amp_level=\"O2\", keep_batchnorm_fp32=False)\\n', 'model = ConvertModelUtils.convert_to_thor_model(model=model, network=net, loss_fn=loss, optimizer=opt,\\n', \"                                                loss_scale_manager=loss_scale, metrics={'acc'},\\n\", '                                                amp_level=\"O2\", keep_batchnorm_fp32=False)\\n', 'loss_cb = LossMonitor()\\n', 'model.train(1, dataset, callbacks=loss_cb, sink_size=4, dataset_sink_mode=True)']"}
{"index": {"_index": "r1.7-python-api", "_id": "mindspore.txt"}}
{"file_link": "https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.html", "text_entry": "['mindspore\\n', '张量\\n', 'mindspore.Tensor\\n', '\\n', '张量，即存储多维数组（n-dimensional array）的数据结构。\\n', '\\n', 'mindspore.COOTensor\\n', '\\n', '用来表示某一张量在给定索引上非零元素的集合，其中索引(indices)指示了每一个非零元素的位置。\\n', '\\n', 'mindspore.CSRTensor\\n', '\\n', '用来表示某一张量在给定索引上非零元素的集合，其中行索引由 indptr 表示，列索引由 indices 。\\n', '\\n', 'mindspore.RowTensor\\n', '\\n', '用来表示一组指定索引的张量切片的稀疏表示。\\n', '\\n', 'mindspore.SparseTensor\\n', '\\n', '用来表示某一张量在给定索引上非零元素的集合。\\n', '\\n', '参数\\n', 'mindspore.Parameter\\n', '\\n', 'Parameter 是 Tensor 的子类，当它们被绑定为Cell的属性时，会自动添加到其参数列表中，并且可以通过Cell的某些方法获取，例如 cell.get_parameters() 。\\n', '\\n', 'mindspore.ParameterTuple\\n', '\\n', '继承于tuple，用于管理多个Parameter。\\n', '\\n', '数据类型\\n', 'mindspore.dtype\\n', '\\n', '创建一个MindSpore数据类型的对象。\\n', '\\n', 'mindspore.dtype_to_nptype\\n', '\\n', '将MindSpore 数据类型转换成NumPy数据类型。\\n', '\\n', 'mindspore.issubclass_\\n', '\\n', '判断 type_ 是否为 dtype 的子类。\\n', '\\n', 'mindspore.dtype_to_pytype\\n', '\\n', '将MindSpore 数据类型转换为Python数据类型。\\n', '\\n', 'mindspore.pytype_to_dtype\\n', '\\n', '将Python数据类型转换为MindSpore数据类型。\\n', '\\n', 'mindspore.get_py_obj_dtype\\n', '\\n', '将Python数据类型转换为MindSpore数据类型。\\n', '\\n', '随机种子\\n', 'mindspore.set_seed\\n', '\\n', '设置全局种子。\\n', '\\n', 'mindspore.get_seed\\n', '\\n', '获取随机种子。\\n', '\\n', '模型\\n', 'mindspore.Model\\n', '\\n', '模型训练或推理的高阶接口。\\n', '\\n', '数据处理工具\\n', 'mindspore.DatasetHelper\\n', '\\n', 'DatasetHelper是一个处理MindData数据集的类，提供数据集信息。\\n', '\\n', 'mindspore.connect_network_with_dataset\\n', '\\n', '将 network 与 dataset_helper 中的数据集连接。\\n', '\\n', '混合精度管理\\n', 'mindspore.LossScaleManager\\n', '\\n', '使用混合精度时，用于管理损失缩放系数（loss scale）的抽象类。\\n', '\\n', 'mindspore.FixedLossScaleManager\\n', '\\n', '损失缩放系数不变的管理器，继承自 mindspore.LossScaleManager 。\\n', '\\n', 'mindspore.DynamicLossScaleManager\\n', '\\n', '动态调整损失缩放系数的管理器，继承自 mindspore.LossScaleManager 。\\n', '\\n', '序列化\\n', 'mindspore.async_ckpt_thread_status\\n', '\\n', '获取异步保存checkpoint文件线程的状态。\\n', '\\n', 'mindspore.build_searched_strategy\\n', '\\n', '构建网络中每个参数的策略，用于分布式推理。\\n', '\\n', 'mindspore.convert_model\\n', '\\n', '将MindIR模型转化为其他格式的模型文件。\\n', '\\n', 'mindspore.export\\n', '\\n', '将MindSpore网络模型导出为指定格式的文件。\\n', '\\n', 'mindspore.load\\n', '\\n', '加载MindIR文件。\\n', '\\n', 'mindspore.load_checkpoint\\n', '\\n', '加载checkpoint文件。\\n', '\\n', 'mindspore.load_distributed_checkpoint\\n', '\\n', '给分布式预测加载checkpoint文件到网络，用于分布式推理。\\n', '\\n', 'mindspore.load_param_into_net\\n', '\\n', '将参数加载到网络中，返回网络中没有被加载的参数列表。\\n', '\\n', 'mindspore.merge_sliced_parameter\\n', '\\n', '将参数切片合并为一个完整的参数，用于分布式推理。\\n', '\\n', 'mindspore.parse_print\\n', '\\n', '解析由 mindspore.ops.Print 生成的数据文件。\\n', '\\n', 'mindspore.restore_group_info_list\\n', '\\n', '从group_info_file_name指向的文件中提取得到通信域的信息，在该通信域内的所有设备的checkpoint文件均与存储group_info_file_name的设备相同，可以直接进行替换。\\n', '\\n', 'mindspore.save_checkpoint\\n', '\\n', '将网络权重保存到checkpoint文件中。\\n', '\\n', '即时编译\\n', 'mindspore.ms_function\\n', '\\n', '将Python函数编译为一张可调用的MindSpore图。\\n', '\\n', 'mindspore.ms_class\\n', '\\n', '用户自定义类的类装饰器。\\n', '\\n', '日志\\n', 'mindspore.get_level\\n', '\\n', '获取日志记录器的级别。\\n', '\\n', 'mindspore.get_log_config\\n', '\\n', '获取日志配置。\\n', '\\n', '自动混合精度\\n', 'mindspore.build_train_network\\n', '\\n', '构建混合精度训练网络。\\n', '\\n', '安装验证\\n', 'mindspore.run_check\\n', '\\n', '提供了便捷的API用以查询MindSpore的安装是否成功。\\n', '\\n', '调试\\n', 'mindspore.set_dump\\n', '\\n', '启用或者禁用 target 及其子节点的Dump数据功能。\\n', '\\n', '内存回收\\n', 'mindspore.ms_memory_recycle\\n', '\\n', '回收MindSpore使用的内存。\\n', '\\n']"}
