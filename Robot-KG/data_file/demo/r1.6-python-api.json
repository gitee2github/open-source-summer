{"index": {"_index": "r1.6-python-api", "_id": "mindspore.boost (experimental).txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.boost.html", "text_entry": "['mindspore.boost (experimental)\\n', 'Boost provide auto accelerating for network, such as Less BN, Gradient Freeze, Gradient accumulation and so on.\\n', '\\n', 'Note\\n', '\\n', 'This feature is a beta feature, and we are still improving its functionality.\\n', '\\n', 'classmindspore.boost.AutoBoost(level=\"O0\", boost_config_dict=\"\")[source]\\n', 'Provide auto accelerating for network.\\n', '\\n', 'Parameters\\n', 'level (str) – Boost config level. Default: “O0”.\\n', '\\n', 'boost_config_dict (dict) –\\n', '\\n', 'User config hyperparameter dict, recommended config format:\\n', '\\n', '{\\n', '    \"boost\": {\\n', '        \"mode\": \"auto\",\\n', '        \"less_bn\": False,\\n', '        \"grad_freeze\": False,\\n', '        \"adasum\": False,\\n', '        \"grad_accumulation\": False,\\n', '        \"dim_reduce\": False\\n', '    },\\n', '    \"common\": {\\n', '        \"gradient_split_groups\": [50, 100],\\n', '        \"device_number\": 8\\n', '    },\\n', '    \"less_bn\": {\\n', '        \"fn_flag\": True,\\n', '        \"gc_flag\": True\\n', '    },\\n', '    \"grad_freeze\": {\\n', '        \"param_groups\": 10,\\n', '        \"freeze_type\": 1,\\n', '        \"freeze_p\": 0.7,\\n', '        \"total_steps\": 65536\\n', '    }\\n', '    \"grad_accumulation\": {\\n', '        \"grad_accumulation_step\": 1\\n', '    },\\n', '    \"dim_reduce\": {\\n', '        \"rho\": 0.55,\\n', '        \"gamma\": 0.9,\\n', '        \"alpha\": 0.001,\\n', '        \"sigma\": 0.4,\\n', '        \"n_components\": 32,\\n', '        \"pca_mat_path\": None,\\n', '        \"weight_load_dir\": None,\\n', '        \"timeout\": 1800\\n', '    }\\n', '}\\n', 'boost:\\n', '\\n', 'mode (str): How to set the boost. Supports [“auto”, “manual”, “enable_all”, “disable_all”]. Default: “auto”.\\n', '\\n', 'auto: Depend on the argument “boost_level” in class model.\\n', '\\n', 'manual: Depen on “boost_config_dict”.\\n', '\\n', 'enable_all: Set all boost functions true.\\n', '\\n', 'disable_all: Set all boost functions false.\\n', '\\n', 'less_bn (bool): Whether to apply less_bn function. Default: False.\\n', '\\n', 'grad_freeze: (bool): Whether to apply grad_freeze function. Default: False.\\n', '\\n', 'adasum (bool): Whether to apply adasum function. Default: False.\\n', '\\n', 'grad_accumulation (bool): Whether to apply grad_accumulation function. Default: False.\\n', '\\n', 'dim_reduce (bool): Whether to apply dim_reduce function. Default: False.\\n', '\\n', 'If set dim_reduce true, other functions will be false. If set grad_freeze true and dim_reduce fasle, other functions will be false.\\n', '\\n', 'common:\\n', '\\n', 'gradient_split_groups (list): The gradient split point of this network. Default: [50, 100].\\n', '\\n', 'device_number (int): Device number. Default: 8.\\n', '\\n', 'less_bn:\\n', '\\n', 'fn_flag (bool): Whether changing fc to fn. Default: True.\\n', '\\n', 'gc_flag (bool): Whether to apply gc. Default: True.\\n', '\\n', 'grad_freeze:\\n', '\\n', 'param_groups (int): The number of parameter groups. Default: 10.\\n', '\\n', 'freeze_type (int): Gradient freeze grouping strategy, select from [0, 1]. Default: 1.\\n', '\\n', 'freeze_p (float): Gradient freezing probability. Default: 0.7.\\n', '\\n', 'total_steps (int): Total training steps. Default: 65536.\\n', '\\n', 'grad_accumulation:\\n', '\\n', 'grad_ccumulation_step (int): Steps to accumulate gradients. Default: 1.\\n', '\\n', 'dim_reduce:\\n', '\\n', 'grad_kdkskdelta_loss=pca_mat⋅grad=−bk⋅grad_k=rhom⋅dk=sigma⋅grad_k.T⋅sk\\n', 'Here:\\n', '\\n', 'pca_mat (array): Shape (k*n), k is part of n_components, n is the size of weight.\\n', '\\n', 'bk (array): Shape (k*k), is the symmetric positive definite matrix in Quasi-Newton method.\\n', '\\n', 'we need to find the m satisfy:\\n', '\\n', 'new_loss<old_loss+delta_loss\\n', 'Then, get delta_grad to update the weights for model:\\n', '\\n', 'grad_k_projnew_grad_momentumdelta_grad=pca_mat.T⋅grad_k=gamma⋅old_grad_momentum+grad−grad_k_proj=alpha⋅new_grad_momentum−pca_mat.T⋅sk\\n', 'rho (float): Generally, it does not need to be modified. Default: 0.55.\\n', '\\n', 'gamma (float): Generally, it does not need to be modified. Default: 0.9.\\n', '\\n', 'alpha (float): Generally, it does not need to be modified. Default: 0.001.\\n', '\\n', 'sigma (float): Generally, it does not need to be modified. Default: 0.4.\\n', '\\n', 'n_components (int): PCA component. Default: 32.\\n', '\\n', 'pca_mat_path (str): The path to load pca mat. Default: None.\\n', '\\n', 'weight_load_dir (str): The directory to load weight files saved as ckpt. Default: None.\\n', '\\n', 'timeout (int): Waiting time to load local pca mat. Default: 1800 second.\\n', '\\n', 'User can load the config through the JSON file or use the dictionary directly. The unconfigured parameters will adopt the default values. Default: “”.\\n', '\\n', 'Raises\\n', 'ValueError – The boost mode not in [“auto”, “manual”, “enable_all”, “disable_all”].\\n', '\\n', 'Supported Platforms:\\n', 'Ascend\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.boost import AutoBoost\\n', '#1) when configuring the dict directly:\\n', 'boost_config_dict = {\"boost\": {\"mode\": \"auto\"}}\\n', 'boost = AutoBoost(\"O1\", boost_config_dict)\\n', '\\n', '#2) when loading the dict from a json file:\\n', 'import json\\n', 'boost_json = \"/path/boost_config.json\"\\n', \"with open(boost_json, 'r') as fp:\\n\", '    boost_config_dict = json.load(fp)\\n', 'boost = AutoBoost(\"O1\", boost_config_dict)\\n', 'network_auto_process_eval(network)[source]\\n', 'Boost network eval.\\n', '\\n', 'Parameters\\n', 'network (Cell) – The inference network.\\n', '\\n', 'network_auto_process_train(network, optimizer)[source]\\n', 'Boost network train.\\n', '\\n', 'Parameters\\n', 'network (Cell) – The training network.\\n', '\\n', 'optimizer (Cell) – Optimizer for updating the weights.\\n', '\\n', 'classmindspore.boost.OptimizerProcess(opt)[source]\\n', 'Process optimizer for Boost. Currently, this class supports adding GC(grad centralization) tags and creating new optimizers.\\n', '\\n', 'Parameters\\n', 'opt (Cell) – Optimizer used.\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import Tensor, Parameter, nn\\n', 'from mindspore import ops\\n', 'from mindspore.boost import OptimizerProcess\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self, in_features, out_features):\\n', '        super(Net, self).__init__()\\n', '        self.weight = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight')\\n\", '        self.matmul = ops.MatMul()\\n', '\\n', '    def construct(self, x):\\n', '        output = self.matmul(x, self.weight)\\n', '        return output\\n', '\\n', 'size, in_features, out_features = 16, 16, 10\\n', 'network = Net(in_features, out_features)\\n', 'optimizer = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', 'optimizer_process = OptimizerProcess(optimizer)\\n', 'optimizer_process.add_grad_centralization(network)\\n', 'optimizer = optimizer_process.generate_new_optimizer()\\n', 'add_grad_centralization(network)[source]\\n', 'Add gradient centralization.\\n', '\\n', 'Parameters\\n', 'network (Cell) – The training network.\\n', '\\n', 'build_gc_params_group(params_dict, parameters)[source]\\n', 'Build the parameter’s group with grad centralization.\\n', '\\n', 'Parameters\\n', 'params_dict (dict) – The network’s parameter dict.\\n', '\\n', 'parameters (list) – The network’s parameter list.\\n', '\\n', 'build_params_dict(network)[source]\\n', 'Build the parameter’s dict of the network.\\n', '\\n', 'Parameters\\n', 'network (Cell) – The training network.\\n', '\\n', 'generate_new_optimizer()[source]\\n', 'Generate new optimizer.\\n', '\\n', 'classmindspore.boost.ParameterProcess[source]\\n', 'Process parameter for Boost. Currently, this class supports creating group parameters and automatically setting gradient segmentation point.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import Tensor, Parameter, nn\\n', 'import mindspore.ops as ops\\n', 'from mindspore.boost import OptimizerProcess\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self, in_features, out_features):\\n', '        super(Net, self).__init__()\\n', '        self.weight = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight')\\n\", '        self.weight2 = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight2')\\n\", '        self.matmul = ops.MatMul()\\n', '        self.matmul2 = ops.MatMul()\\n', '\\n', '    def construct(self, x):\\n', '        output = self.matmul(x, self.weight)\\n', '        output2 = self.matmul2(x, self.weight2)\\n', '        return output + output2\\n', '\\n', 'size, in_features, out_features = 16, 16, 10\\n', 'network = Net(in_features, out_features)\\n', 'new_parameter = net.trainable_params()[:1]\\n', 'parameter_process = ParameterProcess()\\n', 'group_params = parameter_process.generate_group_params(new_parameter, net.trainable_params())\\n', 'assign_parameter_group(parameters, split_point=None)[source]\\n', 'Assign parameter group.\\n', '\\n', 'Parameters\\n', 'parameters (list) – The network’s parameter list.\\n', '\\n', 'split_point (list) – The gradient split point of this network. default: None.\\n', '\\n', 'generate_group_params(parameters, origin_params)[source]\\n', 'Generate group parameters.\\n', '\\n', 'Parameters\\n', 'parameters (list) – The network’s parameter list.\\n', '\\n', 'origin_params (list) – The network’s origin parameter list.\\n', '\\n', 'classmindspore.boost.BoostTrainOneStepCell(network, optimizer, sens=1.0)[source]\\n', 'Boost Network training package class.\\n', '\\n', 'Wraps the network with an optimizer. The resulting Cell is trained with input ‘*inputs’. The backward graph will be created in the construct function to update the parameter. Different parallel modes are available for training.\\n', '\\n', 'Parameters\\n', 'network (Cell) – The training network. The network only supports single output.\\n', '\\n', 'optimizer (Union[Cell]) – Optimizer for updating the weights.\\n', '\\n', 'sens (numbers.Number) – The scaling number to be filled as the input of backpropagation. Default value is 1.0.\\n', '\\n', 'Inputs:\\n', '(*inputs) (Tuple(Tensor)) - Tuple of input tensors with shape (N,…).\\n', '\\n', 'Outputs:\\n', 'Tensor, a tensor means the loss value, the shape of which is usually ().\\n', '\\n', 'Raises\\n', 'TypeError – If sens is not a number.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU CPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import boost\\n', 'net = Net()\\n', 'loss_fn = nn.SoftmaxCrossEntropyWithLogits()\\n', 'optim = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', '#1) Using the WithLossCell existing provide\\n', 'loss_net = nn.WithLossCell(net, loss_fn)\\n', 'train_net = boost.BoostTrainOneStepCell(loss_net, optim)\\n', '\\n', '#2) Using user-defined WithLossCell\\n', 'class MyWithLossCell(Cell):\\n', '   def __init__(self, backbone, loss_fn):\\n', '       super(MyWithLossCell, self).__init__(auto_prefix=False)\\n', '       self._backbone = backbone\\n', '       self._loss_fn = loss_fn\\n', '\\n', '   def construct(self, x, y, label):\\n', '       out = self._backbone(x, y)\\n', '       return self._loss_fn(out, label)\\n', '\\n', '   @property\\n', '   def backbone_network(self):\\n', '       return self._backbone\\n', '\\n', 'loss_net = MyWithLossCell(net, loss_fn)\\n', 'train_net = boost.BoostTrainOneStepCell(loss_net, optim)\\n', 'adasum_process(loss, grads)[source]\\n', 'Adasum algorithm process.\\n', '\\n', 'Parameters\\n', 'loss (Tensor) – Tensor with shape ().\\n', '\\n', 'grads (tuple(Tensor)) – Tuple of gradient tensors.\\n', '\\n', 'Outputs:\\n', 'loss (Tensor) - Tensor with shape ().\\n', '\\n', 'check_adasum_enable()[source]\\n', 'Check adasum enable.\\n', '\\n', 'check_dim_reduce_enable()[source]\\n', 'Check dim_reduce enable.\\n', '\\n', 'gradient_accumulation_process(loss, grads, sens, *inputs)[source]\\n', 'Gradient accumulation algorithm process.\\n', '\\n', 'Parameters\\n', 'loss (Tensor) – Tensor with shape ().\\n', '\\n', 'grads (tuple(Tensor)) – Tuple of gradient tensors.\\n', '\\n', 'sens (Tensor) – Tensor with shape ().\\n', '\\n', 'Outputs:\\n', 'loss (Tensor) - Tensor with shape ().\\n', '\\n', 'gradient_freeze_process(*inputs)[source]\\n', 'Gradient freeze algorithm process.\\n', '\\n', 'Parameters\\n', 'inputs (tuple(Tensor)) – Tuple of input tensors with shape (N,…).\\n', '\\n', 'Outputs:\\n', 'loss (Tensor) - Tensor with shape ().\\n', '\\n', 'classmindspore.boost.BoostTrainOneStepWithLossScaleCell(network, optimizer, scale_sense)[source]\\n', 'Boost Network training with loss scaling.\\n', '\\n', 'This is a training step with loss scaling. It takes a network, an optimizer and possibly a scale update Cell as args. The loss scale value can be updated in both host side or device side. The BoostTrainOneStepWithLossScaleCell will be compiled to be graph which takes *inputs as input data. The Tensor type of scale_sense is acting as loss scaling value. If you want to update it on host side, the value must be provided. If the Tensor type of scale_sense is not given, the loss scale update logic must be provide by Cell type of scale_sense.\\n', '\\n', 'Parameters\\n', 'network (Cell) – The training network. The network only supports single output.\\n', '\\n', 'optimizer (Cell) – Optimizer for updating the weights.\\n', '\\n', 'scale_sense (Union[Tensor, Cell]) – If this value is Cell type, the loss scaling update logic cell.If this value is Tensor type, Tensor with shape () or (1,).\\n', '\\n', 'Inputs:\\n', '(*inputs) (Tuple(Tensor)) - Tuple of input tensors with shape (N,…).\\n', '\\n', 'Outputs:\\n', 'Tuple of 3 Tensor, the loss, overflow flag and current loss scaling value.\\n', '\\n', 'loss (Tensor) - Tensor with shape ().\\n', '\\n', 'overflow (Tensor) - Tensor with shape (), type is bool.\\n', '\\n', 'loss scaling value (Tensor) - Tensor with shape ()\\n', '\\n', 'Raises\\n', 'TypeError – If scale_sense is neither Cell nor Tensor.\\n', '\\n', 'ValueError – If shape of scale_sense is neither (1,) nor ().\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import Tensor, Parameter, nn\\n', 'import mindspore.ops as ops\\n', 'from mindspore.nn import WithLossCell\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore import boost\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self, in_features, out_features):\\n', '        super(Net, self).__init__()\\n', '        self.weight = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight')\\n\", '        self.matmul = ops.MatMul()\\n', '\\n', '    def construct(self, x):\\n', '        output = self.matmul(x, self.weight)\\n', '        return output\\n', '\\n', 'size, in_features, out_features = 16, 16, 10\\n', '#1) when the type of scale_sense is Cell:\\n', 'net = Net(in_features, out_features)\\n', 'loss = nn.MSELoss()\\n', 'optimizer = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', 'net_with_loss = WithLossCell(net, loss)\\n', 'manager = nn.DynamicLossScaleUpdateCell(loss_scale_value=2**12, scale_factor=2, scale_window=1000)\\n', 'train_network = boost.BoostTrainOneStepWithLossScaleCell(net_with_loss, optimizer, scale_sense=manager)\\n', 'input = Tensor(np.ones([out_features, in_features]), mstype.float32)\\n', 'labels = Tensor(np.ones([out_features,]), mstype.float32)\\n', 'output = train_network(input, labels)\\n', '\\n', '#2) when the type of scale_sense is Tensor:\\n', 'net = Net(in_features, out_features)\\n', 'loss = nn.MSELoss()\\n', 'optimizer = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', 'net_with_loss = WithLossCell(net, loss)\\n', 'inputs = Tensor(np.ones([size, in_features]).astype(np.float32))\\n', 'label = Tensor(np.zeros([size, out_features]).astype(np.float32))\\n', 'scaling_sens = Tensor(np.full((1), np.finfo(np.float32).max), dtype=mstype.float32)\\n', 'train_network = boost.BoostTrainOneStepWithLossScaleCell(net_with_loss, optimizer, scale_sense=scaling_sens)\\n', 'output = train_network(inputs, label)\\n', 'classmindspore.boost.LessBN(network, fn_flag=False)[source]\\n', 'Reduce the number of BN automatically to improve the network performance and ensure the network accuracy.\\n', '\\n', 'Parameters\\n', 'network (Cell) – Network to be modified.\\n', '\\n', 'fn_flag (bool) – Replace FC with FN. default: False.\\n', '\\n', 'Examples\\n', '\\n', 'network = boost.LessBN(network)\\n', 'classmindspore.boost.GradientFreeze(param_groups, freeze_type, freeze_p, total_steps)[source]\\n', 'Freezing the gradients of some layers randomly. The number and probability of frozen layers can be configured by users\\n', '\\n', 'Parameters\\n', 'param_groups (Union[tuple, list]) – Groups of parameters for gradients freezing training.\\n', '\\n', 'freeze_type (int) – Strategy of gradients freezing training.\\n', '\\n', 'freeze_p (float) – probability of gradients freezing training.\\n', '\\n', 'total_steps (numbers.Number) – Steps of the whole training.\\n', '\\n', 'Examples\\n', '\\n', 'gradient_freeze_class = boost.GradientFreeze(10, 1, 0.5, 2000)\\n', 'network, optimizer = gradient_freeze_class.freeze_generate(network, optimizer)\\n', 'freeze_generate(network, optimizer)[source]\\n', 'Generate freeze network and optimizer.\\n', '\\n', 'Parameters\\n', 'network (Cell) – The training network.\\n', '\\n', 'optimizer (Cell) – Optimizer for updating the weights.\\n', '\\n', 'generate_freeze_index_sequence(parameter_groups_number, freeze_strategy, freeze_p, total_steps)[source]\\n', 'Generate index sequence for gradient freezing training.\\n', '\\n', 'Parameters\\n', 'parameter_groups_number (int) – The number of parameter groups.\\n', '\\n', 'freeze_strategy (int) – Gradient freeze grouping strategy, select from [0, 1].\\n', '\\n', 'freeze_p (float) – Gradient freezing probability.\\n', '\\n', 'total_steps (int) – Total training steps.\\n', '\\n', 'split_parameters_groups(net, freeze_para_groups_number)[source]\\n', 'Split parameter groups for gradients freezing training.\\n', '\\n', 'Parameters\\n', 'net (Cell) – The training network.\\n', '\\n', 'freeze_para_groups_number (int) – The number of gradient freeze groups.\\n', '\\n', 'classmindspore.boost.FreezeOpt(opt, train_parameter_groups=None, train_strategy=None)[source]\\n', 'Optimizer that supports gradients freezing training.\\n', '\\n', 'Parameters\\n', 'opt (Cell) – non-freezing optimizer instance, such as ‘Momentum’, ‘SGD’.\\n', '\\n', 'train_parameter_groups (Union[tuple, list]) – Groups of parameters for gradients freezing training.\\n', '\\n', 'train_strategy (Union[tuple(int), list(int), Tensor]) – Strategy for gradients freezing training.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend\\n', '\\n', 'mindspore.boost.freeze_cell(reducer_flag, network, optimizer, sens, grad, use_grad_accumulation, mean=None, degree=None, max_accumulation_step=1)[source]\\n', 'Generate freeze network and optimizer.\\n', '\\n', 'Parameters\\n', 'reducer_flag (bool) – Reducer flag.\\n', '\\n', 'network (Cell) – The training network.\\n', '\\n', 'optimizer (Cell) – Optimizer for updating the weights.\\n', '\\n', 'sens (numbers.Number) – The scaling number.\\n', '\\n', 'grad (tuple(Tensor)) – Tuple of gradient tensors.\\n', '\\n', 'use_grad_accumulation (bool) – Use gradient accumulation flag.\\n', '\\n', 'mean (bool) – Gradients mean flag. default: None.\\n', '\\n', 'degree (int) – Device number. default: None.\\n', '\\n', 'max_accumulation_step (int) – Max accumulation steps. default: 1.\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import Tensor, Parameter, nn\\n', 'import mindspore.ops as ops\\n', 'from mindspore.boost.grad_freeze import freeze_cell\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self, in_features, out_features):\\n', '        super(Net, self).__init__()\\n', '        self.weight = Parameter(Tensor(np.ones([in_features, out_features]).astype(np.float32)),\\n', \"                                name='weight')\\n\", '        self.matmul = ops.MatMul()\\n', '\\n', '    def construct(self, x):\\n', '        output = self.matmul(x, self.weight)\\n', '        return output\\n', '\\n', 'in_features, out_features = 16, 10\\n', 'network = Net(in_features, out_features)\\n', 'optimizer = nn.Momentum(net.trainable_params(), learning_rate=0.1, momentum=0.9)\\n', 'grad = ops.GradOperation(get_by_list=True, sens_param=True)\\n', 'freeze_nets = freeze_cell(False, network, optimizer, 1.0, grad, False, None, None, 1)\\n', 'classmindspore.boost.GradientAccumulation(max_accumulation_step, optimizer)[source]\\n', 'After accumulating the gradients of multiple steps, call to optimize its update.\\n', '\\n', 'Parameters\\n', 'max_accumulation_step (int) – Steps to accumulate gradients.\\n', '\\n', 'optimizer (Cell) – Optimizer used.\\n', '\\n', 'classmindspore.boost.AdaSum(rank, device_number, group_number, parameter_tuple)[source]\\n', 'The Adaptive Summation, or AdaSum, is a novel algorithm for improving distributed data parallel training of Deep Learning models.\\n', '\\n', 'Parameters\\n', 'rank (int) – Rank number.\\n', '\\n', 'device_number (int) – Device number.\\n', '\\n', 'group_number (int) – Group number.\\n', '\\n', 'parameter_tuple (Tuple(Parameter)) – Tuple of parameters.\\n', '\\n', 'Inputs:\\n', 'delta_weights (Tuple(Tensor)) - Tuple of gradients.\\n', '\\n', 'parameters (Tuple(Parameter)) - Tuple of current parameters.\\n', '\\n', 'old_parameters (Tuple(Parameter)) - Tuple of last parameters.\\n', '\\n', 'Outputs:\\n', 'adasum_parameters (Tuple(Tensor)) - Tuple of parameters after adasum process.\\n', '\\n', 'classmindspore.boost.DimReduce(network, optimizer, weight, pca_mat_local, n_components, rho, gamma, alpha, sigma, rank, rank_size)[source]\\n', 'The dimension reduce training, is a novel algorithm for accelerating convergence of Deep Learning models.\\n', '\\n', 'grad_kdkskdelta_loss=pca_mat⋅grad=−bk⋅grad_k=rhom⋅dk=sigma⋅grad_k.T⋅sk\\n', 'Here:\\n', '\\n', 'pca_mat (array): Shape (k*n), k is part of n_components, n is the size of weight.\\n', '\\n', 'bk (array): Shape (k*k), is the symmetric positive definite matrix in Quasi-Newton method.\\n', '\\n', 'we need to find the m satisfy:\\n', '\\n', 'new_loss<old_loss+delta_loss\\n', 'Then, get delta_grad to update the weights for model:\\n', '\\n', 'grad_k_projnew_grad_momentumdelta_grad=pca_mat.T⋅grad_k=gamma⋅old_grad_momentum+grad−grad_k_proj=alpha⋅new_grad_momentum−pca_mat.T⋅sk\\n', 'Parameters\\n', 'network (Cell) – The training network. The network only supports single output.\\n', '\\n', 'optimizer (Union[Cell]) – Optimizer for updating the weights.\\n', '\\n', 'weight (Tuple(Parameter)) – Tuple of parameters.\\n', '\\n', 'pca_mat_local (numpy.ndarray) – For PCA operation, k*n, k is part of n_components, n is the size of weight.\\n', '\\n', 'n_components (int) – PCA.components.\\n', '\\n', 'rho (float) – Coefficient.\\n', '\\n', 'gamma (float) – Coefficient.\\n', '\\n', 'alpha (float) – Coefficient.\\n', '\\n', 'sigma (float) – Coefficient.\\n', '\\n', 'rank (int) – Rank number.\\n', '\\n', 'rank_size (int) – Rank size.\\n', '\\n', 'Inputs:\\n', 'loss (Tensor) - Tensor with shape ().\\n', '\\n', 'old_grad (Tuple(Tensor)) - Tuple of gradient tensors.\\n', '\\n', 'weight (Tuple(Tensor)) - Tuple of parameters.\\n', '\\n', 'weight_clone (Tuple(Tensor)) - clone of weight\\n', '\\n', '(*inputs) (Tuple(Tensor)) - Tuple of input tensors with shape (N,…).\\n', '\\n', 'Outputs:\\n', 'loss (Tensor) - Tensor with shape ().']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.common.initializer.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.common.initializer.html", "text_entry": "['mindspore.common.initializer\\n', 'Initializer for cell parameters.\\n', '\\n', 'classmindspore.common.initializer.Initializer(**kwargs)[source]\\n', 'The abstract base class of the initializer.\\n', '\\n', 'Parameters\\n', 'kwargs (dict) – Keyword arguments for Initializer.\\n', '\\n', 'mindspore.common.initializer.initializer(init, shape=None, dtype=mstype.float32)[source]\\n', 'Create and initialize a tensor.\\n', '\\n', 'Parameters\\n', 'init (Union[Tensor, str, Initializer, numbers.Number]) –\\n', '\\n', 'Initialize value.\\n', '\\n', 'str: The init should be the alias of the class inheriting from Initializer and the corresponding class will be called in practice. The value of ‘init’ can be “normal”, “ones” or “zeros”, etc.\\n', '\\n', 'Initializer: The init should be the class inheriting from Initializer to initialize tensor.\\n', '\\n', 'numbers.Number: The Constant will be called to initialize tensor.\\n', '\\n', 'shape (Union[tuple, list, int]) – The shape of the initialized tensor. Default: None.\\n', '\\n', 'dtype (mindspore.dtype) – The type of data in initialized tensor. Default: mindspore.float32.\\n', '\\n', 'Returns\\n', 'Tensor, return is Tensor object.\\n', '\\n', 'Raises\\n', 'TypeError – The type of the argument ‘init’ is not correct.\\n', '\\n', 'ValueError – The shape of the tensor which is passed through ‘init’ is not the same as that passed by ‘shape’.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, One\\n', \"tensor1 = initializer('ones', [1, 2, 3], mindspore.float32)\\n\", 'tensor2 = initializer(One(), [1, 2, 3], mindspore.float32)\\n', 'tensor3 = initializer(0, [1, 2, 3], mindspore.float32)\\n', 'classmindspore.common.initializer.TruncatedNormal(sigma=0.01)[source]\\n', 'Generates an array with values sampled from Truncated Normal distribution in order to initialize a tensor.\\n', '\\n', 'Parameters\\n', 'sigma (float) – The standard deviation of Truncated Normal distribution. Default: 0.01.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, TruncatedNormal\\n', 'tensor1 = initializer(TruncatedNormal(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('truncatedNormal', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Normal(sigma=0.01, mean=0.0)[source]\\n', 'Generates an array with values sampled from Normal distribution N(sigma,mean) in order to initialize a tensor.\\n', '\\n', 'f(x)=12∗π−−−−√∗sigmaexp(−(x−mean)22∗sigma2)\\n', 'Parameters\\n', 'sigma (float) – The standard deviation of Normal distribution. Default: 0.01.\\n', '\\n', 'mean (float) – The mean of Normal distribution. Default: 0.0.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Normal\\n', 'tensor1 = initializer(Normal(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('normal', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Uniform(scale=0.07)[source]\\n', 'Generates an array with values sampled from Uniform distribution U(−scale,scale) in order to initialize a tensor.\\n', '\\n', 'Parameters\\n', 'scale (float) – The bound of the Uniform distribution. Default: 0.07.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Uniform\\n', 'tensor1 = initializer(Uniform(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('uniform', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.HeUniform(negative_slope=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\")[source]\\n', 'Generates an array with values sampled from HeKaiming Uniform distribution U(−boundary,boundary) in order to initialize a tensor, where\\n', '\\n', 'boundary=6(1+a2)×fan_in−−−−−−−−−−−−−−√\\n', 'which is the bound of the HeUniform distribution.\\n', '\\n', 'For details of HeUniform algorithm, please check https://arxiv.org/abs/1502.01852.\\n', '\\n', 'Parameters\\n', 'negative_slope (int, float, bool) – The negative slope of the rectifier used after this layer (only used when nonlinearity is ‘leaky_relu’). Default: 0.\\n', '\\n', 'mode (str) – Either ‘fan_in’ or ‘fan_out’. Choosing ‘fan_in’ preserves the magnitude of the variance of the weights in the forward pass. Choosing ‘fan_out’ preserves the magnitudes in the backwards pass. Default: fan_in.\\n', '\\n', 'nonlinearity (str) – The non-linear function, recommended to use only with ‘relu’ or ‘leaky_relu’. Default: leaky_relu.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, HeUniform\\n', 'tensor1 = initializer(HeUniform(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('he_uniform', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.HeNormal(negative_slope=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\")[source]\\n', 'Generates an array with values sampled from HeKaiming Normal distribution N(0,sigma2) in order to initialize a tensor, where\\n', '\\n', 'sigma=gainN−−√\\n', 'where gain is an optional scaling factor. N is the number of input units of the weight tensor, if mode is ‘fan_in’. If mode is ‘fan_out’, it is the number of output units.\\n', '\\n', 'For details of HeUniform algorithm, please check https://arxiv.org/abs/1502.01852.\\n', '\\n', 'Parameters\\n', 'negative_slope (int, float, bool) – The negative slope of the rectifier used after this layer (only used when nonlinearity is ‘leaky_relu’). Default: 0.\\n', '\\n', 'mode (str) – Either ‘fan_in’ or ‘fan_out’. Choosing ‘fan_in’ preserves the magnitude of the variance of the weights in the forward pass. Choosing ‘fan_out’ preserves the magnitudes in the backwards pass. Default: fan_in.\\n', '\\n', 'nonlinearity (str) – The non-linear function, recommended to use only with ‘relu’ or ‘leaky_relu’. Default: leaky_relu.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, HeNormal\\n', 'tensor1 = initializer(HeNormal(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('he_normal', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.XavierUniform(gain=1)[source]\\n', 'Generates an array with values sampled from Xavier uniform distribution U(−boundary,boundary) in order to initialize a tensor, where:\\n', '\\n', 'boundary=gain∗6nin+nout−−−−−−−−−√\\n', 'where gain is an optional scaling factor.\\n', '\\n', 'where nin is the number of input units in the weight tensor.\\n', '\\n', 'where nout is the number of output units in the weight tensor.\\n', '\\n', 'For details of XavierUniform algorithm, please check http://proceedings.mlr.press/v9/glorot10a.html.\\n', '\\n', 'Parameters\\n', 'gain (float) – An optional scaling factor. Default: 1.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, XavierUniform\\n', 'tensor1 = initializer(XavierUniform(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('xavier_uniform', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.One(**kwargs)[source]\\n', 'Generates an array with constant value of one in order to initialize a tensor.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, One\\n', 'tensor1 = initializer(One(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('ones', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Zero(**kwargs)[source]\\n', 'Generates an array with constant value of zero in order to initialize a tensor.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Zero\\n', 'tensor1 = initializer(Zero(), [1, 2, 3], mindspore.float32)\\n', \"tensor2 = initializer('zeros', [1, 2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Constant(value)[source]\\n', 'Generates an array with constant value in order to initialize a tensor.\\n', '\\n', 'Parameters\\n', 'value (Union[int, numpy.ndarray]) – The value to initialize.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer\\n', 'tensor1 = initializer(0, [1, 2, 3], mindspore.float32)\\n', 'tensor2 = initializer(5, [1, 2, 3], mindspore.float32)\\n', 'classmindspore.common.initializer.Identity(**kwargs)[source]\\n', 'Initialize a 2 dimension identity matrix to fill the input tensor.\\n', '\\n', 'Raises\\n', 'ValueError – If the dimension of input tensor is not equal to 2.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Identity\\n', 'tensor1 = initializer(Identity(), [2, 3], mindspore.float32)\\n', \"tensor2 = initializer('identity', [2, 3], mindspore.float32)\\n\", 'classmindspore.common.initializer.Sparse(sparsity, sigma=0.01)[source]\\n', 'Initialize a 2 dimension sparse matrix to fill the input tensor. The non-zero positions will be filled with the value sampled from the normal distribution N(0,0.01)\\n', '\\n', 'Parameters\\n', 'sparsity (float) – The fraction of elements being set to zero in each column.\\n', '\\n', 'sigma (float) – The standard deviation of the normal distribution. Default: 0.01.\\n', '\\n', 'Raises\\n', 'ValueError – If the dimension of input tensor is not equal to 2.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Sparse\\n', 'tensor1 = initializer(Sparse(sparsity=0.1, sigma=0.01), [5, 8], mindspore.float32)\\n', 'classmindspore.common.initializer.Dirac(groups=1)[source]\\n', 'Initialize input tensor with the Dirac delta function. It tries to preserves the identity of input for convolution layers. For group convolution, each group of channels will be preserved respectively.\\n', '\\n', 'Parameters\\n', 'groups (int) – The number of group in convolution layer. Default: 1.\\n', '\\n', 'Raises\\n', 'ValueError – If the value of group is not in [3, 4, 5].\\n', '\\n', 'ValueError – The first dimension of the initialized tensor cannot be divisible by group.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Dirac\\n', 'tensor1 = initializer(Dirac(groups=2), [6, 4, 3, 3], mindspore.float32)\\n', 'tensor2 = initializer(\"dirac\", [6, 4, 3, 3], mindspore.float32)\\n', 'classmindspore.common.initializer.Orthogonal(gain=1.)[source]\\n', 'Initialize a (semi) orthogonal matrix to fill the input tensor. The dimension of input tensor must have at least 2 dimensions. If the dimension is greater than 2, the trailing dimensions will be flattened.\\n', '\\n', 'Parameters\\n', 'gain (float) – An optional scaling factor. Default: 1.\\n', '\\n', 'Raises\\n', 'ValueError – If the dimension of input tensor is less than 2.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, Orthogonal\\n', 'tensor1 = initializer(Orthogonal(gain=2.), [2, 3, 4], mindspore.float32)\\n', \"tensor2 = initializer('orthogonal', [2, 3, 4], mindspore.float32)\\n\", 'classmindspore.common.initializer.VarianceScaling(scale=1.0, mode=\"fan_in\", distribution=\"truncated_normal\")[source]\\n', 'Randomly initialize an array with scaling to fill the input tensor. When distribution is truncated_normal or untruncated_normal, the value will be sampled from truncated or untruncated normal distribution with a mean of 0 and a scaled standard deviation stddev=sqrt(scale/n). n will be the number of input units if mode is fan_in, the number of output units if mode is fan_out, the average of fan_in and fan_out if mode is fan_avg. When distribution is uniform, the value will be sampled from a uniform distribution within the limit of [-sqrt(3*scale/n), sqrt(3*scale/n)].\\n', '\\n', 'Parameters\\n', 'scale (float) – The scaling factor. Default: 1.0.\\n', '\\n', 'mode (str) – Should be ‘fan_in’, ‘fan_out’ or ‘fan_avg’. Default: ‘fan_in’.\\n', '\\n', 'distribution (str) – The type of distribution chose to sample values. Default: ‘truncated_normal’.\\n', '\\n', 'Raises\\n', 'ValueError – If scale is not greater than 0.\\n', '\\n', 'ValueError – If mode is not fan_in, fan_out or fan_avg.\\n', '\\n', 'ValueError – If distribution is not uniform, truncated_normal or untruncated_normal.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore\\n', 'from mindspore.common.initializer import initializer, VarianceScaling\\n', \"tensor1 = initializer(VarianceScaling(scale=1.0, mode='fan_out',\\n\", \"                                      distribution='untruncated_normal'), [2, 3], mindspore.float32)\\n\", \"tensor2 = initializer('varianceScaling', [2, 3], mindspore.float32)\"]"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.communication.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.communication.html", "text_entry": "['mindspore.communication\\n', 'Collective communication interface. Note the API in the file needs to preset communication environment variables. For the Ascend cards, users need to prepare the rank table, set rank_id and device_id. Please see the Ascend tutorial for more details. For the GPU device, users need to prepare the host file and mpi, please see the GPU tutorial for more details.\\n', '\\n', 'classmindspore.communication.GlobalComm[source]\\n', 'World communication information. The GlobalComm is a global class. The members contain: BACKEND, WORLD_COMM_GROUP.\\n', '\\n', 'mindspore.communication.init(backend_name=None)[source]\\n', 'Initialize distributed backend, e.g. HCCL/NCCL, it is required before using the communication service.\\n', '\\n', 'Note\\n', '\\n', 'The full name of HCCL is Huawei Collective Communication Library. The full name of NCCL is NVIDIA Collective Communication Library. This method should be used after set_context. The user needs to preset communication environment variables before running the following example, please see the docstring of the mindspore.management.\\n', '\\n', 'Parameters\\n', 'backend_name (str) – Backend, using HCCL/NCCL. If the backend_name is None, system will recognize device_target by devices. Default: None.\\n', '\\n', 'Raises\\n', 'TypeError – If backend_name is not a string.\\n', '\\n', 'RuntimeError – If device target is invalid, or backend is invalid, or distributed initialization fails, or the environment variables RANK_ID/MINDSPORE_HCCL_CONFIG_PATH have not been exported when backend is HCCL.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.communication import init\\n', 'init()\\n', 'mindspore.communication.release()[source]\\n', 'Release distributed resource. e.g. HCCL/NCCL.\\n', '\\n', 'Note\\n', '\\n', 'This method should be used after init(). The user needs to preset communication environment variables before running the following example, please see the docstring of the mindspore.managerment.\\n', '\\n', 'Raises\\n', 'RuntimeError – If failed to release distributed resource.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.communication import init, release\\n', 'init()\\n', 'release()\\n', 'mindspore.communication.get_rank(group=GlobalComm.WORLD_COMM_GROUP)[source]\\n', 'Get the rank ID for the current device in the specified collective communication group.\\n', '\\n', 'Note\\n', '\\n', 'This method should be used after init(). The user needs to preset communication environment variables before running the following example, please see the docstring of the mindspore.managerment.\\n', '\\n', 'Parameters\\n', 'group (str) – The communication group to work on. Normally, the group should be created by create_group, otherwise, using the default group. Default: WORLD_COMM_GROUP.\\n', '\\n', 'Returns\\n', 'int, the rank ID of the calling process within the group.\\n', '\\n', 'Raises\\n', 'TypeError – If group is not a string.\\n', '\\n', 'ValueError – If backend is invalid.\\n', '\\n', 'RuntimeError – If HCCL/NCCL is not available.\\n', '\\n', 'from mindspore.communication import init, get_rank\\n', 'init()\\n', 'rank_id = get_rank()\\n', 'print(rank_id)\\n', '# the result is the rank_id in world_group\\n', 'mindspore.communication.get_group_size(group=GlobalComm.WORLD_COMM_GROUP)[source]\\n', 'Get the rank size of the specified collective communication group.\\n', '\\n', 'Note\\n', '\\n', 'This method should be used after init(). The user needs to preset communication environment variables before running the following example, please see the docstring of the mindspore.managerment.\\n', '\\n', 'Parameters\\n', 'group (str) – The communication group to work on. Normally, the group should be created by create_group, otherwise, using the default group. Default: WORLD_COMM_GROUP.\\n', '\\n', 'Returns\\n', 'int, the rank size of the group.\\n', '\\n', 'Raises\\n', 'TypeError – If group is not a string.\\n', '\\n', 'ValueError – If backend is invalid.\\n', '\\n', 'RuntimeError – If HCCL/NCCL is not available.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.context import set_context\\n', 'from mindspore.communication.management import init, get_group_size\\n', 'set_context(device_target=\"Ascend\", device_num=8)\\n', 'init()\\n', 'group_size = get_group_size()\\n', 'print(\"group_size is: \", group_size)\\n', '\\n', 'mindspore.communication.get_world_rank_from_group_rank(group, group_rank_id)[source]\\n', 'Get the rank ID in the world communication group corresponding to the rank ID in the specified user communication group.\\n', '\\n', 'Note\\n', '\\n', 'GPU version of MindSpore doesn’t support this method. The parameter group should not be “hccl_world_group”. This method should be used after init(). The user needs to preset communication environment variables before running the following example, please see the docstring of the mindspore.managerment.\\n', '\\n', 'Parameters\\n', 'group (str) – The communication group to work on. The group is created by create_group.\\n', '\\n', 'group_rank_id (int) – A rank ID in the communication group.\\n', '\\n', 'Returns\\n', 'int, the rank ID in world communication group.\\n', '\\n', 'Raises\\n', 'TypeError – If group_rank_id is not an integer or the group is not a string.\\n', '\\n', 'ValueError – If group is ‘hccl_world_group’ or backend is invalid.\\n', '\\n', 'RuntimeError – If HCCL is not available or MindSpore is GPU version.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.context import set_context\\n', 'from mindspore.communication.management import init, create_group, get_world_rank_from_group_rank\\n', 'set_context(device_target=\"Ascend\")\\n', 'init()\\n', 'group = \"0-4\"\\n', 'rank_ids = [0,4]\\n', 'create_group(group, rank_ids)\\n', 'world_rank_id = get_world_rank_from_group_rank(group, 1)\\n', 'print(\"world_rank_id is: \", world_rank_id)\\n', '\\n', 'mindspore.communication.get_group_rank_from_world_rank(world_rank_id, group)[source]\\n', 'Get the rank ID in the specified user communication group corresponding to the rank ID in the world communication group.\\n', '\\n', 'Note\\n', '\\n', 'GPU version of MindSpore doesn’t support this method. The parameter group should not be “hccl_world_group”. This method should be used after init(). The user needs to preset communication environment variables before running the following example, please see the docstring of the mindspore.managerment.\\n', '\\n', 'Parameters\\n', 'world_rank_id (int) – A rank ID in the world communication group.\\n', '\\n', 'group (str) – The communication group to work on. The group is created by create_group.\\n', '\\n', 'Returns\\n', 'int, the rank ID in the user communication group.\\n', '\\n', 'Raises\\n', 'TypeError – If world_rank_id is not an integer or the group is not a string.\\n', '\\n', 'ValueError – If group is ‘hccl_world_group’ or backend is invalid.\\n', '\\n', 'RuntimeError – If HCCL is not available or MindSpore is GPU version.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.context import set_context\\n', 'from mindspore.communication.management import init, create_group, get_group_rank_from_world_rank\\n', 'set_context(device_target=\"Ascend\")\\n', 'init()\\n', 'group = \"0-4\"\\n', 'rank_ids = [0,4]\\n', 'create_group(group, rank_ids)\\n', 'group_rank_id = get_group_rank_from_world_rank(4, group)\\n', 'print(\"group_rank_id is: \", group_rank_id)\\n', '\\n', 'mindspore.communication.create_group(group, rank_ids)[source]\\n', 'Create a user collective communication group.\\n', '\\n', 'Note\\n', '\\n', 'GPU version of MindSpore doesn’t support this method. The size of rank_ids should be larger than 1, rank_ids should not have duplicate data. This method should be used after init(). Only support global single communication group in PyNative mode. The user needs to preset communication environment variables before running the following example, please see the docstring of the mindspore.managerment.\\n', '\\n', 'Parameters\\n', 'group (str) – The name of the communication group to be created.\\n', '\\n', 'rank_ids (list) – A list of device IDs.\\n', '\\n', 'Raises\\n', 'TypeError – If group is not a string or rank_ids is not a list.\\n', '\\n', 'ValueError – If rank_ids size is not larger than 1, or rank_ids has duplicate data, or backend is invalid.\\n', '\\n', 'RuntimeError – If HCCL is not available or MindSpore is GPU version.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.context import set_context\\n', 'from mindspore.ops import operations as ops\\n', 'from mindspore.communication.management import init, create_group\\n', 'set_context(device_target=\"Ascend\")\\n', 'init()\\n', 'group = \"0-8\"\\n', 'rank_ids = [0,8]\\n', 'create_group(group, rank_ids)\\n', 'allreduce = ops.AllReduce(group)\\n', 'mindspore.communication.get_local_rank(group=GlobalComm.WORLD_COMM_GROUP)[source]\\n', 'Gets local rank ID for current device in specified collective communication group.\\n', '\\n', 'Note\\n', '\\n', 'GPU version of MindSpore doesn’t support this method. This method should be used after init(). The user needs to preset communication environment variables before running the following example, please see the docstring of the mindspore.managerment.\\n', '\\n', 'Parameters\\n', 'group (str) – The communication group to work on. Normally, the group should be created by create_group, otherwise, using the default group. Default: WORLD_COMM_GROUP.\\n', '\\n', 'Returns\\n', 'int, the local rank ID of the calling process within the group.\\n', '\\n', 'Raises\\n', 'TypeError – If group is not a string.\\n', '\\n', 'ValueError – If backend is invalid.\\n', '\\n', 'RuntimeError – If HCCL is not available or MindSpore is GPU version.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.context import set_context\\n', 'from mindspore.communication.management import init, get_rank, get_local_rank\\n', 'set_context(device_target=\"Ascend\", device_num=16) # 2 server, each server with 8 NPU.\\n', 'init()\\n', 'world_rank = get_rank() # rank_id is 9.\\n', 'local_rank = get_local_rank()\\n', 'print(\"local_rank is: {}, world_rank is {}\".format(local_rank, world_rank))\\n', '\\n', 'mindspore.communication.get_local_rank_size(group=GlobalComm.WORLD_COMM_GROUP)[source]\\n', 'Gets local rank size of the specified collective communication group.\\n', '\\n', 'Note\\n', '\\n', 'GPU version of MindSpore doesn’t support this method. This method should be used after init(). The user needs to preset communication environment variables before running the following example, please see the docstring of the mindspore.managerment.\\n', '\\n', 'Parameters\\n', 'group (str) – The communication group to work on. The group is created by create_group or the default world communication group. Default: WORLD_COMM_GROUP.\\n', '\\n', 'Returns\\n', 'int, the local rank size where the calling process is within the group.\\n', '\\n', 'Raises\\n', 'TypeError – If group is not a string.\\n', '\\n', 'ValueError – If backend is invalid.\\n', '\\n', 'RuntimeError – If HCCL is not available or MindSpore is GPU version.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.context import set_context\\n', 'from mindspore.communication.management import init, get_local_rank_size\\n', 'set_context(device_target=\"Ascend\", device_num=16) # 2 server, each server with 8 NPU.\\n', 'init()\\n', 'local_rank_size = get_local_rank_size()\\n', 'print(\"local_rank_size is: \", local_rank_size)\\n', '\\n', 'mindspore.communication.destroy_group(group)[source]\\n', 'Destroy the user collective communication group.\\n', '\\n', 'Note\\n', '\\n', 'GPU version of MindSpore doesn’t support this method. The parameter group should not be “hccl_world_group”. This method should be used after init().\\n', '\\n', 'Parameters\\n', 'group (str) – The communication group to destroy, the group should be created by create_group.\\n', '\\n', 'Raises\\n', 'TypeError – If group is not a string.\\n', '\\n', 'ValueError – If group is “hccl_world_group” or backend is invalid.\\n', '\\n', 'RuntimeError – If HCCL is not available or MindSpore is GPU version.\\n', '\\n', 'mindspore.communication.HCCL_WORLD_COMM_GROUP\\n', 'The string of “hccl_world_group” referring to the default communication group created by HCCL.\\n', '\\n', 'mindspore.communication.NCCL_WORLD_COMM_GROUP\\n', 'The string of “nccl_world_group” referring to the default communication group created by NCCL.']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.compression.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.compression.html", "text_entry": "['mindspore.compression\\n', 'mindspore.compression.quant\\n', 'Quantization module, including base class of the quantizer, the quantization aware training algorithm, and quantization utils.\\n', '\\n', 'mindspore.compression.quant.load_nonquant_param_into_quant_net(quant_model, params_dict, quant_new_params=None)[source]\\n', 'Load fp32 model parameters into quantization model.\\n', '\\n', 'Parameters\\n', 'quant_model (Cell) – Quantization model.\\n', '\\n', 'params_dict (dict) – Parameter dict that stores fp32 parameters.\\n', '\\n', 'quant_new_params (list) – Parameters that exist in quantization network but not in non-quantization network. Default: None.\\n', '\\n', 'Raises\\n', 'TypeError – If quant_new_params is not None and is not list.\\n', '\\n', 'ValueError – If there are parameters in the quant_model that are neither in params_dict nor in quant_new_params.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import load_checkpoint\\n', 'from mindspore.compression.quant.quant_utils import load_nonquant_param_into_quant_net\\n', 'class LeNet5(nn.Cell):\\n', '    def __init__(self, num_class=10, channel=1):\\n', '        super(LeNet5, self).__init__()\\n', '        self.type = \"fusion\"\\n', '        self.num_class = num_class\\n', '\\n', '        # change `nn.Conv2d` to `nn.Conv2dBnAct`\\n', \"        self.conv1 = nn.Conv2dBnAct(channel, 6, 5, pad_mode='valid', activation='relu')\\n\", \"        self.conv2 = nn.Conv2dBnAct(6, 16, 5, pad_mode='valid', activation='relu')\\n\", '        # change `nn.Dense` to `nn.DenseBnAct`\\n', \"        self.fc1 = nn.DenseBnAct(16 * 5 * 5, 120, activation='relu')\\n\", \"        self.fc2 = nn.DenseBnAct(120, 84, activation='relu')\\n\", '        self.fc3 = nn.DenseBnAct(84, self.num_class)\\n', '\\n', '        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\\n', '        self.flatten = nn.Flatten()\\n', '\\n', '    def construct(self, x):\\n', '        x = self.conv1(x)\\n', '        x = self.max_pool2d(x)\\n', '        x = self.conv2(x)\\n', '        x = self.max_pool2d(x)\\n', '        x = self.flatten(x)\\n', '        x = self.fc1(x)\\n', '        x = self.fc2(x)\\n', '        x = self.fc3(x)\\n', '        return x\\n', '\\n', 'net = LeNet5()\\n', 'ckpt_file_name = \"./checkpoint/LeNet5_noquant-1_32.ckpt\"\\n', 'param_dict = load_checkpoint(ckpt_file_name)\\n', 'load_nonquant_param_into_quant_net(net, param_dict)\\n', 'mindspore.compression.quant.query_quant_layers(network)[source]\\n', 'Query the network’s quantization strategy of each quantized layer and print it to the screen, note that all the quantization layers are queried before graph compile optimization in the graph mode, thus, some redundant quantized layers, which not exist in practical execution, may appear.\\n', '\\n', 'Parameters\\n', 'network (Cell) – input network\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.compression.quant import QuantizationAwareTraining\\n', 'from mindspore.compression.quant.quant_utils import query_quant_layers\\n', 'class LeNet5(nn.Cell):\\n', '    def __init__(self, num_class=10, channel=1):\\n', '        super(LeNet5, self).__init__()\\n', '        self.type = \"fusion\"\\n', '        self.num_class = num_class\\n', '\\n', '        # change `nn.Conv2d` to `nn.Conv2dBnAct`\\n', \"        self.conv1 = nn.Conv2dBnAct(channel, 6, 5, pad_mode='valid', activation='relu')\\n\", \"        self.conv2 = nn.Conv2dBnAct(6, 16, 5, pad_mode='valid', activation='relu')\\n\", '        # change `nn.Dense` to `nn.DenseBnAct`\\n', \"        self.fc1 = nn.DenseBnAct(16 * 5 * 5, 120, activation='relu')\\n\", \"        self.fc2 = nn.DenseBnAct(120, 84, activation='relu')\\n\", '        self.fc3 = nn.DenseBnAct(84, self.num_class)\\n', '\\n', '        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\\n', '        self.flatten = nn.Flatten()\\n', '\\n', '    def construct(self, x):\\n', '        x = self.conv1(x)\\n', '        x = self.max_pool2d(x)\\n', '        x = self.conv2(x)\\n', '        x = self.max_pool2d(x)\\n', '        x = self.flatten(x)\\n', '        x = self.fc1(x)\\n', '        x = self.fc2(x)\\n', '        x = self.fc3(x)\\n', '        return x\\n', '\\n', 'net = LeNet5()\\n', 'quantizer = QuantizationAwareTraining(bn_fold=False, per_channel=[True, False], symmetric=[True, False])\\n', 'net_qat = quantizer.quantize(net)\\n', 'query_quant_layers(net_qat)\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', '\\n', 'classmindspore.compression.quant.QuantizationAwareTraining(bn_fold=True, freeze_bn=10000000, quant_delay=(0, 0), quant_dtype=(QuantDtype.INT8, QuantDtype.INT8), per_channel=(False, False), symmetric=(False, False), narrow_range=(False, False), optimize_option=OptimizeOption.QAT, one_conv_fold=True)[source]\\n', 'Quantizer for quantization aware training.\\n', '\\n', 'Parameters\\n', 'bn_fold (bool) – Whether to use bn fold ops for simulation inference operation. Default: True.\\n', '\\n', 'freeze_bn (int) – Number of steps after which BatchNorm OP parameters fixed to global mean and variance. Default: 1e7.\\n', '\\n', 'quant_delay (Union[int, list, tuple]) – Number of steps after which weights and activations are quantized during train and eval. The first element represents weights and the second element represents data flow. Default: (0, 0).\\n', '\\n', 'quant_dtype (Union[QuantDtype, list, tuple]) – Datatype used to quantize weights and activations. The first element represents weights and the second element represents data flow. It is necessary to consider the precision support of hardware devices in the practical quantization infer scenario. Default: (QuantDtype.INT8, QuantDtype.INT8).\\n', '\\n', 'per_channel (Union[bool, list, tuple]) – Quantization granularity based on layer or on channel. If True then base on per channel, otherwise base on per layer. The first element represents weights and the second element represents data flow, and the second element must be False now. Default: (False, False).\\n', '\\n', 'symmetric (Union[bool, list, tuple]) – Whether the quantization algorithm is symmetric or not. If True then base on symmetric, otherwise base on asymmetric. The first element represents weights and the second element represents data flow. Default: (False, False).\\n', '\\n', 'narrow_range (Union[bool, list, tuple]) – Whether the quantization algorithm uses narrow range or not. The first element represents weights and the second element represents data flow. Default: (False, False).\\n', '\\n', 'optimize_option (Union[OptimizeOption, list, tuple]) – Specifies the quant algorithm and options, currently only support QAT and LEARNED_SCALE (Note that, if both QAT and LEARNED_SCALE are configured, LEARNED_SCALE has a higher priority. LEARNED_SCALE currently only work under some constraints, which includes: freeze_bn=0, quant_delay=0, symmetric=True, narrow_range=True, More specifically, for operators such as Relu and Relu6, which only have positive values, we add a negative truncation to optimize this scenario, and narrow_range will automatically match to False). Default: OptimizeOption.QAT.\\n', '\\n', 'one_conv_fold (bool) – Whether to use one conv bn fold ops for simulation inference operation. Default: True.\\n', '\\n', 'Raises\\n', 'TypeError – If the element of quant_delay or freeze_bn is not int.\\n', '\\n', 'TypeError – If bn_fold, one_conv_fold or the element of per_channel, symmetric, narrow_range is not bool.\\n', '\\n', 'TypeError – If the element of quant_dtype is not QuantDtype.\\n', '\\n', 'ValueError – If the length of quant_delay, quant_dtype, per_channel, symmetric or narrow_range is not less than 2.\\n', '\\n', 'ValueError – If the optimize_option is LEARNED_SCALE and freeze_bn is not equal to 0.\\n', '\\n', 'ValueError – If the optimize_option is LEARNED_SCALE and symmetric is not (True, True).\\n', '\\n', 'ValueError – If the optimize_option is LEARNED_SCALE and narrow_range is not (True, True).\\n', '\\n', 'ValueError – If the optimize_option is LEARNED_SCALE and quant_delay is not (0, 0).\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.compression.quant import QuantizationAwareTraining\\n', 'class LeNet5(nn.Cell):\\n', '    def __init__(self, num_class=10, channel=1):\\n', '        super(LeNet5, self).__init__()\\n', '        self.type = \"fusion\"\\n', '        self.num_class = num_class\\n', '\\n', '        # change `nn.Conv2d` to `nn.Conv2dBnAct`\\n', \"        self.conv1 = nn.Conv2dBnAct(channel, 6, 5, pad_mode='valid', activation='relu')\\n\", \"        self.conv2 = nn.Conv2dBnAct(6, 16, 5, pad_mode='valid', activation='relu')\\n\", '        # change `nn.Dense` to `nn.DenseBnAct`\\n', \"        self.fc1 = nn.DenseBnAct(16 * 5 * 5, 120, activation='relu')\\n\", \"        self.fc2 = nn.DenseBnAct(120, 84, activation='relu')\\n\", '        self.fc3 = nn.DenseBnAct(84, self.num_class)\\n', '\\n', '        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\\n', '        self.flatten = nn.Flatten()\\n', '\\n', '    def construct(self, x):\\n', '        x = self.conv1(x)\\n', '        x = self.max_pool2d(x)\\n', '        x = self.conv2(x)\\n', '        x = self.max_pool2d(x)\\n', '        x = self.flatten(x)\\n', '        x = self.fc1(x)\\n', '        x = self.fc2(x)\\n', '        x = self.fc3(x)\\n', '        return x\\n', '\\n', 'net = LeNet5()\\n', 'quantizer = QuantizationAwareTraining(bn_fold=False, per_channel=[True, False], symmetric=[True, False])\\n', 'net_qat = quantizer.quantize(net)\\n', 'quantize(network)[source]\\n', 'Quant API to convert input network to a quantization aware training network.\\n', '\\n', 'Note\\n', '\\n', 'Please refer to the Examples of class: mindspore.compression.quant.QuantizationAwareTraining.\\n', '\\n', 'Parameters\\n', 'network (Cell) – network to be quantized.\\n', '\\n', 'Returns\\n', 'Cell, a quantization aware training network.\\n', '\\n', 'Raises\\n', 'KeyError – If the device_target set in context is not in support_device.\\n', '\\n', 'mindspore.compression.quant.create_quant_config(quant_observer=(nn.FakeQuantWithMinMaxObserver, nn.FakeQuantWithMinMaxObserver), quant_delay=(0, 0), quant_dtype=(QuantDtype.INT8, QuantDtype.INT8), per_channel=(False, False), symmetric=(False, False), narrow_range=(False, False), mode=\"DEFAULT\")[source]\\n', 'Config the observer type of weights and data flow with quant parameters.\\n', '\\n', 'Parameters\\n', 'quant_observer (Union[Observer, list, tuple]) – The types of observer for quantization. The first element applies to weights and the second applies to data flow. Currently, only FakeQuantWithMinMaxObserver supported. Default: (nn.FakeQuantWithMinMaxObserver, nn.FakeQuantWithMinMaxObserver).\\n', '\\n', 'quant_delay (Union[int, list, tuple]) – Number of steps after which weights and activations are quantized during train and eval. The first element represents weights and the second element represents data flow. Default: (0, 0).\\n', '\\n', 'quant_dtype (Union[QuantDtype, list, tuple]) – Datatype used to quantize weights and activations. The first element represents weights and the second element represents data flow. Default: (QuantDtype.INT8, QuantDtype.INT8).\\n', '\\n', 'per_channel (Union[bool, list, tuple]) – Quantization granularity based on layer or on channel. If True then base on per channel, otherwise base on per layer. The first element represents weights and the second element represents data flow, and the second element must be False now. Default: (False, False).\\n', '\\n', 'symmetric (Union[bool, list, tuple]) – Whether the quantization algorithm is symmetric or not. If True then base on symmetric, otherwise base on asymmetric. The first element represents weights and the second element represents data flow. Default: (False, False).\\n', '\\n', 'narrow_range (Union[bool, list, tuple]) – Whether the quantization algorithm uses narrow range or not. The first element represents weights and the second element represents data flow. Default: (False, False).\\n', '\\n', 'mode (str) – Optional quantization mode, currently only DEFAULT`(QAT) and `LEARNED_SCALE are supported. Default: “DEFAULT”.\\n', '\\n', 'Returns\\n', 'QuantConfig, contains the observer type of weight and activation.\\n', '\\n', 'Raises\\n', 'ValueError – If the second element of per_channel is not False.\\n', '\\n', 'classmindspore.compression.quant.OptimizeOption[source]\\n', 'An enum for the model quantization optimize option, currently only support QAT and LEARNED_SCALE.\\n', '\\n', 'mindspore.compression.common\\n', 'Common module for various compression algorithms, now only including datatype definition for quantization.\\n', '\\n', 'classmindspore.compression.common.QuantDtype[source]\\n', 'An enum for quant datatype, contains INT2 ~ INT8, UINT2 ~ UINT8.\\n', '\\n', 'num_bits\\n', 'Get the num bits of the QuantDtype member.\\n', '\\n', 'Returns\\n', 'int, the num bits of the QuantDtype member.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.compression.common import QuantDtype\\n', 'quant_dtype = QuantDtype.INT8\\n', 'num_bits = quant_dtype.num_bits\\n', 'print(num_bits)\\n']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.context.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.context.html", "text_entry": "['mindspore.context\\n', 'The context of mindspore, used to configure the current execution environment, includes the execution mode, execution backend and other feature switches.\\n', '\\n', 'mindspore.context.set_context(**kwargs)[source]\\n', 'Set context for running environment.\\n', '\\n', 'Context should be configured before running your program. If there is no configuration, it will be automatically set according to the device target by default.\\n', '\\n', 'Note\\n', '\\n', 'Attribute name is required for setting attributes. The mode is not recommended to be changed after net was initialized because the implementations of some operations are different in graph mode and pynative mode. Default: GRAPH_MODE.\\n', '\\n', 'Some configurations are device specific, see the below table for details:\\n', '\\n', 'Function Classification\\n', '\\n', 'Configuration Parameters\\n', '\\n', 'Hardware Platform Support\\n', '\\n', 'System Configuration\\n', '\\n', 'device_id\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'device_target\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'max_device_memory\\n', '\\n', 'GPU/Ascend\\n', '\\n', 'variable_memory_max_size\\n', '\\n', 'Ascend\\n', '\\n', 'mempool_block_size\\n', '\\n', 'GPU/Ascend\\n', '\\n', 'Debug Configuration\\n', '\\n', 'save_graphs\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'save_graphs_path\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'enable_dump\\n', '\\n', 'Ascend\\n', '\\n', 'save_dump_path\\n', '\\n', 'Ascend\\n', '\\n', 'enable_profiling\\n', '\\n', 'Ascend\\n', '\\n', 'profiling_options\\n', '\\n', 'Ascend\\n', '\\n', 'print_file_path\\n', '\\n', 'Ascend\\n', '\\n', 'env_config_path\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'precompile_only\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'reserve_class_name_in_scope\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'pynative_synchronize\\n', '\\n', 'GPU/Ascend\\n', '\\n', 'Executive Control\\n', '\\n', 'mode\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'enable_graph_kernel\\n', '\\n', 'Ascend/GPU\\n', '\\n', 'graph_kernel_flags\\n', '\\n', 'Ascend/GPU\\n', '\\n', 'enable_reduce_precision\\n', '\\n', 'Ascend\\n', '\\n', 'auto_tune_mode\\n', '\\n', 'Ascend\\n', '\\n', 'check_bprop\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'max_call_depth\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'enable_sparse\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'grad_for_scalar\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'enable_compile_cache\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'compile_cache_path\\n', '\\n', 'CPU/GPU/Ascend\\n', '\\n', 'Parameters\\n', 'device_id (int) – ID of the target device, the value must be in [0, device_num_per_host-1], while device_num_per_host should be no more than 4096. Default: 0.\\n', '\\n', 'device_target (str) – The target device to run, support “Ascend”, “GPU”, and “CPU”. If device target is not set, the version of MindSpore package is used.\\n', '\\n', 'max_device_memory (str) – Set the maximum memory available for devices. The format is “xxGB”. Default: “1024GB”. The actual used memory size is the minimum of the available memory of the device and max_device_memory.\\n', '\\n', 'variable_memory_max_size (str) – This parameter is deprecated, and will be removed in a future version. Please use parameter ‘max_device_memory’ instead.\\n', '\\n', 'mempool_block_size (str) – Set the size of the memory pool block in PyNative mode for devices. The format is “xxGB”. Default: “1GB”. Minimum size is “1G”. The actual used memory block size is the minimum of the available memory of the device and mempool_block_size.\\n', '\\n', 'save_graphs (bool) – Whether to save graphs. Default: False. When the save_graphs attribute is set as True, attribute of save_graphs_path is used to set the intermediate compilation graph storage path. By default, the graphs are saved in the current directory.\\n', '\\n', 'save_graphs_path (str) – Path to save graphs. Default: “.”. If the specified directory does not exist, the system will automatically create the directory. During distributed training, graphs will be saved to the directory of save_graphs_path/rank_${rank_id}/. rank_id is the ID of the current device in the cluster.\\n', '\\n', 'enable_dump (bool) – This parameters is deprecated, and will be deleted in the next version.\\n', '\\n', 'save_dump_path (str) – This parameters is deprecated, and will be deleted in the next version.\\n', '\\n', 'enable_profiling (bool) – This parameters is deprecated, and will be deleted in the next version. Please use mindspore.profiler.Profiler api instead.\\n', '\\n', 'profiling_options (str) – This parameters is deprecated, and will be deleted in the next version. Please use mindspore.profiler.Profiler api instead.\\n', '\\n', 'print_file_path (str) – The path of saving print data. If this parameter is set, print data is saved to a file by default, and print_file_path is not set, the screen will be displayed. If the saved file already exists, the timestamp suffix will be added to the file. Saving data to a file solves the problem of data loss in screen printing when a large amount of data is generated. If it is not set, an error will be reported: prompt to set the upper absolute path.\\n', '\\n', 'env_config_path (str) –\\n', '\\n', 'Config path for DFX. Through context.set_context(env_config_path=”./mindspore_config.json”)\\n', '\\n', 'configure RDR:\\n', '\\n', 'enable: controls whether the RDR is enabled to collect the key data during training and save key data in the fault scenario. When set to true, the RDR will be turned on. When set to false, the RDR will be turned off.\\n', '\\n', 'mode: sets the mode of RDR on exporting data. When set to 1, the RDR only exports data in the fault scenario. When set to 2, the RDR exports data in the fault scenario and the normal end scenario. Default is 1.\\n', '\\n', 'path: sets the path where RDR saves data. The current path must be absolute.\\n', '\\n', 'Memory reuse:\\n', '\\n', 'mem_Reuse: controls whether the memory reuse function is turned on. When set to True,\\n', '\\n', 'the memory reuse function is turned on. When set to False, the memory reuse function is turned off.\\n', '\\n', 'precompile_only (bool) – Whether to only precompile the network. Default: False. If set to True, the network will only be compiled, not executed.\\n', '\\n', 'reserve_class_name_in_scope (bool) –\\n', '\\n', 'Whether to save the network class name in the scope. Default: True. Each node has a scope. A scope of a subnode is the name of its parent node. If reserve_class_name_in_scope is set to True, the class name will be saved after keyword ‘net-‘ in the scope. For example:\\n', '\\n', 'Default/net-Net1/net-Net2 (reserve_class_name_in_scope=True)\\n', '\\n', 'Default/net/net (reserve_class_name_in_scope=False)\\n', '\\n', 'pynative_synchronize (bool) – Whether to enable synchronous execution of the device in PyNative mode. Default: False. When the value is set to False, the operator is executed asynchronously on the device. When an error occurs in the execution of the operator, the specific error script code location cannot be located, when the value is set to True, the operator is executed synchronously on the device. It will reduce the execution performance of the program. At this time, when an error occurs in the execution of the operator, the location of the error script code can be located according to the call stack of the error.\\n', '\\n', 'mode (int) – Running in GRAPH_MODE(0) or PYNATIVE_MODE(1). Default: GRAPH_MODE(0). GRAPH_MODE or PYNATIVE_MODE can be set by mode attribute and both modes support all backends, default mode is GRAPH_MODE.\\n', '\\n', 'enable_graph_kernel (bool) – Whether to enable graph kernel fusion to optimize network execution performance. Default: False. Indicates whether to enable image-computing convergence to optimize network execution performance. If enable_graph_kernel is set to True, acceleration can be enabled. For details of graph kernel fusion, please check Enabling Graph Kernel Fusion.\\n', '\\n', 'graph_kernel_flags (str) –\\n', '\\n', 'Optimization options of graph kernel fusion, and the priority is higher when it conflicts with enable_graph_kernel. Only for experienced users. For example, context.set_context(graph_kernel_flags=”–opt_level=2 –dump_as_text”). Some general options:\\n', '\\n', 'opt_level: Set the optimization level. Default: 2. Graph kernel fusion can be enabled equivalently by setting opt_level greater than 0. Available values are:\\n', '\\n', '0: disables graph kernel fusion;\\n', '\\n', '1: enables the basic fusion of operators;\\n', '\\n', '2: includes all optimizations of level 1, and turns on more optimizations such as CSE, arithmetic simplification and so on;\\n', '\\n', '3: includes all optimizations of level 2, and turns on more optimizations such as SitchingFusion, ParallelFusion and so on. Optimizations of this level are radical and unstable in some scenarios. Be caution when using this level.\\n', '\\n', 'dump_as_text: dumps detail info as text files. Default: false.\\n', '\\n', 'More options can refer to the implementation code.\\n', '\\n', 'enable_reduce_precision (bool) – Whether to enable precision reduction. If the operator does not support the user-specified precision, the precision will be changed automatically. Default: True.\\n', '\\n', 'auto_tune_mode (str) –\\n', '\\n', 'The mode of auto tune when op building, get the best tiling performance. Default: NO_TUNE. The value must be in [‘RL’, ‘GA’, ‘RL,GA’].\\n', '\\n', 'RL: Reinforcement Learning tune.\\n', '\\n', 'GA: Genetic Algorithm tune.\\n', '\\n', 'RL,GA: When both RL and GA optimization are enabled, the tool automatically selects RL or GA based on different types of operators in the network model. The sequence of RL and GA is not differentiated. (Automatic selection).\\n', '\\n', 'For more information about the enable operator tuning tool settings, please check Enable the operator optimization tool.\\n', '\\n', 'check_bprop (bool) – Whether to check back propagation nodes. The checking ensures that the shape and dtype of back propagation node outputs is the same as input parameters. Default: False.\\n', '\\n', 'max_call_depth (int) – Specify the maximum depth of function call. Must be positive integer. Default: 1000. The max_call_depth parameter needs to be set when the nested call is too deep or the number of subgraphs is too large. If max_call_depth is set larger than before, the system max stack depth should be set larger too, otherwise a core dumped exception may be raised because of system stack overflow.\\n', '\\n', 'enable_sparse (bool) – Whether to enable sparsity feature. Default: False. For details of sparsity and sparse tensor, please check sparse tensor.\\n', '\\n', 'grad_for_scalar (bool) – Whether to get gradient for scalar. Default: False. When grad_for_scalar is set to True, the function’s scalar input can be derived. The default value is False. Because the back-end does not support scaling operations currently, this interface only supports simple operations that can be deduced by the front-end.\\n', '\\n', 'enable_compile_cache (bool) – Whether to save or load the cache of the graph compiled by front-end. After enable_compile_cache is set to True, during the first execution, a hardware-independent compilation cache is generated and exported to a MINDIR file. When the network is executed again, if enable_compile_cache is still set to True and the network scripts are not changed, the compile cache is loaded. Note that only limited automatic detection for the changes of python scripts is supported by now, which means that there is a correctness risk. Default: False. Note that it isn’t yet supported in PS mode. This is an experimental prototype that is subject to change and/or deletion.\\n', '\\n', 'compile_cache_path (str) – Path to save the cache of the graph compiled by front-end. Default: “.”. If the specified directory does not exist, the system will automatically create the directory. The cache will be saved to the directory of compile_cache_path/rank_${rank_id}/. The rank_id is the ID of the current device in the cluster.\\n', '\\n', 'Raises\\n', 'ValueError – If input key is not an attribute in context.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import context\\n', 'context.set_context(mode=context.PYNATIVE_MODE)\\n', 'context.set_context(precompile_only=True)\\n', 'context.set_context(device_target=\"Ascend\")\\n', 'context.set_context(device_id=0)\\n', 'context.set_context(save_graphs=True, save_graphs_path=\"./model.ms\")\\n', 'context.set_context(enable_reduce_precision=True)\\n', 'context.set_context(enable_dump=True, save_dump_path=\".\")\\n', 'context.set_context(enable_graph_kernel=True)\\n', 'context.set_context(graph_kernel_flags=\"--opt_level=2 --dump_as_text\")\\n', 'context.set_context(reserve_class_name_in_scope=True)\\n', 'context.set_context(variable_memory_max_size=\"6GB\")\\n', 'context.set_context(enable_profiling=True,\\n', '                    profiling_options=\\'{\"output\":\"/home/data/output\",\"training_trace\":\"on\"}\\')\\n', 'context.set_context(check_bprop=True)\\n', 'context.set_context(max_device_memory=\"3.5GB\")\\n', 'context.set_context(mempool_block_size=\"1GB\")\\n', 'context.set_context(print_file_path=\"print.pb\")\\n', 'context.set_context(enable_sparse=True)\\n', 'context.set_context(max_call_depth=80)\\n', 'context.set_context(env_config_path=\"./env_config.json\")\\n', 'context.set_context(auto_tune_mode=\"GA,RL\")\\n', 'context.set_context(grad_for_scalar=True)\\n', 'context.set_context(enable_compile_cache=True, compile_cache_path=\"./cache.ms\")\\n', 'context.set_context(pynative_synchronize=True)\\n', 'mindspore.context.get_context(attr_key)[source]\\n', 'Get context attribute value according to the input key. If some attributes are not set, they will be automatically obtained.\\n', '\\n', 'Parameters\\n', 'attr_key (str) – The key of the attribute.\\n', '\\n', 'Returns\\n', 'Object, The value of given attribute key.\\n', '\\n', 'Raises\\n', 'ValueError – If input key is not an attribute in context.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import context\\n', 'context.get_context(\"device_target\")\\n', 'context.get_context(\"device_id\")\\n', 'mindspore.context.set_auto_parallel_context(**kwargs)[source]\\n', 'Set auto parallel context, which is valid only for Ascend and GPU target.\\n', '\\n', 'Auto parallel context should be configured before the initialization of your network.\\n', '\\n', 'Note\\n', '\\n', 'Attribute name is required for setting attributes. If a program has tasks on different parallel modes, before setting a new parallel mode for the next task, interface mindspore.context.reset_auto_parallel_context() should be called to reset the configuration. Setting or changing parallel modes must be called before creating any Initializer, otherwise, it may have RuntimeError when compiling the network.\\n', '\\n', 'Some configurations are parallel mode specific, see the below table for details:\\n', '\\n', 'Common\\n', '\\n', 'AUTO_PARALLEL\\n', '\\n', 'device_num\\n', '\\n', 'gradient_fp32_sync\\n', '\\n', 'global_rank\\n', '\\n', 'loss_repeated_mean\\n', '\\n', 'gradients_mean\\n', '\\n', 'search_mode\\n', '\\n', 'parallel_mode\\n', '\\n', 'strategy_ckpt_load_file\\n', '\\n', 'all_reduce_fusion_config\\n', '\\n', 'strategy_ckpt_save_file\\n', '\\n', 'enable_parallel_optimizer\\n', '\\n', 'dataset_strategy\\n', '\\n', 'parallel_optimizer_config\\n', '\\n', 'pipeline_stages\\n', '\\n', 'grad_accumulation_step\\n', '\\n', 'auto_parallel_search_mode\\n', '\\n', 'comm_fusion\\n', '\\n', 'Parameters\\n', 'device_num (int) – Available device number, the value must be in [1, 4096]. Default: 1.\\n', '\\n', 'global_rank (int) – Global rank id, the value must be in [0, 4095]. Default: 0.\\n', '\\n', 'gradients_mean (bool) – Whether to perform mean operator after allreduce of gradients. “stand_alone” do not support gradients_mean. Default: False.\\n', '\\n', 'gradient_fp32_sync (bool) – Run allreduce of gradients in fp32. “stand_alone”, “data_parallel” and “hybrid_parallel” do not support gradient_fp32_sync. Default: True.\\n', '\\n', 'parallel_mode (str) –\\n', '\\n', 'There are five kinds of parallel modes, “stand_alone”, “data_parallel”, “hybrid_parallel”, “semi_auto_parallel” and “auto_parallel”. Note the pynative mode only supports the “stand_alone” and “data_parallel” mode. Default: “stand_alone”.\\n', '\\n', 'stand_alone: Only one processor is working.\\n', '\\n', 'data_parallel: Distributes the data across different processors.\\n', '\\n', 'hybrid_parallel: Achieves data parallelism and model parallelism manually.\\n', '\\n', 'semi_auto_parallel: Achieves data and model parallelism by setting parallel strategies.\\n', '\\n', 'auto_parallel: Achieving parallelism automatically.\\n', '\\n', 'search_mode (str) –\\n', '\\n', 'There are three kinds of shard strategy search modes: “recursive_programming”, “dynamic_programming” and “sharding_propagation”. Default: “dynamic_programming”.\\n', '\\n', 'recursive_programming: Recursive programming search mode.\\n', '\\n', 'dynamic_programming: Dynamic programming search mode.\\n', '\\n', 'sharding_propagation: Propagate shardings from configured ops to non-configured ops.\\n', '\\n', 'auto_parallel_search_mode (str) – This is the old version of ‘search_mode’. Here, remaining this attribute is for forward compatibility, and this attribute will be deleted in a future MindSpore version.\\n', '\\n', 'parameter_broadcast (bool) – Whether to broadcast parameters before training. Before training, in order to have the same network initialization parameter values for all devices, broadcast the parameters on device 0 to other devices. Parameter broadcasting in different parallel modes is different, data_parallel mode, all parameters are broadcast except for the parameter whose attribute layerwise_parallel is True. Hybrid_parallel, semi_auto_parallel and auto_parallel mode, the segmented parameters do not participate in broadcasting. Default: False.\\n', '\\n', 'strategy_ckpt_load_file (str) – The path to load parallel strategy checkpoint. Default: ‘’\\n', '\\n', 'strategy_ckpt_save_file (str) – The path to save parallel strategy checkpoint. Default: ‘’\\n', '\\n', 'full_batch (bool) – If you load whole batch datasets in auto_parallel mode, this parameter should be set as True. Default: False. The interface is not to be recommended currently, it is better using ‘dataset_strategy’ to replace it.\\n', '\\n', 'dataset_strategy (Union[str, tuple]) – Dataset sharding strategy. Default: “data_parallel”. dataset_strategy=”data_parallel” is equal to full_batch=False, dataset_strategy=”full_batch” is equal to full_batch=True. For dataset load into net by model parallel strategy likes ds_stra ((1, 8), (1, 8)), it requires using set_auto_parallel_context(dataset_strategy=ds_stra).\\n', '\\n', 'enable_parallel_optimizer (bool) – This is a developing feature, which shards the weight update computation for data parallel training in the benefit of time and memory saving. Currently, auto and semi auto parallel mode support all optimizers in both Ascend and GPU. Data parallel mode only supports Lamb and AdamWeightDecay in Ascend . Default: False.\\n', '\\n', 'all_reduce_fusion_config (list) – Set allreduce fusion strategy by parameters indices. Only support ReduceOp.SUM and HCCL_WORLD_GROUP/NCCL_WORLD_GROUP. No Default, if it is not set, the fusion is closed.\\n', '\\n', 'pipeline_stages (int) – Set the stage information for pipeline parallel. This indicates how the devices are distributed alone in the pipeline. The total devices will be divided into ‘pipeline_stags’ stages. Currently, this could only be used when parallel mode semi_auto_parallel is enabled. Default: 1.\\n', '\\n', 'grad_accumulation_step (int) – Set the accumulation steps of gradients in auto and semi auto parallel mode. This should be a positive int. Default: 1.\\n', '\\n', 'parallel_optimizer_config (dict) –\\n', '\\n', 'A dict contains the keys and values for setting the parallel optimizer configure. The configure provides more detailed behavior control about parallel training when parallel optimizer is enabled. Currently it supports the key gradient_accumulation_shard. The configure will be effective when we use context.set_auto_parallel_context(enable_parallel_optimizer=True). It supports the following keys.\\n', '\\n', 'gradient_accumulation_shard: If true, the accumulation gradient parameters will be sharded across the data parallel devices. This will introduce additional communication(ReduceScatter) at each step when accumulate the gradients, but saves a lot of device memories, thus can make model be trained with larger batch size. This configure is effective only when the model runs on pipeline training or gradient accumulation with data parallel. Default True.\\n', '\\n', 'comm_fusion (dict) –\\n', '\\n', 'A dict contains the types and configurations for setting the communication fusion. each communication fusion config has two keys: “mode” and “config”. It supports following communication fusion types and configurations:\\n', '\\n', 'allreduce: If communication fusion type is allreduce. The mode contains: auto, size and index. In auto mode, allreduce fusion is configured by gradients size, and the default fusion threshold is 64 MB. In ‘size’ mode, allreduce fusion is configured by gradients size manually, and the fusion threshold must be larger than 0 MB. In index mode, it is same as all_reduce_fusion_config.\\n', '\\n', 'Raises\\n', 'ValueError – If input key is not attribute in auto parallel context.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import context\\n', 'context.set_auto_parallel_context(device_num=8)\\n', 'context.set_auto_parallel_context(global_rank=0)\\n', 'context.set_auto_parallel_context(gradients_mean=True)\\n', 'context.set_auto_parallel_context(gradient_fp32_sync=False)\\n', 'context.set_auto_parallel_context(parallel_mode=\"auto_parallel\")\\n', 'context.set_auto_parallel_context(search_mode=\"dynamic_programming\")\\n', 'context.set_auto_parallel_context(auto_parallel_search_mode=\"dynamic_programming\")\\n', 'context.set_auto_parallel_context(parameter_broadcast=False)\\n', 'context.set_auto_parallel_context(strategy_ckpt_load_file=\"./strategy_stage1.ckpt\")\\n', 'context.set_auto_parallel_context(strategy_ckpt_save_file=\"./strategy_stage1.ckpt\")\\n', 'context.set_auto_parallel_context(dataset_strategy=((1, 8), (1, 8)))\\n', 'context.set_auto_parallel_context(enable_parallel_optimizer=False)\\n', 'context.set_auto_parallel_context(all_reduce_fusion_config=[8, 160])\\n', 'context.set_auto_parallel_context(pipeline_stages=2)\\n', 'parallel_config = {\"gradient_accumulation_shard\": True}\\n', 'context.set_auto_parallel_context(parallel_optimizer_config=parallel_config, enable_parallel_optimizer=True)\\n', 'comm_fusion_config = {\"allreduce\": {\"mode\": \"size\", \"config\": 32}}\\n', 'context.set_auto_parallel_context(comm_fusion=comm_fusion_config)\\n', 'mindspore.context.get_auto_parallel_context(attr_key)[source]\\n', 'Get auto parallel context attribute value according to the key.\\n', '\\n', 'Parameters\\n', 'attr_key (str) – The key of the attribute.\\n', '\\n', 'Returns\\n', 'Returns attribute value according to the key.\\n', '\\n', 'Raises\\n', 'ValueError – If input key is not attribute in auto parallel context.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import context\\n', 'parallel_mode = context.get_auto_parallel_context(\"parallel_mode\")\\n', 'dataset_strategy = context.get_auto_parallel_context(\"dataset_strategy\")\\n', 'mindspore.context.reset_auto_parallel_context()[source]\\n', 'Reset auto parallel context attributes to the default values:\\n', '\\n', 'device_num: 1.\\n', '\\n', 'global_rank: 0.\\n', '\\n', 'gradients_mean: False.\\n', '\\n', 'gradient_fp32_sync: True.\\n', '\\n', 'parallel_mode: ‘stand_alone’.\\n', '\\n', 'search_mode: ‘dynamic_programming’.\\n', '\\n', 'auto_parallel_search_mode: ‘dynamic_programming’.\\n', '\\n', 'parameter_broadcast: False.\\n', '\\n', 'strategy_ckpt_load_file: ‘’.\\n', '\\n', 'strategy_ckpt_save_file: ‘’.\\n', '\\n', 'full_batch: False.\\n', '\\n', 'enable_parallel_optimizer: False.\\n', '\\n', 'pipeline_stages: 1.\\n', '\\n', 'fusion_threshold: 64.\\n', '\\n', 'classmindspore.context.ParallelMode[source]\\n', 'Parallel mode options.\\n', '\\n', 'There are five kinds of parallel modes, “STAND_ALONE”, “DATA_PARALLEL”, “HYBRID_PARALLEL”, “SEMI_AUTO_PARALLEL” and “AUTO_PARALLEL”. Default: “STAND_ALONE”.\\n', '\\n', 'STAND_ALONE: Only one processor is working.\\n', '\\n', 'DATA_PARALLEL: Distributes the data across different processors.\\n', '\\n', 'HYBRID_PARALLEL: Achieves data parallelism and model parallelism manually.\\n', '\\n', 'SEMI_AUTO_PARALLEL: Achieves data parallelism and model parallelism by setting parallel strategies.\\n', '\\n', 'AUTO_PARALLEL: Achieves parallelism automatically.\\n', '\\n', 'MODE_LIST: The list of all supported parallel modes.\\n', '\\n', 'mindspore.context.set_ps_context(**kwargs)[source]\\n', 'Set parameter server training mode context.\\n', '\\n', 'Note\\n', '\\n', 'Some other environment variables should also be set for parameter server training mode. These environment variables are listed below:\\n', '\\n', 'MS_SERVER_NUM: Server number\\n', '\\n', 'MS_WORKER_NUM: Worker number\\n', '\\n', 'MS_SCHED_HOST: Scheduler IP address\\n', '\\n', 'MS_SCHED_PORT: Scheduler port\\n', '\\n', 'MS_ROLE: The role of this process:\\n', '\\n', 'MS_SCHED: represents the scheduler,\\n', '\\n', 'MS_WORKER: represents the worker,\\n', '\\n', 'MS_PSERVER/MS_SERVER: represents the Server\\n', '\\n', 'Parameters\\n', 'enable_ps (bool) – Whether to enable parameter server training mode. Only after enable_ps is set True, the environment variables will be effective. Default: False.\\n', '\\n', 'config_file_path (string) – Configuration file path used by recovery, parameter server training mode only supports Server disaster recovery currently. Default: ‘’.\\n', '\\n', 'scheduler_manage_port (int) – Scheduler manage port used to scale out/in. Default: 11202.\\n', '\\n', 'enable_ssl (bool) – Set PS SSL mode enabled or disabled. Default: False.\\n', '\\n', 'client_password (str) – Password to decrypt the secret key stored in the client certificate. Default: ‘’.\\n', '\\n', 'server_password (str) – Password to decrypt the secret key stored in the server certificate. Default: ‘’.\\n', '\\n', 'Raises\\n', 'ValueError – If input key is not the attribute in parameter server training mode context.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import context\\n', \"context.set_ps_context(enable_ps=True, enable_ssl=True, client_password='123456', server_password='123456')\\n\", 'mindspore.context.get_ps_context(attr_key)[source]\\n', 'Get parameter server training mode context attribute value according to the key.\\n', '\\n', 'Parameters\\n', 'attr_key (str) –\\n', '\\n', 'The key of the attribute:\\n', '\\n', 'enable_ps (bool): Whether to enable parameter server training mode.\\n', '\\n', 'Returns\\n', 'Returns attribute value according to the key.\\n', '\\n', 'Raises\\n', 'ValueError – If input key is not attribute in auto parallel context.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import context\\n', 'context.get_ps_context(\"enable_ps\")\\n', 'mindspore.context.reset_ps_context()[source]\\n', 'Reset parameter server training mode context attributes to the default values:\\n', '\\n', 'enable_ps: False.\\n', '\\n']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.dataset.audio.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.dataset.audio.html", "text_entry": "['mindspore.dataset.audio\\n', 'This module is to support audio augmentations. It includes two parts: transforms and utils. transforms is a high performance processing module with common audio operations. utils provides some general methods for audio processing.\\n', '\\n', 'Common imported modules in corresponding API examples are as follows:\\n', '\\n', 'import mindspore.dataset as ds\\n', 'import mindspore.dataset.audio.transforms as audio\\n', 'mindspore.dataset.audio.transforms\\n', 'mindspore.dataset.audio.transforms.AllpassBiquad\\n', '\\n', 'Design two-pole all-pass filter for audio waveform of dimension of (…, time).\\n', '\\n', 'mindspore.dataset.audio.transforms.AmplitudeToDB\\n', '\\n', 'Converts the input tensor from amplitude/power scale to decibel scale.\\n', '\\n', 'mindspore.dataset.audio.transforms.Angle\\n', '\\n', 'Calculate the angle of the complex number sequence of shape (…, 2).\\n', '\\n', 'mindspore.dataset.audio.transforms.BandBiquad\\n', '\\n', 'Design two-pole band filter for audio waveform of dimension of (…, time).\\n', '\\n', 'mindspore.dataset.audio.transforms.BandpassBiquad\\n', '\\n', 'Design two-pole band-pass filter.\\n', '\\n', 'mindspore.dataset.audio.transforms.BandrejectBiquad\\n', '\\n', 'Design two-pole band-reject filter for audio waveform of dimension of (…, time).\\n', '\\n', 'mindspore.dataset.audio.transforms.BassBiquad\\n', '\\n', 'Design a bass tone-control effect for audio waveform of dimension of (…, time).\\n', '\\n', 'mindspore.dataset.audio.transforms.ComplexNorm\\n', '\\n', 'Compute the norm of complex tensor input.\\n', '\\n', 'mindspore.dataset.audio.transforms.Contrast\\n', '\\n', 'Apply contrast effect.\\n', '\\n', 'mindspore.dataset.audio.transforms.FrequencyMasking\\n', '\\n', 'Apply masking to a spectrogram in the frequency domain.\\n', '\\n', 'mindspore.dataset.audio.transforms.LowpassBiquad\\n', '\\n', 'Design biquad lowpass filter and perform filtering.\\n', '\\n', 'mindspore.dataset.audio.transforms.TimeMasking\\n', '\\n', 'Apply masking to a spectrogram in the time domain.\\n', '\\n', 'mindspore.dataset.audio.transforms.TimeStretch\\n', '\\n', 'Stretch STFT in time at a given rate, without changing the pitch.\\n', '\\n', 'mindspore.dataset.audio.utils\\n', 'mindspore.dataset.audio.utils.ScaleType\\n', '\\n', 'Scale Types.']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.dataset.config.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.dataset.config.html", "text_entry": "['mindspore.dataset.config\\n', 'The configuration module provides various functions to set and get the supported configuration parameters, and read a configuration file.\\n', '\\n', 'Common imported modules in corresponding API examples are as follows:\\n', '\\n', 'import mindspore.dataset as ds\\n', 'mindspore.dataset.config.set_seed(seed)\\n', 'If the seed is set, the generated random number will be fixed, this helps to produce deterministic results.\\n', '\\n', 'Note\\n', '\\n', 'This set_seed function sets the seed in the Python random library and numpy.random library for deterministic Python augmentations using randomness. This set_seed function should be called with every iterator created to reset the random seed. In the pipeline, this does not guarantee deterministic results with num_parallel_workers > 1.\\n', '\\n', 'Parameters\\n', 'seed (int) – Random number seed. It is used to generate deterministic random numbers.\\n', '\\n', 'Raises\\n', 'ValueError – If seed is invalid when seed < 0 or seed > MAX_UINT_32.\\n', '\\n', 'Examples\\n', '\\n', '# Set a new global configuration value for the seed value.\\n', '# Operations with randomness will use the seed value to generate random values.\\n', 'ds.config.set_seed(1000)\\n', 'mindspore.dataset.config.get_seed()\\n', 'Get random number seed. If the seed has been set, then will return the set value, otherwise it will return the default seed value which equals to std::mt19937::default_seed.\\n', '\\n', 'Returns\\n', 'int, random number seed.\\n', '\\n', 'Examples\\n', '\\n', '# Get the global configuration of seed.\\n', '# If set_seed() is never called before, the default value(std::mt19937::default_seed) will be returned.\\n', 'seed = ds.config.get_seed()\\n', 'mindspore.dataset.config.set_prefetch_size(size)\\n', 'Set the queue capacity of the thread in pipeline.\\n', '\\n', 'Parameters\\n', 'size (int) – The length of the cache queue.\\n', '\\n', 'Raises\\n', 'ValueError – If the queue capacity of the thread is invalid when size <= 0 or size > MAX_INT_32.\\n', '\\n', 'Note\\n', '\\n', 'Since total memory used for prefetch can grow very large with high number of workers, when the number of workers is greater than 4, the per worker prefetch size will be reduced. The actual prefetch size at runtime per-worker will be prefetchsize * (4 / num_parallel_workers).\\n', '\\n', 'Examples\\n', '\\n', '# Set a new global configuration value for the prefetch size.\\n', 'ds.config.set_prefetch_size(1000)\\n', 'mindspore.dataset.config.get_prefetch_size()\\n', 'Get the prefetch size as for number of rows.\\n', '\\n', 'Returns\\n', 'int, total number of rows to be prefetched.\\n', '\\n', 'Examples\\n', '\\n', '# Get the global configuration of prefetch size.\\n', '# If set_prefetch_size() is never called before, the default value(16) will be returned.\\n', 'prefetch_size = ds.config.get_prefetch_size()\\n', 'mindspore.dataset.config.set_num_parallel_workers(num)\\n', 'Set a new global configuration default value for the number of parallel workers. This setting will affect the parallelism of all dataset operation.\\n', '\\n', 'Parameters\\n', 'num (int) – Number of parallel workers to be used as a default for each operation.\\n', '\\n', 'Raises\\n', 'ValueError – If num_parallel_workers is invalid when num <= 0 or num > MAX_INT_32.\\n', '\\n', 'Examples\\n', '\\n', '# Set a new global configuration value for the number of parallel workers.\\n', '# Now parallel dataset operators will run with 8 workers.\\n', 'ds.config.set_num_parallel_workers(8)\\n', 'mindspore.dataset.config.get_num_parallel_workers()\\n', 'Get the global configuration of number of parallel workers. This is the DEFAULT num_parallel_workers value used for each operation, it is not related to AutoNumWorker feature.\\n', '\\n', 'Returns\\n', 'int, number of parallel workers to be used as a default for each operation.\\n', '\\n', 'Examples\\n', '\\n', '# Get the global configuration of parallel workers.\\n', '# If set_num_parallel_workers() is never called before, the default value(8) will be returned.\\n', 'num_parallel_workers = ds.config.get_num_parallel_workers()\\n', 'mindspore.dataset.config.set_numa_enable(numa_enable)\\n', 'Set the default state of numa enabled. If numa_enable is True, need to ensure numa library is installed.\\n', '\\n', 'Parameters\\n', 'numa_enable (bool) – Whether to use numa bind feature.\\n', '\\n', 'Raises\\n', 'TypeError – If numa_enable is not a boolean data type.\\n', '\\n', 'Examples\\n', '\\n', '# Set a new global configuration value for the state of numa enabled.\\n', '# Now parallel dataset operators will run with numa bind function\\n', 'ds.config.set_numa_enable(True)\\n', 'mindspore.dataset.config.get_numa_enable()\\n', 'Get the state of numa to indicate enabled/disabled. This is the DEFAULT numa enabled value used for the all process.\\n', '\\n', 'Returns\\n', 'bool, the default state of numa enabled.\\n', '\\n', 'Examples\\n', '\\n', '# Get the global configuration of numa.\\n', 'numa_state = ds.config.get_numa_enable()\\n', 'mindspore.dataset.config.set_monitor_sampling_interval(interval)\\n', 'Set the default interval (in milliseconds) for monitor sampling.\\n', '\\n', 'Parameters\\n', 'interval (int) – Interval (in milliseconds) to be used for performance monitor sampling.\\n', '\\n', 'Raises\\n', 'ValueError – If interval is invalid when interval <= 0 or interval > MAX_INT_32.\\n', '\\n', 'Examples\\n', '\\n', '# Set a new global configuration value for the monitor sampling interval.\\n', 'ds.config.set_monitor_sampling_interval(100)\\n', 'mindspore.dataset.config.get_monitor_sampling_interval()\\n', 'Get the global configuration of sampling interval of performance monitor.\\n', '\\n', 'Returns\\n', 'int, interval (in milliseconds) for performance monitor sampling.\\n', '\\n', 'Examples\\n', '\\n', '# Get the global configuration of monitor sampling interval.\\n', '# If set_monitor_sampling_interval() is never called before, the default value(1000) will be returned.\\n', 'sampling_interval = ds.config.get_monitor_sampling_interval()\\n', 'mindspore.dataset.config.set_callback_timeout(timeout)\\n', 'Set the default timeout (in seconds) for DSWaitedCallback. In case of a deadlock, the wait function will exit after the timeout period.\\n', '\\n', 'Parameters\\n', 'timeout (int) – Timeout (in seconds) to be used to end the wait in DSWaitedCallback in case of a deadlock.\\n', '\\n', 'Raises\\n', 'ValueError – If timeout is invalid when timeout <= 0 or timeout > MAX_INT_32.\\n', '\\n', 'Examples\\n', '\\n', '# Set a new global configuration value for the timeout value.\\n', 'ds.config.set_callback_timeout(100)\\n', 'mindspore.dataset.config.get_callback_timeout()\\n', 'Get the default timeout for DSWaitedCallback. In case of a deadlock, the wait function will exit after the timeout period.\\n', '\\n', 'Returns\\n', 'int, Timeout (in seconds) to be used to end the wait in DSWaitedCallback in case of a deadlock.\\n', '\\n', 'Examples\\n', '\\n', '# Get the global configuration of callback timeout.\\n', '# If set_callback_timeout() is never called before, the default value(60) will be returned.\\n', 'callback_timeout = ds.config.get_callback_timeout()\\n', 'mindspore.dataset.config.set_auto_num_workers(enable)\\n', 'Set num_parallel_workers for each op automatically(This feature is turned off by default).\\n', '\\n', 'If turned on, the num_parallel_workers in each op will be adjusted automatically, possibly overwriting the num_parallel_workers passed in by user or the default value (if user doesn’t pass anything) set by ds.config.set_num_parallel_workers().\\n', '\\n', 'For now, this function is only optimized for YoloV3 dataset with per_batch_map (running map in batch). This feature aims to provide a baseline for optimized num_workers assignment for each operation. Operation whose num_parallel_workers is adjusted to a new value will be logged.\\n', '\\n', 'Parameters\\n', 'enable (bool) – Whether to enable auto num_workers feature or not.\\n', '\\n', 'Raises\\n', 'TypeError – If enable is not of boolean type.\\n', '\\n', 'Examples\\n', '\\n', '# Enable auto_num_worker feature, this might override the num_parallel_workers passed in by user\\n', 'ds.config.set_auto_num_workers(True)\\n', 'mindspore.dataset.config.get_auto_num_workers()\\n', 'Get the setting (turned on or off) automatic number of workers.\\n', '\\n', 'Returns\\n', 'bool, whether auto number worker feature is turned on.\\n', '\\n', 'Examples\\n', '\\n', '# Get the global configuration of auto number worker feature.\\n', 'num_workers = ds.config.get_auto_num_workers()\\n', 'mindspore.dataset.config.set_enable_shared_mem(enable)\\n', 'Set the default state of shared memory flag. If shared_mem_enable is True, will use shared memory queues to pass data to processes that are created for operators that set python_multiprocessing=True.\\n', '\\n', 'Note\\n', '\\n', 'set_enable_shared_mem is not supported on Windows and MacOS platforms yet.\\n', '\\n', 'Parameters\\n', 'enable (bool) – Whether to use shared memory in operators when python_multiprocessing=True.\\n', '\\n', 'Raises\\n', 'TypeError – If enable is not a boolean data type.\\n', '\\n', 'Examples\\n', '\\n', '# Enable shared memory feature to improve the performance of Python multiprocessing.\\n', 'ds.config.set_enable_shared_mem(True)\\n', 'mindspore.dataset.config.get_enable_shared_mem()\\n', 'Get the default state of shared mem enabled variable.\\n', '\\n', 'Note\\n', '\\n', 'get_enable_shared_mem is not supported on Windows and MacOS platforms yet.\\n', '\\n', 'Returns\\n', 'bool, the state of shared mem enabled variable (default=True).\\n', '\\n', 'Examples\\n', '\\n', '# Get the flag of shared memory feature.\\n', 'shared_mem_flag = ds.config.get_enable_shared_mem()\\n', 'mindspore.dataset.config.set_sending_batches(batch_num)\\n', 'Set the default sending batches when training with sink_mode=True in Ascend device.\\n', '\\n', 'Parameters\\n', 'batch_num (int) – the total sending batches, when batch_num is set, it will wait unless sending batches increase, default is 0 which means will send all batches in dataset.\\n', '\\n', 'Raises\\n', 'TypeError – If batch_num is not in int type.\\n', '\\n', 'Examples\\n', '\\n', '# Set a new global configuration value for the sending batches\\n', 'ds.config.set_sending_batches(10)\\n', 'mindspore.dataset.config.load(file)\\n', 'Load the project configuration from the file format.\\n', '\\n', 'Parameters\\n', 'file (str) – Path of the configuration file to be loaded.\\n', '\\n', 'Raises\\n', 'RuntimeError – If file is invalid and parsing fails.\\n', '\\n', 'Examples\\n', '\\n', '# Set new default configuration according to values in the configuration file.\\n', '# example config file:\\n', '# {\\n', '#     \"logFilePath\": \"/tmp\",\\n', '#     \"numParallelWorkers\": 4,\\n', '#     \"seed\": 5489,\\n', '#     \"monitorSamplingInterval\": 30\\n', '# }\\n', 'config_file = \"/path/to/config/file\"\\n', 'ds.config.load(config_file)\\n', 'mindspore.dataset.config.set_enable_autotune(enable)\\n', 'Set the default state of AutoTune flag. If it is True, will facilitate users to improve performance for a given workload by automatically finding the better settings for data pipeline.\\n', '\\n', 'Parameters\\n', 'enable (bool) – Whether to use AutoTune feature when running data pipeline.\\n', '\\n', 'Raises\\n', 'TypeError – If enable is not a boolean data type.\\n', '\\n', 'Examples\\n', '\\n', '# Enable AutoTune\\n', 'ds.config.set_enable_autotune(True)\\n', 'mindspore.dataset.config.get_enable_autotune()\\n', 'Get the default state of AutoTune enabled variable.\\n', '\\n', 'Returns\\n', 'bool, the state of AutoTune enabled variable (default=True).\\n', '\\n', 'Examples\\n', '\\n', '# Get the flag of AutoTune feature.\\n', 'autotune_flag = ds.config.get_enable_autotune()\\n', 'mindspore.dataset.config.set_autotune_interval(interval)\\n', 'Set the interval (in steps) for data pipeline autotuning. Setting interval to 0 configures autotune to run after every epoch instead of after a certain number of steps. Default value is set to 0, meaning epoch based autotuning.\\n', '\\n', 'Parameters\\n', 'interval (int) – Interval (in steps) to serve as gap for consecutive AutoTune runs.\\n', '\\n', 'Raises\\n', 'ValueError – If interval is invalid when interval < 0 or interval > MAX_INT_32.\\n', '\\n', 'Examples\\n', '\\n', '# Set a new global configuration value for the autotuning interval.\\n', 'ds.config.set_autotune_interval(30)\\n', 'mindspore.dataset.config.get_autotune_interval()\\n', 'Get the global configuration of pipeline autotuning step interval.\\n', '\\n', 'Returns\\n', 'int, interval (in steps) for data pipeline autotuning.\\n', '\\n', 'Examples\\n', '\\n', '# Get the global configuration of the autotuning interval.\\n', '# If set_autotune_interval() is never called before, the default value(30) will be returned.\\n', 'autotune_interval = ds.config.get_autotune_interval()']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.dataset.text.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.dataset.text.html", "text_entry": "['mindspore.dataset.text\\n', 'This module is to support text processing for NLP. It includes two parts: transforms and utils. transforms is a high performance NLP text processing module which is developed with ICU4C and cppjieba. utils provides some general methods for NLP text processing.\\n', '\\n', 'Common imported modules in corresponding API examples are as follows:\\n', '\\n', 'import mindspore.dataset as ds\\n', 'from mindspore.dataset import text\\n', 'mindspore.dataset.text.transforms\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Note\\n', '\\n', 'mindspore.dataset.text.transforms.BasicTokenizer\\n', '\\n', 'Tokenize a scalar tensor of UTF-8 string by specific rules.\\n', '\\n', 'BasicTokenizer is not supported on Windows platform yet.\\n', '\\n', 'mindspore.dataset.text.transforms.BertTokenizer\\n', '\\n', 'Tokenizer used for Bert text process.\\n', '\\n', 'BertTokenizer is not supported on Windows platform yet.\\n', '\\n', 'mindspore.dataset.text.transforms.CaseFold\\n', '\\n', 'Apply case fold operation on UTF-8 string tensor, which is aggressive that can convert more characters into lower case.\\n', '\\n', 'CaseFold is not supported on Windows platform yet.\\n', '\\n', 'mindspore.dataset.text.transforms.JiebaTokenizer\\n', '\\n', 'Tokenize Chinese string into words based on dictionary.\\n', '\\n', 'The integrity of the HMMSEgment algorithm and MPSegment algorithm files must be confirmed.\\n', '\\n', 'mindspore.dataset.text.transforms.Lookup\\n', '\\n', 'Look up a word into an id according to the input vocabulary table.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.transforms.Ngram\\n', '\\n', 'TensorOp to generate n-gram from a 1-D string Tensor.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.transforms.NormalizeUTF8\\n', '\\n', 'Apply normalize operation on UTF-8 string tensor.\\n', '\\n', 'NormalizeUTF8 is not supported on Windows platform yet.\\n', '\\n', 'mindspore.dataset.text.transforms.PythonTokenizer\\n', '\\n', 'Class that applies user-defined string tokenizer into input string.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.transforms.RegexReplace\\n', '\\n', 'Replace a part of UTF-8 string tensor with given text according to regular expressions.\\n', '\\n', 'RegexReplace is not supported on Windows platform yet.\\n', '\\n', 'mindspore.dataset.text.transforms.RegexTokenizer\\n', '\\n', 'Tokenize a scalar tensor of UTF-8 string by regex expression pattern.\\n', '\\n', 'RegexTokenizer is not supported on Windows platform yet.\\n', '\\n', 'mindspore.dataset.text.transforms.SentencePieceTokenizer\\n', '\\n', 'Tokenize scalar token or 1-D tokens to tokens by sentencepiece.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.transforms.SlidingWindow\\n', '\\n', 'Construct a tensor from given data (only support 1-D for now), where each element in the dimension axis is a slice of data starting at the corresponding position, with a specified width.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.transforms.ToNumber\\n', '\\n', 'Tensor operation to convert every element of a string tensor to a number.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.transforms.TruncateSequencePair\\n', '\\n', 'Truncate a pair of rank-1 tensors such that the total length is less than max_length.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.transforms.UnicodeCharTokenizer\\n', '\\n', 'Tokenize a scalar tensor of UTF-8 string to Unicode characters.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.transforms.UnicodeScriptTokenizer\\n', '\\n', 'Tokenize a scalar tensor of UTF-8 string based on Unicode script boundaries.\\n', '\\n', 'UnicodeScriptTokenizer is not supported on Windows platform yet.\\n', '\\n', 'mindspore.dataset.text.transforms.WhitespaceTokenizer\\n', '\\n', 'Tokenize a scalar tensor of UTF-8 string on ICU4C defined whitespaces, such as: ‘ ‘, ‘\\\\t’, ‘\\\\r’, ‘\\\\n’.\\n', '\\n', 'WhitespaceTokenizer is not supported on Windows platform yet.\\n', '\\n', 'mindspore.dataset.text.transforms.WordpieceTokenizer\\n', '\\n', 'Tokenize scalar token or 1-D tokens to 1-D subword tokens.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.utils\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Note\\n', '\\n', 'mindspore.dataset.text.JiebaMode\\n', '\\n', 'An enumeration for JiebaTokenizer.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.NormalizeForm\\n', '\\n', 'An enumeration for NormalizeUTF8.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.SentencePieceModel\\n', '\\n', 'An enumeration for SentencePieceModel.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.SentencePieceVocab\\n', '\\n', 'SentencePiece object that is used to do words segmentation.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.SPieceTokenizerLoadType\\n', '\\n', 'An enumeration for SPieceTokenizerLoadType.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.SPieceTokenizerOutType\\n', '\\n', 'An enumeration for SPieceTokenizerOutType.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.to_str\\n', '\\n', 'Convert NumPy array of bytes to array of str by decoding each element based on charset encoding.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.to_bytes\\n', '\\n', 'Convert NumPy array of str to array of bytes by encoding each element based on charset encoding.\\n', '\\n', 'None\\n', '\\n', 'mindspore.dataset.text.Vocab\\n', '\\n', 'Vocab object that is used to save pairs of words and ids.\\n', '\\n', 'None']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.dataset.transforms.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.dataset.transforms.html", "text_entry": "['mindspore.dataset.transforms\\n', 'This module is to support common augmentations. C_transforms is a high performance image augmentation module which is developed with C++ OpenCV. Py_transforms provide more kinds of image augmentations which are developed with Python PIL.\\n', '\\n', 'Common imported modules in corresponding API examples are as follows:\\n', '\\n', 'import mindspore.dataset as ds\\n', 'import mindspore.dataset.vision.c_transforms as c_vision\\n', 'import mindspore.dataset.vision.py_transforms as py_vision\\n', 'from mindspore.dataset.transforms import c_transforms\\n', 'from mindspore.dataset.transforms import py_transforms\\n', 'mindspore.dataset.transforms.c_transforms\\n', 'mindspore.dataset.transforms.c_transforms.Compose\\n', '\\n', 'Compose a list of transforms into a single transform.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Concatenate\\n', '\\n', 'Tensor operation that concatenates all columns into a single tensor.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Duplicate\\n', '\\n', 'Duplicate the input tensor to output, only support transform one column each time.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Fill\\n', '\\n', 'Tensor operation to fill all elements in the tensor with the specified value.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Mask\\n', '\\n', 'Mask content of the input tensor with the given predicate.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.OneHot\\n', '\\n', 'Tensor operation to apply one hot encoding.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.PadEnd\\n', '\\n', 'Pad input tensor according to pad_shape, input tensor needs to have same rank.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.RandomApply\\n', '\\n', 'Randomly perform a series of transforms with a given probability.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.RandomChoice\\n', '\\n', 'Randomly select one transform from a list of transforms to perform operation.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Relational\\n', '\\n', 'Relationship operator.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Slice\\n', '\\n', 'Slice operation to extract a tensor out using the given n slices.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.TypeCast\\n', '\\n', 'Tensor operation to cast to a given MindSpore data type.\\n', '\\n', 'mindspore.dataset.transforms.c_transforms.Unique\\n', '\\n', 'Perform the unique operation on the input tensor, only support transform one column each time.\\n', '\\n', 'mindspore.dataset.transforms.py_transforms\\n', 'mindspore.dataset.transforms.py_transforms.Compose\\n', '\\n', 'Compose a list of transforms.\\n', '\\n', 'mindspore.dataset.transforms.py_transforms.OneHotOp\\n', '\\n', 'Apply one hot encoding transformation to the input label, make label be more smoothing and continuous.\\n', '\\n', 'mindspore.dataset.transforms.py_transforms.RandomApply\\n', '\\n', 'Randomly perform a series of transforms with a given probability.\\n', '\\n', 'mindspore.dataset.transforms.py_transforms.RandomChoice\\n', '\\n', 'Randomly select one transform from a series of transforms and applies that on the image.\\n', '\\n', 'mindspore.dataset.transforms.py_transforms.RandomOrder\\n', '\\n', 'Perform a series of transforms to the input PIL image in a random order.']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.dataset.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.dataset.html", "text_entry": "['mindspore.dataset\\n', 'This module provides APIs to load and process various common datasets such as MNIST, CIFAR-10, CIFAR-100, VOC, COCO, ImageNet, CelebA, CLUE, etc. It also supports datasets in standard format, including MindRecord, TFRecord, Manifest, etc. Users can also define their own datasets with this module.\\n', '\\n', 'Besides, this module provides APIs to sample data while loading.\\n', '\\n', 'We can enable cache in most of the dataset with its key arguments ‘cache’. Please notice that cache is not supported on Windows platform yet. Do not use it while loading and processing data on Windows. More introductions and limitations can refer Single-Node Tensor Cache.\\n', '\\n', 'Common imported modules in corresponding API examples are as follows:\\n', '\\n', 'import mindspore.dataset as ds\\n', 'from mindspore.dataset.transforms import c_transforms\\n', 'Descriptions of common dataset terms are as follows:\\n', '\\n', 'Dataset, the base class of all the datasets. It provides data processing methods to help preprocess the data.\\n', '\\n', 'SourceDataset, an abstract class to represent the source of dataset pipeline which produces data from data sources such as files and databases.\\n', '\\n', 'MappableDataset, an abstract class to represent a source dataset which supports for random access.\\n', '\\n', 'Iterator, the base class of dataset iterator for enumerating elements.\\n', '\\n', 'Vision\\n', 'mindspore.dataset.Caltech101Dataset\\n', '\\n', 'A source dataset that reads and parses Caltech101 dataset.\\n', '\\n', 'mindspore.dataset.Caltech256Dataset\\n', '\\n', 'A source dataset that reads and parses Caltech256 dataset.\\n', '\\n', 'mindspore.dataset.CelebADataset\\n', '\\n', 'A source dataset that reads and parses CelebA dataset.\\n', '\\n', 'mindspore.dataset.Cifar10Dataset\\n', '\\n', 'A source dataset that reads and parses Cifar10 dataset.\\n', '\\n', 'mindspore.dataset.Cifar100Dataset\\n', '\\n', 'A source dataset that reads and parses Cifar100 dataset.\\n', '\\n', 'mindspore.dataset.CityscapesDataset\\n', '\\n', 'A source dataset that reads and parses Cityscapes dataset.\\n', '\\n', 'mindspore.dataset.CocoDataset\\n', '\\n', 'A source dataset that reads and parses COCO dataset.\\n', '\\n', 'mindspore.dataset.DIV2KDataset\\n', '\\n', 'A source dataset that reads and parses DIV2KDataset dataset.\\n', '\\n', 'mindspore.dataset.EMnistDataset\\n', '\\n', 'A source dataset that reads and parses the EMNIST dataset.\\n', '\\n', 'mindspore.dataset.FakeImageDataset\\n', '\\n', 'A source dataset for generating fake images.\\n', '\\n', 'mindspore.dataset.FashionMnistDataset\\n', '\\n', 'A source dataset that reads and parses the FASHION-MNIST dataset.\\n', '\\n', 'mindspore.dataset.FlickrDataset\\n', '\\n', 'A source dataset that reads and parses Flickr8k and Flickr30k dataset.\\n', '\\n', 'mindspore.dataset.Flowers102Dataset\\n', '\\n', 'A source dataset that reads and parses Flowers102 dataset.\\n', '\\n', 'mindspore.dataset.ImageFolderDataset\\n', '\\n', 'A source dataset that reads images from a tree of directories.\\n', '\\n', 'mindspore.dataset.KMnistDataset\\n', '\\n', 'A source dataset that reads and parses the KMNIST dataset.\\n', '\\n', 'mindspore.dataset.ManifestDataset\\n', '\\n', 'A source dataset for reading images from a Manifest file.\\n', '\\n', 'mindspore.dataset.MnistDataset\\n', '\\n', 'A source dataset that reads and parses the MNIST dataset.\\n', '\\n', 'mindspore.dataset.PhotoTourDataset\\n', '\\n', 'A source dataset that reads and parses the PhotoTour dataset.\\n', '\\n', 'mindspore.dataset.Places365Dataset\\n', '\\n', 'A source dataset that reads and parses the Places365 dataset.\\n', '\\n', 'mindspore.dataset.QMnistDataset\\n', '\\n', 'A source dataset that reads and parses the QMNIST dataset.\\n', '\\n', 'mindspore.dataset.SBDataset\\n', '\\n', 'A source dataset that reads and parses Semantic Boundaries Dataset.\\n', '\\n', 'mindspore.dataset.SBUDataset\\n', '\\n', 'A source dataset that reads and parses the SBU dataset.\\n', '\\n', 'mindspore.dataset.SemeionDataset\\n', '\\n', 'A source dataset that reads and parses Semeion dataset.\\n', '\\n', 'mindspore.dataset.STL10Dataset\\n', '\\n', 'A source dataset that reads and parses STL10 dataset.\\n', '\\n', 'mindspore.dataset.SVHNDataset\\n', '\\n', 'A source dataset that reads and parses SVHN dataset.\\n', '\\n', 'mindspore.dataset.USPSDataset\\n', '\\n', 'A source dataset that reads and parses the USPS dataset.\\n', '\\n', 'mindspore.dataset.VOCDataset\\n', '\\n', 'A source dataset that reads and parses VOC dataset.\\n', '\\n', 'mindspore.dataset.WIDERFaceDataset\\n', '\\n', 'A source dataset that reads and parses WIDERFace dataset.\\n', '\\n', 'Text\\n', 'mindspore.dataset.AGNewsDataset\\n', '\\n', 'A source dataset that reads and parses AG News datasets.\\n', '\\n', 'mindspore.dataset.AmazonReviewDataset\\n', '\\n', 'A source dataset that reads and parses Amazon Review Polarity and Amazon Review Full datasets.\\n', '\\n', 'mindspore.dataset.CLUEDataset\\n', '\\n', 'A source dataset that reads and parses CLUE datasets.\\n', '\\n', 'mindspore.dataset.CoNLL2000Dataset\\n', '\\n', 'A source dataset that reads and parses CoNLL2000 dataset.\\n', '\\n', 'mindspore.dataset.CSVDataset\\n', '\\n', 'A source dataset that reads and parses comma-separated values (CSV) files as dataset.\\n', '\\n', 'mindspore.dataset.DBpediaDataset\\n', '\\n', 'A source dataset that reads and parses the DBpedia dataset.\\n', '\\n', 'mindspore.dataset.EnWik9Dataset\\n', '\\n', 'A source dataset that reads and parses EnWik9 dataset.\\n', '\\n', 'mindspore.dataset.IMDBDataset\\n', '\\n', 'A source dataset that reads and parses Internet Movie Database (IMDb).\\n', '\\n', 'mindspore.dataset.IWSLT2016Dataset\\n', '\\n', 'A source dataset that reads and parses IWSLT2016 datasets.\\n', '\\n', 'mindspore.dataset.IWSLT2017Dataset\\n', '\\n', 'A source dataset that reads and parses IWSLT2017 datasets.\\n', '\\n', 'mindspore.dataset.PennTreebankDataset\\n', '\\n', 'A source dataset that reads and parses PennTreebank datasets.\\n', '\\n', 'mindspore.dataset.SogouNewsDataset\\n', '\\n', 'A source dataset that reads and parses Sogou News dataset.\\n', '\\n', 'mindspore.dataset.TextFileDataset\\n', '\\n', 'A source dataset that reads and parses datasets stored on disk in text format.\\n', '\\n', 'mindspore.dataset.UDPOSDataset\\n', '\\n', 'A source dataset that reads and parses UDPOS dataset.\\n', '\\n', 'mindspore.dataset.WikiTextDataset\\n', '\\n', 'A source dataset that reads and parses WikiText2 and WikiText103 datasets.\\n', '\\n', 'mindspore.dataset.YahooAnswersDataset\\n', '\\n', 'A source dataset that reads and parses the YahooAnswers dataset.\\n', '\\n', 'mindspore.dataset.YelpReviewDataset\\n', '\\n', 'A source dataset that reads and parses Yelp Review Polarity and Yelp Review Full dataset.\\n', '\\n', 'Audio\\n', 'mindspore.dataset.LJSpeechDataset\\n', '\\n', 'A source dataset that reads and parses LJSpeech dataset.\\n', '\\n', 'mindspore.dataset.SpeechCommandsDataset\\n', '\\n', 'A source dataset that reads and parses the SpeechCommands dataset.\\n', '\\n', 'mindspore.dataset.TedliumDataset\\n', '\\n', 'A source dataset that reads and parses Tedlium dataset.\\n', '\\n', 'mindspore.dataset.YesNoDataset\\n', '\\n', 'A source dataset that reads and parses the YesNo dataset.\\n', '\\n', 'Standard Format\\n', 'mindspore.dataset.CSVDataset\\n', '\\n', 'A source dataset that reads and parses comma-separated values (CSV) files as dataset.\\n', '\\n', 'mindspore.dataset.MindDataset\\n', '\\n', 'A source dataset that reads and parses MindRecord dataset.\\n', '\\n', 'mindspore.dataset.TFRecordDataset\\n', '\\n', 'A source dataset that reads and parses datasets stored on disk in TFData format.\\n', '\\n', 'User Defined\\n', 'mindspore.dataset.GeneratorDataset\\n', '\\n', 'A source dataset that generates data from Python by invoking Python data source each epoch.\\n', '\\n', 'mindspore.dataset.NumpySlicesDataset\\n', '\\n', 'Creates a dataset with given data slices, mainly for loading Python data into dataset.\\n', '\\n', 'mindspore.dataset.PaddedDataset\\n', '\\n', 'Creates a dataset with filler data provided by user.\\n', '\\n', 'mindspore.dataset.RandomDataset\\n', '\\n', 'A source dataset that generates random data.\\n', '\\n', 'Graph\\n', 'mindspore.dataset.GraphData\\n', '\\n', 'Reads the graph dataset used for GNN training from the shared file and database.\\n', '\\n', 'Sampler\\n', 'mindspore.dataset.DistributedSampler\\n', '\\n', 'A sampler that accesses a shard of the dataset, it helps divide dataset into multi-subset for distributed training.\\n', '\\n', 'mindspore.dataset.PKSampler\\n', '\\n', 'Samples K elements for each P class in the dataset.\\n', '\\n', 'mindspore.dataset.RandomSampler\\n', '\\n', 'Samples the elements randomly.\\n', '\\n', 'mindspore.dataset.SequentialSampler\\n', '\\n', 'Samples the dataset elements sequentially that is equivalent to not using a sampler.\\n', '\\n', 'mindspore.dataset.SubsetRandomSampler\\n', '\\n', 'Samples the elements randomly from a sequence of indices.\\n', '\\n', 'mindspore.dataset.SubsetSampler\\n', '\\n', 'Samples the elements from a sequence of indices.\\n', '\\n', 'mindspore.dataset.WeightedRandomSampler\\n', '\\n', 'Samples the elements from [0, len(weights) - 1] randomly with the given weights (probabilities).\\n', '\\n', 'Others\\n', 'mindspore.dataset.BatchInfo\\n', '\\n', 'Only the batch size function and per_batch_map of the batch operator can dynamically adjust parameters based on the number of batches and epochs during training.\\n', '\\n', 'mindspore.dataset.DatasetCache\\n', '\\n', 'A client to interface with tensor caching service.\\n', '\\n', 'mindspore.dataset.DSCallback\\n', '\\n', 'Abstract base class used to build a dataset callback class.\\n', '\\n', 'mindspore.dataset.SamplingStrategy\\n', '\\n', 'Specifies the sampling strategy when execute get_sampled_neighbors.\\n', '\\n', 'mindspore.dataset.Schema\\n', '\\n', 'Class to represent a schema of a dataset.\\n', '\\n', 'mindspore.dataset.Shuffle\\n', '\\n', 'Specify the shuffle mode.\\n', '\\n', 'mindspore.dataset.WaitedDSCallback\\n', '\\n', 'Abstract base class used to build a dataset callback class that is synchronized with the training callback.\\n', '\\n', 'mindspore.dataset.OutputFormat\\n', '\\n', 'Specifies the output storage format when execute get_all_neighbors.\\n', '\\n', 'mindspore.dataset.compare\\n', '\\n', 'Compare if two dataset pipelines are the same.\\n', '\\n', 'mindspore.dataset.deserialize\\n', '\\n', 'Construct dataset pipeline from a JSON file produced by de.serialize().\\n', '\\n', 'mindspore.dataset.serialize\\n', '\\n', 'Serialize dataset pipeline into a JSON file.\\n', '\\n', 'mindspore.dataset.show\\n', '\\n', 'Write the dataset pipeline graph to logger.info file.\\n', '\\n', 'mindspore.dataset.utils.imshow_det_bbox\\n', '\\n', 'Draw an image with given bboxes and class labels (with scores).\\n', '\\n', 'mindspore.dataset.zip\\n', '\\n', 'Zip the datasets in the input tuple of datasets.']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.dataset.vision.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.dataset.vision.html", "text_entry": "['mindspore.dataset.vision\\n', 'This module is to support vision augmentations. It includes two parts: c_transforms and py_transforms. C_transforms is a high performance image augmentation module which is developed with c++ opencv. Py_transforms provide more kinds of image augmentations which are developed with Python PIL.\\n', '\\n', 'Common imported modules in corresponding API examples are as follows:\\n', '\\n', 'import mindspore.dataset.vision.c_transforms as c_vision\\n', 'import mindspore.dataset.vision.py_transforms as py_vision\\n', 'from mindspore.dataset.transforms import c_transforms\\n', 'mindspore.dataset.vision.c_transforms\\n', 'mindspore.dataset.vision.c_transforms.AutoContrast\\n', '\\n', 'Apply automatic contrast on input image.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.BoundingBoxAugment\\n', '\\n', 'Apply a given image transform on a random selection of bounding box regions of a given image.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.CenterCrop\\n', '\\n', 'Crop the input image at the center to the given size.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.ConvertColor\\n', '\\n', 'Change the color space of the image.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Crop\\n', '\\n', 'Crop the input image at a specific location.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.CutMixBatch\\n', '\\n', 'Apply CutMix transformation on input batch of images and labels.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.CutOut\\n', '\\n', 'Randomly cut (mask) out a given number of square patches from the input image array.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Decode\\n', '\\n', 'Decode the input image in RGB mode(default) or BGR mode(deprecated).\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Equalize\\n', '\\n', 'Apply histogram equalization on input image.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.GaussianBlur\\n', '\\n', 'Blur input image with the specified Gaussian kernel.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.HorizontalFlip\\n', '\\n', 'Flip the input image horizontally.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.HWC2CHW\\n', '\\n', 'Transpose the input image from shape (H, W, C) to shape (C, H, W).\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Invert\\n', '\\n', 'Apply invert on input image in RGB mode.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.MixUpBatch\\n', '\\n', 'Apply MixUp transformation on input batch of images and labels.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Normalize\\n', '\\n', 'Normalize the input image with respect to mean and standard deviation.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.NormalizePad\\n', '\\n', 'Normalize the input image with respect to mean and standard deviation then pad an extra channel with value zero.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Pad\\n', '\\n', 'Pad the image according to padding parameters.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomAffine\\n', '\\n', 'Apply Random affine transformation to the input image.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomColor\\n', '\\n', 'Adjust the color of the input image by a fixed or random degree.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomColorAdjust\\n', '\\n', 'Randomly adjust the brightness, contrast, saturation, and hue of the input image.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomCrop\\n', '\\n', 'Crop the input image at a random location.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomCropDecodeResize\\n', '\\n', 'A combination of Crop, Decode and Resize.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomCropWithBBox\\n', '\\n', 'Crop the input image at a random location and adjust bounding boxes accordingly.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomHorizontalFlip\\n', '\\n', 'Randomly flip the input image horizontally with a given probability.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomHorizontalFlipWithBBox\\n', '\\n', 'Flip the input image horizontally randomly with a given probability and adjust bounding boxes accordingly.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomPosterize\\n', '\\n', 'Reduce the number of bits for each color channel to posterize the input image randomly with a given probability.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomResize\\n', '\\n', 'Resize the input image using a randomly selected interpolation mode.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomResizedCrop\\n', '\\n', 'Crop the input image to a random size and aspect ratio.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomResizedCropWithBBox\\n', '\\n', 'Crop the input image to a random size and aspect ratio and adjust bounding boxes accordingly.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomResizeWithBBox\\n', '\\n', 'Tensor operation to resize the input image using a randomly selected interpolation mode and adjust bounding boxes accordingly.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomRotation\\n', '\\n', 'Rotate the input image randomly within a specified range of degrees.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomSelectSubpolicy\\n', '\\n', 'Choose a random sub-policy from a policy list to be applied on the input image.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomSharpness\\n', '\\n', 'Adjust the sharpness of the input image by a fixed or random degree.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomSolarize\\n', '\\n', 'Randomly selects a subrange within the specified threshold range and sets the pixel value within the subrange to (255 - pixel).\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomVerticalFlip\\n', '\\n', 'Randomly flip the input image vertically with a given probability.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.RandomVerticalFlipWithBBox\\n', '\\n', 'Flip the input image vertically, randomly with a given probability and adjust bounding boxes accordingly.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Rescale\\n', '\\n', 'Rescale the input image with the given rescale and shift.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Resize\\n', '\\n', 'Resize the input image to the given size with a given interpolation mode.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.ResizeWithBBox\\n', '\\n', 'Resize the input image to the given size and adjust bounding boxes accordingly.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.Rotate\\n', '\\n', 'Rotate the input image by specified degrees.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.SlicePatches\\n', '\\n', 'Slice Tensor to multiple patches in horizontal and vertical directions.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.SoftDvppDecodeRandomCropResizeJpeg\\n', '\\n', 'A combination of Crop, Decode and Resize using the simulation algorithm of Ascend series chip DVPP module.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.SoftDvppDecodeResizeJpeg\\n', '\\n', 'Decode and resize JPEG image using the simulation algorithm of Ascend series chip DVPP module.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.UniformAugment\\n', '\\n', 'Perform randomly selected augmentation on input image.\\n', '\\n', 'mindspore.dataset.vision.c_transforms.VerticalFlip\\n', '\\n', 'Flip the input image vertically.\\n', '\\n', 'mindspore.dataset.vision.py_transforms\\n', 'mindspore.dataset.vision.py_transforms.AutoContrast\\n', '\\n', 'Automatically maximize the contrast of the input PIL Image.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.CenterCrop\\n', '\\n', 'Crop the central region of the input PIL Image with the given size.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Cutout\\n', '\\n', 'Randomly apply a given number of square patches of zeros to a location within the input numpy.ndarray image of shape (C, H, W).\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Decode\\n', '\\n', 'Decode the input raw image to PIL Image format in RGB mode.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Equalize\\n', '\\n', 'Apply histogram equalization on the input PIL Image.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.FiveCrop\\n', '\\n', 'Crop the given image into one central crop and four corners.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Grayscale\\n', '\\n', 'Convert the input PIL Image to grayscale.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.HsvToRgb\\n', '\\n', 'Convert one or more numpy.ndarray images from HSV to RGB.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.HWC2CHW\\n', '\\n', 'Transpose the input numpy.ndarray image of shape (H, W, C) to (C, H, W).\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Invert\\n', '\\n', 'Invert the colors of the input PIL Image.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.LinearTransformation\\n', '\\n', 'Transform the input numpy.ndarray image with a given square transformation matrix and a mean vector.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.MixUp\\n', '\\n', 'Randomly mix up a batch of images together with its labels.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Normalize\\n', '\\n', 'Normalize the input numpy.ndarray image of shape (C, H, W) with the specified mean and standard deviation.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.NormalizePad\\n', '\\n', 'Normalize the input numpy.ndarray image of shape (C, H, W) with the specified mean and standard deviation, then pad an extra channel filled with zeros.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Pad\\n', '\\n', 'Pad the input image on all sides with the given padding parameters.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomAffine\\n', '\\n', 'Apply random affine transformation to the input PIL Image.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomColor\\n', '\\n', 'Adjust the color balance of the input PIL Image by a random degree.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomColorAdjust\\n', '\\n', 'Randomly adjust the brightness, contrast, saturation, and hue of the input PIL Image.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomCrop\\n', '\\n', 'Crop the input PIL Image at a random location with the specified size.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomErasing\\n', '\\n', 'Randomly erase the pixels within a random selected rectangle region with a given probability.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomGrayscale\\n', '\\n', 'Randomly convert the input image into grayscale with a given probability.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomHorizontalFlip\\n', '\\n', 'Randomly flip the input image horizontally with a given probability.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomPerspective\\n', '\\n', 'Randomly apply perspective transformation to the input PIL Image with a given probability.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomResizedCrop\\n', '\\n', 'Randomly crop the image and resize it to a given size.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomRotation\\n', '\\n', 'Rotate the input PIL Image by a random angle.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomSharpness\\n', '\\n', 'Adjust the sharpness of the input PIL Image by a random degree.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RandomVerticalFlip\\n', '\\n', 'Randomly flip the input image vertically with a given probability.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.Resize\\n', '\\n', 'Resize the input PIL Image to the given size.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.RgbToHsv\\n', '\\n', 'Convert one or more numpy.ndarray images from RGB to HSV.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.TenCrop\\n', '\\n', 'Crop the given image into one central crop and four corners plus the flipped version of these.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.ToPIL\\n', '\\n', 'Convert the input decoded numpy.ndarray image to PIL Image.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.ToTensor\\n', '\\n', 'Convert the input PIL Image or numpy.ndarray of shape (H, W, C) in the range [0, 255] to numpy.ndarray of shape (C, H, W) in the range [0.0, 1.0] with the desired dtype.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.ToType\\n', '\\n', 'Convert the input numpy.ndarray image to the desired dtype.\\n', '\\n', 'mindspore.dataset.vision.py_transforms.UniformAugment\\n', '\\n', 'Uniformly select a number of transformations from a sequence and apply them sequentially and randomly, which means that there is a chance that a chosen transformation will not be applied.\\n', '\\n', 'mindspore.dataset.vision.utils\\n', 'mindspore.dataset.vision.Border\\n', '\\n', 'Padding Mode, Border Type.\\n', '\\n', 'mindspore.dataset.vision.ImageBatchFormat\\n', '\\n', 'Data Format of images after batch operation.\\n', '\\n', 'mindspore.dataset.vision.Inter\\n', '\\n', 'Interpolation Modes.\\n', '\\n', 'mindspore.dataset.vision.SliceMode\\n', '\\n', 'Mode to Slice Tensor into multiple parts.']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.mindrecord.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.mindrecord.html", "text_entry": "['mindspore.mindrecord\\n', 'Introduction of MindRecord.\\n', '\\n', 'MindRecord is a module to implement reading, writing, searching and converting for MindSpore format dataset. Users could use the FileWriter API to generate MindRecord data and use the MindDataset API to load MindRecord data. Users could also convert other format datasets to mindrecord data through corresponding sub-module.\\n', '\\n', 'classmindspore.mindrecord.FileWriter(file_name, shard_num=1, overwrite=False)[source]\\n', 'Class to write user defined raw data into MindRecord files.\\n', '\\n', 'Note\\n', '\\n', 'After the MindRecord file is generated, if the file name is changed, the file may fail to be read.\\n', '\\n', 'Parameters\\n', 'file_name (str) – File name of MindRecord file.\\n', '\\n', 'shard_num (int, optional) – The Number of MindRecord files. Default: 1. It should be between [1, 1000].\\n', '\\n', 'overwrite (bool, optional) – Overwrite MindRecord files if true. Default: False.\\n', '\\n', 'Raises\\n', 'ParamValueError – If file_name or shard_num or overwrite is invalid.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.mindrecord import FileWriter\\n', 'schema_json = {\"file_name\": {\"type\": \"string\"}, \"label\": {\"type\": \"int32\"}, \"data\": {\"type\": \"bytes\"}}\\n', 'indexes = [\"file_name\", \"label\"]\\n', 'data = [{\"file_name\": \"1.jpg\", \"label\": 0,\\n', '         \"data\": b\"\\\\x10c\\\\xb3w\\\\xa8\\\\xee$o&<q\\\\x8c\\\\x8e(\\\\xa2\\\\x90\\\\x90\\\\x96\\\\xbc\\\\xb1\\\\x1e\\\\xd4QER\\\\x13?\\\\xff\"},\\n', '        {\"file_name\": \"2.jpg\", \"label\": 56,\\n', '         \"data\": b\"\\\\xe6\\\\xda\\\\xd1\\\\xae\\\\x07\\\\xb8>\\\\xd4\\\\x00\\\\xf8\\\\x129\\\\x15\\\\xd9\\\\xf2q\\\\xc0\\\\xa2\\\\x91YFUO\\\\x1dsE1\"},\\n', '        {\"file_name\": \"3.jpg\", \"label\": 99,\\n', '         \"data\": b\"\\\\xaf\\\\xafU<\\\\xb8|6\\\\xbd}\\\\xc1\\\\x99[\\\\xeaj+\\\\x8f\\\\x84\\\\xd3\\\\xcc\\\\xa0,i\\\\xbb\\\\xb9-\\\\xcdz\\\\xecp{T\\\\xb1\"}]\\n', 'writer = FileWriter(file_name=\"test.mindrecord\", shard_num=1, overwrite=True)\\n', 'writer.add_schema(schema_json, \"test_schema\")\\n', '\\n', 'writer.add_index(indexes)\\n', '\\n', 'writer.write_raw_data(data)\\n', '\\n', 'writer.commit()\\n', '\\n', 'add_index(index_fields)[source]\\n', 'Select index fields from schema to accelerate reading.\\n', '\\n', 'Note\\n', '\\n', 'The index fields should be primitive type. e.g. int/float/str. If the function is not called, the fields of the primitive type in schema are set as indexes by default.\\n', '\\n', 'Please refer to the Examples of class: mindspore.mindrecord.FileWriter.\\n', '\\n', 'Parameters\\n', 'index_fields (list[str]) – fields from schema.\\n', '\\n', 'Returns\\n', 'MSRStatus, SUCCESS or FAILED.\\n', '\\n', 'Raises\\n', 'ParamTypeError – If index field is invalid.\\n', '\\n', 'MRMDefineIndexError – If index field is not primitive type.\\n', '\\n', 'MRMAddIndexError – If failed to add index field.\\n', '\\n', 'MRMGetMetaError – If the schema is not set or failed to get meta.\\n', '\\n', 'add_schema(content, desc=None)[source]\\n', 'The schema is added to describe the raw data to be written.\\n', '\\n', 'Note\\n', '\\n', 'Please refer to the Examples of class: mindspore.mindrecord.FileWriter.\\n', '\\n', 'Parameters\\n', 'content (dict) – Dictionary of schema content.\\n', '\\n', 'desc (str, optional) – String of schema description, Default: None.\\n', '\\n', 'Returns\\n', 'int, schema id.\\n', '\\n', 'Raises\\n', 'MRMInvalidSchemaError – If schema is invalid.\\n', '\\n', 'MRMBuildSchemaError – If failed to build schema.\\n', '\\n', 'MRMAddSchemaError – If failed to add schema.\\n', '\\n', 'commit()[source]\\n', 'Flush data in memory to disk and generate the corresponding database files.\\n', '\\n', 'Note\\n', '\\n', 'Please refer to the Examples of class: mindspore.mindrecord.FileWriter.\\n', '\\n', 'Returns\\n', 'MSRStatus, SUCCESS or FAILED.\\n', '\\n', 'Raises\\n', 'MRMOpenError – If failed to open MindRecord file.\\n', '\\n', 'MRMSetHeaderError – If failed to set header.\\n', '\\n', 'MRMIndexGeneratorError – If failed to create index generator.\\n', '\\n', 'MRMGenerateIndexError – If failed to write to database.\\n', '\\n', 'MRMCommitError – If failed to flush data to disk.\\n', '\\n', 'open_and_set_header()[source]\\n', 'Open writer and set header. The function is only used for parallel writing and is called before the write_raw_data.\\n', '\\n', 'Returns\\n', 'MSRStatus, SUCCESS or FAILED.\\n', '\\n', 'Raises\\n', 'MRMOpenError – If failed to open MindRecord file.\\n', '\\n', 'MRMSetHeaderError – If failed to set header.\\n', '\\n', 'classmethodopen_for_append(file_name)[source]\\n', 'Open MindRecord file and get ready to append data.\\n', '\\n', 'Parameters\\n', 'file_name (str) – String of MindRecord file name.\\n', '\\n', 'Returns\\n', 'FileWriter, file writer object for the opened MindRecord file.\\n', '\\n', 'Raises\\n', 'ParamValueError – If file_name is invalid.\\n', '\\n', 'FileNameError – If path contains invalid characters.\\n', '\\n', 'MRMOpenError – If failed to open MindRecord file.\\n', '\\n', 'MRMOpenForAppendError – If failed to open file for appending data.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.mindrecord import FileWriter\\n', 'schema_json = {\"file_name\": {\"type\": \"string\"}, \"label\": {\"type\": \"int32\"}, \"data\": {\"type\": \"bytes\"}}\\n', 'data = [{\"file_name\": \"1.jpg\", \"label\": 0,\\n', '         \"data\": b\"\\\\x10c\\\\xb3w\\\\xa8\\\\xee$o&<q\\\\x8c\\\\x8e(\\\\xa2\\\\x90\\\\x90\\\\x96\\\\xbc\\\\xb1\\\\x1e\\\\xd4QER\\\\x13?\\\\xff\"}]\\n', 'writer = FileWriter(file_name=\"test.mindrecord\", shard_num=1, overwrite=True)\\n', 'writer.add_schema(schema_json, \"test_schema\")\\n', '\\n', 'writer.write_raw_data(data)\\n', '\\n', 'writer.commit()\\n', '\\n', 'write_append = FileWriter.open_for_append(\"test.mindrecord\")\\n', 'write_append.write_raw_data(data)\\n', '\\n', 'write_append.commit()\\n', '\\n', 'set_header_size(header_size)[source]\\n', 'Set the size of header which contains shard information, schema information, page meta information, etc. The larger a header, the more data the MindRecord file can store. If the size of header is larger than the default size (16MB), users need to call the API to set a proper size.\\n', '\\n', 'Parameters\\n', 'header_size (int) – Size of header, between 16*1024(16KB) and 128*1024*1024(128MB).\\n', '\\n', 'Returns\\n', 'MSRStatus, SUCCESS or FAILED.\\n', '\\n', 'Raises\\n', 'MRMInvalidHeaderSizeError – If failed to set header size.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.mindrecord import FileWriter\\n', 'writer = FileWriter(file_name=\"test.mindrecord\", shard_num=1)\\n', 'writer.set_header_size(1 << 25) # 32MB\\n', '\\n', 'set_page_size(page_size)[source]\\n', 'Set the size of page that represents the area where data is stored, and the areas are divided into two types: raw page and blob page. The larger a page, the more data the page can store. If the size of a sample is larger than the default size (32MB), users need to call the API to set a proper size.\\n', '\\n', 'Parameters\\n', 'page_size (int) – Size of page, between 32*1024(32KB) and 256*1024*1024(256MB).\\n', '\\n', 'Returns\\n', 'MSRStatus, SUCCESS or FAILED.\\n', '\\n', 'Raises\\n', 'MRMInvalidPageSizeError – If failed to set page size.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.mindrecord import FileWriter\\n', 'writer = FileWriter(file_name=\"test.mindrecord\", shard_num=1)\\n', 'writer.set_page_size(1 << 26) # 128MB\\n', '\\n', 'write_raw_data(raw_data, parallel_writer=False)[source]\\n', 'Convert raw data into a series of consecutive MindRecord files after the raw data is verified against the schema.\\n', '\\n', 'Note\\n', '\\n', 'Please refer to the Examples of class: mindspore.mindrecord.FileWriter.\\n', '\\n', 'Parameters\\n', 'raw_data (list[dict]) – List of raw data.\\n', '\\n', 'parallel_writer (bool, optional) – Write raw data in parallel if it equals to True. Default: False.\\n', '\\n', 'Returns\\n', 'MSRStatus, SUCCESS or FAILED.\\n', '\\n', 'Raises\\n', 'ParamTypeError – If index field is invalid.\\n', '\\n', 'MRMOpenError – If failed to open MindRecord file.\\n', '\\n', 'MRMValidateDataError – If data does not match blob fields.\\n', '\\n', 'MRMSetHeaderError – If failed to set header.\\n', '\\n', 'MRMWriteDatasetError – If failed to write dataset.\\n', '\\n', 'classmindspore.mindrecord.FileReader(file_name, num_consumer=4, columns=None, operator=None)[source]\\n', 'Class to read MindRecord files.\\n', '\\n', 'Note\\n', '\\n', 'If file_name is a filename string, it tries to load all MindRecord files generated in a conversion, and throws an exception if a MindRecord file is missing. If file_name is a filename list, only the MindRecord files in the list are loaded.\\n', '\\n', 'Parameters\\n', 'file_name (str, list[str]) – One of MindRecord file or a file list.\\n', '\\n', 'num_consumer (int, optional) – Number of reader workers which load data. Default: 4. It should not be smaller than 1 or larger than the number of processor cores.\\n', '\\n', 'columns (list[str], optional) – A list of fields where corresponding data would be read. Default: None.\\n', '\\n', 'operator (int, optional) – Reserved parameter for operators. Default: None.\\n', '\\n', 'Raises\\n', 'ParamValueError – If file_name, num_consumer or columns is invalid.\\n', '\\n', 'close()[source]\\n', 'Stop reader worker and close file.\\n', '\\n', 'get_next()[source]\\n', 'Yield a batch of data according to columns at a time.\\n', '\\n', 'Yields\\n', 'Dict – a batch whose keys are the same as columns.\\n', '\\n', 'Raises\\n', 'MRMUnsupportedSchemaError – If schema is invalid.\\n', '\\n', 'classmindspore.mindrecord.MindPage(file_name, num_consumer=4)[source]\\n', 'Class to read MindRecord files in pagination.\\n', '\\n', 'Parameters\\n', 'file_name (str) – One of MindRecord files or a file list.\\n', '\\n', 'num_consumer (int, optional) – The number of reader workers which load data. Default: 4. It should not be smaller than 1 or larger than the number of processor cores.\\n', '\\n', 'Raises\\n', 'ParamValueError – If file_name, num_consumer or columns is invalid.\\n', '\\n', 'MRMInitSegmentError – If failed to initialize ShardSegment.\\n', '\\n', 'propertycandidate_fields\\n', 'Return candidate category fields.\\n', '\\n', 'Returns\\n', 'list[str], by which data could be grouped.\\n', '\\n', 'propertycategory_field\\n', 'Getter function for category fields.\\n', '\\n', 'Returns\\n', 'list[str], by which data could be grouped.\\n', '\\n', 'get_category_fields()[source]\\n', 'Return candidate category fields.\\n', '\\n', 'Returns\\n', 'list[str], by which data could be grouped.\\n', '\\n', 'read_at_page_by_id(category_id, page, num_row)[source]\\n', 'Query by category id in pagination.\\n', '\\n', 'Parameters\\n', 'category_id (int) – Category id, referred to the return of read_category_info.\\n', '\\n', 'page (int) – Index of page.\\n', '\\n', 'num_row (int) – Number of rows in a page.\\n', '\\n', 'Returns\\n', 'list[dict], data queried by category id.\\n', '\\n', 'Raises\\n', 'ParamValueError – If any parameter is invalid.\\n', '\\n', 'MRMFetchDataError – If failed to fetch data by category.\\n', '\\n', 'MRMUnsupportedSchemaError – If schema is invalid.\\n', '\\n', 'read_at_page_by_name(category_name, page, num_row)[source]\\n', 'Query by category name in pagination.\\n', '\\n', 'Parameters\\n', 'category_name (str) – String of category field’s value, referred to the return of read_category_info.\\n', '\\n', 'page (int) – Index of page.\\n', '\\n', 'num_row (int) – Number of row in a page.\\n', '\\n', 'Returns\\n', 'list[dict], data queried by category name.\\n', '\\n', 'read_category_info()[source]\\n', 'Return category information when data is grouped by indicated category field.\\n', '\\n', 'Returns\\n', 'str, description of group information.\\n', '\\n', 'Raises\\n', 'MRMReadCategoryInfoError – If failed to read category information.\\n', '\\n', 'set_category_field(category_field)[source]\\n', 'Set category field for reading.\\n', '\\n', 'Note\\n', '\\n', 'Should be a candidate category field.\\n', '\\n', 'Parameters\\n', 'category_field (str) – String of category field name.\\n', '\\n', 'Returns\\n', 'MSRStatus, SUCCESS or FAILED.\\n', '\\n', 'classmindspore.mindrecord.Cifar10ToMR(source, destination)[source]\\n', 'A class to transform from cifar10 to MindRecord.\\n', '\\n', 'Note\\n', '\\n', 'For details about Examples, please refer to Converting the CIFAR-10 Dataset.\\n', '\\n', 'Parameters\\n', 'source (str) – the cifar10 directory to be transformed.\\n', '\\n', 'destination (str) – the MindRecord file path to transform into.\\n', '\\n', 'Raises\\n', 'ValueError – If source or destination is invalid.\\n', '\\n', 'run(fields=None)[source]\\n', 'Execute transformation from cifar10 to MindRecord.\\n', '\\n', 'Parameters\\n', 'fields (list[str], optional) – A list of index fields. Default: None.\\n', '\\n', 'Returns\\n', 'MSRStatus, whether cifar10 is successfully transformed to MindRecord.\\n', '\\n', 'transform(fields=None)[source]\\n', 'Encapsulate the run function to exit normally\\n', '\\n', 'Parameters\\n', 'fields (list[str], optional) – A list of index fields. Default: None.\\n', '\\n', 'Returns\\n', 'MSRStatus, whether cifar10 is successfully transformed to MindRecord.\\n', '\\n', 'classmindspore.mindrecord.Cifar100ToMR(source, destination)[source]\\n', 'A class to transform from cifar100 to MindRecord.\\n', '\\n', 'Note\\n', '\\n', 'For details about Examples, please refer to Converting the CIFAR-10 Dataset.\\n', '\\n', 'Parameters\\n', 'source (str) – the cifar100 directory to be transformed.\\n', '\\n', 'destination (str) – the MindRecord file path to transform into.\\n', '\\n', 'Raises\\n', 'ValueError – If source or destination is invalid.\\n', '\\n', 'run(fields=None)[source]\\n', 'Execute transformation from cifar100 to MindRecord.\\n', '\\n', 'Parameters\\n', 'fields (list[str]) – A list of index field, e.g.[“fine_label”, “coarse_label”]. Default: None.\\n', '\\n', 'Returns\\n', 'MSRStatus, whether cifar100 is successfully transformed to MindRecord.\\n', '\\n', 'transform(fields=None)[source]\\n', 'Encapsulate the run function to exit normally\\n', '\\n', 'Parameters\\n', 'fields (list[str]) – A list of index field, e.g.[“fine_label”, “coarse_label”]. Default: None.\\n', '\\n', 'Returns\\n', 'MSRStatus, whether cifar100 is successfully transformed to MindRecord.\\n', '\\n', 'classmindspore.mindrecord.CsvToMR(source, destination, columns_list=None, partition_number=1)[source]\\n', 'A class to transform from csv to MindRecord.\\n', '\\n', 'Note\\n', '\\n', 'For details about Examples, please refer to Converting CSV Dataset.\\n', '\\n', 'Parameters\\n', 'source (str) – the file path of csv.\\n', '\\n', 'destination (str) – the MindRecord file path to transform into.\\n', '\\n', 'columns_list (list[str], optional) – A list of columns to be read. Default: None.\\n', '\\n', 'partition_number (int, optional) – partition size, Default: 1.\\n', '\\n', 'Raises\\n', 'ValueError – If source, destination, partition_number is invalid.\\n', '\\n', 'RuntimeError – If columns_list is invalid.\\n', '\\n', 'run()[source]\\n', 'Execute transformation from csv to MindRecord.\\n', '\\n', 'Returns\\n', 'MSRStatus, whether csv is successfully transformed to MindRecord.\\n', '\\n', 'transform()[source]\\n', 'Encapsulate the run function to exit normally\\n', '\\n', 'classmindspore.mindrecord.ImageNetToMR(map_file, image_dir, destination, partition_number=1)[source]\\n', 'A class to transform from imagenet to MindRecord.\\n', '\\n', 'Note\\n', '\\n', 'For details about Examples, please refer to Converting the ImageNet Dataset.\\n', '\\n', 'Parameters\\n', 'map_file (str) –\\n', '\\n', 'the map file that indicates label. The map file content should be like this:\\n', '\\n', 'n02119789 0\\n', 'n02100735 1\\n', 'n02110185 2\\n', 'n02096294 3\\n', 'image_dir (str) – image directory contains n02119789, n02100735, n02110185 and n02096294 directory.\\n', '\\n', 'destination (str) – the MindRecord file path to transform into.\\n', '\\n', 'partition_number (int, optional) – partition size. Default: 1.\\n', '\\n', 'Raises\\n', 'ValueError – If map_file, image_dir or destination is invalid.\\n', '\\n', 'run()[source]\\n', 'Execute transformation from imagenet to MindRecord.\\n', '\\n', 'Returns\\n', 'MSRStatus, whether imagenet is successfully transformed to MindRecord.\\n', '\\n', 'transform()[source]\\n', 'Encapsulate the run function to exit normally\\n', '\\n', 'classmindspore.mindrecord.MnistToMR(source, destination, partition_number=1)[source]\\n', 'A class to transform from Mnist to MindRecord.\\n', '\\n', 'Parameters\\n', 'source (str) – directory that contains t10k-images-idx3-ubyte.gz, train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz and train-labels-idx1-ubyte.gz.\\n', '\\n', 'destination (str) – the MindRecord file directory to transform into.\\n', '\\n', 'partition_number (int, optional) – partition size. Default: 1.\\n', '\\n', 'Raises\\n', 'ValueError – If source, destination, partition_number is invalid.\\n', '\\n', 'run()[source]\\n', 'Execute transformation from Mnist to MindRecord.\\n', '\\n', 'Returns\\n', 'MSRStatus, whether successfully written into MindRecord.\\n', '\\n', 'transform()[source]\\n', 'Encapsulate the run function to exit normally\\n', '\\n', 'classmindspore.mindrecord.TFRecordToMR(source, destination, feature_dict, bytes_fields=None)[source]\\n', 'A class to transform from TFRecord to MindRecord.\\n', '\\n', 'Note\\n', '\\n', 'For details about Examples, please refer to Converting TFRecord Dataset.\\n', '\\n', 'Parameters\\n', 'source (str) – the TFRecord file to be transformed.\\n', '\\n', 'destination (str) – the MindRecord file path to transform into.\\n', '\\n', 'feature_dict (dict) – a dictionary that states the feature type, and VarLenFeature is not supported.\\n', '\\n', 'bytes_fields (list, optional) – the bytes fields which are in feature_dict and can be images bytes. Default: None.\\n', '\\n', 'Raises\\n', 'ValueError – If parameter is invalid.\\n', '\\n', 'Exception – when tensorflow module is not found or version is not correct.\\n', '\\n', 'run()[source]\\n', 'Execute transformation from TFRecord to MindRecord.\\n', '\\n', 'Returns\\n', 'MSRStatus, whether TFRecord is successfully transformed to MindRecord.\\n', '\\n', 'tfrecord_iterator()[source]\\n', 'Yield a dictionary whose keys are fields in schema.\\n', '\\n', 'Yields\\n', 'dict, data dictionary whose keys are the same as columns.\\n', '\\n', 'tfrecord_iterator_oldversion()[source]\\n', 'Yield a dict with key to be fields in schema, and value to be data. This function is for old version tensorflow whose version number < 2.1.0\\n', '\\n', 'Yields\\n', 'dict, data dictionary whose keys are the same as columns.\\n', '\\n', 'transform()[source]\\n', 'Encapsulate the run function to exit normally']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.nn.probability.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.nn.probability.html", "text_entry": "['mindspore.nn.probability\\n', 'Bijectors\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.probability.bijector.Bijector\\n', '\\n', 'Bijecotr class.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.Exp\\n', '\\n', 'Exponential Bijector.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.GumbelCDF\\n', '\\n', 'GumbelCDF Bijector.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.Invert\\n', '\\n', 'Invert Bijector.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.PowerTransform\\n', '\\n', 'PowerTransform Bijector.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.ScalarAffine\\n', '\\n', 'Scalar Affine Bijector.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.bijector.Softplus\\n', '\\n', 'Softplus Bijector.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'Distributions\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.probability.distribution.Bernoulli\\n', '\\n', 'Bernoulli Distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Beta\\n', '\\n', 'Beta distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.probability.distribution.Categorical\\n', '\\n', 'Categorical distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Cauchy\\n', '\\n', 'Cauchy distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.probability.distribution.Distribution\\n', '\\n', 'Base class for all mathematical distributions.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Exponential\\n', '\\n', 'Exponential Distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Gamma\\n', '\\n', 'Gamma distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.probability.distribution.Geometric\\n', '\\n', 'Geometric Distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Gumbel\\n', '\\n', 'Gumbel distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Logistic\\n', '\\n', 'Logistic distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.LogNormal\\n', '\\n', 'LogNormal distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Normal\\n', '\\n', 'Normal distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Poisson\\n', '\\n', 'Poisson Distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.probability.distribution.TransformedDistribution\\n', '\\n', 'Transformed Distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.probability.distribution.Uniform\\n', '\\n', 'Uniform Distribution.\\n', '\\n', 'Ascend GPU']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.nn.transformer.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.nn.transformer.html", "text_entry": "['mindspore.nn.transformer\\n', 'Note\\n', '\\n', 'Transformer Networks. This is an experimental interface that is subject to change or deletion.\\n', '\\n', 'classmindspore.nn.transformer.AttentionMask(seq_length, parallel_config=default_dpmp_config)[source]\\n', 'Get the Lower triangular matrix from the input mask. The input mask is a 2D tensor (batch_size, seq_length) with 1 and 0, where 1 indicates the current position is a valid token, otherwise not.\\n', '\\n', 'Parameters\\n', 'seq_length (int) – The sequence length of the input tensor.\\n', '\\n', 'parallel_config (OpParallelConfig) – The parallel configure. Default default_dpmp_config, an instance of OpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'input_mask (Tensor) - The mask indicating whether each position is a valid input with (batch_size, seq_length).\\n', '\\n', 'Outputs:\\n', 'Tensor. The attention mask matrix with shape (batch_size, seq_length, seq_length).\\n', '\\n', 'Raises\\n', 'TypeError – seq_length is not an integer.\\n', '\\n', 'ValueError – seq_length is not a positive value.\\n', '\\n', 'TypeError – parallel_config is not a subclass of OpParallelConfig.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore.nn.transformer import AttentionMask\\n', 'from mindspore import Tensor\\n', 'mask = AttentionMask(seq_length=4)\\n', 'mask_array = np.array([[1, 1, 1, 0]], np.float32)\\n', 'inputs = Tensor(mask_array)\\n', 'res = mask(inputs)\\n', 'print(res)\\n', '\\n', '\\n', '\\n', '\\n', 'classmindspore.nn.transformer.VocabEmbedding(vocab_size, embedding_size, parallel_config=default_embedding_parallel_config, param_init=\"normal\")[source]\\n', 'The embedding lookup table from the 0-th dim of the parameter table. When the parallel_config.vocab_emb_dp is True and in the AUTO_PARALLEL mode, the embedding lookup will be trained by the data parallel way, as the parameters will be repeated on each device. If false, the embedding table will be sharded into n parts at the 0-th dimension of the embedding table, where the n is the model parallel way determined by the parallel_config(EmbeddingOpParallelConfig).\\n', '\\n', 'Note\\n', '\\n', 'When AUTO_PARALLEL mode is enabled, this layer support only 2-d dimension inputs, as the shard is designed for 2d inputs.\\n', '\\n', 'Parameters\\n', 'vocab_size – (int): Size of the dictionary of embeddings.\\n', '\\n', 'embedding_size – (int): The size of each embedding vector.\\n', '\\n', 'parallel_config (EmbeddingOpParallelConfig) – The parallel config of network. Default default_embedding_parallel_config, an instance of EmbeddingOpParallelConfig with default args.\\n', '\\n', 'param_init – (Union[Tensor, str, Initializer, numbers.Number]): Initializer for the embedding_table. Refer to class initializer for the values of string when a string is specified. Default: ‘normal’.\\n', '\\n', 'Inputs:\\n', 'input_ids (Tensor) - The tokenized inputs with datatype int32 with shape (batch_size, seq_length)\\n', '\\n', 'Outputs:\\n', 'Tuple, a tuple contains (output, embedding_table)\\n', '\\n', 'output (Tensor) - The embedding vector for the input with shape (batch_size, seq_length, embedding_size).\\n', '\\n', 'embedding_table (Tensor) - The embedding table with shape (vocab_size, embedding_size).\\n', '\\n', 'Raises\\n', 'ValueError – If the parallel_config.vocab_emb_dp is True, the vocab size is not a multiple of parallel_config.model_parallel\\n', '\\n', 'ValueError – vocab_size is not a positive value.\\n', '\\n', 'ValueError – embedding_size is not a positive value.\\n', '\\n', 'TypeError – parallel_config is not a subclass of OpParallelConfig.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore.nn.transformer import VocabEmbedding\\n', 'from mindspore import Tensor\\n', 'from mindspore import dtype as mstype\\n', 'model = VocabEmbedding(vocab_size=30, embedding_size=30)\\n', 'tensor = Tensor(np.ones((20, 15)), mstype.int32)\\n', 'output, table = model(tensor)\\n', 'print(output.shape)\\n', '\\n', 'print(table.shape)\\n', '\\n', 'classmindspore.nn.transformer.MultiHeadAttention(batch_size, src_seq_length, tgt_seq_length, hidden_size, num_heads, hidden_dropout_rate=0.1, attention_dropout_rate=0.1, compute_dtype=mstype.float16, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, use_past=False, parallel_config=default_dpmp_config)[source]\\n', 'This is an implementation of multihead attention in the paper Attention is all you need. Given the query vector with source length, and the key and value vector with target length, the attention will be performed as the following\\n', '\\n', 'MultiHeadAttention(query,key,vector)=Concat(head1,…,headh)WO\\n', 'where headi=Attention(QWQi,KWKi,VWVi). The default is with a bias.\\n', '\\n', 'if query, key and value tensor is same, then it will be self attention.\\n', '\\n', 'Parameters\\n', 'batch_size (int) – The batch size of the input tensor.\\n', '\\n', 'src_seq_length (int) – The sequence length of the query vector.\\n', '\\n', 'tgt_seq_length (int) – The sequence length of the key and value vector.\\n', '\\n', 'hidden_size (int) – The hidden size of the input.\\n', '\\n', 'num_heads (int) – The number of the heads.\\n', '\\n', 'hidden_dropout_rate (float) – The dropout rate of the final output of the layer. Default:0.1.\\n', '\\n', 'attention_dropout_rate (float) – The dropout rate of the attention scores. Default:0.1.\\n', '\\n', 'compute_dtype (dtype.Number) – The computation type of dense. Default dtype.float16. Should be dtype.float32 or dtype.float16.\\n', '\\n', 'softmax_compute_type (dtype.Number) – The type of softmax computation module. Default dtype.float32. Should be dtype.float32 or dtype.float16.\\n', '\\n', 'param_init_type (dtype.Number) – The parameter initialization type of the module. Default dtype.float32. Should be dtype.float32 or dtype.float16.\\n', '\\n', 'use_past (bool) – Use the past state to compute, used for incremental prediction. For example, if we have two words and want to generate the ten more words. We just need to compute the two words’ state only once, and generate the next word one by one. When use_past is True, there are two steps to run the prediction. In the first step, set the is_first_iteration to be True by model.add_flags_recursive(is_first_iteration=True), and pass the full inputs. Then, set the is_first_iteration to be False by model.add_flags_recursive(is_first_iteration=False). At this moment, pass the single step’s input tensor, and loop it. Default False.\\n', '\\n', 'parallel_config (OpParallelConfig) – The parallel configure. Default default_dpmp_config, an instance of OpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'query_tensor (Tensor) - The query vector with shape (batch_size, src_seq_length, hidden_size) or (batch_size * src_seq_length, hidden_size), if the use_past is False or is_first_iteration=True. Otherwise, must be (batch_size, 1, hidden_size)\\n', '\\n', 'key_tensor (Tensor) - The key vector with shape (batch_size, tgt_seq_length, hidden_size) or (batch_size * tgt_seq_length, hidden_size), if the use_past is False or is_first_iteration=True. Otherwise, must be (batch_size, 1, hidden_size)\\n', '\\n', 'value_tensor (Tensor) - The value vector with shape (batch_size, tgt_seq_length, hidden_size) or (batch_size * tgt_seq_length, hidden_size), if the use_past is False or is_first_iteration=True. Otherwise, must be (batch_size, 1, hidden_size)\\n', '\\n', 'attention_mask (Tensor) - The attention mask matrix with shape (batch_size, src_seq_length, tgt_seq_length), if the use_past is False or is_first_iteration=True. Otherwise, must be (batch_size, 1, tgt_seq_length)\\n', '\\n', 'key_past (Tensor) - Float16 tensor with shape (batch_size, num_heads, size_per_head, tgt_seq_length). The past calculated key vector. Used for incremental prediction when the use_past is True. Default None.\\n', '\\n', 'value_past (Tensor) - Float16 tensor with shape (batch_size, num_heads, tgt_seq_length, size_per_head). The past calculated value vector. Used for incremental prediction when the use_past is True. Default None.\\n', '\\n', 'batch_valid_length (Tensor) - Int32 tensor with shape (batch_size,) the past calculated the index. Used for incremental prediction when the use_past is True. Default None.\\n', '\\n', 'Outputs:\\n', 'Tuple, a tuple contains(output, layer_present)\\n', '\\n', 'output (Tensor) - Tensor, the float tensor of the output of the layer with shape (batch_size, src_seq_length, hidden_size) or (batch_size * src_seq_length, hidden_size), if the use_past is False or is_first_iteration=True. Otherwise, it will be (batch_size, 1, hidden_size).\\n', '\\n', 'layer_present (Tuple) - A tuple of the Tensor of the projected key and value vector with ((batch_size, num_heads, size_per_head, tgt_seq_length), (batch_size, num_heads, tgt_seq_length, size_per_head)).\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore.nn.transformer import MultiHeadAttention\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore import Tensor\\n', 'model = MultiHeadAttention(batch_size=2, hidden_size=15, src_seq_length=20, tgt_seq_length=20,\\n', '                           num_heads=3)\\n', 'from_tensor = Tensor(np.ones((2, 20, 15)), mstype.float32)\\n', 'to_tensor = Tensor(np.ones((2, 20, 15)), mstype.float16)\\n', 'attention_mask = Tensor(np.ones((2, 20, 20)), mstype.float16)\\n', 'attn_out, past = model(from_tensor, to_tensor, to_tensor, attention_mask)\\n', 'print(attn_out.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', '# When use use_past=True, it includes two steps to implement the incremental prediction.\\n', \"# Step 1: set is_first_iteration=True, and input the full sequence length's state.\\n\", '# We need to prepare the memory parameters for saving key and value states firstly.\\n', 'model = MultiHeadAttention(batch_size=2, hidden_size=15, src_seq_length=20, tgt_seq_length=20,\\n', '                           num_heads=3, use_past=True)\\n', 'key_past = Tensor(np.zeros(shape=(2, 3, 5, 20)), mstype.float16)\\n', 'value_past = Tensor(np.zeros(shape=(2, 3, 20, 5)), mstype.float16)\\n', 'batch_valid_length = Tensor(np.ones((2,)), mstype.int32)\\n', '# Set is_first_iteration=True to generate the full memory states\\n', 'model.add_flags_recursive(is_first_iteration=True)\\n', 'attn_out, past = model(from_tensor, to_tensor, to_tensor, attention_mask, key_past, value_past,\\n', '                       batch_valid_length)\\n', 'print(attn_out.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'from_tensor = Tensor(np.ones((2, 1, 15)), mstype.float32)\\n', 'to_tensor = Tensor(np.ones((2, 1, 15)), mstype.float16)\\n', 'attention_mask = Tensor(np.ones((2, 1, 20)), mstype.float16)\\n', '# Step 2: set is_first_iteration=False, and pass the single word to run the prediction rather than the full\\n', '# sequence.\\n', 'model.add_flags_recursive(is_first_iteration=False)\\n', 'attn_out, past = model(from_tensor, to_tensor, to_tensor, attention_mask, key_past, value_past,\\n', '                       batch_valid_length)\\n', 'print(attn_out.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'classmindspore.nn.transformer.FeedForward(hidden_size, ffn_hidden_size, dropout_rate, hidden_act=\"gelu\", expert_num=1, param_init_type=mstype.float32, parallel_config=default_dpmp_config)[source]\\n', 'The multilayer perceptron with two linear layers with dropout applied at final output. The first linear will project the input dimension from hidden_size to ffn_hidden_size, the second linear will project the dimension from ffn_hidden_size to hidden_size. The first linear is sharded on the relative dimension, the second linear is sharded on the output dimension. The overview process can be\\n', '\\n', 'Dropout((xW1+b1)W2+b2))\\n', 'where the W1,W2,b1 and b2 are trainable parameters.\\n', '\\n', 'Parameters\\n', 'hidden_size – (int): The dimension of the inputs.\\n', '\\n', 'ffn_hidden_size – (int): The intermediate hidden size.\\n', '\\n', 'dropout_rate – (float): The dropout rate for the second linear’s output.\\n', '\\n', 'hidden_act – (str): The activation of the internal feedforward layer. Supports ‘relu’, ‘relu6’, ‘tanh’, ‘gelu’, ‘fast_gelu’, ‘elu’, ‘sigmoid’, ‘prelu’, ‘leakyrelu’, ‘hswish’, ‘hsigmoid’, ‘logsigmoid’ and so on. Default: gelu.\\n', '\\n', 'expert_num – (int): The number of experts used in Linear. For the case expert_num > 1, BatchMatMul is used and the first dimension in BatchMatMul indicate expert_num. Default: 1.\\n', '\\n', 'param_init_type – (dtype.Number): The parameter initialization type. Should be dtype.float32 or dtype.float16. Default: dtype.float32.\\n', '\\n', 'parallel_config (OpParallelConfig) – The config of parallel setting, see OpParallelConfig. Default default_dpmp_config, an instance of OpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'x (Tensor) - should be [batch, seq_length, hidden_size] or [batch * seq_length, hidden_size]. Float tensor.\\n', '\\n', 'Outputs:\\n', 'Tensor, the output of this layer after mapping. The shape is [batch, seq_length, hidden_size] or [batch * seq_length, hidden_size].\\n', '\\n', 'Raises\\n', 'ValueError – hidden_act is not a string.\\n', '\\n', 'TypeError – parallel_config is not a subclass of OpParallelConfig.\\n', '\\n', 'ValueError – ffn_hidden_size is not a multiple of the model parallel way.\\n', '\\n', 'ValueError – hidden_size is not a multiple of the model parallel way.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore.nn.transformer import FeedForward\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore import Tensor\\n', 'model = FeedForward(hidden_size=15, ffn_hidden_size=30, dropout_rate=0.1)\\n', 'tensor = Tensor(np.ones((2, 20, 15)), mstype.float32)\\n', 'output = model(tensor)\\n', 'print(output.shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerEncoder(batch_size, num_layers, hidden_size, ffn_hidden_size, seq_length, num_heads, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, hidden_act=\"gelu\", post_layernorm_residual=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, lambda_func=None, offset=0, use_past=False, moe_config=default_moe_config, parallel_config=default_transformer_config)[source]\\n', 'Transformer Encoder module with multi-layer stacked of TransformerEncoderLayer, including multihead self attention and feedforward layer.\\n', '\\n', 'Parameters\\n', 'batch_size (int) – The batch size of the input tensor.\\n', '\\n', 'num_layers (int) – The layers of the TransformerEncoderLayer\\n', '\\n', 'hidden_size (int) – The hidden size of the input.\\n', '\\n', 'ffn_hidden_size (int) – The hidden size of bottleneck in the feedforward layer.\\n', '\\n', 'seq_length (int) – The seq_length of the input tensor.\\n', '\\n', 'num_heads (int) – The number of the heads.\\n', '\\n', 'attention_dropout_rate (float) – The dropout rate of the attention scores. Default:0.1.\\n', '\\n', 'hidden_dropout_rate (float) – The dropout rate of the final output of the layer. Default:0.1.\\n', '\\n', 'hidden_act (str) – The activation of the internal feedforward layer. Supports ‘relu’, ‘relu6’, ‘tanh’, ‘gelu’, ‘fast_gelu’, ‘elu’, ‘sigmoid’, ‘prelu’, ‘leakyrelu’, ‘hswish’, ‘hsigmoid’, ‘logsigmoid’ and so on. Default: gelu.\\n', '\\n', 'post_layernorm_residual (bool) – Do residuals adds before the layernorm. Default False.\\n', '\\n', 'layernorm_compute_type (dtype.Number) – The computation type of the layernorm. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'softmax_compute_type (dtype.Number) – The computation type of the softmax in the attention. Should be dtype.float32 or dtype.float16. Default mstype.float32.\\n', '\\n', 'param_init_type (dtype.Number) – The parameter initialization type of the module. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'lambda_func – A function can determine the fusion index, pipeline stages and recompute attribute. If the user wants to determine the pipeline stage and gradient aggregation fusion, the user can pass a function that accepts network, layer_id, offset, parallel_config, layers. The network(Cell) represents the transformer block, layer_id(int) means the layer index for the current module, counts from zero, offset(int) means the layer_index needs an offset, if there are other modules in the net. The default setting for the pipeline is: (layer_id + offset) // (layers / pipeline_stage). Default None.\\n', '\\n', 'offset (int) – The initial layer index for the encoder. Used for setting the fusion id and stage id, to not overlap with the encoder layer. Default 0.\\n', '\\n', 'use_past (bool) – Use the past state to compute, used for incremental prediction. For example, if we have two words and want to generate the ten more words. We just need to compute the two words’ state only once, and generate the next word one by one. When use_past is True, there are two steps to run the prediction. In the first step, set the is_first_iteration to be True by model.add_flags_recursive(is_first_iteration=True), and pass the full inputs. Then, set the is_first_iteration to be False by model.add_flags_recursive(is_first_iteration=False). At this moment, pass the single step’s input tensor, and loop it. Default False.\\n', '\\n', 'moe_config (MoEConfig) – The configuration of MoE (Mixture of Expert). Default is an instance of MoEConfig with default values. Please see MoEConfig.\\n', '\\n', 'parallel_config (TransformerOpParallelConfig) – The parallel configure. Default default_transformer_config, an instance of TransformerOpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'hidden_states (Tensor) - Tensor, shape should be [batch_size, seq_length, hidden_size] or [batch_size * seq_length, hidden_size], if the use_past is False or is_first_iteration=True. Otherwise, should be [batch_size, 1, hidden_size].\\n', '\\n', 'attention_mask (Tensor) - Tensor, attention mask with shape [batch_size, seq_length, seq_length]\\n', '\\n', 'init_reset (Tensor) - A bool tensor with shape [1], used to clear the past key parameter and past value parameter used in the incremental prediction. Only valid when use_past is True. Default True.\\n', '\\n', 'batch_valid_length (Tensor) - Int32 tensor with shape [batch_size] the past calculated the index. Used for incremental prediction when the use_past is True. Default None.\\n', '\\n', 'Outputs:\\n', 'Tuple, a tuple contains(output, layer_present)\\n', '\\n', 'output (Tensor) - The float tensor of the output of the layer with shape (batch_size, seq_length, hidden_size) or (batch_size * seq_length, hidden_size), if the use_past is False or is_first_iteration=True. Otherwise, it will be (batch_size, 1, hidden_size).\\n', '\\n', 'layer_present (Tuple) - A tuple with size of num_layers, where each tuple contains the Tensor the projected key and value vector with shape ((batch_size, num_heads, size_per_head, seq_length), and (batch_size, num_heads, seq_length, size_per_head)).\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import TransformerEncoder\\n', 'from mindspore import Tensor\\n', 'model = TransformerEncoder(batch_size=2, num_layers=2, hidden_size=8, ffn_hidden_size=64, seq_length=16,\\n', '                           num_heads=2)\\n', 'encoder_input_value = Tensor(np.ones((2, 16, 8)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 16, 16)), mstype.float16)\\n', 'output, past = model(encoder_input_value, encoder_input_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(len(past))\\n', '\\n', 'print(past[0][0].shape)\\n', '\\n', 'print(past[0][1].shape)\\n', '\\n', '# When use use_past=True, it includes two steps to implement the incremental prediction.\\n', \"# Step 1: set is_first_iteration=True, and input the full sequence length's state.\\n\", 'batch_valid_length = Tensor(np.ones((2,)), mstype.int32)\\n', 'init_reset = Tensor([True], mstype.bool_)\\n', '# Set is_first_iteration=True to generate the full memory states\\n', 'model = TransformerEncoder(batch_size=2, hidden_size=8, ffn_hidden_size=64, seq_length=16,\\n', '                           num_heads=2, num_layers=2, use_past=True)\\n', 'model.add_flags_recursive(is_first_iteration=True)\\n', 'hidden, past = model(encoder_input_value, encoder_input_mask, init_reset, batch_valid_length)\\n', 'print(hidden.shape)\\n', '\\n', 'print(past[0][0].shape)\\n', '\\n', 'print(past[0][1].shape)\\n', '\\n', 'encoder_input_value = Tensor(np.ones((2, 1, 8)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 1, 16)), mstype.float16)\\n', 'init_reset = Tensor([False], mstype.bool_)\\n', '# Step 2: set is_first_iteration=False, and pass the single word to run the prediction rather than the full\\n', '# sequence.\\n', 'model.add_flags_recursive(is_first_iteration=False)\\n', 'hidden, past = model(encoder_input_value, encoder_input_mask, init_reset, batch_valid_length)\\n', 'print(hidden.shape)\\n', '\\n', 'print(past[0][0].shape)\\n', '\\n', 'print(past[0][1].shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerDecoder(num_layers, batch_size, hidden_size, ffn_hidden_size, src_seq_length, tgt_seq_length, num_heads, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, post_layernorm_residual=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, hidden_act=\"gelu\", lambda_func=None, use_past=False, offset=0, moe_config=default_moe_config, parallel_config=default_transformer_config)[source]\\n', 'Transformer Decoder module with multi-layer stacked of TransformerDecoderLayer, including multihead self attention, cross attention and feedforward layer.\\n', '\\n', 'Parameters\\n', 'num_layers (int) – The layers of the TransformerDecoderLayer.\\n', '\\n', 'batch_size (int) – The batch size of the input tensor.\\n', '\\n', 'hidden_size (int) – The hidden size of the input.\\n', '\\n', 'ffn_hidden_size (int) – The hidden size of bottleneck in the feedforward layer.\\n', '\\n', 'src_seq_length (int) – The input source sequence length.\\n', '\\n', 'tgt_seq_length (int) – The input target sequence length.\\n', '\\n', 'num_heads (int) – The number of the heads.\\n', '\\n', 'attention_dropout_rate (float) – The dropout rate of the attention scores. Default:0.1.\\n', '\\n', 'hidden_dropout_rate (float) – The dropout rate of the final output of the layer. Default:0.1.\\n', '\\n', 'post_layernorm_residual (bool) – Do residuals adds before the layernorm. Default False.\\n', '\\n', 'layernorm_compute_type (dtype.Number) – The computation type of the layernorm. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'softmax_compute_type (dtype.Number) – The computation type of the softmax in the attention. Should be dtype.float32 or dtype.float16. Default mstype.float32.\\n', '\\n', 'param_init_type (dtype.Number) – The parameter initialization type of the module. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'hidden_act (str) – The activation of the internal feedforward layer. Supports ‘relu’, ‘relu6’, ‘tanh’, ‘gelu’, ‘fast_gelu’, ‘elu’, ‘sigmoid’, ‘prelu’, ‘leakyrelu’, ‘hswish’, ‘hsigmoid’, ‘logsigmoid’ and so on. Default: gelu.\\n', '\\n', 'lambda_func – A function can determine the fusion index, pipeline stages and recompute attribute. If the user wants to determine the pipeline stage and gradient aggregation fusion, the user can pass a function that accepts network, layer_id, offset, parallel_config, layers. The network(Cell) represents the transformer block, layer_id(int) means the layer index for the current module, counts from zero, offset(int) means the layer_index needs an offset, if there are other modules in the net. The default setting for the pipeline is: (layer_id + offset) // (layers / pipeline_stage). Default: None.\\n', '\\n', 'use_past (bool) – Use the past state to compute, used for incremental prediction. Default False.\\n', '\\n', 'offset (int) – The initial layer index for the decoder. Used for setting the fusion id and stage id, to not overlap with the encoder layer. Default 0.\\n', '\\n', 'moe_config (MoEConfig) – The configuration of MoE (Mixture of Expert). Default is an instance of MoEConfig with default values. Please see MoEConfig.\\n', '\\n', 'parallel_config (TransformerOpParallelConfig) – The parallel configure. Default default_transformer_config, an instance of TransformerOpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'hidden_stats (Tensor) - The input tensor with shape [batch_size, seq_length, hidden_size] or [batch_size * seq_length, hidden_size]\\n', '\\n', 'attention_mask (Tensor) - The attention mask for decoder with shape [batch_size, seq_length, seq_length]\\n', '\\n', 'encoder_output (Tensor) - The output of the encoder with shape [batch_size, seq_length, hidden_size] or [batch_size * seq_length, hidden_size]. Note this args can not be passed by None when the net is in outermost layer. Default None.\\n', '\\n', 'memory_mask (Tensor) - The memory mask of the cross attention with shape [batch, tgt_seq_length, src_seq_length] where tgt_seq_length is the length of the decoder. Note this args can not be passed by None when the net is in outermost layer. Default None.\\n', '\\n', 'init_reset (Tensor) - A bool tensor with shape [1], used to clear the past key parameter and past value parameter used in the incremental prediction. Only valid when use_past is True. Default True.\\n', '\\n', 'batch_valid_length (Tensor) - Int32 tensor with shape [batch_size] the past calculated the index. Used for incremental prediction when the use_past is True. Default None.\\n', '\\n', 'Outputs:\\n', 'Tuple, a tuple contains(output, layer_present)\\n', '\\n', 'output (Tensor) - The output logit of this layer. The shape is [batch, tgt_seq_length, hidden_size] or [batch * tgt_seq_length, hidden_size]\\n', '\\n', 'layer_present (Tuple) - A tuple with size of num_layers, where each tuple is the tensor of the projected key and value vector in self attention with shape ((batch_size, num_heads, size_per_head, tgt_seq_length), (batch_size, num_heads, tgt_seq_length, size_per_head), and of the projected key and value vector in cross attention with shape (batch_size, num_heads, size_per_head, src_seq_length), (batch_size, num_heads, src_seq_length, size_per_head)).\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import TransformerDecoder\\n', 'from mindspore import Tensor\\n', 'model = TransformerDecoder(batch_size=2, num_layers=1, hidden_size=64, ffn_hidden_size=64,\\n', '                           num_heads=2, src_seq_length=20, tgt_seq_length=10)\\n', 'encoder_input_value = Tensor(np.ones((2, 20, 64)), mstype.float32)\\n', 'decoder_input_value = Tensor(np.ones((2, 10, 64)), mstype.float32)\\n', 'decoder_input_mask = Tensor(np.ones((2, 10, 10)), mstype.float16)\\n', 'memory_mask = Tensor(np.ones((2, 10, 20)), mstype.float16)\\n', 'output, past = model(decoder_input_value, decoder_input_mask, encoder_input_value, memory_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(len(past))\\n', '\\n', 'print(past[0][0].shape)\\n', '\\n', 'print(past[0][1].shape)\\n', '\\n', 'print(past[0][2].shape)\\n', '\\n', 'print(past[0][3].shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerEncoderLayer(batch_size, hidden_size, ffn_hidden_size, num_heads, seq_length, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, post_layernorm_residual=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, hidden_act=\"gelu\", use_past=False, moe_config=default_moe_config, parallel_config=default_dpmp_config)[source]\\n', 'Transformer Encoder Layer. This is an implementation of the single layer of the transformer encoder layer, including multihead attention and feedward layer.\\n', '\\n', 'Parameters\\n', 'batch_size (int) – The batch size of the input tensor.\\n', '\\n', 'hidden_size (int) – The hidden size of the input.\\n', '\\n', 'ffn_hidden_size (int) – The hidden size of bottleneck in the feedforward layer.\\n', '\\n', 'num_heads (int) – The number of the heads.\\n', '\\n', 'seq_length (int) – The input sequence length.\\n', '\\n', 'attention_dropout_rate (float) – The dropout rate of the attention scores. Default:0.1.\\n', '\\n', 'hidden_dropout_rate (float) – The dropout rate of the final output of the layer. Default:0.1.\\n', '\\n', 'post_layernorm_residual (bool) – Do residuals adds before the layernorm. Default False.\\n', '\\n', 'layernorm_compute_type (dtype.Number) – The computation type of the layernorm. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'softmax_compute_type (dtype.Number) – The computation type of the softmax in the attention. Should be dtype.float32 or dtype.float16. Default mstype.float32.\\n', '\\n', 'param_init_type (dtype.Number) – The parameter initialization type of the module. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'hidden_act (str) – The activation of the internal feedforward layer. Supports ‘relu’, ‘relu6’, ‘tanh’, ‘gelu’, ‘fast_gelu’, ‘elu’, ‘sigmoid’, ‘prelu’, ‘leakyrelu’, ‘hswish’, ‘hsigmoid’, ‘logsigmoid’ and so on. Default: gelu.\\n', '\\n', 'use_past (bool) – Use the past state to compute, used for incremental prediction. For example, if we have two words and want to generate the ten more words. We just need to compute the two words’ state only once, and generate the next word one by one. When use_past is True, there are two steps to run the prediction. In the first step, set the is_first_iteration to be True by model.add_flags_recursive(is_first_iteration=True), and pass the full inputs. Then, set the is_first_iteration to be False by model.add_flags_recursive(is_first_iteration=False). At this moment, pass the single step’s input tensor, and loop it. Default False.\\n', '\\n', 'moe_config (MoEConfig) – The configuration of MoE (Mixture of Expert). Default is an instance of MoEConfig with default values. Please see MoEConfig.\\n', '\\n', 'parallel_config (OpParallelConfig) – The parallel configure. Default default_dpmp_config, an instance of OpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'x (Tensor) - Float Tensor, shape should be [batch_size, seq_length, hidden_size] or [batch_size * seq_length, hidden_size], if the use_past is False or is_first_iteration=True. Otherwise, should be [batch_size, 1, hidden_size]\\n', '\\n', 'input_mask (Tensor) - Float Tensor, attention mask with shape [batch_size, seq_length, seq_length], if the use_past is False or is_first_iteration=True. Otherwise, should be [batch_size, 1, hidden_size]\\n', '\\n', 'init_reset (Tensor) - A bool tensor with shape [1], used to clear the past key parameter and past value parameter used in the incremental prediction. Only valid when use_past is True. Default True.\\n', '\\n', 'batch_valid_length (Tensor) - Int32 tensor with shape [batch_size] the past calculated the index. Used for incremental prediction when the use_past is True. Default None.\\n', '\\n', 'Outputs:\\n', 'Tuple, a tuple contains(output, layer_present).\\n', '\\n', 'output (Tensor) - The float tensor of the output of the layer with shape (batch_size, seq_length, hidden_size) or (batch_size * seq_length, hidden_size), if the use_past is False or is_first_iteration=True. Otherwise, it will be (batch_size, 1, hidden_size)\\n', '\\n', 'layer_present (Tuple) - A tuple of the Tensor of the projected key and value vector with ((batch_size, num_heads, size_per_head, seq_length), (batch_size, num_heads, seq_length, size_per_head)).\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import TransformerEncoderLayer\\n', 'from mindspore import Tensor\\n', 'model = TransformerEncoderLayer(batch_size=2, hidden_size=8, ffn_hidden_size=64, seq_length=16,\\n', '                                num_heads=2)\\n', 'encoder_input_value = Tensor(np.ones((2, 16, 8)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 16, 16)), mstype.float16)\\n', 'output, past = model(encoder_input_value, encoder_input_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', '# When use use_past=True, it includes two steps to implement the incremental prediction.\\n', \"# Step 1: set is_first_iteration=True, and input the full sequence length's state.\\n\", 'batch_valid_length = Tensor(np.ones((2,)), mstype.int32)\\n', 'init_reset = Tensor([True], mstype.bool_)\\n', '# Set is_first_iteration=True to generate the full memory states\\n', 'model = TransformerEncoderLayer(batch_size=2, hidden_size=8, ffn_hidden_size=64, seq_length=16,\\n', '                                num_heads=2, use_past=True)\\n', 'model.add_flags_recursive(is_first_iteration=True)\\n', 'hidden, past = model(encoder_input_value, encoder_input_mask, init_reset, batch_valid_length)\\n', 'print(hidden.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'encoder_input_value = Tensor(np.ones((2, 1, 8)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 1, 16)), mstype.float16)\\n', 'init_reset = Tensor([False], mstype.bool_)\\n', '# Step 2: set is_first_iteration=False, and pass the single word to run the prediction rather than the full\\n', '# sequence.\\n', 'model.add_flags_recursive(is_first_iteration=False)\\n', 'hidden, past = model(encoder_input_value, encoder_input_mask, init_reset, batch_valid_length)\\n', 'print(hidden.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerDecoderLayer(hidden_size, ffn_hidden_size, num_heads, batch_size, src_seq_length, tgt_seq_length, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, post_layernorm_residual=False, use_past=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, hidden_act=\"gelu\", moe_config=default_moe_config, parallel_config=default_dpmp_config)[source]\\n', 'Transformer Decoder Layer. This is an implementation of the single layer of the transformer decoder layer, including self-attention, cross attention and feedward layer. When the encoder_output is None, the cross attention will not be effective.\\n', '\\n', 'Parameters\\n', 'hidden_size (int) – The hidden size of the input.\\n', '\\n', 'ffn_hidden_size (int) – The hidden size of bottleneck in the feedforward layer.\\n', '\\n', 'num_heads (int) – The number of the heads.\\n', '\\n', 'batch_size (int) – The batch size of the input tensor.\\n', '\\n', 'src_seq_length (int) – The input source sequence length.\\n', '\\n', 'tgt_seq_length (int) – The input target sequence length.\\n', '\\n', 'attention_dropout_rate (float) – The dropout rate of the attention scores. Default:0.1.\\n', '\\n', 'hidden_dropout_rate (float) – The dropout rate of the final output of the layer. Default:0.1.\\n', '\\n', 'post_layernorm_residual (bool) – Do residuals adds before the layernorm. Default False.\\n', '\\n', 'use_past (bool) – Use the past state to compute, used for incremental prediction. Default False.\\n', '\\n', 'layernorm_compute_type (dtype.Number) – The computation type of the layernorm. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'softmax_compute_type (dtype.Number) – The computation type of the softmax in the attention. Should be dtype.float32 or dtype.float16. Default mstype.float32.\\n', '\\n', 'param_init_type (dtype.Number) – The parameter initialization type of the module. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'hidden_act (str) – The activation of the internal feedforward layer. Supports ‘relu’, ‘relu6’, ‘tanh’, ‘gelu’, ‘fast_gelu’, ‘elu’, ‘sigmoid’, ‘prelu’, ‘leakyrelu’, ‘hswish’, ‘hsigmoid’, ‘logsigmoid’ and so on. Default: gelu.\\n', '\\n', 'moe_config (MoEConfig) – The configuration of MoE (Mixture of Expert). Default is an instance of MoEConfig with default values. Please see MoEConfig.\\n', '\\n', 'parallel_config (OpParallelConfig) – The parallel configure. Default default_dpmp_config, an instance of OpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'hidden_stats (Tensor) - The input tensor with shape [batch_size, tgt_seq_length, hidden_size] or [batch_size * tgt_seq_length, hidden_size].\\n', '\\n', 'decoder_mask (Tensor) - The attention mask for decoder with shape [batch_size, src_seq_length, seq_length].\\n', '\\n', 'encoder_output (Tensor) - The output of the encoder with shape [batch_size, seq_length, hidden_size] or [batch_size * seq_length, hidden_size]. Note this args can not be passed by None when the net is in outermost layer. Default None.\\n', '\\n', 'memory_mask (Tensor) - The memory mask of the cross attention with shape [batch, tgt_seq_length, src_seq_length] where tgt_seq_length is the length of the decoder. Note this args can not be passed by None when the net is in outermost layer. Default None.\\n', '\\n', 'init_reset (Tensor) - A bool tensor with shape [1], used to clear the past key parameter and past value parameter used in the incremental prediction. Only valid when use_past is True. Default True.\\n', '\\n', 'batch_valid_length (Tensor) - Int32 tensor with shape [batch_size] the past calculated the index. Used for incremental prediction when the use_past is True. Default None.\\n', '\\n', 'Outputs:\\n', 'Tuple, a tuple contains(output, layer_present)\\n', '\\n', 'output (Tensor) - The output logit of this layer. The shape is [batch, seq_length, hidden_size] or [batch * seq_length, hidden_size].\\n', '\\n', 'layer_present (Tensor) - A tuple, where each tuple is the tensor of the projected key and value vector in self attention with shape ((batch_size, num_heads, size_per_head, tgt_seq_length), (batch_size, num_heads, tgt_seq_length, size_per_head), and of the projected key and value vector in cross attention with shape (batch_size, num_heads, size_per_head, src_seq_length), (batch_size, num_heads, src_seq_length, size_per_head)).\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import TransformerDecoderLayer\\n', 'from mindspore import Tensor\\n', 'model = TransformerDecoderLayer(batch_size=2, hidden_size=64, ffn_hidden_size=64, num_heads=2,\\n', '                                src_seq_length=20, tgt_seq_length=10)\\n', 'encoder_input_value = Tensor(np.ones((2, 20, 64)), mstype.float32)\\n', 'decoder_input_value = Tensor(np.ones((2, 10, 64)), mstype.float32)\\n', 'decoder_input_mask = Tensor(np.ones((2, 10, 10)), mstype.float16)\\n', 'memory_mask = Tensor(np.ones((2, 10, 20)), mstype.float16)\\n', 'output, past = model(decoder_input_value, decoder_input_mask, encoder_input_value, memory_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(past[0].shape)\\n', '\\n', 'print(past[1].shape)\\n', '\\n', 'print(past[2].shape)\\n', '\\n', 'print(past[3].shape)\\n', '\\n', 'classmindspore.nn.transformer.Transformer(hidden_size, batch_size, ffn_hidden_size, src_seq_length, tgt_seq_length, encoder_layers=3, decoder_layers=3, num_heads=2, attention_dropout_rate=0.1, hidden_dropout_rate=0.1, hidden_act=\"gelu\", post_layernorm_residual=False, layernorm_compute_type=mstype.float32, softmax_compute_type=mstype.float32, param_init_type=mstype.float32, lambda_func=None, use_past=False, moe_config=default_moe_config, parallel_config=default_transformer_config)[source]\\n', 'Transformer module including encoder and decoder. The difference with the original implements is the module use the residual addition before the layer normalization. And the default hidden act is gelu. The details can be found in Attention is all you need.\\n', '\\n', 'Note\\n', '\\n', 'This is an experimental interface that is subject to change or deletion.\\n', '\\n', 'Parameters\\n', 'hidden_size (int) – The hidden size of the input.\\n', '\\n', 'batch_size (int) – The batch size of the input tensor.\\n', '\\n', 'ffn_hidden_size (int) – The hidden size of bottleneck in the feedforward layer.\\n', '\\n', 'src_seq_length (int) – The seq_length of the encoder’s input tensor.\\n', '\\n', 'tgt_seq_length (int) – The seq_length of the decoder’s input tensor.\\n', '\\n', 'encoder_layers (int) – The layers of the TransformerEncoderLayer. Default 3.\\n', '\\n', 'decoder_layers (int) – The layers of the TransformerDecoderLayer. Default 3.\\n', '\\n', 'num_heads (int) – The number of the heads. Default: 2.\\n', '\\n', 'attention_dropout_rate (float) – The dropout rate of the attention scores. Default:0.1.\\n', '\\n', 'hidden_dropout_rate (float) – The dropout rate of the final output of the layer. Default:0.1.\\n', '\\n', 'hidden_act (str) – The activation of the internal feedforward layer. Supports ‘relu’, ‘relu6’, ‘tanh’, ‘gelu’, ‘fast_gelu’, ‘elu’, ‘sigmoid’, ‘prelu’, ‘leakyrelu’, ‘hswish’, ‘hsigmoid’, ‘logsigmoid’ and so on. Default: gelu.\\n', '\\n', 'post_layernorm_residual (bool) – Do residuals adds before the layernorm. Default False.\\n', '\\n', 'layernorm_compute_type (dtype.Number) – The computation type of the layernorm. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'softmax_compute_type (dtype.Number) – The computation type of the softmax in the attention. Should be dtype.float32 or dtype.float16. Default mstype.float32.\\n', '\\n', 'param_init_type (dtype.Number) – The parameter initialization type of the module. Should be dtype.float32 or dtype.float16. Default dtype.float32.\\n', '\\n', 'lambda_func – A function can determine the fusion index, pipeline stages and recompute attribute. If the user wants to determine the pipeline stage and gradient aggregation fusion, the user can pass a function that accepts network, layer_id, offset, parallel_config, layers. The network(Cell) represents the transformer block, layer_id(int) means the layer index for the current module, counts from zero, offset(int) means the layer_index needs an offset, if there are other modules in the net. The default setting for the pipeline is: (layer_id + offset) // ((encoder_layers + decoder_layers) / pipeline_stage). Default None.\\n', '\\n', 'use_past (bool) – Use the past state to compute, used for incremental prediction. Default False.\\n', '\\n', 'moe_config (MoEConfig) – The configuration of MoE (Mixture of Expert). Default is an instance of MoEConfig with default values. Please see MoEConfig.\\n', '\\n', 'parallel_config (TransformerOpParallelConfig) – The parallel configure. Default default_transformer_config, an instance of TransformerOpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'encoder_inputs (Tensor) - The input tensor with shape [batch_size, seq_length, hidden_size] or [batch_size * seq_length, hidden_size].\\n', '\\n', 'encoder_masks (Tensor) - The attention mask for decoder with shape [batch_size, seq_length, seq_length].\\n', '\\n', 'decoder_inputs (Tensor) - The output of the encoder with shape [batch_size, seq_length, hidden_size] or [batch_size * seq_length, hidden_size], this should be none if the decoder layer is 0.\\n', '\\n', 'decoder_masks (Tensor) - The attention mask for decoder with shape [batch_size, seq_length, seq_length]\\n', '\\n', 'memory_mask (Tensor) - The memory mask of the cross attention with shape [batch, tgt_seq_length, src_seq_length] where tgt_seq_length is the length of the decoder. The output of the encoder with shape [batch_size, seq_length, hidden_size], this should be none if the decoder layer is 0.\\n', '\\n', 'init_reset (Tensor) - A bool tensor with shape [1], used to clear the past key parameter and past value parameter used in the incremental prediction. Only valid when use_past is True. Default True.\\n', '\\n', 'batch_valid_length (Tensor) - Int32 tensor with shape [batch_size] the past calculated the index. Used for incremental prediction when the use_past is True. Default None.\\n', '\\n', 'Outputs:\\n', 'Tuple, a tuple contains(output, encoder_layer_present, decoder_layer_present)\\n', '\\n', 'output (Tensor) - If there is only encoder, the output logit of the encoder layer. The shape is [batch, src_seq_length, hidden_size] or [batch * src_seq_length, hidden_size], if there are encoder and decoders, the output is from the decoder layer. The shape is [batch, tgt_seq_length, hidden_size] or [batch * tgt_seq_length, hidden_size].\\n', '\\n', 'encoder_layer_present (Tuple) - A tuple with size of num_layers, where each tuple is the tensor the projected key and value vector in self attention with shape ((batch_size, num_heads, size_per_head, src_seq_length), (batch_size, num_heads, src_seq_length, size_per_head)).\\n', '\\n', 'decoder_layer_present (Tuple) - A tuple with size of num_layers, where each tuple is the tensor of the projected key and value vector in self attention with shape ((batch_size, num_heads, size_per_head, tgt_seq_length), (batch_size, num_heads, tgt_seq_length, size_per_head)), and the projected key and value vector in cross attention with shape (batch_size, num_heads, size_per_head, src_seq_length), (batch_size, num_heads, src_seq_length, size_per_head)). If the decoder is not set, the returned value will be None.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import Transformer\\n', 'from mindspore import Tensor\\n', 'model = Transformer(batch_size=2, encoder_layers=1, decoder_layers=2, hidden_size=64, ffn_hidden_size=64,\\n', '        src_seq_length=20, tgt_seq_length=10)\\n', 'encoder_input_value = Tensor(np.ones((2, 20, 64)), mstype.float32)\\n', 'encoder_input_mask = Tensor(np.ones((2, 20, 20)), mstype.float16)\\n', 'decoder_input_value = Tensor(np.ones((2, 10, 64)), mstype.float32)\\n', 'decoder_input_mask = Tensor(np.ones((2, 10, 10)), mstype.float16)\\n', 'memory_mask = Tensor(np.ones((2, 10, 20)), mstype.float16)\\n', 'output, en_past, de_past = model(encoder_input_value, encoder_input_mask, decoder_input_value,\\n', '                                 decoder_input_mask, memory_mask)\\n', 'print(output.shape)\\n', '\\n', 'print(len(en_past))\\n', '\\n', 'print(len(de_past))\\n', '\\n', 'print(en_past[0][0].shape)\\n', '\\n', 'print(en_past[0][1].shape)\\n', '\\n', 'print(de_past[0][0].shape)\\n', '\\n', 'print(de_past[0][1].shape)\\n', '\\n', 'print(de_past[0][2].shape)\\n', '\\n', 'print(de_past[0][3].shape)\\n', '\\n', 'classmindspore.nn.transformer.TransformerOpParallelConfig(data_parallel=1, model_parallel=1, pipeline_stage=1, micro_batch_num=1, recompute=default_transformer_recompute_config, optimizer_shard=False, gradient_aggregation_group=4, vocab_emb_dp=True)[source]\\n', 'TransformerOpParallelConfig for the setting global data parallel, model parallel and fusion group. The parallel configure setting.\\n', '\\n', 'Note\\n', '\\n', 'Except the recompute argument, other arguments will not be effective when the user doesn’t set auto_parallel_context to SEMI_AUTO_PARALLEL or AUTO_PARALLEL. The micro_batch_num must be greater than or equal to pipeline_stage when training. The data_parallel*model_parallel *pipeline_stage must be equal or less equal to the device. When setting the pipeline stage and optimizer_shard, the config will overwrite the auto_parallel_context. When given the 8 devices and the data_parallel is 1 and model_parallel is 1, the calculation will be repeated on each device.\\n', '\\n', 'Parameters\\n', 'data_parallel (int) – The data parallel way. The input data will be sliced into n parts for each layer according to the data parallel way. Default: 1.\\n', '\\n', 'model_parallel (int) – The model parallel way. The parameters of dense layers in MultiheadAttention and FeedForward layer will be sliced according to the model parallel way. Default: 1.\\n', '\\n', 'pipeline_stage (int) – The number of the pipeline stage. Should be a positive value. Default: 1.\\n', '\\n', 'micro_batch_num (int) – The micro size of the batches for the pipeline training. Default: 1.\\n', '\\n', 'optimizer_shard (bool) – Whether to enable optimizer shard. Default False.\\n', '\\n', 'gradient_aggregation_group (int) – The fusion group size of the optimizer state sharding. Default: 4.\\n', '\\n', 'recompute (Union[TransformerRecomputeConfig, bool]) – The configuration of recomputation for the transformer block. Default: The default configuration of TransformerRecomputeConfig.\\n', '\\n', 'vocab_emb_dp (bool) – Shard embedding in model parallel or data parallel. Default: True.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.nn.transformer import TransformerRecomputeConfig\\n', 'recompute_config=TransformerRecomputeConfig(recompute=True, parallel_optimizer_comm_recompute=True, \\\\\\n', '                                            mp_comm_recompute=True, recompute_slice_activation=True)\\n', 'config=TransformerOpParallelConfig(data_parallel=1, model_parallel=1, recompute=recompute_config)\\n', 'propertydp_mp_config\\n', 'To obtain the EmbeddingParallelConfig for the setting data parallel, model parallel and embedding parallel.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.nn.transformer import TransformerOpParallelConfig\\n', 'config=TransformerOpParallelConfig(data_parallel=1, model_parallel=1, vocab_emb_dp=True)\\n', 'parallel_config = config.dp_mp_config\\n', 'propertyembedding_dp_mp_config\\n', 'To obtain the EmbeddingParallelConfig for the setting data parallel, model parallel and embedding parallel.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'config=TransformerOpParallelConfig(data_parallel=1, model_parallel=1, vocab_emb_dp=True)\\n', 'parallel_config = config.embedding_dp_mp_config\\n', 'classmindspore.nn.transformer.EmbeddingOpParallelConfig(data_parallel=1, model_parallel=1, vocab_emb_dp=True)[source]\\n', 'EmbeddingOpParallelConfig for the setting data parallel or row slice for the embedding table.\\n', '\\n', 'Parameters\\n', 'data_parallel (int) – The data parallel way. The input data will be sliced into n parts for embedding layer according to this value. Default 1.\\n', '\\n', 'model_parallel (int) – The model parallel way. The embedding table parameters will be sliced according to the model parallel way. Default: 1.\\n', '\\n', 'vocab_emb_dp (bool) – Shard embedding in model parallel or data parallel. If true, the embedding lookup will be a data parallel style training and model_parallel value will be ignored. If false, the embedding table will be sharded into n parts at the 0-th dimension row slice of the embedding table, where the n is the model parallel way determined by this parameter. Default: True\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.nn.transformer import EmbeddingOpParallelConfig\\n', 'config=EmbeddingOpParallelConfig(data_parallel=1, model_parallel=1, vocab_emb_dp=True)\\n', 'propertydp_mp_config\\n', 'To obtain the DPMPlConfig for the setting data parallel, model parallel\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.nn.transformer import EmbeddingOpParallelConfig\\n', 'config=EmbeddingOpParallelConfig(data_parallel=1, model_parallel=1, vocab_emb_dp=True)\\n', 'parallel_config = config.dp_mp_config\\n', 'classmindspore.nn.transformer.TransformerRecomputeConfig(recompute=False, parallel_optimizer_comm_recompute=False, mp_comm_recompute=True, recompute_slice_activation=False)[source]\\n', 'TransformerRecomputeConfig for the setting recompute attributes for encoder/decoder layers.\\n', '\\n', 'Parameters\\n', 'recompute (bool) – Enable recomputation of the transformer block or not. Default: False.\\n', '\\n', 'parallel_optimizer_comm_recompute (bool) – Specifies whether the communication operator allgathers introduced by optimizer shard are recomputed in auto parallel or semi auto parallel mode. Default: False.\\n', '\\n', 'mp_comm_recompute (bool) – Specifies whether the model parallel communication operators in the cell are recomputed in auto parallel or semi auto parallel mode. Default: True.\\n', '\\n', 'recompute_slice_activation (bool) – Slice the cell output which would remains in memory. Default: False.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.nn.transformer import TransformerRecomputeConfig\\n', 'config=TransformerRecomputeConfig(recompute=True, parallel_optimizer_comm_recompute=True, \\\\\\n', '                                  mp_comm_recompute=True, recompute_slice_activation=True)\\n', 'classmindspore.nn.transformer.CrossEntropyLoss(parallel_config=default_dpmp_config)[source]\\n', 'Calculate the cross entropy loss.\\n', '\\n', 'Parameters\\n', 'parallel_config (OpParallelConfig) – The parallel configure. Default default_dpmp_config, an instance of OpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'logits (Tensor) - Tensor of shape (N, C). Data type must be float16 or float32. The output logits of the backbone.\\n', '\\n', 'labels (Tensor) - Tensor of shape (N, ). The ground truth label of the sample.\\n', '\\n', 'input_mask (Tensor) - Tensor of shape (N, ). input_mask indicates whether there are padded inputs and for padded inputs it will not be counted into loss.\\n', '\\n', 'Outputs:\\n', 'Tensor. The corresponding cross entropy loss\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import CrossEntropyLoss\\n', 'from mindspore import Tensor\\n', 'loss = CrossEntropyLoss()\\n', 'logits = Tensor(np.array([[3, 5, 6, 9, 12, 33, 42, 12, 32, 72]]), mstype.float32)\\n', 'labels_np = np.array([1]).astype(np.int32)\\n', 'input_mask = Tensor(np.ones(1).astype(np.float32))\\n', 'labels = Tensor(labels_np)\\n', 'output = loss(logits, labels, input_mask)\\n', 'print(output.shape)\\n', '\\n', 'classmindspore.nn.transformer.OpParallelConfig(data_parallel=1, model_parallel=1)[source]\\n', 'OpParallelConfig for the setting data parallel and model parallel.\\n', '\\n', 'Parameters\\n', 'data_parallel (int) – The data parallel way. Default: 1\\n', '\\n', 'model_parallel (int) – The model parallel way. Default: 1\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.nn.transformer import OpParallelConfig\\n', 'config=OpParallelConfig(data_parallel=1, model_parallel=1)\\n', 'classmindspore.nn.transformer.FixedSparseAttention(batch_size, num_heads, size_per_head, block_size, seq_length=1024, num_different_global_patterns=4, parallel_config=default_dpmp_config)[source]\\n', 'Fixed Sparse Attention Layer\\n', '\\n', 'This function contains the sparse attention primitives used in Sparse Transformers (see paper). https://arxiv.org/abs/1904.10509 Specifically, it includes the following: 1. A faster implementation of normal attention (the upper triangle is not computed, and many operations are fused). 2. An implementation of “strided” and “fixed” attention, as in the Sparse Transformers paper.\\n', '\\n', 'Parameters\\n', 'batch_size (int) – Number of input batch size.\\n', '\\n', 'num_heads (int) – Number of attention heads.\\n', '\\n', 'size_per_head (int) – An integer determining embedding size of each attention head, only supports 64, 128 for now.\\n', '\\n', 'block_size (int) – An integer determining the block size. Current implementation of sparse self-attention is based on blocked sparse matrices. In which this parameter defines the size of such blocks, Block X Block. Only supports 64 for now.\\n', '\\n', 'seq_length (int) – length of input sequence, only supports 1024 for now. Default 1024.\\n', '\\n', 'num_different_global_patterns (int) – An integer determining the number of different global attentions layouts. While global attention can be fixed by which block/s are representative of any local window, since there are multi-heads, each head can use a different global representative, only supports 4 for now. Default 4.\\n', '\\n', 'parallel_config (OpParallelConfig) – The config of parallel setting, see OpParallelConfig. Default default_dpmp_config, an instance of OpParallelConfig with default args.\\n', '\\n', 'Inputs:\\n', 'q (Tensor) - Tensor query (mstype.fp16 [batch_size, seq_length, hidden_size]): Sequence of queries to query the context.\\n', '\\n', 'k (Tensor) - Tensor key (mstype.fp16 [batch_size, seq_length, hidden_size]): Sequence of queries to query the context.\\n', '\\n', 'v (Tensor) - Tensor value (mstype.fp16 [batch size, sequence length, Embedding Size]): Sequence of queries to query the context.\\n', '\\n', 'attention_mask (Tensor) - Float Tensor the mask of (mstype.fp32, mstype.fp16 [batch_size, seq_length, seq_length]): Lower triangular matrix to pass masked information.\\n', '\\n', 'Outputs:\\n', 'A Tensor. The output of the attention with shape [batch_size, seq_length, hidden_size]\\n', '\\n', 'Supported Platforms:\\n', 'Ascend\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import dtype as mstype\\n', 'from mindspore.nn.transformer import FixedSparseAttention\\n', 'from mindspore import Tensor\\n', 'model = FixedSparseAttention(batch_size=2,\\n', '                             num_heads=8,\\n', '                             size_per_head=64,\\n', '                             block_size=64)\\n', 'q = Tensor(np.ones((2, 1024, 8*64)), mstype.float16)\\n', 'k = Tensor(np.ones((2, 1024, 8*64)), mstype.float16)\\n', 'v = Tensor(np.ones((2, 1024, 8*64)), mstype.float16)\\n', 'attention_mask = Tensor(np.ones((2, 1024, 1024)), mstype.float32)\\n', 'output = model(q, k, v, attention_mask)\\n', 'print(output.shape)\\n', '\\n', 'classmindspore.nn.transformer.MoEConfig(expert_num=1, capacity_factor=1.1, aux_loss_factor=0.05, num_experts_chosen=1)[source]\\n', 'The configuration of MoE (Mixture of Expert).\\n', '\\n', 'Parameters\\n', 'expert_num (int) – The number of experts employed. Default: 1\\n', '\\n', 'capacity_factor (float) – The factor is used to indicate how much to expand expert capacity, which is >=1.0. Default: 1.1.\\n', '\\n', 'aux_loss_factor (float) – The factor is used to indicate how much the load balance loss (produced by the router) to be added to the entire model loss, which is < 1.0. Default: 0.05.\\n', '\\n', 'num_experts_chosen (int) – The number of experts is chosen by each token. Since only ‘Top1’ routing policy is supported currently, the value should be 1. Default: 1.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.nn.transformer import MoEConfig\\n', 'moe_config = MoEConfig(expert_num=4, capacity_factor=5.0, aux_loss_factor=0.05, num_experts_chosen=1)']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.nn.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.nn.html", "text_entry": "['mindspore.nn\\n', 'Neural Networks Cells.\\n', '\\n', 'Pre-defined building blocks or computing units to construct neural networks.\\n', '\\n', 'Compared with the previous version, the added, deleted and supported platforms change information of mindspore.nn operators in MindSpore, please refer to the link https://gitee.com/mindspore/docs/blob/r1.6/resource/api_updates/nn_api_updates.md.\\n', '\\n', 'Cell\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.Cell\\n', '\\n', 'Base class for all neural networks.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.GraphCell\\n', '\\n', 'Base class for running the graph loaded from a MindIR.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Containers\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.CellList\\n', '\\n', 'Holds Cells in a list.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SequentialCell\\n', '\\n', 'Sequential cell container.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Convolution Layers\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.Conv1d\\n', '\\n', '1D convolution layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv1dTranspose\\n', '\\n', '1D transposed convolution layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv2d\\n', '\\n', '2D convolution layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv2dTranspose\\n', '\\n', '2D transposed convolution layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv3d\\n', '\\n', '3D convolution layer.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.Conv3dTranspose\\n', '\\n', 'Compute a 3D transposed convolution, which is also known as a deconvolution (although it is not an actual deconvolution).\\n', '\\n', 'Ascend GPU\\n', '\\n', 'Gradient\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.Jvp\\n', '\\n', 'Compute the jacobian-vector-product of the given fn.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Vjp\\n', '\\n', 'Computes the dot product between a vector v and the Jacobian of the given fn at the point given by the inputs.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Recurrent Layers\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.GRUCell\\n', '\\n', 'A GRU(Gated Recurrent Unit) cell.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.GRU\\n', '\\n', 'Stacked GRU (Gated Recurrent Unit) layers.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.LSTMCell\\n', '\\n', 'A LSTM (Long Short-Term Memory) cell.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.LSTM\\n', '\\n', 'Stacked LSTM (Long Short-Term Memory) layers.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.RNNCell\\n', '\\n', 'An Elman RNN cell with tanh or ReLU non-linearity.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.RNN\\n', '\\n', 'Stacked Elman RNN layers.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Sparse Layers\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.Embedding\\n', '\\n', 'A simple lookup table that stores embeddings of a fixed dictionary and size.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.EmbeddingLookup\\n', '\\n', 'Returns a slice of the input tensor based on the specified indices.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MultiFieldEmbeddingLookup\\n', '\\n', 'Returns a slice of input tensor based on the specified indices and the field ids.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.SparseToDense\\n', '\\n', 'Converts a sparse tensor into dense.\\n', '\\n', 'CPU\\n', '\\n', 'mindspore.nn.SparseTensorDenseMatmul\\n', '\\n', 'Multiplies sparse matrix a and dense matrix b.\\n', '\\n', 'CPU\\n', '\\n', 'Non-linear Activations\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.CELU\\n', '\\n', 'Continuously differentiable exponential linear units activation function.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.ELU\\n', '\\n', 'Exponential Linear Unit activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.FastGelu\\n', '\\n', 'Fast Gaussian error linear unit activation function.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.GELU\\n', '\\n', 'Gaussian error linear unit activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.get_activation\\n', '\\n', 'Gets the activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.HShrink\\n', '\\n', 'Applies the hard shrinkage function element-wise, each element complies the follow function:\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.HSigmoid\\n', '\\n', 'Hard sigmoid activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.HSwish\\n', '\\n', 'Hard swish activation function.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.nn.LeakyReLU\\n', '\\n', 'Leaky ReLU activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.LogSigmoid\\n', '\\n', 'Logsigmoid activation function.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.LogSoftmax\\n', '\\n', 'LogSoftmax activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.PReLU\\n', '\\n', 'PReLU activation function.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.ReLU\\n', '\\n', 'Rectified Linear Unit activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ReLU6\\n', '\\n', 'Compute ReLU6 activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Sigmoid\\n', '\\n', 'Sigmoid activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Softmax\\n', '\\n', 'Softmax activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SoftShrink\\n', '\\n', 'Applies the SoftShrink function element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.Tanh\\n', '\\n', 'Tanh activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Utilities\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.ClipByNorm\\n', '\\n', 'Clips tensor values to a maximum L2-norm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Dense\\n', '\\n', 'The dense connected layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Dropout\\n', '\\n', 'Dropout layer for the input.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Flatten\\n', '\\n', 'Flatten layer for the input.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.L1Regularizer\\n', '\\n', 'Applies l1 regularization to weights.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Norm\\n', '\\n', 'Computes the norm of vectors, currently including Euclidean norm, i.e., L2-norm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.OneHot\\n', '\\n', 'Returns a one-hot tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Pad\\n', '\\n', 'Pads the input tensor according to the paddings and mode.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Range\\n', '\\n', 'Creates a sequence of numbers in range [start, limit) with step size delta.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ResizeBilinear\\n', '\\n', 'Samples the input tensor to the given size or scale_factor by using bilinear interpolate.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.nn.Roll\\n', '\\n', 'Rolls the elements of a tensor along an axis.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.Tril\\n', '\\n', 'Returns a tensor with elements above the kth diagonal zeroed.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Triu\\n', '\\n', 'Returns a tensor with elements below the kth diagonal zeroed.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Unfold\\n', '\\n', 'Extracts patches from images.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'Images Functions\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.CentralCrop\\n', '\\n', 'Crops the central region of the images with the central_fraction.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ImageGradients\\n', '\\n', 'Returns two tensors, the first is along the height dimension and the second is along the width dimension.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MSSSIM\\n', '\\n', 'Returns MS-SSIM index between two images.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.PSNR\\n', '\\n', 'Returns Peak Signal-to-Noise Ratio of two image batches.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SSIM\\n', '\\n', 'Returns SSIM index between two images.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Normalization Layers\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.BatchNorm1d\\n', '\\n', 'Batch Normalization layer over a 2D input.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.BatchNorm2d\\n', '\\n', 'Batch Normalization layer over a 4D input.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.BatchNorm3d\\n', '\\n', 'Batch Normalization layer over a 5D input.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.GlobalBatchNorm\\n', '\\n', 'The GlobalBatchNorm interface is deprecated, please use the mindspore.nn.SyncBatchNorm instead.\\n', '\\n', 'deprecated\\n', '\\n', 'mindspore.nn.GroupNorm\\n', '\\n', 'Group Normalization over a mini-batch of inputs.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.InstanceNorm2d\\n', '\\n', 'Instance Normalization layer over a 4D input.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.nn.LayerNorm\\n', '\\n', 'Applies Layer Normalization over a mini-batch of inputs.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MatrixDiag\\n', '\\n', 'Returns a batched diagonal tensor with a given batched diagonal values.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.MatrixDiagPart\\n', '\\n', 'Returns the batched diagonal part of a batched tensor.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.MatrixSetDiag\\n', '\\n', 'Modifies the batched diagonal part of a batched tensor.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.SyncBatchNorm\\n', '\\n', 'Sync Batch Normalization layer over a N-dimension input.\\n', '\\n', 'Ascend\\n', '\\n', 'Pooling layers\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.AvgPool1d\\n', '\\n', '1D average pooling for temporal data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.AvgPool2d\\n', '\\n', '2D average pooling for temporal data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MaxPool1d\\n', '\\n', '1D max pooling operation for temporal data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MaxPool2d\\n', '\\n', '2D max pooling operation for temporal data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Quantized Functions\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.ActQuant\\n', '\\n', 'Quantization aware training activation function.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.Conv2dBnAct\\n', '\\n', 'A combination of convolution, Batchnorm, and activation layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Conv2dBnFoldQuant\\n', '\\n', '2D convolution with Batch Normalization operation folded construct.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.Conv2dBnFoldQuantOneConv\\n', '\\n', '2D convolution which use the convolution layer statistics once to calculate Batch Normalization operation folded construct.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.Conv2dBnWithoutFoldQuant\\n', '\\n', '2D convolution and batchnorm without fold with fake quantized construct.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.Conv2dQuant\\n', '\\n', '2D convolution with fake quantized operation layer.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.DenseBnAct\\n', '\\n', 'A combination of Dense, Batchnorm, and the activation layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.DenseQuant\\n', '\\n', 'The fully connected layer with fake quantized operation.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.FakeQuantWithMinMaxObserver\\n', '\\n', 'Quantization aware operation which provides the fake quantization observer function on data with min and max.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.MulQuant\\n', '\\n', 'Adds fake quantized operation after Mul operation.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.TensorAddQuant\\n', '\\n', 'Adds fake quantized operation after TensorAdd operation.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'Loss Functions\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.BCELoss\\n', '\\n', 'BCELoss creates a criterion to measure the binary cross entropy between the true labels and predicted labels.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.BCEWithLogitsLoss\\n', '\\n', 'Adds sigmoid activation function to input logits, and uses the given logits to compute binary cross entropy between the logits and the labels.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.CosineEmbeddingLoss\\n', '\\n', 'CosineEmbeddingLoss creates a criterion to measure the similarity between two tensors using cosine distance.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.DiceLoss\\n', '\\n', 'The Dice coefficient is a set similarity loss.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.FocalLoss\\n', '\\n', 'The loss function proposed by Kaiming team in their paper Focal Loss for Dense Object Detection improves the effect of image object detection.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.L1Loss\\n', '\\n', 'L1Loss creates a criterion to measure the mean absolute error (MAE) between x and y element-wise, where x is the input Tensor and y is the labels Tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.LossBase\\n', '\\n', 'Base class for other losses.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MSELoss\\n', '\\n', 'MSELoss creates a criterion to measure the mean squared error (squared L2-norm) between x and y element-wise, where x is the input and y is the labels.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MultiClassDiceLoss\\n', '\\n', 'When there are multiple classifications, label is transformed into multiple binary classifications by one hot.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.RMSELoss\\n', '\\n', 'RMSELoss creates a criterion to measure the root mean square error between x and y element-wise, where x is the input and y is the labels.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SampledSoftmaxLoss\\n', '\\n', 'Computes the sampled softmax training loss.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.nn.SmoothL1Loss\\n', '\\n', 'A loss class for learning region proposals.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SoftMarginLoss\\n', '\\n', 'A loss class for two-class classification problems.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.SoftmaxCrossEntropyWithLogits\\n', '\\n', 'Computes softmax cross entropy between logits and labels.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Optimizer Functions\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.Adagrad\\n', '\\n', 'Implements the Adagrad algorithm with ApplyAdagrad Operator.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.nn.Adam\\n', '\\n', 'Updates gradients by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.AdamOffload\\n', '\\n', 'This optimizer will offload Adam optimizer to host CPU and keep parameters being updated on the device, to minimize the memory cost.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.AdamWeightDecay\\n', '\\n', 'Implements the Adam algorithm with weight decay.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ASGD\\n', '\\n', 'Implements Average Stochastic Gradient Descent.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.FTRL\\n', '\\n', 'Implements the FTRL algorithm with ApplyFtrl Operator.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.Lamb\\n', '\\n', 'An optimizer that implements the Lamb(Layer-wise Adaptive Moments optimizer for Batching training) algorithm.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.LARS\\n', '\\n', 'Implements the LARS algorithm with LARSUpdate Operator.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.LazyAdam\\n', '\\n', 'Updates gradients by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Momentum\\n', '\\n', 'An optimizer that implements the Momentum algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Optimizer\\n', '\\n', 'Base class for updating parameters.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ProximalAdagrad\\n', '\\n', 'Implements the ProximalAdagrad algorithm with ApplyProximalAdagrad Operator.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.nn.RMSProp\\n', '\\n', 'Implements Root Mean Squared Propagation (RMSProp) algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Rprop\\n', '\\n', 'Implements Resilient backpropagation.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.SGD\\n', '\\n', 'Implements stochastic gradient descent.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.thor\\n', '\\n', 'Updates gradients by second-order algorithm–THOR.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'Wrapper Functions\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.DistributedGradReducer\\n', '\\n', 'A distributed optimizer.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.DynamicLossScaleUpdateCell\\n', '\\n', 'Dynamic Loss scale update cell.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.FixedLossScaleUpdateCell\\n', '\\n', 'Update cell with fixed loss scaling value.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.ForwardValueAndGrad\\n', '\\n', 'Encapsulate training network.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.GetNextSingleOp\\n', '\\n', 'Cell to run for getting the next operation.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.MicroBatchInterleaved\\n', '\\n', 'Wrap the network with Batch Size.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.ParameterUpdate\\n', '\\n', 'Cell that updates parameter.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.PipelineCell\\n', '\\n', 'Wrap the network with Micro Batch.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.TimeDistributed\\n', '\\n', 'The time distributed layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.TrainOneStepCell\\n', '\\n', 'Network training package class.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.TrainOneStepWithLossScaleCell\\n', '\\n', 'Network training with loss scaling.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.WithEvalCell\\n', '\\n', 'Wraps the forward network with the loss function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.WithGradCell\\n', '\\n', 'Cell that returns the gradients.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.WithLossCell\\n', '\\n', 'Cell with loss function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Math Functions\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.MatMul\\n', '\\n', 'The nn.MatMul interface is deprecated, please use the mindspore.ops.matmul instead.\\n', '\\n', 'deprecated\\n', '\\n', 'mindspore.nn.Moments\\n', '\\n', 'Calculates the mean and variance of x.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ReduceLogSumExp\\n', '\\n', 'Reduces a dimension of a tensor by calculating exponential for all elements in the dimension, then calculate logarithm of the sum.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Metrics\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.Accuracy\\n', '\\n', 'Calculates the accuracy for classification and multilabel data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.auc\\n', '\\n', 'Computes the AUC(Area Under the Curve) using the trapezoidal rule.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.BleuScore\\n', '\\n', 'Calculates the BLEU score.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ConfusionMatrix\\n', '\\n', 'Computes the confusion matrix, which is commonly used to evaluate the performance of classification models, including binary classification and multiple classification.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ConfusionMatrixMetric\\n', '\\n', 'Computes metrics related to confusion matrix.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.CosineSimilarity\\n', '\\n', 'Computes representation similarity.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Dice\\n', '\\n', 'The Dice coefficient is a set similarity metric.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.F1\\n', '\\n', 'Calculates the F1 score.\\n', '\\n', 'To Be Developed\\n', '\\n', 'mindspore.nn.Fbeta\\n', '\\n', 'Calculates the fbeta score.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.HausdorffDistance\\n', '\\n', 'Calculates the Hausdorff distance.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.get_metric_fn\\n', '\\n', 'Gets the metric method based on the input name.\\n', '\\n', 'To Be Developed\\n', '\\n', 'mindspore.nn.Loss\\n', '\\n', 'Calculates the average of the loss.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MAE\\n', '\\n', 'Calculates the mean absolute error(MAE).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.MeanSurfaceDistance\\n', '\\n', 'Computes the Average Surface Distance from y_pred to y under the default setting.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Metric\\n', '\\n', 'Base class of metric.\\n', '\\n', 'To Be Developed\\n', '\\n', 'mindspore.nn.MSE\\n', '\\n', 'Measures the mean squared error(MSE).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.names\\n', '\\n', 'Gets all names of the metric methods.\\n', '\\n', 'To Be Developed\\n', '\\n', 'mindspore.nn.OcclusionSensitivity\\n', '\\n', 'Calculates the occlusion sensitivity of the model for a given image.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Perplexity\\n', '\\n', 'Computes perplexity.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Precision\\n', '\\n', 'Calculates precision for classification and multilabel data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Recall\\n', '\\n', 'Calculates recall for classification and multilabel data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.ROC\\n', '\\n', 'Calculates the ROC curve.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.RootMeanSquareDistance\\n', '\\n', 'Computes the Root Mean Square Surface Distance from y_pred to y under the default setting.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.rearrange_inputs\\n', '\\n', 'This decorator is used to rearrange the inputs according to its indexes attribute of the class.\\n', '\\n', 'To Be Developed\\n', '\\n', 'mindspore.nn.Top1CategoricalAccuracy\\n', '\\n', 'Calculates the top-1 categorical accuracy.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.Top5CategoricalAccuracy\\n', '\\n', 'Calculates the top-5 categorical accuracy.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.TopKCategoricalAccuracy\\n', '\\n', 'Calculates the top-k categorical accuracy.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Dynamic Learning Rate\\n', 'LearningRateSchedule\\n', 'The dynamic learning rates in this module are all subclasses of LearningRateSchedule. Pass the instance of LearningRateSchedule to an optimizer. During the training process, the optimizer calls the instance taking current step as input to get the current learning rate.\\n', '\\n', 'import mindspore.nn as nn\\n', '\\n', 'min_lr = 0.01\\n', 'max_lr = 0.1\\n', 'decay_steps = 4\\n', 'cosine_decay_lr = nn.CosineDecayLR(min_lr, max_lr, decay_steps)\\n', '\\n', 'net = Net()\\n', 'optim = nn.Momentum(net.trainable_params(), learning_rate=cosine_decay_lr, momentum=0.9)\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.nn.CosineDecayLR\\n', '\\n', 'Calculates learning rate based on cosine decay function.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.ExponentialDecayLR\\n', '\\n', 'Calculates learning rate based on exponential decay function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.InverseDecayLR\\n', '\\n', 'Calculates learning rate base on inverse-time decay function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.NaturalExpDecayLR\\n', '\\n', 'Calculates learning rate base on natural exponential decay function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.nn.PolynomialDecayLR\\n', '\\n', 'Calculates learning rate base on polynomial decay function.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.nn.WarmUpLR\\n', '\\n', 'Gets learning rate warming up.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'Dynamic LR\\n', 'The dynamic learning rates in this module are all functions. Call the function and pass the result to an optimizer. During the training process, the optimizer takes result[current step] as current learning rate.\\n', '\\n', 'import mindspore.nn as nn\\n', '\\n', 'min_lr = 0.01\\n', 'max_lr = 0.1\\n', 'total_step = 6\\n', 'step_per_epoch = 1\\n', 'decay_epoch = 4\\n', '\\n', 'lr= nn.cosine_decay_lr(min_lr, max_lr, total_step, step_per_epoch, decay_epoch)\\n', '\\n', 'net = Net()\\n', 'optim = nn.Momentum(net.trainable_params(), learning_rate=lr, momentum=0.9)\\n', 'mindspore.nn.cosine_decay_lr\\n', '\\n', 'Calculates learning rate base on cosine decay function.\\n', '\\n', 'mindspore.nn.exponential_decay_lr\\n', '\\n', 'Calculates learning rate base on exponential decay function.\\n', '\\n', 'mindspore.nn.inverse_decay_lr\\n', '\\n', 'Calculates learning rate base on inverse-time decay function.\\n', '\\n', 'mindspore.nn.natural_exp_decay_lr\\n', '\\n', 'Calculates learning rate base on natural exponential decay function.\\n', '\\n', 'mindspore.nn.piecewise_constant_lr\\n', '\\n', 'Get piecewise constant learning rate.\\n', '\\n', 'mindspore.nn.polynomial_decay_lr\\n', '\\n', 'Calculates learning rate base on polynomial decay function.\\n', '\\n', 'mindspore.nn.warmup_lr\\n', '\\n', 'Gets learning rate warming up.']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.numpy.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.numpy.html", "text_entry": "['mindspore.numpy\\n', 'Numpy-like interfaces in mindspore.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore.numpy as np\\n', 'Note\\n', '\\n', 'array_ops.py defines all the array operation interfaces.\\n', '\\n', 'array_creations.py defines all the array generation interfaces.\\n', '\\n', 'math_ops.py defines all the math operations on tensors.\\n', '\\n', 'logic_ops.py defines all the logical operations on tensors.\\n', '\\n', 'dtypes.py defines all the mindspore.numpy dtypes (mainly redirected from mindspore)\\n', '\\n', 'Array Generation\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.numpy.arange\\n', '\\n', 'Returns evenly spaced values within a given interval.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.array\\n', '\\n', 'Creates a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.asarray\\n', '\\n', 'Converts the input to tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.asfarray\\n', '\\n', 'Similar to asarray, converts the input to a float tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.bartlett\\n', '\\n', 'Returns the Bartlett window.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.blackman\\n', '\\n', 'Returns the Blackman window.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.copy\\n', '\\n', 'Returns a tensor copy of the given object.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diag\\n', '\\n', 'Extracts a diagonal or construct a diagonal array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diag_indices\\n', '\\n', 'Returns the indices to access the main diagonal of an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diagflat\\n', '\\n', 'Creates a two-dimensional array with the flattened input as a diagonal.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diagonal\\n', '\\n', 'Returns specified diagonals.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.empty\\n', '\\n', 'Returns a new array of given shape and type, without initializing entries.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.empty_like\\n', '\\n', 'Returns a new array with the same shape and type as a given array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.eye\\n', '\\n', 'Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.full\\n', '\\n', 'Returns a new tensor of given shape and type, filled with fill_value.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.full_like\\n', '\\n', 'Returns a full array with the same shape and type as a given array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.geomspace\\n', '\\n', 'Returns numbers spaced evenly on a log scale (a geometric progression).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.hamming\\n', '\\n', 'Returns the Hamming window.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.hanning\\n', '\\n', 'Returns the Hanning window.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.histogram_bin_edges\\n', '\\n', 'Function to calculate only the edges of the bins used by the histogram function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.identity\\n', '\\n', 'Returns the identity tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.indices\\n', '\\n', 'Returns an array representing the indices of a grid.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ix_\\n', '\\n', 'Constructs an open mesh from multiple sequences.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.linspace\\n', '\\n', 'Returns evenly spaced values within a given interval.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logspace\\n', '\\n', 'Returns numbers spaced evenly on a log scale.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.meshgrid\\n', '\\n', 'Returns coordinate matrices from coordinate vectors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.mgrid\\n', '\\n', 'mgrid is an NdGrid instance with sparse=False.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ogrid\\n', '\\n', 'ogrid is an NdGrid instance with sparse=True.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ones\\n', '\\n', 'Returns a new tensor of given shape and type, filled with ones.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ones_like\\n', '\\n', 'Returns an array of ones with the same shape and type as a given array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.pad\\n', '\\n', 'Pads an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.trace\\n', '\\n', 'Returns the sum along diagonals of the array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tri\\n', '\\n', 'Returns a tensor with ones at and below the given diagonal and zeros elsewhere.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tril\\n', '\\n', 'Returns a lower triangle of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tril_indices\\n', '\\n', 'Returns the indices for the lower-triangle of an (n, m) array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tril_indices_from\\n', '\\n', 'Returns the indices for the lower-triangle of arr.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.triu\\n', '\\n', 'Returns an upper triangle of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.triu_indices\\n', '\\n', 'Returns the indices for the upper-triangle of an (n, m) array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.triu_indices_from\\n', '\\n', 'Returns the indices for the upper-triangle of arr.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.vander\\n', '\\n', 'Generates a Vandermonde matrix.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.zeros\\n', '\\n', 'Returns a new tensor of given shape and type, filled with zeros.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.zeros_like\\n', '\\n', 'Returns an array of zeros with the same shape and type as a given array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Array Operation\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.numpy.append\\n', '\\n', 'Appends values to the end of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.apply_along_axis\\n', '\\n', 'Applies a function to 1-D slices along the given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.apply_over_axes\\n', '\\n', 'Applies a function repeatedly over multiple axes.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.array_split\\n', '\\n', 'Splits a tensor into multiple sub-tensors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.array_str\\n', '\\n', 'Returns a string representation of the data in an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.atleast_1d\\n', '\\n', 'Converts inputs to arrays with at least one dimension.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.atleast_2d\\n', '\\n', 'Reshapes inputs as arrays with at least two dimensions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.atleast_3d\\n', '\\n', 'Reshapes inputs as arrays with at least three dimensions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.broadcast_arrays\\n', '\\n', 'Broadcasts any number of arrays against each other.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.broadcast_to\\n', '\\n', 'Broadcasts an array to a new shape.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.choose\\n', '\\n', 'Construct an array from an index array and a list of arrays to choose from.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.column_stack\\n', '\\n', 'Stacks 1-D tensors as columns into a 2-D tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.concatenate\\n', '\\n', 'Joins a sequence of tensors along an existing axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.dsplit\\n', '\\n', 'Splits a tensor into multiple sub-tensors along the 3rd axis (depth).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.dstack\\n', '\\n', 'Stacks tensors in sequence depth wise (along the third axis).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.expand_dims\\n', '\\n', 'Expands the shape of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.flip\\n', '\\n', 'Reverses the order of elements in an array along the given axis.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.fliplr\\n', '\\n', 'Flips the entries in each row in the left/right direction.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.flipud\\n', '\\n', 'Flips the entries in each column in the up/down direction.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.hsplit\\n', '\\n', 'Splits a tensor into multiple sub-tensors horizontally (column-wise).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.hstack\\n', '\\n', 'Stacks tensors in sequence horizontally.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.moveaxis\\n', '\\n', 'Moves axes of an array to new positions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.piecewise\\n', '\\n', 'Evaluates a piecewise-defined function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ravel\\n', '\\n', 'Returns a contiguous flattened tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.repeat\\n', '\\n', 'Repeats elements of an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.reshape\\n', '\\n', 'Reshapes a tensor without changing its data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.roll\\n', '\\n', 'Rolls a tensor along given axes.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.rollaxis\\n', '\\n', 'Rolls the specified axis backwards, until it lies in the given position.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.rot90\\n', '\\n', 'Rotates a tensor by 90 degrees in the plane specified by axes.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.numpy.select\\n', '\\n', 'Returns an array drawn from elements in choicelist, depending on conditions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.size\\n', '\\n', 'Returns the number of elements along a given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.split\\n', '\\n', 'Splits a tensor into multiple sub-tensors along the given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.squeeze\\n', '\\n', 'Removes single-dimensional entries from the shape of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.stack\\n', '\\n', 'Joins a sequence of arrays along a new axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.swapaxes\\n', '\\n', 'Interchanges two axes of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.take\\n', '\\n', 'Takes elements from an array along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.take_along_axis\\n', '\\n', 'Takes values from the input array by matching 1d index and data slices.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tile\\n', '\\n', 'Constructs an array by repeating a the number of times given by reps.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.transpose\\n', '\\n', 'Reverses or permutes the axes of a tensor; returns the modified tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.unique\\n', '\\n', 'Finds the unique elements of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.unravel_index\\n', '\\n', 'Converts a flat index or array of flat indices into a tuple of coordinate arrays.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.vsplit\\n', '\\n', 'Splits a tensor into multiple sub-tensors vertically (row-wise).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.vstack\\n', '\\n', 'Stacks tensors in sequence vertically.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.where\\n', '\\n', 'Returns elements chosen from x or y depending on condition.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Logic\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.numpy.array_equal\\n', '\\n', 'Returns True if input arrays have same shapes and all elements equal.\\n', '\\n', 'GPU CPU Ascend\\n', '\\n', 'mindspore.numpy.array_equiv\\n', '\\n', 'Returns True if input arrays are shape consistent and all elements equal.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.equal\\n', '\\n', 'Returns the truth value of (x1 == x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.greater\\n', '\\n', 'Returns the truth value of (x1 > x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.greater_equal\\n', '\\n', 'Returns the truth value of (x1 >= x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.in1d\\n', '\\n', 'Tests whether each element of a 1-D array is also present in a second array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.isclose\\n', '\\n', 'Returns a boolean tensor where two tensors are element-wise equal within a tolerance.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.isfinite\\n', '\\n', 'Tests element-wise for finiteness (not infinity or not Not a Number).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.isin\\n', '\\n', 'Calculates element in test_elements, broadcasting over element only.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.isinf\\n', '\\n', 'Tests element-wise for positive or negative infinity.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.isnan\\n', '\\n', 'Tests element-wise for NaN and return result as a boolean array.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.isneginf\\n', '\\n', 'Tests element-wise for negative infinity, returns result as bool array.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.isposinf\\n', '\\n', 'Tests element-wise for positive infinity, returns result as bool array.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.isscalar\\n', '\\n', 'Returns True if the type of element is a scalar type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.less\\n', '\\n', 'Returns the truth value of (x1 < x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.less_equal\\n', '\\n', 'Returns the truth value of (x1 <= x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logical_and\\n', '\\n', 'Computes the truth value of x1 AND x2 element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logical_not\\n', '\\n', 'Computes the truth value of NOT a element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logical_or\\n', '\\n', 'Computes the truth value of x1 OR x2 element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logical_xor\\n', '\\n', 'Computes the truth value of x1 XOR x2, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.not_equal\\n', '\\n', 'Returns (x1 != x2) element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.signbit\\n', '\\n', 'Returns element-wise True where signbit is set (less than zero).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sometrue\\n', '\\n', 'Tests whether any array element along a given axis evaluates to True.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Math\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.numpy.absolute\\n', '\\n', 'Calculates the absolute value element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.add\\n', '\\n', 'Adds arguments element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.amax\\n', '\\n', 'Returns the maximum of an array or maximum along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.amin\\n', '\\n', 'Returns the minimum of an array or minimum along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arccos\\n', '\\n', 'Trigonometric inverse cosine, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arccosh\\n', '\\n', 'Inverse hyperbolic cosine, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arcsin\\n', '\\n', 'Inverse sine, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arcsinh\\n', '\\n', 'Inverse hyperbolic sine element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arctan\\n', '\\n', 'Trigonometric inverse tangent, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.arctan2\\n', '\\n', 'Element-wise arc tangent of x1/x2 choosing the quadrant correctly.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.numpy.arctanh\\n', '\\n', 'Inverse hyperbolic tangent element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.numpy.argmax\\n', '\\n', 'Returns the indices of the maximum values along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.argmin\\n', '\\n', 'Returns the indices of the minimum values along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.around\\n', '\\n', 'Evenly round to the given number of decimals.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.average\\n', '\\n', 'Computes the weighted average along the specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.bincount\\n', '\\n', 'Count number of occurrences of each value in array of non-negative ints.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.bitwise_and\\n', '\\n', 'Computes the bit-wise AND of two arrays element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.numpy.bitwise_or\\n', '\\n', 'Computes the bit-wise OR of two arrays element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.numpy.bitwise_xor\\n', '\\n', 'Computes the bit-wise XOR of two arrays element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.numpy.cbrt\\n', '\\n', 'Returns the cube-root of a tensor, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ceil\\n', '\\n', 'Returns the ceiling of the input, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.clip\\n', '\\n', 'Clips (limits) the values in an array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.convolve\\n', '\\n', 'Returns the discrete, linear convolution of two one-dimensional sequences.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.copysign\\n', '\\n', 'Changes the sign of x1 to that of x2, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.corrcoef\\n', '\\n', 'Returns Pearson product-moment correlation coefficients.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.correlate\\n', '\\n', 'Cross-correlation of two 1-dimensional sequences.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.numpy.cos\\n', '\\n', 'Cosine element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.cosh\\n', '\\n', 'Hyperbolic cosine, element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.numpy.count_nonzero\\n', '\\n', 'Counts the number of non-zero values in the tensor x.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.cov\\n', '\\n', 'Estimates a covariance matrix, given data and weights.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.cross\\n', '\\n', 'Returns the cross product of two (arrays of) vectors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.cumprod\\n', '\\n', 'Returns the cumulative product of elements along a given axis.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.numpy.cumsum\\n', '\\n', 'Returns the cumulative sum of the elements along a given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.deg2rad\\n', '\\n', 'Converts angles from degrees to radians.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.diff\\n', '\\n', 'Calculates the n-th discrete difference along the given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.digitize\\n', '\\n', 'Returns the indices of the bins to which each value in input array belongs.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.divide\\n', '\\n', 'Returns a true division of the inputs, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.divmod\\n', '\\n', 'Returns element-wise quotient and remainder simultaneously.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.dot\\n', '\\n', 'Returns the dot product of two arrays.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ediff1d\\n', '\\n', 'The differences between consecutive elements of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.exp\\n', '\\n', 'Calculates the exponential of all elements in the input array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.exp2\\n', '\\n', 'Calculates 2**p for all p in the input array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.expm1\\n', '\\n', 'Calculates exp(x) - 1 for all elements in the array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.fix\\n', '\\n', 'Rounds to nearest integer towards zero.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.float_power\\n', '\\n', 'First array elements raised to powers from second array, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.floor\\n', '\\n', 'Returns the floor of the input, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.floor_divide\\n', '\\n', 'Returns the largest integer smaller or equal to the division of the inputs.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.fmod\\n', '\\n', 'Returns the element-wise remainder of division.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.gcd\\n', '\\n', 'Returns the greatest common divisor of |x1| and |x2|.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.gradient\\n', '\\n', 'Returns the gradient of a N-dimensional array.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.heaviside\\n', '\\n', 'Computes the Heaviside step function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.histogram\\n', '\\n', 'Computes the histogram of a dataset.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.histogram2d\\n', '\\n', 'Computes the multidimensional histogram of some data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.histogramdd\\n', '\\n', 'Computes the multidimensional histogram of some data.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.hypot\\n', '\\n', 'Given the “legs” of a right triangle, returns its hypotenuse.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.inner\\n', '\\n', 'Returns the inner product of two tensors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.interp\\n', '\\n', 'One-dimensional linear interpolation for monotonically increasing sample points.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.invert\\n', '\\n', 'Computes bit-wise inversion, or bit-wise NOT, element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.numpy.kron\\n', '\\n', 'Kronecker product of two arrays.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.lcm\\n', '\\n', 'Returns the lowest common multiple of |x1| and |x2|.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.log\\n', '\\n', 'Returns the natural logarithm, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.log10\\n', '\\n', 'Base-10 logarithm of x.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.log1p\\n', '\\n', 'Returns the natural logarithm of one plus the input array, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.log2\\n', '\\n', 'Base-2 logarithm of x.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logaddexp\\n', '\\n', 'Logarithm of the sum of exponentiations of the inputs.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.logaddexp2\\n', '\\n', 'Logarithm of the sum of exponentiations of the inputs in base of 2.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.matmul\\n', '\\n', 'Returns the matrix product of two arrays.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.matrix_power\\n', '\\n', 'Raises a square matrix to the (integer) power n.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.maximum\\n', '\\n', 'Returns the element-wise maximum of array elements.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.mean\\n', '\\n', 'Computes the arithmetic mean along the specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.minimum\\n', '\\n', 'Element-wise minimum of tensor elements.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.multi_dot\\n', '\\n', 'Computes the dot product of two or more arrays in a single function call, while automatically selecting the fastest evaluation order.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.multiply\\n', '\\n', 'Multiplies arguments element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.nancumsum\\n', '\\n', 'Return the cumulative sum of array elements over a given axis treating Not a Numbers (NaNs) as zero.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanmax\\n', '\\n', 'Return the maximum of an array or maximum along an axis, ignoring any NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanmean\\n', '\\n', 'Computes the arithmetic mean along the specified axis, ignoring NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanmin\\n', '\\n', 'Returns the minimum of array elements over a given axis, ignoring any NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanstd\\n', '\\n', 'Computes the standard deviation along the specified axis, while ignoring NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nansum\\n', '\\n', 'Returns the sum of array elements over a given axis treating Not a Numbers (NaNs) as zero.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.nanvar\\n', '\\n', 'Computes the variance along the specified axis, while ignoring NaNs.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.numpy.negative\\n', '\\n', 'Numerical negative, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.norm\\n', '\\n', 'Matrix or vector norm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.outer\\n', '\\n', 'Computes the outer product of two vectors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polyadd\\n', '\\n', 'Finds the sum of two polynomials.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polyder\\n', '\\n', 'Returns the derivative of the specified order of a polynomial.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polyint\\n', '\\n', 'Returns an antiderivative (indefinite integral) of a polynomial.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polymul\\n', '\\n', 'Finds the product of two polynomials.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.numpy.polysub\\n', '\\n', 'Difference (subtraction) of two polynomials.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.polyval\\n', '\\n', 'Evaluates a polynomial at specific values.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.positive\\n', '\\n', 'Numerical positive, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.power\\n', '\\n', 'First array elements raised to powers from second array, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.promote_types\\n', '\\n', 'Returns the data type with the smallest size and smallest scalar kind.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ptp\\n', '\\n', 'Range of values (maximum - minimum) along an axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.rad2deg\\n', '\\n', 'Converts angles from radians to degrees.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.radians\\n', '\\n', 'Converts angles from degrees to radians.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.ravel_multi_index\\n', '\\n', 'Converts a tuple of index arrays into an array of flat indices, applying boundary modes to the multi-index.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.numpy.reciprocal\\n', '\\n', 'Returns the reciprocal of the argument, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.remainder\\n', '\\n', 'Returns element-wise remainder of division.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.result_type\\n', '\\n', 'Returns the type that results from applying the type promotion rules to the arguments.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.rint\\n', '\\n', 'Rounds elements of the array to the nearest integer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.searchsorted\\n', '\\n', 'Finds indices where elements should be inserted to maintain order.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sign\\n', '\\n', 'Returns an element-wise indication of the sign of a number.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sin\\n', '\\n', 'Trigonometric sine, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sinh\\n', '\\n', 'Hyperbolic sine, element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.numpy.sqrt\\n', '\\n', 'Returns the non-negative square-root of an array, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.square\\n', '\\n', 'Returns the element-wise square of the input.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.std\\n', '\\n', 'Computes the standard deviation along the specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.subtract\\n', '\\n', 'Subtracts arguments, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.sum\\n', '\\n', 'Returns sum of array elements over a given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tan\\n', '\\n', 'Computes tangent element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.numpy.tanh\\n', '\\n', 'Computes hyperbolic tangent element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.tensordot\\n', '\\n', 'Computes tensor dot product along specified axes.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.trapz\\n', '\\n', 'Integrates along the given axis using the composite trapezoidal rule.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.true_divide\\n', '\\n', 'Returns a true division of the inputs, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.trunc\\n', '\\n', 'Returns the truncated value of the input, element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.unwrap\\n', '\\n', 'Unwraps by changing deltas between values to 2*pi complement.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.numpy.var\\n', '\\n', 'Computes the variance along the specified axis.\\n', '\\n', 'Ascend GPU CPU']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.ops.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.ops.html", "text_entry": "['mindspore.ops\\n', 'Operators can be used in the construct function of Cell.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore.ops as ops\\n', 'Compared with the previous version, the added, deleted and supported platforms change information of mindspore.ops operators in MindSpore, please refer to the link https://gitee.com/mindspore/docs/blob/r1.6/resource/api_updates/ops_api_updates.md.\\n', '\\n', 'operations\\n', 'The Primitive operators in operations need to be instantiated before being used.\\n', '\\n', 'Neural Network Operators\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.Acosh\\n', '\\n', 'Computes inverse hyperbolic cosine of the inputs element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Adam\\n', '\\n', 'Updates gradients by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AdamNoUpdateParam\\n', '\\n', 'Updates gradients by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'CPU\\n', '\\n', 'mindspore.ops.AdamWeightDecay\\n', '\\n', 'Updates gradients by the Adaptive Moment Estimation algorithm with weight decay (AdamWeightDecay).\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.AdaptiveAvgPool2D\\n', '\\n', 'AdaptiveAvgPool2D operation.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.ApplyAdadelta\\n', '\\n', 'Updates relevant entries according to the adadelta scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyAdagrad\\n', '\\n', 'Updates relevant entries according to the adagrad scheme.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.ApplyAdagradDA\\n', '\\n', 'Update var according to the proximal adagrad scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyAdagradV2\\n', '\\n', 'Updates relevant entries according to the adagradv2 scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyAdaMax\\n', '\\n', 'Updates relevant entries according to the adamax scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyAddSign\\n', '\\n', 'Updates relevant entries according to the AddSign algorithm.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyCenteredRMSProp\\n', '\\n', 'Optimizer that implements the centered RMSProp algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ApplyGradientDescent\\n', '\\n', 'Updates var by subtracting alpha * delta from it.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ApplyMomentum\\n', '\\n', 'Optimizer that implements the Momentum algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ApplyPowerSign\\n', '\\n', 'Updates relevant entries according to the AddSign algorithm.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyProximalAdagrad\\n', '\\n', 'Updates relevant entries according to the proximal adagrad algorithm.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyProximalGradientDescent\\n', '\\n', 'Updates relevant entries according to the FOBOS(Forward Backward Splitting) algorithm.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ApplyRMSProp\\n', '\\n', 'Optimizer that implements the Root Mean Square prop(RMSProp) algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AvgPool\\n', '\\n', 'Average pooling operation.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AvgPool3D\\n', '\\n', '3D Average pooling operation.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BasicLSTMCell\\n', '\\n', 'It’s similar to operator DynamicRNN.\\n', '\\n', 'Deprecated\\n', '\\n', 'mindspore.ops.BatchNorm\\n', '\\n', 'Batch Normalization for input data and updated parameters.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.BCEWithLogitsLoss\\n', '\\n', 'Adds sigmoid activation function to input logits, and uses the given logits to compute binary cross entropy between the logits and the label.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.BiasAdd\\n', '\\n', 'Returns sum of input and bias tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.BinaryCrossEntropy\\n', '\\n', 'Computes the binary cross entropy between the logits and the labels.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ComputeAccidentalHits\\n', '\\n', 'Compute accidental hits of sampled classes which match target classes.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Conv2D\\n', '\\n', '2D convolution layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Conv2DBackpropInput\\n', '\\n', 'The Conv2DBackpropInput interface is deprecated, please refer to mindspore.ops.Conv2dTranspose if you want to do unsampling.\\n', '\\n', 'Deprecated\\n', '\\n', 'mindspore.ops.Conv2DTranspose\\n', '\\n', 'Compute a 2D transposed convolution, which is also known as a deconvolution (although it is not an actual deconvolution).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Conv3D\\n', '\\n', '3D convolution layer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Conv3DTranspose\\n', '\\n', 'Computes a 3D transposed convolution, which is also known as a deconvolution (although it is not an actual deconvolution).\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.CTCGreedyDecoder\\n', '\\n', 'Performs greedy decoding on the logits given in inputs.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.CTCLoss\\n', '\\n', 'Calculates the CTC (Connectionist Temporal Classification) loss and the gradient.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.DataFormatDimMap\\n', '\\n', 'Returns the dimension index in the destination data format given in the source data format.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.DepthwiseConv2dNative\\n', '\\n', 'DepthwiseConv2dNative will be deprecated in the future.\\n', '\\n', 'Deprecated\\n', '\\n', 'mindspore.ops.Dropout\\n', '\\n', 'During training, randomly zeroes some of the elements of the input tensor with probability 1-keep_prob from a Bernoulli distribution.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Dropout2D\\n', '\\n', 'During training, randomly zeroes some of the channels of the input tensor with probability 1-keep_prob from a Bernoulli distribution(For a 4-dimensional tensor with a shape of NCHW, the channel feature map refers to a 2-dimensional feature map with the shape of HW).\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Dropout3D\\n', '\\n', 'During training, randomly zeroes some of the channels of the input tensor with probability 1-keep_prob from a Bernoulli distribution(For a 5-dimensional tensor with a shape of NCDHW, the channel feature map refers to a 3-dimensional feature map with a shape of DHW).\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.DropoutDoMask\\n', '\\n', 'The DropoutDoMask interface is deprecated, please use the mindspore.ops.Dropout instead.\\n', '\\n', 'Deprecated\\n', '\\n', 'mindspore.ops.DropoutGenMask\\n', '\\n', 'The DropoutGenMask interface is deprecated, please use the mindspore.ops.Dropout instead.\\n', '\\n', 'Deprecated\\n', '\\n', 'mindspore.ops.DynamicGRUV2\\n', '\\n', 'Applies a single-layer gated recurrent unit (GRU) to an input sequence.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.DynamicRNN\\n', '\\n', 'Applies a recurrent neural network to the input.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Elu\\n', '\\n', 'Computes exponential linear:\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FastGeLU\\n', '\\n', 'Fast Gaussian Error Linear Units activation function.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Flatten\\n', '\\n', 'Flattens a tensor without changing its batch size on the 0-th axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FloorMod\\n', '\\n', 'Computes the remainder of division element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FusedSparseAdam\\n', '\\n', 'Merges the duplicate value of the gradient and then updates parameters by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.FusedSparseLazyAdam\\n', '\\n', 'Merges the duplicate value of the gradient and then updates parameters by the Adaptive Moment Estimation (Adam) algorithm.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.FusedSparseProximalAdagrad\\n', '\\n', 'Merges the duplicate value of the gradient and then updates relevant entries according to the proximal adagrad algorithm.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.GeLU\\n', '\\n', 'Gaussian Error Linear Units activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.GetNext\\n', '\\n', 'Returns the next element in the dataset queue.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.HShrink\\n', '\\n', 'Applies the hard shrinkage function element-wise, each element complies with the following function:\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.HSigmoid\\n', '\\n', 'Hard sigmoid activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.HSwish\\n', '\\n', 'Hard swish activation function.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.KLDivLoss\\n', '\\n', 'Computes the Kullback-Leibler divergence between the logits and the labels.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.L2Loss\\n', '\\n', 'Calculates half of the L2 norm of a tensor without sqrt.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.L2Normalize\\n', '\\n', 'L2 Normalization Operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LARSUpdate\\n', '\\n', 'Conducts LARS (layer-wise adaptive rate scaling) update on the sum of squares of gradient.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.LayerNorm\\n', '\\n', 'Applies the Layer Normalization to the input tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LogSoftmax\\n', '\\n', 'Log Softmax activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LRN\\n', '\\n', 'Local Response Normalization.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.LSTM\\n', '\\n', 'Performs the Long Short-Term Memory (LSTM) on the input.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.MaxPool\\n', '\\n', 'Max pooling operation.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MaxPool3D\\n', '\\n', '3D max pooling operation.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.MaxPoolWithArgmax\\n', '\\n', 'Performs max pooling on the input Tensor and returns both max values and indices.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.MirrorPad\\n', '\\n', 'Pads the input tensor according to the paddings and mode.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Mish\\n', '\\n', 'Computes MISH(A Self Regularized Non-Monotonic Neural Activation Function) of input tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.NLLLoss\\n', '\\n', 'Gets the negative log likelihood loss between logits and labels.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.OneHot\\n', '\\n', 'Computes a one-hot tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Pad\\n', '\\n', 'Pads the input tensor according to the paddings.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.PReLU\\n', '\\n', 'Parametric Rectified Linear Unit activation function.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ReLU\\n', '\\n', 'Computes ReLU (Rectified Linear Unit activation function) of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReLU6\\n', '\\n', 'Computes ReLU (Rectified Linear Unit) upper bounded by 6 of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReLUV2\\n', '\\n', 'Rectified Linear Unit activation function.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ResizeBilinear\\n', '\\n', 'Resizes an image to a certain size using the bilinear interpolation.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.RNNTLoss\\n', '\\n', 'Computes the RNNTLoss and its gradient with respect to the softmax outputs.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ROIAlign\\n', '\\n', 'Computes the Region of Interest (RoI) Align operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SeLU\\n', '\\n', 'Computes SeLU (scaled exponential Linear Unit) of input tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SGD\\n', '\\n', 'Computes the stochastic gradient descent.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Sigmoid\\n', '\\n', 'Sigmoid activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SigmoidCrossEntropyWithLogits\\n', '\\n', 'Uses the given logits to compute sigmoid cross entropy between the logits and the label.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SmoothL1Loss\\n', '\\n', 'Computes smooth L1 loss, a robust L1 loss.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SoftMarginLoss\\n', '\\n', 'SoftMarginLoss operation.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Softmax\\n', '\\n', 'Softmax operation.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SoftmaxCrossEntropyWithLogits\\n', '\\n', 'Gets the softmax cross-entropy value between logits and labels with one-hot encoding.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Softplus\\n', '\\n', 'Softplus activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SoftShrink\\n', '\\n', 'Applies the SoftShrink function element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Softsign\\n', '\\n', 'Softsign activation function.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SparseApplyAdagrad\\n', '\\n', 'Updates relevant entries according to the adagrad scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SparseApplyAdagradV2\\n', '\\n', 'Updates relevant entries according to the adagrad scheme, one more epsilon attribute than SparseApplyAdagrad.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SparseApplyProximalAdagrad\\n', '\\n', 'Updates relevant entries according to the proximal adagrad algorithm.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.SparseSoftmaxCrossEntropyWithLogits\\n', '\\n', 'Computes the softmax cross-entropy value between logits and sparse encoding labels.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.Stack\\n', '\\n', 'Stacks a list of tensors in specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Tanh\\n', '\\n', 'Tanh activation function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.TopK\\n', '\\n', 'Finds values and indices of the k largest entries along the last dimension.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Unstack\\n', '\\n', 'Unstacks tensor in specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Math Operators\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.Abs\\n', '\\n', 'Returns absolute value of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AccumulateNV2\\n', '\\n', 'Computes accumulation of all input tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ACos\\n', '\\n', 'Computes arccosine of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Add\\n', '\\n', 'Adds two input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AddN\\n', '\\n', 'Computes addition of all input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ApproximateEqual\\n', '\\n', 'Returns True if abs(x-y) is smaller than tolerance element-wise, otherwise False.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Asin\\n', '\\n', 'Computes arcsine of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Asinh\\n', '\\n', 'Computes inverse hyperbolic sine of the input element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AssignAdd\\n', '\\n', 'Updates a Parameter by adding a value to it.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.AssignSub\\n', '\\n', 'Updates a Parameter by subtracting a value from it.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Atan\\n', '\\n', 'Computes the trigonometric inverse tangent of the input element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Atan2\\n', '\\n', 'Returns arctangent of x/y element-wise.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.Atanh\\n', '\\n', 'Computes inverse hyperbolic tangent of the input element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.BatchMatMul\\n', '\\n', 'Computes matrix multiplication between two tensors by batch.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.BesselI0e\\n', '\\n', 'Computes BesselI0e of input element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BesselI1e\\n', '\\n', 'Computes BesselI1e of input element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BitwiseAnd\\n', '\\n', 'Returns bitwise and of two tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BitwiseOr\\n', '\\n', 'Returns bitwise or of two tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BitwiseXor\\n', '\\n', 'Returns bitwise xor of two tensors element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Cdist\\n', '\\n', 'Computes batched the p-norm distance between each pair of the two collections of row vectors.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Ceil\\n', '\\n', 'Rounds a tensor up to the closest integer element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Cos\\n', '\\n', 'Computes cosine of input element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Conj\\n', '\\n', 'Returns a tensor of complex numbers that are the complex conjugate of each element in input.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.Cosh\\n', '\\n', 'Computes hyperbolic cosine of input element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.CumProd\\n', '\\n', 'Computes the cumulative product of the tensor x along axis.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.CumSum\\n', '\\n', 'Computes the cumulative sum of input tensor along axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Div\\n', '\\n', 'Computes the quotient of dividing the first input tensor by the second input tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.DivNoNan\\n', '\\n', 'Computes a safe divide and returns 0 if the y is zero.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Eps\\n', '\\n', 'Creates a tensor filled with minimum value in x dtype.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Equal\\n', '\\n', 'Computes the equivalence between two tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.EqualCount\\n', '\\n', 'Computes the number of the same elements of two tensors.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.Erf\\n', '\\n', 'Computes the Gauss error function of x element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Erfc\\n', '\\n', 'Computes the complementary error function of x element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Erfinv\\n', '\\n', 'Computes the inverse error function of input.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Exp\\n', '\\n', 'Returns exponential of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Expm1\\n', '\\n', 'Returns exponential then minus 1 of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FloatStatus\\n', '\\n', 'Determines if the elements contain Not a Number(NaN), infinite or negative infinite.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.Floor\\n', '\\n', 'Rounds a tensor down to the closest integer element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FloorDiv\\n', '\\n', 'Divides the first input tensor by the second input tensor element-wise and round down to the closest integer.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Ger\\n', '\\n', 'Ger product of x1 and x2.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Greater\\n', '\\n', 'Computes the boolean value of x>y element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.GreaterEqual\\n', '\\n', 'Computes the boolean value of x>=y element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.HistogramFixedWidth\\n', '\\n', 'Returns a rank 1 histogram counting the number of entries in values that fall into every bin.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Imag\\n', '\\n', 'Returns a new tensor containing imaginary value of the input.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.IndexAdd\\n', '\\n', 'Adds tensor y to specified axis and indices of tensor x.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.InplaceAdd\\n', '\\n', 'Adds v into specified rows of x.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.InplaceSub\\n', '\\n', 'Subtracts v into specified rows of x.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Inv\\n', '\\n', 'Computes Reciprocal of input tensor element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Invert\\n', '\\n', 'Flips all bits of input tensor element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.IsInf\\n', '\\n', 'Determines which elements are inf or -inf for each position\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.IsNan\\n', '\\n', 'Determines which elements are NaN for each position.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.Lerp\\n', '\\n', 'Does a linear interpolation of two tensors start and end based on a float or tensor weight.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Less\\n', '\\n', 'Computes the boolean value of x<y element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LessEqual\\n', '\\n', 'Computes the boolean value of x<=y element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LinSpace\\n', '\\n', 'Returns a Tensor whose value is num evenly spaced in the interval start and stop (including start and stop), and the length of the output Tensor is num.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Log\\n', '\\n', 'Returns the natural logarithm of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Log1p\\n', '\\n', 'Returns the natural logarithm of one plus the input tensor element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.LogicalAnd\\n', '\\n', 'Computes the “logical AND” of two tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LogicalNot\\n', '\\n', 'Computes the “logical NOT” of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LogicalOr\\n', '\\n', 'Computes the “logical OR” of two tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.LpNorm\\n', '\\n', 'Returns the matrix norm or vector norm of a given tensor.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.MatMul\\n', '\\n', 'Multiplies matrix a and matrix b.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MatrixInverse\\n', '\\n', 'Returns the inverse of the input matrix.\\n', '\\n', 'GPU CPU\\n', '\\n', 'mindspore.ops.Maximum\\n', '\\n', 'Computes the maximum of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Minimum\\n', '\\n', 'Computes the minimum of input tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Mod\\n', '\\n', 'Computes the remainder of dividing the first input tensor by the second input tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Mul\\n', '\\n', 'Multiplies two tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MulNoNan\\n', '\\n', 'Computes x * y element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Neg\\n', '\\n', 'Returns a tensor with negative values of the input tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.NMSWithMask\\n', '\\n', 'When object detection problem is performed in the computer vision field, object detection algorithm generates a plurality of bounding boxes.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.NotEqual\\n', '\\n', 'Computes the non-equivalence of two tensors element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.NPUAllocFloatStatus\\n', '\\n', 'Allocates a flag to store the overflow status.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.NPUClearFloatStatus\\n', '\\n', 'Clears the flag which stores the overflow status.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.NPUGetFloatStatus\\n', '\\n', 'Updates the flag which is the output tensor of NPUAllocFloatStatus with the latest overflow status.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Pow\\n', '\\n', 'Computes a tensor to the power of the second input.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Real\\n', '\\n', 'Returns a Tensor that is the real part of the input.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.RealDiv\\n', '\\n', 'Divides the first input tensor by the second input tensor in floating-point type element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Reciprocal\\n', '\\n', 'Returns reciprocal of a tensor element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ReduceAll\\n', '\\n', 'Reduces a dimension of a tensor by the “logicalAND” of all elements in the dimension, by default.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceAny\\n', '\\n', 'Reduces a dimension of a tensor by the “logical OR” of all elements in the dimension, by default.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceMax\\n', '\\n', 'Reduces a dimension of a tensor by the maximum value in this dimension, by default.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceMean\\n', '\\n', 'Reduces a dimension of a tensor by averaging all elements in the dimension, by default.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceMin\\n', '\\n', 'Reduces a dimension of a tensor by the minimum value in the dimension, by default.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReduceProd\\n', '\\n', 'Reduces a dimension of a tensor by multiplying all elements in the dimension, by default.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ReduceSum\\n', '\\n', 'Reduces a dimension of a tensor by summing all elements in the dimension, by default.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Round\\n', '\\n', 'Returns half to even of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Rsqrt\\n', '\\n', 'Computes reciprocal of square root of input tensor element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Sign\\n', '\\n', 'Performs sign on the tensor element-wise.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.Sin\\n', '\\n', 'Computes sine of the input element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Sinh\\n', '\\n', 'Computes hyperbolic sine of the input element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.Sqrt\\n', '\\n', 'Returns square root of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Square\\n', '\\n', 'Returns square of a tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SquaredDifference\\n', '\\n', 'Subtracts the second input tensor from the first input tensor element-wise and returns square of it.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SquareSumAll\\n', '\\n', 'Returns the square sum of a tensor element-wise\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Sub\\n', '\\n', 'Subtracts the second input tensor from the first input tensor element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Tan\\n', '\\n', 'Computes tangent of x element-wise.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.TruncateDiv\\n', '\\n', 'Divides the first input tensor by the second input tensor element-wise for integer types, negative numbers will round fractional quantities towards zero.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.TruncateMod\\n', '\\n', 'Returns the remainder of division element-wise.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Xdivy\\n', '\\n', 'Divides the first input tensor by the second input tensor element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Xlogy\\n', '\\n', 'Computes the first input tensor multiplied by the logarithm of second input tensor element-wise.\\n', '\\n', 'Ascend\\n', '\\n', 'Array Operators\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.ApplyFtrl\\n', '\\n', 'Updates relevant entries according to the FTRL scheme.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Argmax\\n', '\\n', 'Returns the indices of the maximum value of a tensor across the axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ArgMaxWithValue\\n', '\\n', 'Calculates the maximum value with the corresponding index.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Argmin\\n', '\\n', 'Returns the indices of the minimum value of a tensor across the axis.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ArgMinWithValue\\n', '\\n', 'Calculates the minimum value with corresponding index, and returns indices and values.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.BatchToSpace\\n', '\\n', 'Divides batch dimension with blocks and interleaves these blocks back into spatial dimensions.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.BatchToSpaceND\\n', '\\n', 'Divides batch dimension with blocks and interleaves these blocks back into spatial dimensions.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.BroadcastTo\\n', '\\n', 'Broadcasts input tensor to a given shape.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Cast\\n', '\\n', 'Returns a tensor with the new specified data type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Concat\\n', '\\n', 'Connect tensor in the specified axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.DepthToSpace\\n', '\\n', 'Rearrange blocks of depth data into spatial dimensions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.DType\\n', '\\n', 'Returns the data type of the input tensor as mindspore.dtype.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.DynamicShape\\n', '\\n', 'Returns the shape of the input tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.EditDistance\\n', '\\n', 'Computes the Levenshtein Edit Distance.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.EmbeddingLookup\\n', '\\n', 'Returns a slice of input tensor based on the specified indices.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.ExpandDims\\n', '\\n', 'Adds an additional dimension to input_x at the given axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ExtractVolumePatches\\n', '\\n', 'Extract patches from input and put them in the “depth” output dimension.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Eye\\n', '\\n', 'Creates a tensor with ones on the diagonal and zeros in the rest.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Fill\\n', '\\n', 'Creates a tensor filled with a scalar value.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.FusedSparseFtrl\\n', '\\n', 'Merges the duplicate value of the gradient and then updates relevant entries according to the FTRL-proximal scheme.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.Gather\\n', '\\n', 'Returns a slice of the input tensor based on the specified indices and axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.GatherD\\n', '\\n', 'Gathers values along an axis specified by dim.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.GatherNd\\n', '\\n', 'Gathers slices from a tensor by indices.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Identity\\n', '\\n', 'Returns a Tensor with the same shape and contents as input.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.InplaceUpdate\\n', '\\n', 'Updates specified rows with values in v.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.InvertPermutation\\n', '\\n', 'Computes the inverse of an index permutation.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.IsFinite\\n', '\\n', 'Determines which elements are finite for each position.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.IsInstance\\n', '\\n', 'Checks whether an object is an instance of a target type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.IsSubClass\\n', '\\n', 'Checks whether this type is a sub-class of another type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.MaskedFill\\n', '\\n', 'Fills elements of self tensor with value where mask is True.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.MaskedSelect\\n', '\\n', 'Returns a new 1-D Tensor which indexes the input tensor according to the boolean mask.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.Meshgrid\\n', '\\n', 'Generates coordinate matrices from given coordinate tensors.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Ones\\n', '\\n', 'Creates a tensor filled with value ones.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.OnesLike\\n', '\\n', 'Creates a new tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Padding\\n', '\\n', 'Extends the last dimension of the input tensor from 1 to pad_dim_size, by filling with 0.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ParallelConcat\\n', '\\n', 'Concats tensor in the first dimension.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Randperm\\n', '\\n', 'Generates n random samples from 0 to n-1 without repeating.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Rank\\n', '\\n', 'Returns the rank of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Reshape\\n', '\\n', 'Reshapes the input tensor with the same values based on a given shape tuple.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ResizeNearestNeighbor\\n', '\\n', 'Resizes the input tensor by using the nearest neighbor algorithm.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ReverseSequence\\n', '\\n', 'Reverses variable length slices.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ReverseV2\\n', '\\n', 'Reverses specific dimensions of a tensor.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Rint\\n', '\\n', 'Returns an integer that is closest to x element-wise.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SameTypeShape\\n', '\\n', 'Checks whether the data type and shape of two tensors are the same.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScalarCast\\n', '\\n', 'Casts the input scalar to another type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScalarToArray\\n', '\\n', 'Converts a scalar to a Tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScalarToTensor\\n', '\\n', 'Converts a scalar to a Tensor, and converts the data type to the specified type.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScatterAdd\\n', '\\n', 'Updates the value of the input tensor through the addition operation.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScatterDiv\\n', '\\n', 'Updates the value of the input tensor through the divide operation.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.ScatterMax\\n', '\\n', 'Updates the value of the input tensor through the maximum operation.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.ScatterMin\\n', '\\n', 'Updates the value of the input tensor through the minimum operation.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.ScatterMul\\n', '\\n', 'Updates the value of the input tensor through the multiply operation.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.ScatterNd\\n', '\\n', 'Scatters a tensor into a new tensor depending on the specified indices.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScatterNdAdd\\n', '\\n', 'Applies sparse addition to individual values or slices in a tensor.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ScatterNdSub\\n', '\\n', 'Applies sparse subtraction to individual values or slices in a tensor.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ScatterNdUpdate\\n', '\\n', 'Updates tensor values by using input indices and value.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ScatterNonAliasingAdd\\n', '\\n', 'Applies sparse addition to the input using individual values or slices.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ScatterSub\\n', '\\n', 'Updates the value of the input tensor through the subtraction operation.\\n', '\\n', 'Ascend CPU GPU\\n', '\\n', 'mindspore.ops.ScatterUpdate\\n', '\\n', 'Updates tensor values by using input indices and value.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Select\\n', '\\n', 'Returns the selected elements, either from input x or input y, depending on the condition.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Shape\\n', '\\n', 'Returns the shape of the input tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Size\\n', '\\n', 'Returns the size of a Tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Slice\\n', '\\n', 'Slices a tensor in the specified shape.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Sort\\n', '\\n', 'Sorts the elements of the input tensor along a given dimension in ascending order by value.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SpaceToBatch\\n', '\\n', 'SpaceToBatch is deprecated.\\n', '\\n', 'Deprecated\\n', '\\n', 'mindspore.ops.SpaceToBatchND\\n', '\\n', 'Divides spatial dimensions into blocks and combines the block size with the original batch.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SpaceToDepth\\n', '\\n', 'Rearrange blocks of spatial data into depth.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SparseApplyFtrl\\n', '\\n', 'Updates relevant entries according to the FTRL-proximal scheme.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.SparseApplyFtrlV2\\n', '\\n', 'Updates relevant entries according to the FTRL-proximal scheme.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.SparseGatherV2\\n', '\\n', 'Returns a slice of input tensor based on the specified indices and axis.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.Split\\n', '\\n', 'Splits the input tensor into output_num of tensors along the given axis and output numbers.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.SplitV\\n', '\\n', 'Splits the input tensor into num_split tensors along the given dimension.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Squeeze\\n', '\\n', 'Returns a tensor with the same data type but dimensions of 1 are removed based on axis.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.StridedSlice\\n', '\\n', 'Extracts a strided slice of a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.TensorScatterAdd\\n', '\\n', 'Creates a new tensor by adding the values from the positions in input_x indicated by indices, with values from updates.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.TensorScatterMax\\n', '\\n', 'By comparing the value at the position indicated by the index in input_x with the value in the update, the value at the index will eventually be equal to the largest one to create a new tensor.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.TensorScatterMin\\n', '\\n', 'By comparing the value at the position indicated by the index in input_x with the value in the updates, the value at the index will eventually be equal to the smallest one to create a new tensor.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.TensorScatterSub\\n', '\\n', 'Creates a new tensor by subtracting the values from the positions in input_x indicated by indices, with values from updates.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.TensorScatterUpdate\\n', '\\n', 'Creates a new tensor by updating the positions in input_x indicated by indices, with values from update.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Tile\\n', '\\n', 'Replicates a tensor with given multiples times.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Transpose\\n', '\\n', 'Permutes the dimensions of the input tensor according to input permutation.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.TupleToArray\\n', '\\n', 'Converts a tuple to a tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Unique\\n', '\\n', 'Returns the unique elements of input tensor and also return a tensor containing the index of each value of input tensor corresponding to the output unique tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.UniqueWithPad\\n', '\\n', 'Returns unique elements and relative indexes in 1-D tensor, filled with padding num.\\n', '\\n', 'Ascend CPU\\n', '\\n', 'mindspore.ops.UnsortedSegmentMax\\n', '\\n', 'Computes the maximum along segments of a tensor.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.UnsortedSegmentMin\\n', '\\n', 'Computes the minimum of a tensor along segments.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.UnsortedSegmentProd\\n', '\\n', 'Computes the product of a tensor along segments.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.UnsortedSegmentSum\\n', '\\n', 'Computes the sum of a tensor along segments.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Zeros\\n', '\\n', 'Creates a tensor filled with value zeros.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ZerosLike\\n', '\\n', 'Creates a new tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Communication Operators\\n', 'Note that the APIs in the following list need to preset communication environment variables. For the Ascend devices, users need to prepare the rank table, set rank_id and device_id. Please see the Ascend tutorial for more details. For the GPU device, users need to prepare the host file and mpi, please see the GPU tutorial .\\n', '\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.AllGather\\n', '\\n', 'Gathers tensors from the specified communication group.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.AllReduce\\n', '\\n', 'Reduces the tensor data across all devices in such a way that all devices will get the same final result.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.AlltoAll\\n', '\\n', 'AlltoAll is a collective operation.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Broadcast\\n', '\\n', 'Broadcasts the tensor to the whole group.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.NeighborExchange\\n', '\\n', 'NeighborExchange is a collective operation.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.NeighborExchangeV2\\n', '\\n', 'NeighborExchangeV2 is a collective operation.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.ReduceOp\\n', '\\n', 'Operation options for reducing tensors.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ReduceScatter\\n', '\\n', 'Reduces and scatters tensors from the specified communication group.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'Debug Operators\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.HistogramSummary\\n', '\\n', 'Outputs the tensor to protocol buffer through histogram summary operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.HookBackward\\n', '\\n', 'This operation is used as a tag to hook gradient in intermediate variables.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.ImageSummary\\n', '\\n', 'Outputs the image tensor to protocol buffer through image summary operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.InsertGradientOf\\n', '\\n', 'Attaches callback to the graph node that will be invoked on the node’s gradient.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Print\\n', '\\n', 'Outputs the tensor or string to stdout.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.ScalarSummary\\n', '\\n', 'Outputs a scalar to a protocol buffer through a scalar summary operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.TensorSummary\\n', '\\n', 'Outputs a tensor to a protocol buffer through a tensor summary operator.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Random Operators\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.Gamma\\n', '\\n', 'Produces random positive floating-point values x, distributed according to probability density function:\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.LogUniformCandidateSampler\\n', '\\n', 'Generates random labels with a log-uniform distribution for sampled_candidates.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Multinomial\\n', '\\n', 'Returns a tensor sampled from the multinomial probability distribution located in the corresponding row of tensor input.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.Poisson\\n', '\\n', 'Produces random non-negative integer values i, distributed according to discrete probability function:\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.RandomCategorical\\n', '\\n', 'Generates random samples from a given categorical distribution tensor.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.RandomChoiceWithMask\\n', '\\n', 'Generates a random sample as index tensor with a mask tensor from a given tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.StandardLaplace\\n', '\\n', 'Generates random numbers according to the Laplace random number distribution (mean=0, lambda=1).\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.StandardNormal\\n', '\\n', 'Generates random numbers according to the standard Normal (or Gaussian) random number distribution.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.UniformCandidateSampler\\n', '\\n', 'Uniform candidate sampler.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.UniformInt\\n', '\\n', 'Produces random integer values i, uniformly distributed on the closed interval [minval, maxval), that is, distributed according to the discrete probability function:\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.UniformReal\\n', '\\n', 'Produces random floating-point values i, uniformly distributed to the interval [0, 1).\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Image Operators\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.CropAndResize\\n', '\\n', 'Extracts crops from the input image tensor and resizes them.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Sparse Operators\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.SparseToDense\\n', '\\n', 'Converts a sparse representation into a dense tensor.\\n', '\\n', 'CPU\\n', '\\n', 'mindspore.ops.SparseTensorDenseMatmul\\n', '\\n', 'Multiplies sparse matrix A by dense matrix B.\\n', '\\n', 'CPU\\n', '\\n', 'Custom Operators\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.Custom\\n', '\\n', 'Custom primitive is used for user defined operators and is to enhance the expressive ability of built-in primitives.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'Other Operators\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.Assign\\n', '\\n', 'Assigns Parameter with a value.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.BoundingBoxDecode\\n', '\\n', 'Decodes bounding boxes locations.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.BoundingBoxEncode\\n', '\\n', 'Encodes bounding boxes locations.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.CheckBprop\\n', '\\n', 'Checks whether the data type and the shape of corresponding elements from tuples x and y are the same.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.CheckValid\\n', '\\n', 'Checks bounding box.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.Depend\\n', '\\n', 'Depend is used for processing dependency operations.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.InTopK\\n', '\\n', 'Determines whether the targets are in the top k predictions.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'mindspore.ops.IOU\\n', '\\n', 'Calculates intersection over union for boxes.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.NoRepeatNGram\\n', '\\n', 'Updates log_probs with repeat n-grams.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Partial\\n', '\\n', 'Makes a partial function instance.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.PopulationCount\\n', '\\n', 'Calculates population count.\\n', '\\n', 'Ascend\\n', '\\n', 'composite\\n', 'The composite operators are the pre-defined combination of operators.\\n', '\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.batch_dot\\n', '\\n', 'Computation of batch dot product between samples in two tensors containing batch dims.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.clip_by_global_norm\\n', '\\n', 'Clips tensor values by the ratio of the sum of their norms.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.clip_by_value\\n', '\\n', 'Clips tensor values to a specified min and max.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.core\\n', '\\n', 'A decorator that adds a flag to the function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.count_nonzero\\n', '\\n', 'Count number of nonzero elements across axis of input tensor\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.cummin\\n', '\\n', 'Computation of the cumulative minimum of elements of ‘x’ in the dimension axis, and the index location of each maximum value found in the dimension ‘axis’.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.dot\\n', '\\n', 'Computation a dot product between samples in two tensors.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.gamma\\n', '\\n', 'Generates random numbers according to the Gamma random number distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.GradOperation\\n', '\\n', 'A higher-order function which is used to generate the gradient function for the input function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.HyperMap\\n', '\\n', 'Hypermap will apply the set operation to input sequences.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.laplace\\n', '\\n', 'Generates random numbers according to the Laplace random number distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.Map\\n', '\\n', 'Map will apply the set operation on input sequences.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.matmul\\n', '\\n', 'Returns the matrix product of two arrays.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.multinomial\\n', '\\n', 'Returns a tensor sampled from the multinomial probability distribution located in the corresponding row of the input tensor.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.MultitypeFuncGraph\\n', '\\n', 'Generates overloaded functions.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.normal\\n', '\\n', 'Generates random numbers according to the Normal (or Gaussian) random number distribution.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.poisson\\n', '\\n', 'Generates random numbers according to the Poisson random number distribution.\\n', '\\n', 'Ascend\\n', '\\n', 'mindspore.ops.repeat_elements\\n', '\\n', 'Repeat elements of a tensor along an axis, like np.repeat.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.sequence_mask\\n', '\\n', 'Returns a mask tensor representing the first N positions of each cell.\\n', '\\n', 'GPU\\n', '\\n', 'mindspore.ops.tensor_dot\\n', '\\n', 'Computation of Tensor contraction on arbitrary axes between tensors a and b.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.uniform\\n', '\\n', 'Generates random numbers according to the Uniform random number distribution.\\n', '\\n', 'Ascend GPU\\n', '\\n', 'functional\\n', 'The functional operators are the pre-instantiated Primitive operators, which can be used directly as a function. The use cases of some functional operators are as follows:\\n', '\\n', 'from mindspore import Tensor, ops\\n', 'from mindspore import dtype as mstype\\n', '\\n', 'input_x = Tensor(-1, mstype.int32)\\n', \"input_dict = {'x':1, 'y':2}\\n\", '\\n', 'result_abs = ops.absolute(input_x)\\n', 'print(result_abs)\\n', '\\n', \"result_in_dict = ops.in_dict('x', input_dict)\\n\", 'print(result_in_dict)\\n', '\\n', \"result_not_in_dict = ops.not_in_dict('x', input_dict)\\n\", 'print(result_not_in_dict)\\n', '\\n', 'result_isconstant = ops.isconstant(input_x)\\n', 'print(result_isconstant)\\n', '\\n', 'result_typeof = ops.typeof(input_x)\\n', 'print(result_typeof)\\n', '\\n', '# outputs:\\n', '# 1\\n', '# True\\n', '# False\\n', '# True\\n', '# Tensor[Int32]\\n', 'functional\\n', '\\n', 'Description\\n', '\\n', 'mindspore.ops.absolute\\n', '\\n', 'Refer to mindspore.ops.Abs.\\n', '\\n', 'mindspore.ops.acos\\n', '\\n', 'Refer to mindspore.ops.ACos.\\n', '\\n', 'mindspore.ops.acosh\\n', '\\n', 'Refer to mindspore.ops.Acosh.\\n', '\\n', 'mindspore.ops.add\\n', '\\n', 'Refer to mindspore.ops.Add.\\n', '\\n', 'mindspore.ops.addn\\n', '\\n', 'Refer to mindspore.ops.AddN.\\n', '\\n', 'mindspore.ops.asin\\n', '\\n', 'Refer to mindspore.ops.Asin.\\n', '\\n', 'mindspore.ops.asinh\\n', '\\n', 'Refer to mindspore.ops.Asinh.\\n', '\\n', 'mindspore.ops.assign\\n', '\\n', 'Refer to mindspore.ops.Assign.\\n', '\\n', 'mindspore.ops.assign_add\\n', '\\n', 'Refer to mindspore.ops.AssignAdd.\\n', '\\n', 'mindspore.ops.assign_sub\\n', '\\n', 'Refer to mindspore.ops.AssignSub.\\n', '\\n', 'mindspore.ops.atan\\n', '\\n', 'Refer to mindspore.ops.Atan.\\n', '\\n', 'mindspore.ops.atan2\\n', '\\n', 'Refer to mindspore.ops.Atan2.\\n', '\\n', 'mindspore.ops.atanh\\n', '\\n', 'Refer to mindspore.ops.Atanh.\\n', '\\n', 'mindspore.ops.bitwise_and\\n', '\\n', 'Refer to mindspore.ops.BitwiseAnd.\\n', '\\n', 'mindspore.ops.bitwise_or\\n', '\\n', 'Refer to mindspore.ops.BitwiseOr.\\n', '\\n', 'mindspore.ops.bitwise_xor\\n', '\\n', 'Refer to mindspore.ops.BitwiseXor.\\n', '\\n', 'mindspore.ops.bool_and\\n', '\\n', 'Calculate the result of logical AND operation. (Usage is the same as “and” in Python)\\n', '\\n', 'mindspore.ops.bool_eq\\n', '\\n', 'Determine whether the Boolean values are equal. (Usage is the same as “==” in Python)\\n', '\\n', 'mindspore.ops.bool_not\\n', '\\n', 'Calculate the result of logical NOT operation. (Usage is the same as “not” in Python)\\n', '\\n', 'mindspore.ops.bool_or\\n', '\\n', 'Calculate the result of logical OR operation. (Usage is the same as “or” in Python)\\n', '\\n', 'mindspore.ops.cast\\n', '\\n', 'Refer to mindspore.ops.Cast.\\n', '\\n', 'mindspore.ops.cos\\n', '\\n', 'Refer to mindspore.ops.Cos.\\n', '\\n', 'mindspore.ops.cosh\\n', '\\n', 'Refer to mindspore.ops.Cosh.\\n', '\\n', 'mindspore.ops.cumprod\\n', '\\n', 'Refer to mindspore.ops.CumProd.\\n', '\\n', 'mindspore.ops.cumsum\\n', '\\n', 'Refer to mindspore.ops.CumSum.\\n', '\\n', 'mindspore.ops.div\\n', '\\n', 'Refer to mindspore.ops.RealDiv.\\n', '\\n', 'mindspore.ops.depend\\n', '\\n', 'Refer to mindspore.ops.Depend.\\n', '\\n', 'mindspore.ops.dtype\\n', '\\n', 'Refer to mindspore.ops.DType.\\n', '\\n', 'mindspore.ops.erf\\n', '\\n', 'Refer to mindspore.ops.Erf.\\n', '\\n', 'mindspore.ops.erfc\\n', '\\n', 'Refer to mindspore.ops.Erfc.\\n', '\\n', 'mindspore.ops.eye\\n', '\\n', 'Refer to mindspore.ops.Eye.\\n', '\\n', 'mindspore.ops.equal\\n', '\\n', 'Refer to mindspore.ops.Equal.\\n', '\\n', 'mindspore.ops.expand_dims\\n', '\\n', 'Refer to mindspore.ops.ExpandDims.\\n', '\\n', 'mindspore.ops.exp\\n', '\\n', 'Refer to mindspore.ops.Exp.\\n', '\\n', 'mindspore.ops.fill\\n', '\\n', 'Refer to mindspore.ops.Fill.\\n', '\\n', 'mindspore.ops.floor\\n', '\\n', 'Refer to mindspore.ops.Floor.\\n', '\\n', 'mindspore.ops.floordiv\\n', '\\n', 'Refer to mindspore.ops.FloorDiv.\\n', '\\n', 'mindspore.ops.floormod\\n', '\\n', 'Refer to mindspore.ops.FloorMod.\\n', '\\n', 'mindspore.ops.gather\\n', '\\n', 'Refer to mindspore.ops.Gather.\\n', '\\n', 'mindspore.ops.gather_d\\n', '\\n', 'Refer to mindspore.ops.GatherD.\\n', '\\n', 'mindspore.ops.gather_nd\\n', '\\n', 'Refer to mindspore.ops.GatherNd.\\n', '\\n', 'mindspore.ops.ge\\n', '\\n', 'Refer to mindspore.ops.GreaterEqual.\\n', '\\n', 'mindspore.ops.gt\\n', '\\n', 'Refer to mindspore.ops.Greater.\\n', '\\n', 'mindspore.ops.invert\\n', '\\n', 'Refer to mindspore.ops.Invert.\\n', '\\n', 'mindspore.ops.in_dict\\n', '\\n', 'Determine if a str in dict.\\n', '\\n', 'mindspore.ops.is_not\\n', '\\n', 'Determine whether the input is not the same as the other one. (Usage is the same as “is not” in Python)\\n', '\\n', 'mindspore.ops.is_\\n', '\\n', 'Determine whether the input is the same as the other one. (Usage is the same as “is” in Python)\\n', '\\n', 'mindspore.ops.isconstant\\n', '\\n', 'Determine whether the object is constant.\\n', '\\n', 'mindspore.ops.isfinite\\n', '\\n', 'Refer to mindspore.ops.IsFinite.\\n', '\\n', 'mindspore.ops.isinstance_\\n', '\\n', 'Refer to mindspore.ops.IsInstance.\\n', '\\n', 'mindspore.ops.isnan\\n', '\\n', 'Refer to mindspore.ops.IsNan.\\n', '\\n', 'mindspore.ops.issubclass_\\n', '\\n', 'Refer to mindspore.ops.IsSubClass.\\n', '\\n', 'mindspore.ops.log\\n', '\\n', 'Refer to mindspore.ops.Log.\\n', '\\n', 'mindspore.ops.logical_and\\n', '\\n', 'Refer to mindspore.ops.LogicalAnd.\\n', '\\n', 'mindspore.ops.le\\n', '\\n', 'Refer to mindspore.ops.LessEqual.\\n', '\\n', 'mindspore.ops.less\\n', '\\n', 'Refer to mindspore.ops.Less.\\n', '\\n', 'mindspore.ops.logical_and\\n', '\\n', 'Refer to mindspore.ops.LogicalAnd.\\n', '\\n', 'mindspore.ops.logical_not\\n', '\\n', 'Refer to mindspore.ops.LogicalNot.\\n', '\\n', 'mindspore.ops.logical_or\\n', '\\n', 'Refer to mindspore.ops.LogicalOr.\\n', '\\n', 'mindspore.ops.maximum\\n', '\\n', 'Refer to mindspore.ops.Maximum.\\n', '\\n', 'mindspore.ops.minimum\\n', '\\n', 'Refer to mindspore.ops.Minimum.\\n', '\\n', 'mindspore.ops.mul\\n', '\\n', 'Refer to mindspore.ops.Mul.\\n', '\\n', 'mindspore.ops.neg_tensor\\n', '\\n', 'Refer to mindspore.ops.Neg.\\n', '\\n', 'mindspore.ops.not_equal\\n', '\\n', 'Refer to mindspore.ops.NotEqual.\\n', '\\n', 'mindspore.ops.not_in_dict\\n', '\\n', 'Determine whether the object is not in the dict.\\n', '\\n', 'mindspore.ops.ones_like\\n', '\\n', 'Refer to mindspore.ops.OnesLike.\\n', '\\n', 'mindspore.ops.partial\\n', '\\n', 'Refer to mindspore.ops.Partial.\\n', '\\n', 'mindspore.ops.pows\\n', '\\n', 'Refer to mindspore.ops.Pow.\\n', '\\n', 'mindspore.ops.print_\\n', '\\n', 'Refer to mindspore.ops.Print.\\n', '\\n', 'mindspore.ops.rank\\n', '\\n', 'Refer to mindspore.ops.Rank.\\n', '\\n', 'mindspore.ops.reduce_max\\n', '\\n', 'Refer to mindspore.ops.ReduceMax.\\n', '\\n', 'mindspore.ops.reduce_mean\\n', '\\n', 'Refer to mindspore.ops.ReduceMean.\\n', '\\n', 'mindspore.ops.reduce_min\\n', '\\n', 'Refer to mindspore.ops.ReduceMin.\\n', '\\n', 'mindspore.ops.reduce_prod\\n', '\\n', 'Refer to mindspore.ops.ReduceProd.\\n', '\\n', 'mindspore.ops.reduce_sum\\n', '\\n', 'Refer to mindspore.ops.ReduceSum.\\n', '\\n', 'mindspore.ops.reshape\\n', '\\n', 'Refer to mindspore.ops.Reshape.\\n', '\\n', 'mindspore.ops.same_type_shape\\n', '\\n', 'Refer to mindspore.ops.SameTypeShape.\\n', '\\n', 'mindspore.ops.scalar_add\\n', '\\n', 'Get the sum of two numbers. (Usage is the same as “+” in Python)\\n', '\\n', 'mindspore.ops.scalar_cast\\n', '\\n', 'Refer to mindspore.ops.ScalarCast.\\n', '\\n', 'mindspore.ops.check_bprop\\n', '\\n', 'Refer to mindspore.ops.CheckBprop.\\n', '\\n', 'mindspore.ops.scalar_div\\n', '\\n', 'Get the quotient of dividing the first input number by the second input number. (Usage is the same as “/” in Python)\\n', '\\n', 'mindspore.ops.scalar_eq\\n', '\\n', 'Determine whether two numbers are equal. (Usage is the same as “==” in Python)\\n', '\\n', 'mindspore.ops.scalar_floordiv\\n', '\\n', 'Divide the first input number by the second input number and round down to the closest integer. (Usage is the same as “//” in Python)\\n', '\\n', 'mindspore.ops.scalar_ge\\n', '\\n', 'Determine whether the number is greater than or equal to another number. (Usage is the same as “>=” in Python)\\n', '\\n', 'mindspore.ops.scalar_gt\\n', '\\n', 'Determine whether the number is greater than another number. (Usage is the same as “>” in Python)\\n', '\\n', 'mindspore.ops.scalar_le\\n', '\\n', 'Determine whether the number is less than or equal to another number. (Usage is the same as “<=” in Python)\\n', '\\n', 'mindspore.ops.scalar_log\\n', '\\n', 'Get the natural logarithm of the input number.\\n', '\\n', 'mindspore.ops.scalar_lt\\n', '\\n', 'Determine whether the number is less than another number. (Usage is the same as “<” in Python)\\n', '\\n', 'mindspore.ops.scalar_mod\\n', '\\n', 'Get the remainder of dividing the first input number by the second input number. (Usage is the same as “%” in Python)\\n', '\\n', 'mindspore.ops.scalar_mul\\n', '\\n', 'Get the product of the input two numbers. (Usage is the same as “*” in Python)\\n', '\\n', 'mindspore.ops.scalar_ne\\n', '\\n', 'Determine whether two numbers are not equal. (Usage is the same as “!=” in Python)\\n', '\\n', 'mindspore.ops.scalar_pow\\n', '\\n', 'Compute a number to the power of the second input number.\\n', '\\n', 'mindspore.ops.scalar_sub\\n', '\\n', 'Subtract the second input number from the first input number. (Usage is the same as “-” in Python)\\n', '\\n', 'mindspore.ops.scalar_to_array\\n', '\\n', 'Refer to mindspore.ops.ScalarToArray.\\n', '\\n', 'mindspore.ops.scalar_to_tensor\\n', '\\n', 'Refer to mindspore.ops.ScalarToTensor.\\n', '\\n', 'mindspore.ops.scalar_uadd\\n', '\\n', 'Get the positive value of the input number.\\n', '\\n', 'mindspore.ops.scalar_usub\\n', '\\n', 'Get the negative value of the input number.\\n', '\\n', 'mindspore.ops.scatter_nd\\n', '\\n', 'Refer to mindspore.ops.ScatterNd.\\n', '\\n', 'mindspore.ops.scatter_nd_update\\n', '\\n', 'Refer to mindspore.ops.ScatterNdUpdate.\\n', '\\n', 'mindspore.ops.scatter_update\\n', '\\n', 'Refer to mindspore.ops.ScatterUpdate.\\n', '\\n', 'mindspore.ops.shape\\n', '\\n', 'Refer to mindspore.ops.Shape.\\n', '\\n', 'mindspore.ops.shape_mul\\n', '\\n', 'The input of shape_mul must be shape multiply elements in tuple(shape).\\n', '\\n', 'mindspore.ops.sin\\n', '\\n', 'Refer to mindspore.ops.Sin.\\n', '\\n', 'mindspore.ops.sinh\\n', '\\n', 'Refer to mindspore.ops.Sinh.\\n', '\\n', 'mindspore.ops.size\\n', '\\n', 'Refer to mindspore.ops.Size.\\n', '\\n', 'mindspore.ops.sort\\n', '\\n', 'Refer to mindspore.ops.Sort.\\n', '\\n', 'mindspore.ops.sqrt\\n', '\\n', 'Refer to mindspore.ops.Sqrt.\\n', '\\n', 'mindspore.ops.square\\n', '\\n', 'Refer to mindspore.ops.Square.\\n', '\\n', 'mindspore.ops.squeeze\\n', '\\n', 'Refer to mindspore.ops.Squeeze.\\n', '\\n', 'mindspore.ops.stack\\n', '\\n', 'Refer to mindspore.ops.Stack.\\n', '\\n', 'mindspore.ops.stop_gradient\\n', '\\n', 'Disable update during back propagation. (stop_gradient)\\n', '\\n', 'mindspore.ops.strided_slice\\n', '\\n', 'Refer to mindspore.ops.StridedSlice.\\n', '\\n', 'mindspore.ops.string_concat\\n', '\\n', 'Concatenate two strings.\\n', '\\n', 'mindspore.ops.string_eq\\n', '\\n', 'Determine if two strings are equal.\\n', '\\n', 'mindspore.ops.sub\\n', '\\n', 'Refer to mindspore.ops.Sub.\\n', '\\n', 'mindspore.ops.tan\\n', '\\n', 'Refer to mindspore.ops.Tan.\\n', '\\n', 'mindspore.ops.tanh\\n', '\\n', 'Refer to mindspore.ops.Tanh.\\n', '\\n', 'mindspore.ops.tensor_add\\n', '\\n', 'Refer to mindspore.ops.Add.\\n', '\\n', 'mindspore.ops.tensor_div\\n', '\\n', 'Refer to mindspore.ops.RealDiv.\\n', '\\n', 'mindspore.ops.tensor_exp\\n', '\\n', 'Refer to mindspore.ops.Exp.\\n', '\\n', 'mindspore.ops.tensor_expm1\\n', '\\n', 'Refer to mindspore.ops.Expm1.\\n', '\\n', 'mindspore.ops.tensor_floordiv\\n', '\\n', 'Refer to mindspore.ops.FloorDiv.\\n', '\\n', 'mindspore.ops.tensor_ge\\n', '\\n', 'Refer to mindspore.ops.GreaterEqual.\\n', '\\n', 'mindspore.ops.tensor_gt\\n', '\\n', 'Refer to mindspore.ops.Greater.\\n', '\\n', 'mindspore.ops.tensor_le\\n', '\\n', 'Refer to mindspore.ops.LessEqual.\\n', '\\n', 'mindspore.ops.tensor_lt\\n', '\\n', 'Refer to mindspore.ops.Less.\\n', '\\n', 'mindspore.ops.tensor_mod\\n', '\\n', 'Refer to mindspore.ops.FloorMod.\\n', '\\n', 'mindspore.ops.tensor_mul\\n', '\\n', 'Refer to mindspore.ops.Mul.\\n', '\\n', 'mindspore.ops.tensor_pow\\n', '\\n', 'Refer to mindspore.ops.Pow.\\n', '\\n', 'mindspore.ops.tensor_scatter_add\\n', '\\n', 'Refer to mindspore.ops.TensorScatterAdd.\\n', '\\n', 'mindspore.ops.tensor_scatter_update\\n', '\\n', 'Refer to mindspore.ops.TensorScatterUpdate.\\n', '\\n', 'mindspore.ops.tensor_slice\\n', '\\n', 'Refer to mindspore.ops.Slice.\\n', '\\n', 'mindspore.ops.tensor_sub\\n', '\\n', 'Refer to mindspore.ops.Sub.\\n', '\\n', 'mindspore.ops.tile\\n', '\\n', 'Refer to mindspore.ops.Tile.\\n', '\\n', 'mindspore.ops.transpose\\n', '\\n', 'Refer to mindspore.ops.Transpose.\\n', '\\n', 'mindspore.ops.tuple_to_array\\n', '\\n', 'Refer to mindspore.ops.TupleToArray.\\n', '\\n', 'mindspore.ops.typeof\\n', '\\n', 'Get type of object.\\n', '\\n', 'mindspore.ops.zeros_like\\n', '\\n', 'Refer to mindspore.ops.ZerosLike.\\n', '\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.ops.grad\\n', '\\n', 'A wrapper function to generate the gradient function for the input function.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.jvp\\n', '\\n', 'Compute the jacobian-vector-product of the given network.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.narrow\\n', '\\n', 'Returns a narrowed tensor from input tensor.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.select\\n', '\\n', 'Returns the selected elements, either from input x or input y, depending on the condition cond.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'mindspore.ops.vjp\\n', '\\n', 'Compute the vector-jacobian-product of the given network.\\n', '\\n', 'Ascend GPU CPU\\n', '\\n', 'primitive\\n', 'mindspore.ops.constexpr\\n', '\\n', 'Creates a PrimitiveWithInfer operator that can infer the value at compile time.\\n', '\\n', 'mindspore.ops.prim_attr_register\\n', '\\n', 'Primitive attributes register.\\n', '\\n', 'mindspore.ops.Primitive\\n', '\\n', 'Primitive is the base class of operator primitives in python.\\n', '\\n', 'mindspore.ops.PrimitiveWithCheck\\n', '\\n', 'PrimitiveWithCheck is the base class of primitives in python defines functions for checking operator input arguments but used the infer method registered in c++ source codes.\\n', '\\n', 'mindspore.ops.PrimitiveWithInfer\\n', '\\n', 'PrimitiveWithInfer is the base class of primitives in python and defines functions for tracking inference in python.\\n', '\\n', 'vm_impl_registry\\n', 'mindspore.ops.get_vm_impl_fn\\n', '\\n', 'Gets the virtual implementation function by a primitive object or primitive name.\\n', '\\n', 'op_info_register\\n', 'mindspore.ops.AiCPURegOp\\n', '\\n', 'Class for AiCPU operator information register.\\n', '\\n', 'mindspore.ops.custom_info_register\\n', '\\n', 'A decorator which is used to bind the registration information to the func parameter of mindspore.ops.Custom.\\n', '\\n', 'mindspore.ops.CustomRegOp\\n', '\\n', 'Class used for generating the registration information for the func parameter of mindspore.ops.Custom.\\n', '\\n', 'mindspore.ops.DataType\\n', '\\n', 'Various combinations of dtype and format of Ascend ops.\\n', '\\n', 'mindspore.ops.op_info_register\\n', '\\n', 'A decorator which is used to register an operator.\\n', '\\n', 'mindspore.ops.TBERegOp\\n', '\\n', 'Class for TBE operator information register.']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.parallel.nn.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.parallel.nn.html", "text_entry": "['mindspore.parallel.nn\\n', 'The import path of Transformer APIs have been modified from mindspore.parallel.nn to mindspore.nn.transformer, while the usage of these APIs stay unchanged. The original import path will retain one or two versions. You can view the changes using the examples described below\\n', '\\n', '# r1.5\\n', 'from mindspore.parallel.nn import Transformer\\n', '\\n', '# Current\\n', 'from mindspore.nn.transformer import Transformer']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.parallel.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.parallel.html", "text_entry": "['mindspore.parallel\\n', 'Interfaces for parallel-related functionality\\n', '\\n', 'mindspore.parallel.set_algo_parameters(**kwargs)[source]\\n', 'Set parameters in the algorithm for parallel strategy searching. See a typical use in test_auto_parallel_resnet.py.\\n', '\\n', 'Note\\n', '\\n', 'The attribute name is required. This interface works ONLY in AUTO_PARALLEL mode.\\n', '\\n', 'Parameters\\n', 'fully_use_devices (bool) – Whether ONLY searching strategies that fully use all available devices. Default: True. For example with 8 devices available, if set true, strategy (4, 1) will not be included in ReLU’s candidate strategies, because strategy (4, 1) only utilizes 4 devices.\\n', '\\n', 'elementwise_op_strategy_follow (bool) – Whether the elementwise operator has the consistent strategies as its subsequent operators. Default: False. For the example of ReLU followed by Add, where ReLU is elementwise operator, if this flag is set true, then the searched strategy by the algorithm guarantees that strategies of these two operators are consistent, e.g., ReLU’s strategy (8, 1) and Add’s strategy ((8, 1), (8, 1)).\\n', '\\n', 'enable_algo_approxi (bool) – Whether to enable the approximation in the algorithms. Default: False. Due to large solution space in searching parallel strategy for large DNN model, the algorithm takes fairly long time in this case. To mitigate it, if this flag is set true, an approximation is made to discard some candidate strategies, so that the solution space is shrunken.\\n', '\\n', 'algo_approxi_epsilon (float) – The epsilon value used in the approximation algorithm. Default: 0.1. This value describes the extent of approximation. For example, the number of candidate strategies of an operator is S, if ‘enable_algo_approxi’ is true, then the remaining strategies is of size: min{S, 1/epsilon}.\\n', '\\n', 'tensor_slice_align_enable (bool) – Whether to check the shape of tensor slice of MatMul. Default: False. Due to properties of some hardware, MatMul kernel only with large shapes can show advantages. If this flag is true, then the slice shape of MatMul is checked to prevent irregular shapes.\\n', '\\n', 'tensor_slice_align_size (int) – The minimum tensor slice shape of MatMul, the value must be in [1, 1024]. Default: 16. If ‘tensor_slice_align_enable’ is set true, then the slice size of last dimension of MatMul tensors should be multiple of this value.\\n', '\\n', 'Raises\\n', 'ValueError – If context keyword is not recognized.\\n', '\\n', 'mindspore.parallel.reset_algo_parameters()[source]\\n', 'Reset the algorithm parameter attributes.\\n', '\\n', 'Note\\n', '\\n', 'This interface works ONLY in AUTO_PARALLEL mode.\\n', '\\n', 'After reset, the values of the attributes are:\\n', '\\n', 'fully_use_devices: True.\\n', '\\n', 'elementwise_op_strategy_follow: False.\\n', '\\n', 'enable_algo_approxi: False.\\n', '\\n', 'algo_approxi_epsilon: 0.1.\\n', '\\n', 'tensor_slice_align_enable: False.\\n', '\\n', 'tensor_slice_align_size: 16.\\n', '\\n', 'mindspore.parallel.get_algo_parameters(attr_key)[source]\\n', 'Get the algorithm parameter config attributes.\\n', '\\n', 'Note\\n', '\\n', 'The attribute name is required. This interface works ONLY in AUTO_PARALLEL mode.\\n', '\\n', 'Parameters\\n', 'attr_key (str) – The key of the attribute. The keys include: “fully_use_devices”, “elementwise_op_strategy_follow”, “enable_algo_approxi”, “algo_approxi_epsilon”, “tensor_slice_align_enable”,”tensor_slice_align_size”.\\n', '\\n', 'Returns\\n', 'Return attribute value according to the key.\\n', '\\n', 'Raises\\n', 'ValueError – If context keyword is not recognized.']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.profiler.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.profiler.html", "text_entry": "['mindspore.profiler\\n', 'Profiler Module Introduction.\\n', '\\n', 'This module provides Python APIs to enable the profiling of MindSpore neural networks. Users can import the mindspore.profiler.Profiler, initialize the Profiler object to start profiling, and use Profiler.analyse() to stop profiling and analyse the results. To visualize the profiling results, users can open MindSpore Web, find the corresponding ‘run’ button/option and click the profile link. Now, Profiler supports the AICore operator analysis.\\n', '\\n', 'classmindspore.profiler.Profiler(**kwargs)[source]\\n', 'Performance profiling API.\\n', '\\n', 'This API enables MindSpore users to profile the performance of neural network. Profiler supports Ascend and GPU, both of them are used in the same way, but only output_path in args works on GPU. And it can only be initialized once.\\n', '\\n', 'Parameters\\n', 'output_path (str) – Output data path.\\n', '\\n', 'optypes_not_deal (str) – This parameter is deprecated. (Ascend only) Op type names, determine the data of which optype should be collected and analysed, will deal with all op if null. Different op types should be separated by comma.\\n', '\\n', 'ascend_job_id (str) – This parameter is deprecated. (Ascend only) The directory where the profiling files to be parsed are located. This parameter is used to support offline parsing.\\n', '\\n', 'profile_communication (bool) – Whether to collect communication performance data in a multi devices training, collect when True. Default is False. Setting this parameter has no effect during single device training.\\n', '\\n', 'profile_memory (bool) – Whether to collect tensor memory data, collect when True. Default is False.\\n', '\\n', 'start_profile (bool) – The start_profile parameter controls whether to enable or disable performance data collection based on conditions. The default value is True.\\n', '\\n', 'Raises\\n', 'RuntimeError – If ascend_job_id is transferred with data that does not match the current MindSpore version.\\n', '\\n', 'Examples\\n', '\\n', 'import numpy as np\\n', 'from mindspore import nn, context\\n', 'from mindspore import Model\\n', 'import mindspore.dataset as ds\\n', 'from mindspore.profiler import Profiler\\n', '\\n', '\\n', 'class Net(nn.Cell):\\n', '    def __init__(self):\\n', '        super(Net, self).__init__()\\n', '        self.fc = nn.Dense(2,2)\\n', '    def construct(self, x):\\n', '        return self.fc(x)\\n', '\\n', 'def generator():\\n', '    for i in range(2):\\n', '        yield (np.ones([2, 2]).astype(np.float32), np.ones([2]).astype(np.int32))\\n', '\\n', 'def train(net):\\n', '    optimizer = nn.Momentum(net.trainable_params(), 1, 0.9)\\n', '    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\\n', '    data = ds.GeneratorDataset(generator, [\"data\", \"label\"])\\n', '    model = Model(net, loss, optimizer)\\n', '    model.train(1, data)\\n', '\\n', \"if __name__ == '__main__':\\n\", '    # If the device_target is GPU, set the device_target to \"GPU\"\\n', '    context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\")\\n', '\\n', '    # Init Profiler\\n', '    # Note that the Profiler should be initialized after context.set_context and before model.train\\n', '    # If you are running in parallel mode on Ascend, the Profiler should be initialized before HCCL\\n', '    # initialized.\\n', '    profiler = Profiler()\\n', '\\n', '    # Train Model\\n', '    net = Net()\\n', '    train(net)\\n', '\\n', '    # Profiler end\\n', '    profiler.analyse()\\n', 'analyse()[source]\\n', 'Collect and analyse performance data, called after training or during training. The example shows above.\\n', '\\n', 'staticprofile(network, profile_option)[source]\\n', 'Get the number of trainable parameters in the training network.\\n', '\\n', 'Parameters\\n', 'network (Cell) – The training network.\\n', '\\n', 'profile_option (ProfileOption) – The profile option.\\n', '\\n', 'Returns\\n', 'dict, the key is the option name, the value is the result of option.\\n', '\\n', 'start()[source]\\n', 'Used for Ascend, GPU, start profiling. Profiling can be turned on based on step and epoch.\\n', '\\n', 'Raises\\n', 'RuntimeError – If the profiler has already started.\\n', '\\n', 'RuntimeError – If MD profiling has stopped, repeated start action is not supported.\\n', '\\n', 'RuntimeError – If the start_profile value is set to False.\\n', '\\n', 'Examples\\n', '\\n', 'class StopAtStep(Callback):\\n', '    def __init__(self, start_step, stop_step):\\n', '        super(StopAtStep, self).__init__()\\n', '        self.start_step = start_step\\n', '        self.stop_step = stop_step\\n', '        self.profiler = Profiler(start_profile=False)\\n', '\\n', '    def step_begin(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        step_num = cb_params.cur_step_num\\n', '        if step_num == self.start_step:\\n', '            self.profiler.start()\\n', '\\n', '    def step_end(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        step_num = cb_params.cur_step_num\\n', '        if step_num == self.stop_step:\\n', '            self.profiler.stop()\\n', '\\n', '    def end(self, run_context):\\n', '        self.profiler.analyse()\\n', 'stop()[source]\\n', 'Used for Ascend, GPU, stop profiling. Profiling can be turned off based on step and epoch.\\n', '\\n', 'Raises\\n', 'RuntimeError – If the profiler has not started, this function is disabled.\\n', '\\n', 'Examples\\n', '\\n', 'class StopAtEpoch(Callback):\\n', '    def __init__(self, start_epoch, stop_epoch):\\n', '        super(StopAtEpoch, self).__init__()\\n', '        self.start_epoch = start_epoch\\n', '        self.stop_epoch = stop_epoch\\n', '        self.profiler = Profiler(start_profile=False)\\n', '\\n', '    def epoch_begin(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        epoch_num = cb_params.cur_epoch_num\\n', '        if epoch_num == self.start_epoch:\\n', '            self.profiler.start()\\n', '\\n', '    def epoch_end(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        epoch_num = cb_params.cur_epoch_num\\n', '        if epoch_num == self.stop_epoch:\\n', '            self.profiler.stop()\\n', '\\n', '    def end(self, run_context):\\n', '        self.profiler.analyse()\\n', 'classmindspore.profiler.ProfileOption[source]\\n', 'This Class is deprecated. Profile Option Enum which be used in Profiler.profile.']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.scipy.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.scipy.html", "text_entry": "['mindspore.scipy\\n', 'Scipy-like interfaces in mindspore.\\n', '\\n', 'mindspore.scipy.linalg\\n', 'Linear algebra submodule\\n', '\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.scipy.linalg.block_diag\\n', '\\n', 'Create a block diagonal matrix from provided arrays.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.eigh\\n', '\\n', 'Solve a standard or generalized eigenvalue problem for a complex Hermitian or real symmetric matrix.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.inv\\n', '\\n', 'Compute the inverse of a matrix.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.lu\\n', '\\n', 'Compute pivoted LU decomposition of a general matrix.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.linalg.lu_factor\\n', '\\n', 'Compute pivoted LU decomposition of a square matrix, and its outputs can be directly used as the inputs of lu_solve.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.optimize\\n', 'Optimize submodule\\n', '\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.scipy.optimize.line_search\\n', '\\n', 'Inexact line search that satisfies strong Wolfe conditions.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.optimize.minimize\\n', '\\n', 'Minimization of scalar function of one or more variables.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.sparse.linalg\\n', 'Sparse linear algebra submodule\\n', '\\n', 'API Name\\n', '\\n', 'Description\\n', '\\n', 'Supported Platforms\\n', '\\n', 'mindspore.scipy.sparse.linalg.cg\\n', '\\n', 'Use Conjugate Gradient iteration to solve Ax=b.\\n', '\\n', 'CPU GPU\\n', '\\n', 'mindspore.scipy.sparse.linalg.gmres\\n', '\\n', 'GMRES solves the linear system Ax=b for x, given A and b.\\n', '\\n', 'CPU GPU']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.train.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.train.html", "text_entry": "['mindspore.train\\n', 'mindspore.train.summary\\n', 'Summary related classes and functions. User can use SummaryRecord to dump the summary data, the summary is a series of operations to collect data for analysis and visualization.\\n', '\\n', 'classmindspore.train.summary.SummaryRecord(log_dir, file_prefix=\"events\", file_suffix=\"_MS\", network=None, max_file_size=None, raise_exception=False, export_options=None)[source]\\n', 'SummaryRecord is used to record the summary data and lineage data.\\n', '\\n', 'The API will create a summary file and lineage files lazily in a given directory and writes data to them. It writes the data to files by executing the ‘record’ method. In addition to recording the data bubbled up from the network by defining the summary operators, SummaryRecord also supports to record extra data which can be added by calling add_value.\\n', '\\n', 'Note\\n', '\\n', 'Make sure to close the SummaryRecord at the end, otherwise the process will not exit. Please see the Example section below to learn how to close properly in two ways.\\n', '\\n', 'Only one SummaryRecord instance is allowed at a time, otherwise it will cause data writing problems.\\n', '\\n', 'SummaryRecord only supports Linux systems.\\n', '\\n', 'The Summary is not supported when compile source with -s on option.\\n', '\\n', 'Parameters\\n', 'log_dir (str) – The log_dir is a directory location to save the summary.\\n', '\\n', 'file_prefix (str) – The prefix of file. Default: “events”.\\n', '\\n', 'file_suffix (str) – The suffix of file. Default: “_MS”.\\n', '\\n', 'network (Cell) – Obtain a pipeline through network for saving graph summary. Default: None.\\n', '\\n', 'max_file_size (int, optional) – The maximum size of each file that can be written to disk (in bytes). For example, to write not larger than 4GB, specify max_file_size=4*1024**3. Default: None, which means no limit.\\n', '\\n', 'raise_exception (bool, optional) – Sets whether to throw an exception when a RuntimeError or OSError exception occurs in recording data. Default: False, this means that error logs are printed and no exception is thrown.\\n', '\\n', 'export_options (Union[None, dict]) –\\n', '\\n', 'Perform custom operations on the export data. Note that the size of export files is not limited by the max_file_size. You can customize the export data with a dictionary. For example, you can set {‘tensor_format’: ‘npy’} to export tensor as npy file. The data that supports control is shown below. Default: None, it means that the data is not exported.\\n', '\\n', 'tensor_format (Union[str, None]): Customize the export tensor format. Supports [“npy”, None]. Default: None, it means that the tensor is not exported.\\n', '\\n', 'npy: export tensor as npy file.\\n', '\\n', 'Raises\\n', 'TypeError – max_file_size is not int or file_prefix and file_suffix is not string.\\n', '\\n', 'ValueError – The Summary is not supported, please without -s on and recompile source.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    # use in with statement to auto close\\n', '    with SummaryRecord(log_dir=\"./summary_dir\") as summary_record:\\n', '        pass\\n', '\\n', '    # use in try .. finally .. to ensure closing\\n', '    try:\\n', '        summary_record = SummaryRecord(log_dir=\"./summary_dir\")\\n', '    finally:\\n', '        summary_record.close()\\n', 'add_value(plugin, name, value)[source]\\n', 'Add value to be recorded later.\\n', '\\n', 'Parameters\\n', 'plugin (str) –\\n', '\\n', 'The plugin of the value.\\n', '\\n', 'graph: the value is a computational graph.\\n', '\\n', 'scalar: the value is a scalar.\\n', '\\n', 'image: the value is an image.\\n', '\\n', 'tensor: the value is a tensor.\\n', '\\n', 'histogram: the value is a histogram.\\n', '\\n', 'train_lineage: the value is a lineage data for the training phase.\\n', '\\n', 'eval_lineage: the value is a lineage data for the evaluation phase.\\n', '\\n', 'dataset_graph: the value is a dataset graph.\\n', '\\n', 'custom_lineage_data: the value is a customized lineage data.\\n', '\\n', 'name (str) – The value of the name.\\n', '\\n', 'value (Union[Tensor, GraphProto, TrainLineage, EvaluationLineage, DatasetGraph, UserDefinedInfo]) –\\n', '\\n', 'The value to store.\\n', '\\n', 'The data type of value should be ‘GraphProto’ (see mindspore/ccsrc/anf_ir.proto) object when the plugin is ‘graph’.\\n', '\\n', 'The data type of value should be ‘Tensor’ object when the plugin is ‘scalar’, ‘image’, ‘tensor’ or ‘histogram’.\\n', '\\n', 'The data type of value should be a ‘TrainLineage’ object when the plugin is ‘train_lineage’, see mindspore/ccsrc/lineage.proto.\\n', '\\n', 'The data type of value should be a ‘EvaluationLineage’ object when the plugin is ‘eval_lineage’, see mindspore/ccsrc/lineage.proto.\\n', '\\n', 'The data type of value should be a ‘DatasetGraph’ object when the plugin is ‘dataset_graph’, see mindspore/ccsrc/lineage.proto.\\n', '\\n', 'The data type of value should be a ‘UserDefinedInfo’ object when the plugin is ‘custom_lineage_data’, see mindspore/ccsrc/lineage.proto.\\n', '\\n', 'Raises\\n', 'ValueError – plugin is not in the optional value.\\n', '\\n', 'TypeError – name is not non-empty string，or the data type of value is not ‘Tensor’ object when the plugin is ‘scalar’, ‘image’, ‘tensor’ or ‘histogram’.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import Tensor\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', \"        summary_record.add_value('scalar', 'loss', Tensor(0.1))\\n\", 'close()[source]\\n', 'Flush the buffer and write files to disk and close summary records. Please use the statement to autoclose.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    try:\\n', '        summary_record = SummaryRecord(log_dir=\"./summary_dir\")\\n', '    finally:\\n', '        summary_record.close()\\n', 'flush()[source]\\n', 'Flush the buffer and write files to disk.\\n', '\\n', 'Call it to make sure that all pending events have been written to disk.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', '        summary_record.flush()\\n', 'propertylog_dir\\n', 'Get the full path of the log file.\\n', '\\n', 'Returns\\n', 'str, the full path of log file.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', '        log_dir = summary_record.log_dir\\n', 'record(step, train_network=None, plugin_filter=None)[source]\\n', 'Record the summary.\\n', '\\n', 'Parameters\\n', 'step (int) – Represents training step number.\\n', '\\n', 'train_network (Cell) – The spare network for saving graph. Default: None, it means just do not save the graph summary when the original network graph is None.\\n', '\\n', 'plugin_filter (Optional[Callable[[str], bool]]) – The filter function, which is used to filter out which plugin should be written. Default: None.\\n', '\\n', 'Returns\\n', 'bool, whether the record process is successful or not.\\n', '\\n', 'Raises\\n', 'TypeError – step is not int，or train_network is not mindspore.nn.Cell 。\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', '        result = summary_record.record(step=2)\\n', '        print(result)\\n', '\\n', '\\n', 'set_mode(mode)[source]\\n', 'Set the model running phase. Different phases affect data recording.\\n', '\\n', 'Parameters\\n', 'mode (str) –\\n', '\\n', 'The mode to be set, which should be ‘train’ or ‘eval’. When the mode is ‘eval’, summary_record will not record the data of summary operators.\\n', '\\n', 'train：the model running phase is train mode.\\n', '\\n', 'eval：the model running phase is eval mode，When the mode is ‘eval’, summary_record will not record the data of summary operators.\\n', '\\n', 'Raises\\n', 'ValueError – mode is not in the optional value.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore.train.summary import SummaryRecord\\n', \"if __name__ == '__main__':\\n\", '    with SummaryRecord(log_dir=\"./summary_dir\", file_prefix=\"xx_\", file_suffix=\"_yy\") as summary_record:\\n', \"        summary_record.set_mode('eval')\\n\", 'mindspore.train.callback\\n', 'Callback related classes and functions.\\n', '\\n', 'classmindspore.train.callback.Callback[source]\\n', 'Abstract base class used to build a callback class. Callbacks are context managers which will be entered and exited when passing into the Model. You can use this mechanism to initialize and release resources automatically.\\n', '\\n', 'Callback function will execute some operations in the current step or epoch. To create a custom callback, subclass Callback and override the method associated with the stage of interest. For details of Callback fusion, please check Callback.\\n', '\\n', 'It holds the information of the model. Such as network, train_network, epoch_num, batch_num, loss_fn, optimizer, parallel_mode, device_number, list_callback, cur_epoch_num, cur_step_num, dataset_sink_mode, net_outputs and so on.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import Model, nn\\n', 'from mindspore.train.callback import Callback\\n', 'class Print_info(Callback):\\n', '    def step_end(self, run_context):\\n', '        cb_params = run_context.original_args()\\n', '        print(\"step_num: \", cb_params.cur_step_num)\\n', '\\n', 'print_cb = Print_info()\\n', 'dataset = create_custom_dataset()\\n', 'net = Net()\\n', \"loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'optim = nn.Momentum(net.trainable_params(), 0.01, 0.9)\\n', 'model = Model(net, loss_fn=loss, optimizer=optim)\\n', 'model.train(1, dataset, callbacks=print_cb)\\n', '\\n', 'begin(run_context)[source]\\n', 'Called once before the network executing.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Include some information of the model.\\n', '\\n', 'end(run_context)[source]\\n', 'Called once after network training.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Include some information of the model.\\n', '\\n', 'epoch_begin(run_context)[source]\\n', 'Called before each epoch beginning.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Include some information of the model.\\n', '\\n', 'epoch_end(run_context)[source]\\n', 'Called after each epoch finished.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Include some information of the model.\\n', '\\n', 'step_begin(run_context)[source]\\n', 'Called before each step beginning.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Include some information of the model.\\n', '\\n', 'step_end(run_context)[source]\\n', 'Called after each step finished.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Include some information of the model.\\n', '\\n', 'classmindspore.train.callback.LossMonitor(per_print_times=1)[source]\\n', 'Monitor the loss in training.\\n', '\\n', 'If the loss is NAN or INF, it will terminate training.\\n', '\\n', 'Note\\n', '\\n', 'If per_print_times is 0, do not print loss.\\n', '\\n', 'Parameters\\n', 'per_print_times (int) – How many steps to print once loss. During sink mode, it will print loss in the nearest step. Default: 1.\\n', '\\n', 'Raises\\n', 'ValueError – If per_print_times is not an integer or less than zero.\\n', '\\n', 'step_end(run_context)[source]\\n', 'Print training loss at the end of step.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Context of the train running.\\n', '\\n', 'classmindspore.train.callback.TimeMonitor(data_size=None)[source]\\n', 'Monitor the time in training.\\n', '\\n', 'Parameters\\n', 'data_size (int) – How many steps are the intervals between print information each time. if the program get batch_num during training, data_size will be set to batch_num, otherwise data_size will be used. Default: None.\\n', '\\n', 'Raises\\n', 'ValueError – If data_size is not positive int.\\n', '\\n', 'epoch_begin(run_context)[source]\\n', 'Record time at the beginning of epoch.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Context of the process running.\\n', '\\n', 'epoch_end(run_context)[source]\\n', 'Print process cost time at the end of epoch.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Context of the process running.\\n', '\\n', 'classmindspore.train.callback.ModelCheckpoint(prefix=\"CKP\", directory=None, config=None)[source]\\n', 'The checkpoint callback class.\\n', '\\n', 'It is called to combine with train process and save the model and network parameters after training.\\n', '\\n', 'Note\\n', '\\n', 'In the distributed training scenario, please specify different directories for each training process to save the checkpoint file. Otherwise, the training may fail.\\n', '\\n', 'Parameters\\n', 'prefix (str) – The prefix name of checkpoint files. Default: “CKP”.\\n', '\\n', 'directory (str) – The path of the folder which will be saved in the checkpoint file. By default, the file is saved in the current directory. Default: None.\\n', '\\n', 'config (CheckpointConfig) – Checkpoint strategy configuration. Default: None.\\n', '\\n', 'Raises\\n', 'ValueError – If the prefix is invalid.\\n', '\\n', 'TypeError – If the config is not CheckpointConfig type.\\n', '\\n', 'end(run_context)[source]\\n', 'Save the last checkpoint after training finished.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Context of the train running.\\n', '\\n', 'propertylatest_ckpt_file_name\\n', 'Return the latest checkpoint path and file name.\\n', '\\n', 'step_end(run_context)[source]\\n', 'Save the checkpoint at the end of step.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Context of the train running.\\n', '\\n', 'classmindspore.train.callback.SummaryCollector(summary_dir, collect_freq=10, collect_specified_data=None, keep_default_action=True, custom_lineage_data=None, collect_tensor_freq=None, max_file_size=None, export_options=None)[source]\\n', 'SummaryCollector can help you to collect some common information.\\n', '\\n', 'It can help you to collect loss, learning late, computational graph and so on. SummaryCollector also enables the summary operator to collect data to summary files.\\n', '\\n', 'Note\\n', '\\n', 'Multiple SummaryCollector instances in callback list are not allowed.\\n', '\\n', 'Not all information is collected at the training phase or at the eval phase.\\n', '\\n', 'SummaryCollector always record the data collected by the summary operator.\\n', '\\n', 'SummaryCollector only supports Linux systems.\\n', '\\n', 'The Summary is not supported when compile source with -s on option.\\n', '\\n', 'Parameters\\n', 'summary_dir (str) – The collected data will be persisted to this directory. If the directory does not exist, it will be created automatically.\\n', '\\n', 'collect_freq (int) – Set the frequency of data collection, it should be greater than zero, and the unit is step. If a frequency is set, we will collect data when (current steps % freq) equals to 0, and the first step will be collected at any time. It is important to note that if the data sink mode is used, the unit will become the epoch. It is not recommended to collect data too frequently, which can affect performance. Default: 10.\\n', '\\n', 'collect_specified_data (Union[None, dict]) –\\n', '\\n', 'Perform custom operations on the collected data. By default, if set to None, all data is collected as the default behavior. You can customize the collected data with a dictionary. For example, you can set {‘collect_metric’: False} to control not collecting metrics. The data that supports control is shown below. Default: None.\\n', '\\n', 'collect_metric (bool): Whether to collect training metrics, currently only the loss is collected. The first output will be treated as the loss and it will be averaged. Default: True.\\n', '\\n', 'collect_graph (bool): Whether to collect the computational graph. Currently, only training computational graph is collected. Default: True.\\n', '\\n', 'collect_train_lineage (bool): Whether to collect lineage data for the training phase, this field will be displayed on the lineage page of MindInsight. Default: True.\\n', '\\n', 'collect_eval_lineage (bool): Whether to collect lineage data for the evaluation phase, this field will be displayed on the lineage page of MindInsight. Default: True.\\n', '\\n', 'collect_input_data (bool): Whether to collect dataset for each training. Currently only image data is supported. If there are multiple columns of data in the dataset, the first column should be image data. Default: True.\\n', '\\n', 'collect_dataset_graph (bool): Whether to collect dataset graph for the training phase. Default: True.\\n', '\\n', 'histogram_regular (Union[str, None]): Collect weight and bias for parameter distribution page and displayed in MindInsight. This field allows regular strings to control which parameters to collect. It is not recommended to collect too many parameters at once, as it can affect performance. Note that if you collect too many parameters and run out of memory, the training will fail. Default: None, it means only the first five parameters are collected.\\n', '\\n', 'collect_landscape (Union[dict,None]): Collect the parameters needed to create the loss landscape.\\n', '\\n', 'landscape_size (int): Specify the image resolution of the generated loss landscape. For example, if it is set to 128, the resolution of the landscape is 128 * 128. The calculation time increases with the increase of resolution. Default: 40. Optional values: between 3 and 256.\\n', '\\n', 'unit (str): Specify the interval strength of the training process. Default: “step”. Optional: epoch/step.\\n', '\\n', 'create_landscape (dict): Select how to create loss landscape. Training process loss landscape(train) and training result loss landscape(result). Default: {“train”: True, “result”: True}. Optional: True/False.\\n', '\\n', 'num_samples (int): The size of the dataset used to create the loss landscape. For example, in image dataset, You can set num_samples is 128, which means that 128 images are used to create loss landscape. Default: 128.\\n', '\\n', 'intervals (List[List[int]]): Specifies the interval in which the loss landscape. For example: If the user wants to create loss landscape of two training processes, they are 1-5 epoch and 6-10 epoch respectively. They anc set [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]. Note: Each interval have at least three epochs.\\n', '\\n', 'keep_default_action (bool) – This field affects the collection behavior of the ‘collect_specified_data’ field. True: it means that after specified data is set, non-specified data is collected as the default behavior. False: it means that after specified data is set, only the specified data is collected, and the others are not collected. Default: True.\\n', '\\n', 'custom_lineage_data (Union[dict, None]) – Allows you to customize the data and present it on the MingInsight lineage page. In the custom data, the type of the key supports str, and the type of value supports str, int and float. Default: None, it means there is no custom data.\\n', '\\n', 'collect_tensor_freq (Optional[int]) – The same semantics as the collect_freq, but controls TensorSummary only. Because TensorSummary data is too large to be compared with other summary data, this parameter is used to reduce its collection. By default, The maximum number of steps for collecting TensorSummary data is 20, but it will not exceed the number of steps for collecting other summary data. For example, given collect_freq=10, when the total steps is 600, TensorSummary will be collected 20 steps, while other summary data 61 steps, but when the total steps is 20, both TensorSummary and other summary will be collected 3 steps. Also note that when in parallel mode, the total steps will be split evenly, which will affect the number of steps TensorSummary will be collected. Default: None, which means to follow the behavior as described above.\\n', '\\n', 'max_file_size (Optional[int]) – The maximum size in bytes of each file that can be written to the disk. For example, to write not larger than 4GB, specify max_file_size=4*1024**3. Default: None, which means no limit.\\n', '\\n', 'export_options (Union[None, dict]) –\\n', '\\n', 'Perform custom operations on the export data. Note that the size of export files is not limited by the max_file_size. You can customize the export data with a dictionary. For example, you can set {‘tensor_format’: ‘npy’} to export tensor as npy file. The data that supports control is shown below. Default: None, it means that the data is not exported.\\n', '\\n', 'tensor_format (Union[str, None]): Customize the export tensor format. Supports [“npy”, None]. Default: None, it means that the tensor is not exported.\\n', '\\n', 'npy: export tensor as npy file.\\n', '\\n', 'Raises\\n', 'ValueError – The Summary is not supported, please without -s on and recompile source.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore.nn as nn\\n', 'from mindspore import context\\n', 'from mindspore.train.callback import SummaryCollector\\n', 'from mindspore import Model\\n', 'from mindspore.nn import Accuracy\\n', '\\n', \"if __name__ == '__main__':\\n\", '    # If the device_target is GPU, set the device_target to \"GPU\"\\n', '    context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\")\\n', \"    mnist_dataset_dir = '/path/to/mnist_dataset_directory'\\n\", '    # The detail of create_dataset method shown in model_zoo.official.cv.lenet.src.dataset.py\\n', '    ds_train = create_dataset(mnist_dataset_dir, 32)\\n', '    # The detail of LeNet5 shown in model_zoo.official.cv.lenet.src.lenet.py\\n', '    network = LeNet5(10)\\n', '    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\\n', '    net_opt = nn.Momentum(network.trainable_params(), 0.01, 0.9)\\n', '    model = Model(network, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()}, amp_level=\"O2\")\\n', '\\n', '    # Simple usage:\\n', \"    summary_collector = SummaryCollector(summary_dir='./summary_dir')\\n\", '    model.train(1, ds_train, callbacks=[summary_collector], dataset_sink_mode=False)\\n', '\\n', '    # Do not collect metric and collect the first layer parameter, others are collected by default\\n', \"    specified={'collect_metric': False, 'histogram_regular': '^conv1.*'}\\n\", \"    summary_collector = SummaryCollector(summary_dir='./summary_dir', collect_specified_data=specified)\\n\", '    model.train(1, ds_train, callbacks=[summary_collector], dataset_sink_mode=False)\\n', 'classmindspore.train.callback.CheckpointConfig(save_checkpoint_steps=1, save_checkpoint_seconds=0, keep_checkpoint_max=5, keep_checkpoint_per_n_minutes=0, integrated_save=True, async_save=False, saved_network=None, append_info=None, enc_key=None, enc_mode=\"AES-GCM\", exception_save=False)[source]\\n', 'The configuration of model checkpoint.\\n', '\\n', 'Note\\n', '\\n', 'During the training process, if dataset is transmitted through the data channel, It is suggested to set ‘save_checkpoint_steps’ to an integer multiple of loop_size. Otherwise, the time to save the checkpoint may be biased. It is recommended to set only one save strategy and one keep strategy at the same time. If both save_checkpoint_steps and save_checkpoint_seconds are set, save_checkpoint_seconds will be invalid. If both keep_checkpoint_max and keep_checkpoint_per_n_minutes are set, keep_checkpoint_per_n_minutes will be invalid.\\n', '\\n', 'Parameters\\n', 'save_checkpoint_steps (int) – Steps to save checkpoint. Default: 1.\\n', '\\n', 'save_checkpoint_seconds (int) – Seconds to save checkpoint. Can’t be used with save_checkpoint_steps at the same time. Default: 0.\\n', '\\n', 'keep_checkpoint_max (int) – Maximum number of checkpoint files can be saved. Default: 5.\\n', '\\n', 'keep_checkpoint_per_n_minutes (int) – Save the checkpoint file every keep_checkpoint_per_n_minutes minutes. Can’t be used with keep_checkpoint_max at the same time. Default: 0.\\n', '\\n', 'integrated_save (bool) – Whether to merge and save the split Tensor in the automatic parallel scenario. Integrated save function is only supported in automatic parallel scene, not supported in manual parallel. Default: True.\\n', '\\n', 'async_save (bool) – Whether asynchronous execution saves the checkpoint to a file. Default: False.\\n', '\\n', 'saved_network (Cell) – Network to be saved in checkpoint file. If the saved_network has no relation with the network in training, the initial value of saved_network will be saved. Default: None.\\n', '\\n', 'append_info (list) – The information save to checkpoint file. Support “epoch_num”, “step_num” and dict. The key of dict must be str, the value of dict must be one of int float and bool. Default: None.\\n', '\\n', 'enc_key (Union[None, bytes]) – Byte type key used for encryption. If the value is None, the encryption is not required. Default: None.\\n', '\\n', 'enc_mode (str) – This parameter is valid only when enc_key is not set to None. Specifies the encryption mode, currently supports ‘AES-GCM’ and ‘AES-CBC’. Default: ‘AES-GCM’.\\n', '\\n', 'exception_save (bool) – Whether to save the current checkpoint when an exception occurs. Default: False.\\n', '\\n', 'Raises\\n', 'ValueError – If input parameter is not the correct type.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import Model, nn\\n', 'from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\\n', 'from mindspore.common.initializer import Normal\\n', '\\n', 'class LeNet5(nn.Cell):\\n', '    def __init__(self, num_class=10, num_channel=1):\\n', '        super(LeNet5, self).__init__()\\n', \"        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\\n\", \"        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\\n\", '        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))\\n', '        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\\n', '        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\\n', '        self.relu = nn.ReLU()\\n', '        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\\n', '        self.flatten = nn.Flatten()\\n', '\\n', '    def construct(self, x):\\n', '        x = self.max_pool2d(self.relu(self.conv1(x)))\\n', '        x = self.max_pool2d(self.relu(self.conv2(x)))\\n', '        x = self.flatten(x)\\n', '        x = self.relu(self.fc1(x))\\n', '        x = self.relu(self.fc2(x))\\n', '        x = self.fc3(x)\\n', '        return x\\n', '\\n', 'net = LeNet5()\\n', \"loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'optim = nn.Momentum(net.trainable_params(), 0.01, 0.9)\\n', 'model = Model(net, loss_fn=loss, optimizer=optim)\\n', \"data_path = './MNIST_Data'\\n\", 'dataset = create_dataset(data_path)\\n', 'config = CheckpointConfig(saved_network=net)\\n', \"ckpoint_cb = ModelCheckpoint(prefix='LeNet5', directory='./checkpoint', config=config)\\n\", 'model.train(10, dataset, callbacks=ckpoint_cb)\\n', 'propertyappend_dict\\n', 'Get the value of append_dict.\\n', '\\n', 'propertyasync_save\\n', 'Get the value of _async_save.\\n', '\\n', 'propertyenc_key\\n', 'Get the value of _enc_key\\n', '\\n', 'propertyenc_mode\\n', 'Get the value of _enc_mode\\n', '\\n', 'get_checkpoint_policy()[source]\\n', 'Get the policy of checkpoint.\\n', '\\n', 'propertyintegrated_save\\n', 'Get the value of _integrated_save.\\n', '\\n', 'propertykeep_checkpoint_max\\n', 'Get the value of _keep_checkpoint_max.\\n', '\\n', 'propertykeep_checkpoint_per_n_minutes\\n', 'Get the value of _keep_checkpoint_per_n_minutes.\\n', '\\n', 'propertysave_checkpoint_seconds\\n', 'Get the value of _save_checkpoint_seconds.\\n', '\\n', 'propertysave_checkpoint_steps\\n', 'Get the value of _save_checkpoint_steps.\\n', '\\n', 'propertysaved_network\\n', 'Get the value of _saved_network\\n', '\\n', 'classmindspore.train.callback.RunContext(original_args)[source]\\n', 'Provide information about the model.\\n', '\\n', 'Provide information about original request to model function. Callback objects can stop the loop by calling request_stop() of run_context.\\n', '\\n', 'Parameters\\n', 'original_args (dict) – Holding the related information of model.\\n', '\\n', 'get_stop_requested()[source]\\n', 'Return whether a stop is requested or not.\\n', '\\n', 'Returns\\n', 'bool, if true, model.train() stops iterations.\\n', '\\n', 'original_args()[source]\\n', 'Get the _original_args object.\\n', '\\n', 'Returns\\n', 'Dict, an object that holds the original arguments of model.\\n', '\\n', 'request_stop()[source]\\n', 'Set stop requirement during training.\\n', '\\n', 'Callbacks can use this function to request stop of iterations. model.train() checks whether this is called or not.\\n', '\\n', 'classmindspore.train.callback.LearningRateScheduler(learning_rate_function)[source]\\n', 'Change the learning_rate during training.\\n', '\\n', 'Parameters\\n', 'learning_rate_function (Function) – The function about how to change the learning rate during training.\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import Model\\n', 'from mindspore.train.callback import LearningRateScheduler\\n', 'import mindspore.nn as nn\\n', '\\n', 'def learning_rate_function(lr, cur_step_num):\\n', '    if cur_step_num%1000 == 0:\\n', '        lr = lr*0.1\\n', '    return lr\\n', '\\n', 'lr = 0.1\\n', 'momentum = 0.9\\n', 'net = Net()\\n', 'loss = nn.SoftmaxCrossEntropyWithLogits()\\n', 'optim = nn.Momentum(net.trainable_params(), learning_rate=lr, momentum=momentum)\\n', 'model = Model(net, loss_fn=loss, optimizer=optim)\\n', '\\n', 'dataset = create_custom_dataset(\"custom_dataset_path\")\\n', 'model.train(1, dataset, callbacks=[LearningRateScheduler(learning_rate_function)],\\n', '            dataset_sink_mode=False)\\n', 'step_end(run_context)[source]\\n', 'Change the learning_rate at the end of step.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Context of the train running.\\n', '\\n', 'classmindspore.train.callback.SummaryLandscape(summary_dir)[source]\\n', 'SummaryLandscape can help you to collect loss landscape information. It can create landscape in PCA direction or random direction by calculating loss.\\n', '\\n', 'Note\\n', '\\n', 'SummaryLandscape only supports Linux systems.\\n', '\\n', 'Parameters\\n', 'summary_dir (str) – The path of summary is used to save the model weight, metadata and other data required to create landscape.\\n', '\\n', 'Examples\\n', '\\n', 'import mindspore.nn as nn\\n', 'from mindspore import context\\n', 'from mindspore.train.callback import SummaryCollector, SummaryLandscape\\n', 'from mindspore import Model\\n', 'from mindspore.nn import Loss, Accuracy\\n', '\\n', \"if __name__ == '__main__':\\n\", '    # If the device_target is Ascend, set the device_target to \"Ascend\"\\n', '    context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\\n', \"    mnist_dataset_dir = '/path/to/mnist_dataset_directory'\\n\", '    # The detail of create_dataset method shown in model_zoo.official.cv.lenet.src.dataset.py\\n', '    ds_train = create_dataset(mnist_dataset_dir, 32)\\n', '    # The detail of LeNet5 shown in model_zoo.official.cv.lenet.src.lenet.py\\n', '    network = LeNet5(10)\\n', '    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\\n', '    net_opt = nn.Momentum(network.trainable_params(), 0.01, 0.9)\\n', '    model = Model(network, net_loss, net_opt, metrics={\"Accuracy\": Accuracy()})\\n', '    # Simple usage for collect landscape information:\\n', '    interval_1 = [1, 2, 3, 4, 5]\\n', \"    summary_collector = SummaryCollector(summary_dir='./summary/lenet_interval_1',\\n\", '                                         collect_specified_data={\\'collect_landscape\\':{\"landscape_size\": 4,\\n', '                                                                                       \"unit\": \"step\",\\n', '                                                                         \"create_landscape\":{\"train\":True,\\n', '                                                                                            \"result\":False},\\n', '                                                                         \"num_samples\": 2048,\\n', '                                                                         \"intervals\": [interval_1]}\\n', '                                                                   })\\n', '    model.train(1, ds_train, callbacks=[summary_collector], dataset_sink_mode=False)\\n', '\\n', '    # Simple usage for visualization landscape:\\n', '    def callback_fn():\\n', '        network = LeNet5(10)\\n', '        net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\\n', '        metrics = {\"Loss\": Loss()}\\n', '        model = Model(network, net_loss, metrics=metrics)\\n', \"        mnist_dataset_dir = '/path/to/mnist_dataset_directory'\\n\", '        ds_eval = create_dataset(mnist_dataset_dir, 32)\\n', '        return model, network, ds_eval, metrics\\n', '\\n', \"    summary_landscape = SummaryLandscape('./summary/lenet_interval_1')\\n\", '    # parameters of collect_landscape can be modified or unchanged\\n', '    summary_landscape.gen_landscapes_with_multi_process(callback_fn,\\n', '                                                       collect_landscape={\"landscape_size\": 4,\\n', '                                                                        \"create_landscape\":{\"train\":False,\\n', '                                                                                           \"result\":False},\\n', '                                                                         \"num_samples\": 2048,\\n', '                                                                         \"intervals\": [interval_1]},\\n', '                                                        device_ids=[1])\\n', 'clean_ckpt()[source]\\n', 'Clean the checkpoint.\\n', '\\n', 'gen_landscapes_with_multi_process(callback_fn, collect_landscape=None, device_ids=None, output=None)[source]\\n', 'Use the multi process to generate landscape.\\n', '\\n', 'Parameters\\n', 'callback_fn (python function) –\\n', '\\n', 'A python function object. User needs to write a function, it has no input, and the return requirements are as follows.\\n', '\\n', 'mindspore.train.Model: User’s model object.\\n', '\\n', 'mindspore.nn.Cell: User’s network object.\\n', '\\n', 'mindspore.dataset: User’s dataset object for create loss landscape.\\n', '\\n', 'mindspore.nn.Metrics: User’s metrics object.\\n', '\\n', 'collect_landscape (Union[dict, None]) –\\n', '\\n', 'The meaning of the parameters when creating loss landscape is consistent with the fields with the same name in SummaryCollector. The purpose of setting here is to allow users to freely modify creating parameters. Default: None.\\n', '\\n', 'landscape_size (int): Specify the image resolution of the generated loss landscape. For example, if it is set to 128, the resolution of the landscape is 128 * 128. The calculation time increases with the increase of resolution. Default: 40. Optional values: between 3 and 256.\\n', '\\n', 'create_landscape (dict): Select how to create loss landscape. Training process loss landscape(train) and training result loss landscape(result). Default: {“train”: True, “result”: True}. Optional: True/False.\\n', '\\n', 'num_samples (int): The size of the dataset used to create the loss landscape. For example, in image dataset, You can set num_samples is 2048, which means that 2048 images are used to create loss landscape. Default: 2048.\\n', '\\n', 'intervals (List[List[int]): Specifies the interval in which the loss landscape. For example: If the user wants to create loss landscape of two training processes, they are 1-5 epoch and 6-10 epoch respectively. They can set [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]. Note: Each interval have at least three epochs.\\n', '\\n', 'device_ids (List(int)) – Specifies which devices are used to create loss landscape. For example: [0, 1] refers to creating loss landscape with device 0 and device 1. Default: None.\\n', '\\n', 'output (str) – Specifies the path to save the loss landscape. Default: None. The default save path is the same as the summary file.\\n', '\\n', 'classmindspore.train.callback.FederatedLearningManager(model, sync_frequency, sync_type=\"fixed\", **kwargs)[source]\\n', 'Manage Federated Learning during training.\\n', '\\n', 'Parameters\\n', 'model (nn.Cell) – A training model.\\n', '\\n', 'sync_frequency (int) – Synchronization frequency of parameters in Federated Learning. Note that in dataset sink mode, the unit of the frequency is the number of epochs. Otherwise, the unit of the frequency is the number of steps.\\n', '\\n', 'sync_type (str) –\\n', '\\n', 'Parameter synchronization type in Federated Learning. Supports [“fixed”, “adaptive”]. Default: “fixed”.\\n', '\\n', 'fixed: The frequency of parameter synchronization is fixed.\\n', '\\n', 'adaptive: The frequency of parameter synchronization changes adaptively.\\n', '\\n', 'Note\\n', '\\n', 'This is an experimental prototype that is subject to change.\\n', '\\n', 'step_end(run_context)[source]\\n', 'Synchronization parameters at the end of step. If sync_type is “adaptive”, the synchronous frequency is adaptively adjusted here.\\n', '\\n', 'Parameters\\n', 'run_context (RunContext) – Context of the train running.\\n', '\\n', 'mindspore.train.train_thor\\n', 'convert to second order related classes and functions.\\n', '\\n', 'classmindspore.train.train_thor.ConvertNetUtils[source]\\n', 'Convert net to thor layer net\\n', '\\n', 'convert_to_thor_net(net)[source]\\n', 'This interface is used to convert a network to thor layer network, in order to calculate and store the second-order information matrix.\\n', '\\n', 'Note\\n', '\\n', 'This interface is automatically called by the second-order optimizer thor.\\n', '\\n', 'Parameters\\n', 'net (Cell) – Network to be trained by the second-order optimizer thor.\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'ConvertNetUtils().convert_to_thor_net(net)\\n', 'classmindspore.train.train_thor.ConvertModelUtils[source]\\n', 'Convert model to thor model.\\n', '\\n', 'staticconvert_to_thor_model(model, network, loss_fn=None, optimizer=None, metrics=None, amp_level=\"O0\", loss_scale_manager=None, keep_batchnorm_fp32=False)[source]\\n', 'This interface is used to convert model to thor model.\\n', '\\n', 'Parameters\\n', 'model (Object) – High-Level API for Training. Model groups layers into an object with training features.\\n', '\\n', 'network (Cell) – A training network.\\n', '\\n', 'loss_fn (Cell) – Objective function. Default: None.\\n', '\\n', 'optimizer (Cell) – Optimizer used to updating the weights. Default: None.\\n', '\\n', 'metrics (Union[dict, set]) – A Dictionary or a set of metrics to be evaluated by the model during training. eg: {‘accuracy’, ‘recall’}. Default: None.\\n', '\\n', 'amp_level (str) –\\n', '\\n', 'Level for mixed precision training. Supports [“O0”, “O2”, “O3”, “auto”]. Default: “O0”.\\n', '\\n', 'O0: Do not change.\\n', '\\n', 'O2: Cast network to float16, keep batchnorm run in float32, using dynamic loss scale.\\n', '\\n', 'O3: Cast network to float16, with additional property ‘keep_batchnorm_fp32=False’.\\n', '\\n', 'auto: Set level to recommended level in different devices. O2 is recommended on GPU, O3 is recommended on Ascend. The recommended level is based on the expert experience, cannot always generalize. User should specify the level for special network.\\n', '\\n', 'loss_scale_manager (Union[None, LossScaleManager]) – If it is None, the loss would not be scaled. Otherwise, scale the loss by LossScaleManager and optimizer can not be None. It is a key argument. e.g. Use loss_scale_manager=None to set the value.\\n', '\\n', 'keep_batchnorm_fp32 (bool) – Keep Batchnorm running in float32. If True, the level setting before will be overwritten. Default: False.\\n', '\\n', 'Returns\\n', 'High-Level API for Training.\\n', 'Model groups layers into an object with training features.\\n', '\\n', 'Return type\\n', 'model (Object)\\n', '\\n', 'Supported Platforms:\\n', 'Ascend GPU\\n', '\\n', 'Examples\\n', '\\n', 'from mindspore import nn\\n', 'from mindspore import Tensor\\n', 'from mindspore.nn import thor\\n', 'from mindspore import Model\\n', 'from mindspore import FixedLossScaleManager\\n', 'from mindspore.train.callback import LossMonitor\\n', 'from mindspore.train.train_thor import ConvertModelUtils\\n', '\\n', 'net = Net()\\n', 'dataset = create_dataset()\\n', 'temp = Tensor([4e-4, 1e-4, 1e-5, 1e-5], mstype.float32)\\n', 'opt = thor(net, learning_rate=temp, damping=temp, momentum=0.9, loss_scale=128, frequency=4)\\n', \"loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\\n\", 'loss_scale = FixedLossScaleManager(128, drop_overflow_update=False)\\n', \"model = Model(net, loss_fn=loss, optimizer=opt, loss_scale_manager=loss_scale, metrics={'acc'},\\n\", '              amp_level=\"O2\", keep_batchnorm_fp32=False)\\n', 'model = ConvertModelUtils.convert_to_thor_model(model=model, network=net, loss_fn=loss, optimizer=opt,\\n', \"                                                loss_scale_manager=loss_scale, metrics={'acc'},\\n\", '                                                amp_level=\"O2\", keep_batchnorm_fp32=False)\\n', 'loss_cb = LossMonitor()\\n', 'model.train(1, dataset, callbacks=loss_cb, sink_size=4, dataset_sink_mode=True)\\n']"}
{"index": {"_index": "r1.6-python-api", "_id": "mindspore.txt"}}
{"file_link": "https://www.mindspore.cn/docs/api/zh-CN/r1.6/api_python/mindspore.html", "text_entry": "['mindspore\\n', 'Tensor\\n', 'mindspore.Tensor\\n', '\\n', 'Tensor is a data structure that stores an n-dimensional array.\\n', '\\n', 'mindspore.RowTensor\\n', '\\n', 'A sparse representation of a set of tensor slices at given indices.\\n', '\\n', 'mindspore.SparseTensor\\n', '\\n', 'A sparse representation of a set of nonzero elements from a tensor at given indices.\\n', '\\n', 'Parameter\\n', 'mindspore.Parameter\\n', '\\n', 'An object holding weights of cells, after initialized Parameter is a subtype of Tensor.\\n', '\\n', 'mindspore.ParameterTuple\\n', '\\n', 'Class for storing tuple of parameters.\\n', '\\n', 'DataType\\n', 'classmindspore.dtype\\n', 'Create a data type object of MindSpore.\\n', '\\n', 'The actual path of dtype is /mindspore/common/dtype.py. Run the following command to import the package:\\n', '\\n', 'from mindspore import dtype as mstype\\n', 'Numeric Type\\n', '\\n', 'Currently, MindSpore supports Int type, Uint type and Float type. The following table lists the details.\\n', '\\n', 'Definition\\n', '\\n', 'Description\\n', '\\n', 'mindspore.int8 , mindspore.byte\\n', '\\n', '8-bit integer\\n', '\\n', 'mindspore.int16 , mindspore.short\\n', '\\n', '16-bit integer\\n', '\\n', 'mindspore.int32 , mindspore.intc\\n', '\\n', '32-bit integer\\n', '\\n', 'mindspore.int64 , mindspore.intp\\n', '\\n', '64-bit integer\\n', '\\n', 'mindspore.uint8 , mindspore.ubyte\\n', '\\n', 'unsigned 8-bit integer\\n', '\\n', 'mindspore.uint16 , mindspore.ushort\\n', '\\n', 'unsigned 16-bit integer\\n', '\\n', 'mindspore.uint32 , mindspore.uintc\\n', '\\n', 'unsigned 32-bit integer\\n', '\\n', 'mindspore.uint64 , mindspore.uintp\\n', '\\n', 'unsigned 64-bit integer\\n', '\\n', 'mindspore.float16 , mindspore.half\\n', '\\n', '16-bit floating-point number\\n', '\\n', 'mindspore.float32 , mindspore.single\\n', '\\n', '32-bit floating-point number\\n', '\\n', 'mindspore.float64 , mindspore.double\\n', '\\n', '64-bit floating-point number\\n', '\\n', 'mindspore.complex64\\n', '\\n', '64-bit complex number\\n', '\\n', 'mindspore.complex128\\n', '\\n', '128-bit complex number\\n', '\\n', 'Other Type\\n', '\\n', 'For other defined types, see the following table.\\n', '\\n', 'Type\\n', '\\n', 'Description\\n', '\\n', 'tensor\\n', '\\n', 'MindSpore’s tensor type. Data format uses NCHW. For details, see tensor.\\n', '\\n', 'bool_\\n', '\\n', 'Boolean True or False.\\n', '\\n', 'int_\\n', '\\n', 'Integer scalar.\\n', '\\n', 'uint\\n', '\\n', 'Unsigned integer scalar.\\n', '\\n', 'float_\\n', '\\n', 'Floating-point scalar.\\n', '\\n', 'complex\\n', '\\n', 'Complex scalar.\\n', '\\n', 'number\\n', '\\n', 'Number, including int_ , uint , float_ , complex and bool_ .\\n', '\\n', 'list_\\n', '\\n', 'List constructed by tensor , such as List[T0,T1,...,Tn] , where the element Ti can be of different types.\\n', '\\n', 'tuple_\\n', '\\n', 'Tuple constructed by tensor , such as Tuple[T0,T1,...,Tn] , where the element Ti can be of different types.\\n', '\\n', 'function\\n', '\\n', 'Function. Return in two ways, when function is not None, returns Func directly, the other returns Func(args: List[T0,T1,…,Tn], retval: T) when function is None.\\n', '\\n', 'type_type\\n', '\\n', 'Type definition of type.\\n', '\\n', 'type_none\\n', '\\n', 'No matching return type, corresponding to the type(None) in Python.\\n', '\\n', 'symbolic_key\\n', '\\n', 'The value of a variable is used as a key of the variable in env_type .\\n', '\\n', 'env_type\\n', '\\n', 'Used to store the gradient of the free variable of a function, where the key is the symbolic_key of the free variable’s node and the value is the gradient.\\n', '\\n', 'Tree Topology\\n', '\\n', 'The relationships of the above types are as follows:\\n', '\\n', '└─────── number\\n', '    │   ├─── bool_\\n', '    │   ├─── int_\\n', '    │   │   ├─── int8, byte\\n', '    │   │   ├─── int16, short\\n', '    │   │   ├─── int32, intc\\n', '    │   │   └─── int64, intp\\n', '    │   ├─── uint\\n', '    │   │   ├─── uint8, ubyte\\n', '    │   │   ├─── uint16, ushort\\n', '    │   │   ├─── uint32, uintc\\n', '    │   │   └─── uint64, uintp\\n', '    │   ├─── float_\\n', '    │   │   ├─── float16\\n', '    │   │   ├─── float32\\n', '    │   │   └─── float64\\n', '    │   └─── complex\\n', '    │       ├─── complex64\\n', '    │       └─── complex128\\n', '    ├─── tensor\\n', '    │   ├─── Array[Float32]\\n', '    │   └─── ...\\n', '    ├─── list_\\n', '    │   ├─── List[Int32,Float32]\\n', '    │   └─── ...\\n', '    ├─── tuple_\\n', '    │   ├─── Tuple[Int32,Float32]\\n', '    │   └─── ...\\n', '    ├─── function\\n', '    │   ├─── Func\\n', '    │   ├─── Func[(Int32, Float32), Int32]\\n', '    │   └─── ...\\n', '    ├─── type_type\\n', '    ├─── type_none\\n', '    ├─── symbolic_key\\n', '    └─── env_type\\n', 'mindspore.dtype_to_nptype\\n', '\\n', 'Convert MindSpore dtype to numpy data type.\\n', '\\n', 'mindspore.issubclass_\\n', '\\n', 'Determine whether type_ is a subclass of dtype.\\n', '\\n', 'mindspore.dtype_to_pytype\\n', '\\n', 'Convert MindSpore dtype to python data type.\\n', '\\n', 'mindspore.pytype_to_dtype\\n', '\\n', 'Convert python type to MindSpore type.\\n', '\\n', 'mindspore.get_py_obj_dtype\\n', '\\n', 'Get the MindSpore data type, which corresponds to python type or variable.\\n', '\\n', 'Seed\\n', 'mindspore.set_seed\\n', '\\n', 'Set global seed.\\n', '\\n', 'mindspore.get_seed\\n', '\\n', 'Get global seed.\\n', '\\n', 'Model\\n', 'mindspore.Model\\n', '\\n', 'High-Level API for training or inference.\\n', '\\n', 'Dataset Helper\\n', 'mindspore.DatasetHelper\\n', '\\n', 'DatasetHelper is a class to process the MindData dataset and provides the information of dataset.\\n', '\\n', 'mindspore.connect_network_with_dataset\\n', '\\n', 'Connect the network with dataset in dataset_helper.\\n', '\\n', 'Loss Scale Manager\\n', 'mindspore.LossScaleManager\\n', '\\n', 'Loss scale (Magnification factor of gradients when mix precision is used) manager abstract class.\\n', '\\n', 'mindspore.FixedLossScaleManager\\n', '\\n', 'Loss scale(Magnification factor of gradients when mix precision is used) manager with a fixed loss scale value, inherits from mindspore.LossScaleManager.\\n', '\\n', 'mindspore.DynamicLossScaleManager\\n', '\\n', 'Loss scale(Magnification factor of gradients when mix precision is used) manager with loss scale dynamically adjusted, inherits from mindspore.LossScaleManager.\\n', '\\n', 'Serialization\\n', 'mindspore.save_checkpoint\\n', '\\n', 'Save checkpoint to a specified file.\\n', '\\n', 'mindspore.load_checkpoint\\n', '\\n', 'Load checkpoint info from a specified file.\\n', '\\n', 'mindspore.load_param_into_net\\n', '\\n', 'Load parameters into network.\\n', '\\n', 'mindspore.export\\n', '\\n', 'Export the MindSpore network into an offline model in the specified format.\\n', '\\n', 'mindspore.load\\n', '\\n', 'Load MindIR.\\n', '\\n', 'mindspore.parse_print\\n', '\\n', 'Parse saved data generated by mindspore.ops.Print.\\n', '\\n', 'mindspore.build_searched_strategy\\n', '\\n', 'Build strategy of every parameter in network.\\n', '\\n', 'mindspore.merge_sliced_parameter\\n', '\\n', 'Merge parameter slices into one parameter.\\n', '\\n', 'mindspore.load_distributed_checkpoint\\n', '\\n', 'Load checkpoint into net for distributed predication.\\n', '\\n', 'mindspore.async_ckpt_thread_status\\n', '\\n', 'Get the status of asynchronous save checkpoint thread.\\n', '\\n', 'mindspore.restore_group_info_list\\n', '\\n', 'Build rank list, the checkpoint of ranks in the rank list has the same contents with the local rank who saves the group_info_file_name.\\n', '\\n', 'JIT\\n', 'mindspore.ms_function\\n', '\\n', 'Create a callable MindSpore graph from a Python function.\\n', '\\n', 'Log\\n', 'mindspore.get_level\\n', '\\n', 'Get the logger level.\\n', '\\n', 'mindspore.get_log_config\\n', '\\n', 'Get logger configurations.\\n', '\\n', 'Automatic Mixed Precision\\n', 'mindspore.build_train_network\\n', '\\n', 'Build the mixed precision training cell automatically.\\n', '\\n', 'Installation Verification\\n', 'mindspore.run_check\\n', '\\n', 'Provide a convenient API to check if the installation is successful or failed.\\n', '\\n', 'Debugging\\n', 'mindspore.set_dump\\n', '\\n', 'Enable or disable dump for the target and its contents.\\n', '\\n', 'Memory Recycle\\n', 'mindspore.ms_memory_recycle\\n', '\\n', 'Recycle memory used by MindSpore.']"}
