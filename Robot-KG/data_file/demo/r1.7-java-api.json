{"index": {"_index": "r1.7-java-api", "_id": "Graph.txt"}}
{"file_link": "https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_java/graph.html", "text_entry": "['Graph\\n', '\\n', '\\n', 'import com.mindspore.Graph;\\n', 'Graph定义了MindSpore的计算图。\\n', '\\n', '公有成员函数\\n', 'function\\n', 'boolean load(String file)\\n', 'long getGraphPtr()\\n', 'void free()\\n', 'load\\n', ' boolean load(String file)\\n', '从指定文件加载MindSpore模型。\\n', '\\n', '参数\\n', '\\n', 'file: 模型文件名。\\n', '\\n', '返回值\\n', '\\n', '是否加载成功。\\n', '\\n', 'getGraphPtr\\n', 'public long getGraphPtr()\\n', '获取底层计算图指针。\\n', '\\n', '返回值\\n', '\\n', '底层计算图指针。\\n', '\\n', 'free\\n', 'public void free()\\n', '释放计算图内存。']"}
{"index": {"_index": "r1.7-java-api", "_id": "Model.txt"}}
{"file_link": "https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_java/model.html", "text_entry": "['Model\\n', '\\n', '\\n', 'import com.mindspore.Model;\\n', 'Model定义了MindSpore中编译和运行的模型。\\n', '\\n', '公有成员函数\\n', 'function\\n', 'boolean build(MappedByteBuffer buffer, int modelType, MSContext context, char[] dec_key, String dec_mode)\\n', 'boolean build(Graph graph, MSContext context, TrainCfg cfg)\\n', 'boolean build(MappedByteBuffer buffer, MSContext context)\\n', 'boolean build(String modelPath, MSContext context, char[] dec_key, String dec_mode)\\n', 'boolean build(String modelPath, MSContext context)\\n', 'boolean predict()\\n', 'boolean runStep()\\n', 'boolean resize(List<MSTensor> inputs, int[][] dims)\\n', 'List<MSTensor> getInputs()\\n', 'List<MSTensor> getOutputs()\\n', 'MSTensor getInputsByTensorName(String tensorName)\\n', 'MSTensor getOutputByTensorName(String tensorName)\\n', 'List<MSTensor> getOutputsByNodeName(String nodeName)\\n', 'List<String> getOutputTensorNames()\\n', 'boolean export(String fileName, int quantizationType, boolean isOnlyExportInfer,List<String> outputTensorNames)\\n', 'List<MSTensor> getFeatureMaps()\\n', 'boolean updateFeatureMaps(List<MSTensor> features)\\n', 'boolean setTrainMode(boolean isTrain)\\n', 'boolean getTrainMode()\\n', 'boolean setLearningRate(float learning_rate)\\n', 'boolean setupVirtualBatch(int virtualBatchMultiplier, float learningRate, float momentum)\\n', 'void free()\\n', 'ModelType\\n', 'build\\n', 'public boolean build(Graph graph, MSContext context, TrainCfg cfg)\\n', '通过模型计算图编译MindSpore模型。\\n', '\\n', '参数\\n', '\\n', 'graph: 模型计算图。\\n', '\\n', 'context: 编译运行上下文。\\n', '\\n', 'cfg: 训练配置。\\n', '\\n', '返回值\\n', '\\n', '是否编译成功。\\n', '\\n', 'public boolean build(MappedByteBuffer buffer, int modelType, MSContext context, char[] dec_key, String dec_mode)\\n', '通过模型计算图内存块编译MindSpore模型。\\n', '\\n', '参数\\n', '\\n', 'buffer: 模型计算图内存块。\\n', '\\n', 'modelType: 模型计算图类型，可选MindIR、ONNX。\\n', '\\n', 'context: 运行时Context上下文。\\n', '\\n', 'dec_key: 模型解密秘钥。\\n', '\\n', 'dec_mode: 模型解密算法，可选AES-GCM、AES-CBC。\\n', '\\n', '返回值\\n', '\\n', '是否编译成功。\\n', '\\n', 'public boolean build(final MappedByteBuffer buffer, int modelType, MSContext context)\\n', '通过模型计算图内存块编译MindSpore模型。\\n', '\\n', '参数\\n', '\\n', 'buffer: 模型计算图内存块。\\n', '\\n', 'modelType: 模型计算图类型，可选MindIR、ONNX。\\n', '\\n', 'context: 运行时Context上下文。\\n', '\\n', '返回值\\n', '\\n', '是否编译成功。\\n', '\\n', 'public boolean build(String modelPath, int modelType, MSContext context, char[] dec_key, String dec_mode)\\n', '通过模型计算图文件编译MindSpore MindiR模型。\\n', '\\n', '参数\\n', '\\n', 'modelPath: 模型计算图文件。\\n', '\\n', 'modelType: 模型计算图类型，可选MindIR、ONNX。\\n', '\\n', 'context: 运行时Context上下文。\\n', '\\n', 'dec_key: 模型解密秘钥。\\n', '\\n', 'dec_mode: 模型解密算法，可选AES-GCM、AES-CBC。\\n', '\\n', '返回值\\n', '\\n', '是否编译成功。\\n', '\\n', 'public boolean build(String modelPath, int modelType, MSContext context)\\n', '通过模型计算图文件编译MindSpore MindIR模型。\\n', '\\n', '参数\\n', '\\n', 'modelPath: 模型计算图文件。\\n', '\\n', 'modelType: 模型计算图类型，可选MindIR、ONNX。\\n', '\\n', 'context: 运行时Context上下文。\\n', '\\n', '返回值\\n', '\\n', '是否编译成功。\\n', '\\n', 'predict\\n', 'public boolean predict()\\n', '执行推理。\\n', '\\n', '返回值\\n', '\\n', '是否推理成功。\\n', '\\n', 'runStep\\n', 'public boolean runStep()\\n', '执行单步训练。\\n', '\\n', '返回值\\n', '\\n', '是否单步训练成功。\\n', '\\n', 'resize\\n', 'public boolean resize(List<MSTensor> inputs, int[][] dims)\\n', '调整输入的形状。\\n', '\\n', '参数\\n', '\\n', 'inputs: 模型对应的所有输入。\\n', '\\n', 'dims: 输入对应的新的shape，顺序注意要与inputs一致。\\n', '\\n', '返回值\\n', '\\n', '调整输入形状是否成功。\\n', '\\n', 'getInputs\\n', 'public List<MSTensor> getInputs()\\n', '获取MindSpore模型的输入tensor列表。\\n', '\\n', '返回值\\n', '\\n', '所有输入MSTensor组成的List。\\n', '\\n', 'getOutputs\\n', 'public List<MSTensor> getOutputs()\\n', '获取MindSpore模型的输出tensor列表。\\n', '\\n', '返回值\\n', '\\n', '所有输出MSTensor组成的List。\\n', '\\n', 'getInputsByTensorName\\n', 'public MSTensor getInputsByTensorName(String tensorName)\\n', '通过张量名获取MindSpore模型的输入张量。\\n', '\\n', '参数\\n', '\\n', 'tensorName: 张量名。\\n', '\\n', '返回值\\n', '\\n', 'tensorName所对应的输入MSTensor。\\n', '\\n', 'getOutputByTensorName\\n', 'public MSTensor getOutputByTensorName(String tensorName)\\n', '通过张量名获取MindSpore模型的输出张量。\\n', '\\n', '参数\\n', '\\n', 'tensorName: 张量名。\\n', '\\n', '返回值\\n', '\\n', '该张量所对应的MSTensor。\\n', '\\n', 'getOutputsByNodeName\\n', 'public List<MSTensor> getOutputsByNodeName(String nodeName)\\n', '通过节点名获取MindSpore模型的MSTensors输出。\\n', '\\n', '参数\\n', '\\n', 'nodeName: 节点名。\\n', '\\n', '返回值\\n', '\\n', '该节点所有输出MSTensor组成的List。\\n', '\\n', 'getOutputTensorNames\\n', 'public List<String> getOutputTensorNames()\\n', '获取由当前会话所编译的模型的输出张量名。\\n', '\\n', '返回值\\n', '\\n', '按顺序排列的输出张量名组成的List。\\n', '\\n', 'export\\n', 'public boolean export(String fileName, int quantizationType, boolean isOnlyExportInfer,List<String> outputTensorNames)\\n', '导出模型。\\n', '\\n', '参数\\n', '\\n', 'fileName: 模型文件名称。\\n', '\\n', 'quantizationType: 量化类型。可选不量化，权重量化。\\n', '\\n', 'isOnlyExportInfer: 是否只导推理图。\\n', '\\n', 'outputTensorNames: 指定导出图结尾的tensor名称。\\n', '\\n', '返回值\\n', '\\n', '导出模型是否成功。\\n', '\\n', 'getFeatureMaps\\n', 'public List<MSTensor> getFeatureMaps()\\n', '获取权重参数。\\n', '\\n', '返回值\\n', '\\n', '权重参数列表。\\n', '\\n', 'updateFeatureMaps\\n', 'public boolean updateFeatureMaps(List<MSTensor> features)\\n', '更新权重参数。\\n', '\\n', '参数\\n', '\\n', 'features: 新的权重参数列表。\\n', '\\n', '返回值\\n', '\\n', '权重是否更新成功。\\n', '\\n', 'setTrainMode\\n', 'public boolean setTrainMode(boolean isTrain)\\n', '设置训练或推理模式。\\n', '\\n', '参数\\n', '\\n', 'isTrain: 是否训练。\\n', '\\n', '返回值\\n', '\\n', '运行模式是否设置成功。\\n', '\\n', 'getTrainMode\\n', 'public boolean getTrainMode()\\n', '获取训练模式。\\n', '\\n', '返回值\\n', '\\n', '是否是训练模式。\\n', '\\n', 'setLearningRate\\n', 'public boolean setLearningRate(float learning_rate)\\n', '设置学习率。\\n', '\\n', '参数\\n', '\\n', 'learning_rate: 学习率。\\n', '\\n', '返回值\\n', '\\n', '学习率设置是否成功。\\n', '\\n', 'setupVirtualBatch\\n', 'public boolean setupVirtualBatch(int virtualBatchMultiplier, float learningRate, float momentum)\\n', '设置虚批次系数。\\n', '\\n', '参数\\n', '\\n', 'virtualBatchMultiplier: 虚批次系数，实际批次数需要乘以此系数。\\n', '\\n', 'learningRate: 学习率。\\n', '\\n', 'momentum: 动量系数。\\n', '\\n', '返回值\\n', '\\n', '虚批次系数设置是否成功。\\n', '\\n', 'free\\n', 'public void free()\\n', '释放Model内存。\\n', '\\n', 'ModelType\\n', 'import com.mindspore.config.ModelType;\\n', '模型文件类型。\\n', '\\n', 'public static final int MT_MINDIR = 0;\\n', 'public static final int MT_AIR = 1;\\n', 'public static final int MT_OM = 2;\\n', 'public static final int MT_ONNX = 3;\\n', 'public static final int MT_MINDIR_OPT = 4;']"}
{"index": {"_index": "r1.7-java-api", "_id": "ModelParallelRunner.txt"}}
{"file_link": "https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_java/model_parallel_runner.html", "text_entry": "['ModelParallelRunner\\n', '\\n', '\\n', 'import com.mindspore.config.RunnerConfig;\\n', 'ModelParallelRunner定义了MindSpore Lite并发推理。\\n', '\\n', '公有成员函数\\n', 'function\\n', 'long getModelParallelRunnerPtr()\\n', 'boolean init()\\n', 'boolean predict()\\n', 'boolean getInputs()\\n', 'boolean getOutputs()\\n', 'void free()\\n', 'getModelParallelRunnerPtr\\n', 'public long getModelParallelRunnerPtr()\\n', '获取底层并发推理类指针。\\n', '\\n', '返回值\\n', '\\n', '底层并发推理类指针。\\n', '\\n', 'init\\n', 'public boolean init(String modelPath, RunnerConfig runnerConfig)\\n', '根据路径读取加载模型，生成一个或者多个模型，并将所有模型编译至可在Device上运行的状态。\\n', '\\n', '参数\\n', '\\n', 'modelPath: 模型文件路径。\\n', '\\n', 'runnerConfig: 一个RunnerConfig结构体。定义了并发推理模型的配置参数。\\n', '\\n', '返回值\\n', '\\n', '是否初始化成功。\\n', '\\n', 'public boolean init(String modelPath)\\n', '根据路径读取加载模型，生成一个或者多个模型，并将所有模型编译至可在Device上运行的状态。\\n', '\\n', '参数\\n', '\\n', 'modelPath: 模型文件路径。\\n', '\\n', '返回值\\n', '\\n', '是否初始化成功。\\n', '\\n', 'predict\\n', 'public boolean predict(List<MSTensor> inputs, List<MSTensor> outputs)\\n', '并发推理模型。\\n', '\\n', '参数\\n', '\\n', 'inputs: 模型输入。\\n', '\\n', 'outputs: 模型输出。\\n', '\\n', '返回值\\n', '\\n', '是否推理成功。\\n', '\\n', 'getInputs\\n', 'public List<MSTensor> getInputs()\\n', '获取模型所有输入张量。\\n', '\\n', '返回值\\n', '\\n', '模型的输入张量列表。\\n', '\\n', 'getOutputs\\n', 'public List<MSTensor> getOutputs()\\n', '获取模型所有输入张量。\\n', '\\n', '返回值\\n', '\\n', '模型的输出张量列表。\\n', '\\n', 'free\\n', 'public void free()\\n', '释放并发推理类内存。\\n', '\\n']"}
{"index": {"_index": "r1.7-java-api", "_id": "MSContext.txt"}}
{"file_link": "https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_java/mscontext.html", "text_entry": "['MSContext\\n', '\\n', '\\n', 'import com.mindspore.config.MSContext;\\n', 'MSContext类用于配置运行时的上下文配置。\\n', '\\n', '公有成员函数\\n', 'function\\n', 'boolean init()\\n', 'boolean init(int threadNum, int cpuBindMode)\\n', 'boolean init(int threadNum, int cpuBindMode, boolean isEnableParallel)\\n', 'boolean addDeviceInfo(int deviceType, boolean isEnableFloat16)\\n', 'boolean addDeviceInfo(int deviceType, boolean isEnableFloat16, int npuFreq)\\n', 'void free()\\n', 'long getMSContextPtr()\\n', 'DeviceType\\n', 'CpuBindMode\\n', 'init\\n', 'public boolean init()\\n', '使用默认参数初始化MSContext，2线程，不绑核，不开启异构并行。\\n', '\\n', '返回值\\n', '\\n', '初始化是否成功。\\n', '\\n', 'public boolean init(int threadNum, int cpuBindMode)\\n', '使用线程数和绑＆模式初始化MSContext。\\n', '\\n', '参数\\n', '\\n', 'threadNum: 线程数。\\n', '\\n', 'cpuBindMode: CPU绑定模式，cpuBindMode在com.mindspore.config.CpuBindMode中定义。\\n', '\\n', '返回值\\n', '\\n', '初始化是否成功。\\n', '\\n', 'public boolean init(int threadNum, int cpuBindMode, boolean isEnableParallel)\\n', '初始化MSContext。\\n', '\\n', '参数\\n', '\\n', 'threadNum: 线程数。\\n', '\\n', 'cpuBindMode: CPU绑定模式，cpuBindMode在com.mindspore.config.CpuBindMode中定义。\\n', '\\n', 'isEnableParallel: 是否开启异构并行。\\n', '\\n', '返回值\\n', '\\n', '初始化是否成功。\\n', '\\n', 'addDeviceInfo\\n', 'boolean addDeviceInfo(int deviceType, boolean isEnableFloat16)\\n', '添加运行设备信息。\\n', '\\n', '参数\\n', '\\n', 'deviceType: 设备类型，deviceType在com.mindspore.config.DeviceType中定义。\\n', '\\n', 'isEnableFloat16: 是否开启fp16。\\n', '\\n', '返回值\\n', '\\n', '设备添加是否成功。\\n', '\\n', 'boolean addDeviceInfo(int deviceType, boolean isEnableFloat16, int npuFreq)\\n', '添加运行设备信息。\\n', '\\n', '参数\\n', '\\n', 'deviceType: 设备类型，deviceType在com.mindspore.config.DeviceType中定义。\\n', '\\n', 'isEnableFloat16: 是否开启fp16。\\n', '\\n', 'npuFreq: NPU运行频率，仅当deviceType为npu才需要。\\n', '\\n', '返回值\\n', '\\n', '设备添加是否成功。\\n', '\\n', 'getMSContextPtr\\n', 'public long getMSContextPtr()\\n', '获取MSContext底层运行指针。\\n', '\\n', '返回值\\n', '\\n', 'MSContext底层运行指针。\\n', '\\n', 'free\\n', 'public void free()\\n', '释放MSContext运行过程中动态分配的内存。\\n', '\\n', 'DeviceType\\n', 'import com.mindspore.config.DeviceType;\\n', '设备类型。\\n', '\\n', '公有成员变量\\n', 'public static final int DT_CPU = 0;\\n', 'public static final int DT_GPU = 1;\\n', 'public static final int DT_NPU = 2;\\n', 'DeviceType的值为0，指定设备类型为CPU。\\n', '\\n', 'DeviceType的值为1，指定设备类型为GPU。\\n', '\\n', 'DeviceType的值为2，指定设备类型为NPU。\\n', '\\n', 'CpuBindMode\\n', 'import com.mindspore.config.CpuBindMode;\\n', '绑核策略。\\n', '\\n', '公有成员变量\\n', 'public static final int MID_CPU = 2;\\n', 'public static final int HIGHER_CPU = 1;\\n', 'public static final int NO_BIND = 0;\\n', 'CpuBindMode的值为2，优先绑定中核。\\n', '\\n', 'CpuBindMode的值为1，优先绑定大核。\\n', '\\n', 'CpuBindMode的值为0，不绑核。\\n', '\\n']"}
{"index": {"_index": "r1.7-java-api", "_id": "MSTensor.txt"}}
{"file_link": "https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_java/mstensor.html", "text_entry": "['MSTensor\\n', '\\n', '\\n', 'import com.mindspore.MSTensor;\\n', 'MSTensor定义了MindSpore中的张量。\\n', '\\n', '公有成员函数\\n', 'function\\n', 'MSTensor createTensor(String tensorName, int dataType, int[] tensorShape, ByteBuffer buffer)\\n', 'int[] getShape()\\n', 'int getDataType()\\n', 'byte[] getByteData()\\n', 'float[] getFloatData()\\n', 'int[] getIntData()\\n', 'long[] getLongData()\\n', 'void setData(byte[] data)\\n', 'void setData(ByteBuffer data)\\n', 'long size()\\n', 'int elementsNum()\\n', 'void free()\\n', 'String tensorName()\\n', 'DataType\\n', 'createTensor\\n', 'public static MSTensor createTensor(String tensorName, int dataType, int[] tensorShape, ByteBuffer buffer)\\n', '生成MindSpore MSTensor。\\n', '\\n', '参数\\n', '\\n', 'tensorName: 张量名称。\\n', '\\n', 'dataType: 张量数据类型。\\n', '\\n', 'tensorShape: 张量形状。\\n', '\\n', 'buffer: 张量数据。\\n', '\\n', '返回值\\n', '\\n', 'MindSpore MSTensor。\\n', '\\n', 'getShape\\n', 'public int[] getShape()\\n', '获取MindSpore MSTensor的形状。\\n', '\\n', '返回值\\n', '\\n', '一个包含MindSpore MSTensor形状数值的整型数组。\\n', '\\n', 'getDataType\\n', 'public int getDataType()\\n', 'DataType在com.mindspore.DataType中定义。\\n', '\\n', '返回值\\n', '\\n', 'MindSpore MSTensor类的MindSpore DataType。\\n', '\\n', 'getByteData\\n', 'public byte[] getByteData()\\n', '获得MSTensor的输出数据，数据类型为byte类型。\\n', '\\n', '返回值\\n', '\\n', '包含所有MSTensor输出数据的byte类型数组。\\n', '\\n', 'getFloatData\\n', 'public float[] getFloatData()\\n', '获得MSTensor的输出数据，数据类型为float类型。\\n', '\\n', '返回值\\n', '\\n', '包含所有MSTensor输出数据的float类型数组。\\n', '\\n', 'getIntData\\n', 'public int[] getIntData()\\n', '获得MSTensor的输出数据，数据类型为int类型。\\n', '\\n', '返回值\\n', '\\n', '包含所有MSTensor输出数据的int类型数组。\\n', '\\n', 'getLongData\\n', 'public long[] getLongData()\\n', '获得MSTensor的输出数据，数据类型为long类型。\\n', '\\n', '返回值\\n', '\\n', '包含所有MSTensor输出数据的long类型数组。\\n', '\\n', 'setData\\n', 'public void setData(byte[] data)\\n', '设定MSTensor的输入数据。\\n', '\\n', '参数\\n', '\\n', 'data: byte[]类型的输入数据。\\n', '\\n', 'public void setData(ByteBuffer data)\\n', '设定MSTensor的输入数据。\\n', '\\n', '参数\\n', '\\n', 'data: ByteBuffer类型的输入数据。\\n', '\\n', 'size\\n', 'public long size()\\n', '获取MSTensor中的数据的字节数大小。\\n', '\\n', '返回值\\n', '\\n', 'MSTensor中的数据的字节数大小。\\n', '\\n', 'elementsNum\\n', 'public int elementsNum()\\n', '获取MSTensor中的元素个数。\\n', '\\n', '返回值\\n', '\\n', 'MSTensor中的元素个数。\\n', '\\n', 'free\\n', 'public void free()\\n', '释放MSTensor运行过程中动态分配的内存。\\n', '\\n', 'tensorName\\n', 'public String tensorName()\\n', '返回tensor的名称。\\n', '\\n', '返回值\\n', '\\n', 'tensor的名称。\\n', '\\n', 'DataType\\n', 'import com.mindspore.config.DataType;\\n', 'DataType定义了MindSpore中的张量的数据类型。\\n', '\\n', '公有成员变量\\n', 'public static final int kNumberTypeBool = 30;\\n', 'public static final int kNumberTypeInt = 31;\\n', 'public static final int kNumberTypeInt8 = 32;\\n', 'public static final int kNumberTypeInt16 = 33;\\n', 'public static final int kNumberTypeInt32 = 34;\\n', 'public static final int kNumberTypeInt64 = 35;\\n', 'public static final int kNumberTypeUInt = 36;\\n', 'public static final int kNumberTypeUInt8 = 37;\\n', 'public static final int kNumberTypeUInt16 = 38;\\n', 'public static final int kNumberTypeUint32 = 39;\\n', 'public static final int kNumberTypeUInt64 = 40;\\n', 'public static final int kNumberTypeFloat = 41;\\n', 'public static final int kNumberTypeFloat16 = 42;\\n', 'public static final int kNumberTypeFloat32 = 43;\\n', 'public static final int kNumberTypeFloat64 = 44;']"}
{"index": {"_index": "r1.7-java-api", "_id": "RunnerConfig.txt"}}
{"file_link": "https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_java/runner_config.html", "text_entry": "['RunnerConfig\\n', '\\n', '\\n', 'RunnerConfig定义了MindSpore Lite并发推理的配置参数。\\n', '\\n', '公有成员函数\\n', 'function\\n', 'boolean init()\\n', 'boolean setWorkerNum()\\n', 'long getRunnerConfigPtr()\\n', 'void free()\\n', 'init\\n', 'public boolean init()\\n', '并发推理的配置参数初始化。\\n', '\\n', '返回值\\n', '\\n', '是否初始化成功。\\n', '\\n', 'public boolean init(MSContext msContext)\\n', '并发推理的配置参数初始化。\\n', '\\n', '参数\\n', '\\n', 'msContext: 并发推理运行时的上下文配置。\\n', '\\n', '返回值\\n', '\\n', '是否初始化成功。\\n', '\\n', 'setWorkerNum\\n', 'public void setWorkerNum(int workerNum)\\n', '并发推理中模型个数参数设置。\\n', '\\n', '参数\\n', '\\n', 'workerNum: 配置文件中设置模型个数。\\n', '\\n', 'getRunnerConfigPtr\\n', 'public long getRunnerConfigPtr()\\n', '获取底层并发推理配置参数指针。\\n', '\\n', '返回值\\n', '\\n', '底层并发推理配置参数指针。\\n', '\\n', 'free\\n', 'public void free()\\n', '释放runnerConfig。\\n', '\\n']"}
{"index": {"_index": "r1.7-java-api", "_id": "样例.txt"}}
{"file_link": "https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_java/lite_java_example.html", "text_entry": "['样例\\n', '极简Demo↗\\n', '基于Java接口的Android应用开发↗\\n', '高阶用法↗']"}
{"index": {"_index": "r1.7-java-api", "_id": "类列表.txt"}}
{"file_link": "https://www.mindspore.cn/lite/api/zh-CN/r1.7/api_java/class_list.html", "text_entry": "['类列表\\n', '\\n', '\\n', '包\\t类\\t描述\\n', 'com.mindspore.config\\tMSContext\\tMSContext用于保存执行期间的上下文。\\n', 'com.mindspore.config\\tCpuBindMode\\tCpuBindMode定义了CPU绑定模式。\\n', 'com.mindspore.config\\tDeviceType\\tDeviceType定义了后端设备类型。\\n', 'com.mindspore\\tModel\\tModel定义了MindSpore中的模型，用于计算图的编译和执行。\\n', 'com.mindspore\\tGraph\\tModel定义了MindSpore中的计算图。\\n', 'com.mindspore\\tMSTensor\\tMSTensor定义了MindSpore中的张量。\\n', 'com.mindspore\\tModelParallelRunner\\t定义了MindSpore Lite并发推理。\\n', 'com.mindspore.config\\tDataType\\tDataType定义了所支持的数据类型。\\n', 'com.mindspore.config\\tVersion\\tVersion用于获取MindSpore的版本信息。\\n', 'com.mindspore.config\\tModelType\\tModelType 定义了模型文件的类型。\\n', 'com.mindspore.config\\tRunnerConfig\\tRunnerConfig 定义并发推理的配置参数。']"}
