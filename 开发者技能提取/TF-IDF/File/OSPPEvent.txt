event
"一个端口支持多种协议可以使部署和运维更为方便，甚至在一些特殊的开发场景也能降低复杂度。
1、对于协议切换/架构升级的场景，通常需要同时暴露多个协议，单端口多协议能最大程度上带来运维的便捷性。
2、从后端开发的角度一套业务代码加少许配置就能暴露多个端口也能带来降低开发成本 目前 Dubbo 支持一个应用对外发布多种 RPC 协议，但这些 RPC 协议都需要独立占用一个服务端端口，另外 Dubbo QoS 也同样占用了一个端口。维护这些端口的监听需要消耗一定的资源，同时暴露多端口对于运维也存在一定复杂度，如 VIP /域名等。因此可以通过在同一个端口支持多种复用协议来降低复杂度，提高易用性
例如：一个业务逻辑需要提供给不同语言、不同业务方进行调用。 
当前大多数 rpc 框架均不支持该逻辑（包括 Dubbo）以 Dubbo 举例，使用Triple 协议并开启所有默认服务，会开启如下默认端口 Triple: 50051、Metadata : 20880、Qos: 22222。如果后续增加其他功能可能还会更多，这很不优雅，并且还启动了多个 Netty Server，造成了资源浪费。 如果本地需要测试，在不修改配置的情况下端口会冲突导致启动失败，体验很差。 

实现服务端同端口多协议暴露,将各种协议服务使用一种统一的方式使用同一个 Netty Server 进行暴露
将Qos 协议和 Triple 协议使用同一个端口暴露
将 Dubbo 的其他协议进行接入

熟练使用 Java
了解基础网络通信原理
了解Netty工作原理"
"Spark GraphX 是基于 Spark 的开源图计算系统，在社区和工业界有着大量用户。但是受限于Spark的本身，以及 Java/Scala 的语言限制，其性能远远落后于近些年来涌现的基于C++实现的图计算系统，例如GraphScope。作为一站式图计算解决方案，GraphScope希望积极拥抱Java图计算生态，使得GraphX算法可以无缝运行在 GraphScope 图分析引擎上，且获得大幅性能提升。
为了达成这个目的，我们需要将 Spark RDD 中的数据提供给 GraphScope，从而进行计算。由于 GraphScope 的 Analytical engine 会以MPI进程组的方式启动，所以你需要通过跨进程通信将数据传输给 GraphScope。
通过完成这个任务，你将帮助 GraphScope 跨越和 GraphX 之间的数据交互障碍，最终使得 GraphX 算法可以运行在 GraphScope 的计算引擎上，从而获得运行性能的大幅提升

设计并实现一套方案，使得存储在Spark RDD中的数据可以传输到另外一个C++进程中，通过封装好的接口，C++进程可以读取存储在该Spark RDD中的数据。
完整的Spark RDD Reader的实现，支持在C++进程中读取Spark RDD中的数据。
性能测试报告，在较大规模数据集上RDD Reader的表现

你的方案应该至少支持基础类型数据和scala.Tuple
可供参考的方案：共享内存/rpc/pip"
"PFS(Polar FileSystem)是阿里开源的针对数据库的文件系统；CurveBS是网易开源的分布式块存储系统。PFS+CurveBS旨在打造云原生数据库的存储解决方案。当前PFS和CurveBS已经对接、联调完成，但是缺乏在物理机上简易的部署方式。

支持PFS+CurveBS的客户端在CentOS7/8、Debian9/10、Ubuntu打包
有install工具可以一键安装并启动服务
通过CI测试，验证打包的正确性

熟悉基本的 Linux 命令
熟悉脚本语言 Bash script
熟悉 fpm 工具使用"
"支持将KubeEdge边缘节点部署到OpenHarmony操作系统，支持小型化嵌入式设备。

KubeEdge边缘节点在OpenHarmony操作系统设备运行起来
在OpenHarmony操作系统设备上运行KubeEdge应用

了解KubeEdge部署原理，了解OpenHarmony系统"
"Kruise Rollouts是一个 Bypass 组件，它为一系列 Kubernetes 工作负载(如deployment和CloneSet)提供了高级部署功能，如金丝雀、流量路由和渐进式发布功能。但是 Rollouts 和工作负载之间是 1v1 的关系，无法记录部署过程中的快照信息，因此我们要实现一个 CRD 来记录每次执行 rollout 的相关信息，比如 Pod IP, Name, 当次部署策略、类型等。

根据设计文档实现 RolloutHistory CRD
能够实现 RolloutHistory 基本功能，例如记录 rollout 的发布过程中的信息
Cli命令行展示 rollout 过程可见性

熟悉 kubenetes 基本原理
了解 Kubernetes Controller 标准扩展原理及其实现"
"U2PL是一个半监督语义分割领域的网络，半监督任务的关键在于充分利用无标签数据，基于「 Every Pixel Matters」的理念，有效利用了包括不可靠样本在内的全部无标签数据，大幅提升了算法精度。具体来说，预测结果的可靠与否，我们可以通过熵 (per-pixel entropy) 来衡量，低熵表示预测结果可靠，高熵表示预测结果不可靠。即使是不可靠的预测结果，虽然无法打上确定的伪标签，但仍可以作为部分类别的负样本，从而参与到模型的训练，从而让所有的无标签样本都能在训练过程中发挥作用。

1.实现U2PL语义分割网络模型 2.精度、性能等相关指标达到论文标准 3.代码满足MindSpore models仓规范要求 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"Halo 是一款现代化的开源博客/CMS 系统，但主题的多样性和数量还不够丰富，需要不断开发新的主题，给 Halo 社区用户更多的选择。
目前，Halo 的服务端仅支持 Freemarker 模板渲染引擎，主题创作者需要结合该模板引擎、HTML、CSS 和 JavaScript 来实现一款完整的博客主题。

完成一款全新的 Halo 主题并发布至 Halo 社区
根据社区的反馈并持续优化

熟悉 HTML、CSS 和 JavaScript 前端技术栈
了解模板渲染引擎：Freemarker
熟练掌握代码版本管理工具：Git"
"Apache Doris当前的日期类型（DATE、DATETIME）有以下一些问题：
1. 日期类型在存储层的存储格式，和在计算层的内存格式不同，所以查询时需要进行一次格式转换，效率较低。
2. DATETIME类型只能精确到秒，当用户有毫秒甚至微秒的存储需求时，无法满足。
3. DATETIME是以服务器本地时区存储的时间，Doris不支持存储时区信息，这与很多数据库系统的功能不匹配。 

1. 调研Trino、PostgreSQL、mysql等数据库的日期类型，包括类型的存储格式、精度、表示范围、使用方式等。
2. 优化Doris现有的DATE、DateTime类型，已获得性能上的提升
3. 引入Timestamp(w/o timezone)类型，以支持更高精度的时间和时区信息存储

1. 优化后的日期类型的计算性能能够在标准测试集上（TPC-H）有显著提升。 2. 开发并实现 Timestamp类型。

对 C++ 语言熟悉，有数据库存储或计算层的开发经验。"
"提供Java类型的调度任务，包括Jar和自定义Java代码两种方式，通过WEBUI定义Java运行时所需要的Resources、Libs资源文件和JVM参数，覆盖定时任务调用Java程序场景并提升用户方便配置。

可执行的Java类型任务插件
Java类型插件支持Jar方式，提供Resources、Libs资源文件和JVM参数的动态参数输入
Java类型插件支持WebUI自定义Java代码方式，提供Java类即时编译，执行

熟悉Shell、Java、SPI、Java compiler、VUE3、TypeScript"
"可编程控制器技术作为一种以微处理器及其存储器为控制中心的自动化装置,在工业自动化控制领域发挥着越来越重要的作用。随着工业制造技术的不断进步以及过程的不断复杂化,对所需的控制程序提出了新的要求。传统的PLC编程模式方式（指令表语言和梯形语言等）功能已经达到极限，长期以来PLC的研制走的是一条专用化的道路，不同厂商使用不同的编程规则,使得在其获得成功的同时也带来了许多不便。 
IEC61131-3作为第一个为工业自动化控制系统的软件设计提供标准化编程语言的国际标准极大地改进了工业控制系统的编程软件质量,提高了软件开发效率。它定义的一系列图形化语言和文本语言,不仅对系统集成商和系统工程师的编程带来很大的方便,而且对最终用户同样会带来很大的方便。 
本项目基于IEC61131-3标准对PLC系统的代码编译部分进行设计与实现，主要任务分为三个部分：一是文本处理部分，主要内容是设计PLC结构化文本语言的BNF范式，并使用自动化生成工具正确地生成AST树。二是静态检查部分，主要内容为设计符号表、作用域等结构，并对AST树进行处理，输出中间表达结构。三是翻译部分，主要任务为设计运行时支持库，并根据此支持库提供的内容，使用上一步的中间表达结构生成目标文件。

静态检查程序
符号表、作用域结构设计
遍历AST树并正确生成中间表达结构
翻译程序
由中间结构生成目标语言的程序
目标语言的运行时支持库

生成的目标语言可以阅读，代码意义明确
最终生成的程序运行速度较优
运行支持库可拓展，代码意义明确
静态语义检查提供供调试使用的接口
生成的目标语言运行结果与源语言无差"
"说出一段话描述代码功能，就能得到相应的代码，是智能代码复用（easy copy&paste）的重要基础。Towhee 通过AI能力生成embedding，使得一切非结构数据都能高效地被存储和搜索。随着工程代码以几何速度增长，很多人希望Towhee这样的开源项目能够提供自然语言到代码的查询能力，并在此基础上，构建实用又好玩的AI for code工具。

一个基于Towhee的natural laguage-programming laguage retrieval demo

Solid knowledge of python and hands-on experience of algorithm optimization"
"Linux社区引入页表检查（page table check）特性[1][2][3]，可以在page table操作时增加校验，从而检查是否存在非法共享，提前发现问题，确保防止某些内存损坏。

合入Linux社区 page table check 特性到 openEuler5.10内核
新增arm64的支持到openEuler5.10
相关的bugfix合入到openEuler5.10

熟悉Linux内存模块（如页表相关操作等）
熟悉Linux内核开发"
"随着数据时效性对企业的精细化运营越来越重要，""实时即未来""、""实时数仓""成为了近几年炙手可热的词。流计算领域也在这几年发生了巨大的变化, 但在这个领域中，还没有一个行业标准的基准测试,本项目要求开发一个测试工具，能够对 TDengine 流计算特性的所有功能，在各种使用场景中进行测试，保证 TDengine 流计算特性的正确性和健壮性, 测试范围包括并不限于功能、性能、稳定性测试, 同时要保证能够采集到相应的吞吐量、延迟、CPU和内存等信息。

测试工具的设计文档、代码和使用手册
基础场景的测试用例
交付物全部提交到 TDengine 的 GitHub 仓库

测试工具能够模拟生产者，产生数据流，写入 TDengine
测试工具能够模拟消费者，从 TDengine 进行消费
测试工具支持通过命令行参数，或配置脚本，获取生产者的行为
测试工具支持通过命令行参数，或配置脚本，获取消费者的行为
支持测试脚本控制该测试工具，对 TDengine 流计算特性的所有功能进行测试
"
"Puppet-xp 是 Wechaty 社区中一个供开发者免费接入个人微信的 puppet，是在微信生态下入门 Chatbot 的良好选择之一。
Puppet-xp 使用 Frida 框架接入个人微信，使前端开发者也可以参与到 puppet 的开发过程中。然而因 Frida 内部机制及当前代码实现方式原因，存在两个问题，需要进行解决：
当前其核心代码使用 JavaScript 编写，且只能使用单文件，不利于编写与维护大量代码。不能在运行前进行有效的验证，运行起来错误的代码会直接导致程序崩溃。且造成程序崩溃后，没有有效的信息来快速判断引发错误的代码位置，非常不利于开发和使用，因此需要使用 TypeScript 对核心代码进行重构，便于维护和开发。
存在内存释放不及时的问题，会导致长时间运行的 Chatbot 占用内存会越来越多，不利于 Chatbot 的稳定运行，因此需要解决内存占用问题。
需要功能增强：
适配支持自动登录的个人微信版本，如 3.5.x 。
需要注意：
此项目不是纯粹的 Nodejs 项目，涉及到动态追踪调试，需要学习一定的汇编和 C++ 知识

调查 Agent 长时间运行后的内存占用情况、运行稳定性
1. 对 agent 的各功能进行测试，统计各功能引发的内存占用额外增长情况。
2. 跟踪统计代码中各处申请内存的生命周期。
3.对比重构前后的测试情况，总结性能和稳定性提升情况。
使用 TypeScript 对 Agent 进行全面重构
1. 将现有 agent js 代码拆分为不同功能模块，并使用 TypeScript 重构。
2. 解决使用 TypeScript 重构后的 agent 可能产生的程序运行崩溃问题。
适配个人微信 3.5.x 以后的版本
适配 3.5.x 以后的版本，以支持自动登录功能。需确保各功能可在新版本中的可用性。

Frida
熟悉 Frida 框架，了解其内存管理机制，熟悉 Frida-compile 工具
TypeScript
熟练使用 TypeScript 编写和组织代码
动态跟踪调试
熟练使用动态跟踪调试工具，快速定位异常问题"
"目前RISCV的kprobe通过将内核任意地址上的指令替换成ebreak指令，以实现代码插桩的功能。但通过ebreak劫持正常指令流会带来较大的性能开销。目前社区在arm，x86，powerpc指令集上实现了kprobe optimizer的功能，这个功能是将桩点的ebreak指令替换成跳转指令，既能劫持原指令流又不会引入断点异常。本项目用于在riscv的Linux内核上实现kprobe optimizer的方案。

1.包含在Linux内核源码里的kprobe optimizer代码实现。
2.在用户态和内核态的kprobe optimizer测试代码。
3.基于跳转实现的kprobe能实现插桩和删桩，并通过tracing文件系统获取被插入桩点的调用信息。
4.内核稳定运行，不会出现性能和功能的回归。
5.代码能合入到Linux内核社区或者openeuler内核社区。

1.熟悉Linux内核的编译和构建。(Required)
2.熟悉RISCV指令集，尤其是异常处理流程和分支指令，原子指令，ldl/stc指令。(Required)
3.熟悉Linux内核的kprobe，livepatch，function trace等相关技术原理。(Preferable)
4.熟悉可执行程序ELF格式或者动态加载的原理。（Preferable）
5. 有在多核环境下编写程序的经验。（Preferable）"
"RT-Thread Smart提供了一部分的跨进程通信机制，以channel & shared memory方式进行通信（IPC，Inter-Process Communication，进程间通信）。通信机制涉及到整个系统中的运行效率，特别是当一些系统服务运行在用户态，用户态应用程序需要使用这些基础能力的时候。
这个项目希望在RT-Thread Smart的多核环境下（例如树莓派4B的32位环境或 64位环境），完成对IPC典型通信流程的量化测量并在TraceView上进行可视化展示，给出优化方案。最后通过用户态运行网络协议栈，用户态应用程序执行iperf3的方式，来提升系统调用、IPC整体性能状况。

测量现有IPC机制在单核和多核环境的开销和最坏执行时间，找到其潜在改进点，并提出设计和使用上的相关建议；
将兼容现有内核架构的优化措施合并到RT-Thread Smart代码仓库，并形成一份设计方案的文档

良好的沟通与交流能力
清晰理解CPU架构寄存器级情况，了解模式切换时涉及的栈，变量变化情况
良好的动手能力，静态汇编，C语言，能够完成长链条深入挖掘信息
如果可能，熟悉网络协议栈和RT-Smart内核"
"为了构建完善的基于openEuler的ROS软件生态，需要将以ROS为载体的部分VIO算法迁移至openEuler。VIO算法作为当前自动驾驶/AI领域关键的模块之一，能在openEuler的ROS上运行起来有着重要意义。当前应用广泛的开源VO/VIO算法有很多，开源的SVO/DSO/ORB/VINS等均用C++实现，可以作为很好的入门软件进行学习。还可以作为一个入口，扩展更多的相关软件包进入基于openEuler的ROS软件生态

1、选取的VIO算法软件包以rpm包形式提交到src-openeuler对应仓库（由sig-ROS创建）；
2、自动化脚本执行VIO算法测试数据集，并输出数据集执行结果，脚本同步上传src-openeuler对应仓库；
3、《基于openEuler的VIO软件移植指南》、《基于openEuler的VIO软件测试报告》，报告覆盖ROS安装与基础功能测试、规范性自检、功能性测试、测试结果，以word形式存放到代码仓库的doc目录。

1.熟悉ROS，可以进行基本的ROS软件开发；
2.了解VO/VIO/VSLAM算法；
3.熟悉C++编程语言，熟悉CMake;
4.熟悉linux"
"当前整个 Erlang 生态都没有 MQTT-SN 客户端库的实现。因此需要新增一个 Erlang 的客户端实现来完善 EMQX 对 MQTT-SN 测试和应用。

实现 MQTT-SN v1.2 协议所需的基本通信逻辑
实现所有类型的数据包交换
支持睡眠模式
增加单元测试（可选，非必需）
完成文档说明

熟悉网络编程
熟悉 Erlang 语言或对 Erlang 有兴趣
有执行力"
"MindSpore拥有多种常用创建Tensor的方法，但还不够完善，现需要补齐创建Tensor的方法 10+。
参考：torch.from_numpy
torch.bernoulli
torch.multinomial
torch.poisson
torch.rand_like
torch.randint_like
torch.randn_like
torch.sparse_coo_tensor
torch.as_tensor
torch.as_strided
torch.frombuffer
torch.empty_strided
torch.randperm
基于MindSpore实现上述方法

1.补齐10+MindSpore 创建Tensor的方法 2. 相关能力对标标杆、接口设计符合社区规范 3.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"DiskANN ( https://github.com/microsoft/DiskANN ) 是一个可扩展的基于图的索引，用于近似最近邻搜索。我们希望将 DiskANN 引入 Milvus 并使其成为 Milvus 可以支持的索引类型之一（其他索引类型包括Faiss、HNSW、Annoy、NGT 和 ScaNN）

DiskANN 成为 Milvus 中的一种可靠的索引类型，具有合理的性能。

研究型论文阅读能力
熟练的cpp程序员
（加分项）了解和掌握cmake"
"实现 Resource 的插件化
实现具体的插件 Resource 包括但不限于本地文件系统，GitHub, GitLab, Amazon S3, 阿里云 OSS
Python API 的通过测试覆盖率，当前阈值为 90%
文档，包括开发（如何二开实现插件）和使用（每个 Resource 插件使用）

熟悉python，包括decorator、io、network、unittest、document"
"Embedding功能完善包含三个子工作：

1. DeepRec EmbeddingVariable算子并行性能优化
EmbeddingVariable（EV）是DeepRec中提供的保存稀疏特征embedding数据的Variable，在训练的前向过程中通过查询EV中hash table获取对应特征的embedding数据，反向过程则会更新EV中的数据。目前为了加速前后向的过程，使用了Shard并行的方式进行加速。但是目前在使用Shard时传入的cost是一个静态的值，这导致并行效率并不高，我们需要通过优化cost来提高并行效率。通过这个项目，你可以熟悉推荐场景中的各种模型，了解推荐场景中前沿的技术以及学习工业界的深度学习引擎的设计与开发思路。

2. DeepRec 支持通过feature_column API使用multi-hash功能
为了减少推荐模型中稀疏部分的大小，multi-hash是一种常用的方法。目前DeepRec中支持通过底层API get_multihash_variable接口使用multi-hash功能，但是不支持通过feature_column使用。为了完善整体的功能性，我们需要支持通过feature_column接口使用multi-hash功能。在这个项目中你会了解到推荐场景中前沿的技术、学习工业界的深度学习引擎的设计与开发思路。

3. DeepRec 动态维度embedding功能优化
DeepRec支持了动态维度的embedding功能，但是目前这个功能目前还需要进一步优化，一方面这个功能需要用户通过构造Variable来记录频次，这在特征数目经常变动的推荐场景中给用户带来了使用困难；另一方面，目前的实现中更高的特征维度会带来更高的查询开销，会影响整体的性能。我们需要你从易用性和性能两方面进行优化。在这个项目中，在这个项目中你会了解到推荐场景中前沿的技术、学习工业界的深度学习引擎的设计与开发思路。

优化后的KvResourceGatherOp 优化后的多个ApplyOp
支持通过feature_column API使用multi-hash功能 相关功能的unit test
优化后的动态维度embedding功能 相关功能的unit test

熟练掌握C++
熟练掌握Python
能够在导师的指导下熟悉并理解DeepRec相关的代码并完成开发
对搜索、推荐、广告领域有兴趣
对深度学习稀疏模型训练/预测引擎有兴趣"
"用于RT-Thread Smart开源操作系统的，基于xmake的类buildroot的交叉构建系统：smart-build，它可以编译基础的软件包（调用xmake & xrepo的方式），构建出基本的应用程序，并输出相关文件到根文件系统文件夹下。
希望可以做到：
针对系列的软件包，构建类似buildroot的menuconfig选择软件包及配置；
支持两种以上架构的编译工具链，如arm、aarch64、risc-v等中的两种，并可选择；
支持软件包的不同版本，并处理好依赖关系，并从网络上下载下来到本地；
支持release模式编译，支持debug模式编译；
支持按静态库模式编译，支持按动态库模式编译；
支持在最终输出到根文件系统时strip掉多余的符号信息；

能够基于RT-Thread Smart应用程序构建的方式，构建一个个的程序，并输出到rt-smart/userapps/root目录下，并可以使用已有脚本转成rootfs的映像文件
可通过 menuconfig 可视化配置工具链和编译选项
支持两种以上架构的编译工具链，如arm、aarch64、risc-v等中的两种
支持软件包的不同版本，并处理好依赖关系，并从网络上下载下来到本地
支持 Debug/Release 编译模式切换
支持静态库和动态库切换
支持在最终输出到根文件系统时strip掉多余的符号信息

熟悉构建系统，熟悉基于GNU GCC & ld 的编译过程
熟悉lua语言，对xmake、xrepo有一定的了解
熟悉git操作"
"在开源软件操作系统中，软件包之间复杂依赖关系的分析与维护是软件包管理系统正常运行的重要基础，实践证明，通过将软件包依赖关系问题问题转变为布尔可满足(SAT)问题的基本映射规则，可以高效实现复杂的软件包管理系统。

设计并使用Rust语言实现以上各组成部分并完成基本功能测试

1.软件依赖关系解析：支持主流Linux发行版软件包，如RPM(必选), DEB等，的依赖关系，并设计高效、可靠的数据结构对依赖关系进行存储，提供简单易用的数据结构访问；
2.软件仓库解析：支持主流Linux发行版软件仓库，如RPM(必选), DEB等，的软件仓库内容解析，并设计高效、可靠的数据结构对其进行存储，提供简单易用的数据结构访问；
3.基于SAT算法的软件包依赖分析：将软件依赖关系转变为布尔可满足(SAT)问题的基本映射规则，并实现SAT求解器，对给定的软件包进行依赖求解，输出给定的软件仓库中能否满足其依赖。"
"完成Elasticsearch对接适配openGauss，使得openGauss可以使用ES来提供更强大的文本检索能力

1、参照ZomboDB中的实现方式，完成openGauss和Elasticsearch的集成对接 2、输出相关设计文档、使用方法和测试用例 3、提供使用ES前后的性能对比数据

1、了解openGauss基础功能与插件扩展 2、熟悉Rust语言"
"自动化程序验证（auto-active verification）是一种有前景的形式化验证手段，是构建正确、可靠的系统的基础设施（更多具体概念可以参考学习 Dafny 项目文档）。SimpleCompiler目前支持了一个C99标准的子集的语言，本项目期望在SimpleCompiler的语言上原生支持 require, ensure，invariant等操作，并通过SMT Solver实现自动验证。

在SimpleCompiler的语言上原生支持 require, ensure，invariant等操作，实现以下例子的自动化程序验证： ```c int verify(int n) { require(n >= 0); int x, y; x = n; y = 0; while (x > 0) { invariant(x >= 0); invariant(x + y == n); x = x - 1; y = y + 1; } ensure(y == n); return y; } ```

C/C++
了解霍尔逻辑（Hoare Logic）与符号执行"
"目前，Sedna在创建边云协同任务之后，只能通过命令行来查询任务的状态、参数以及指标，缺乏可视化以及运维功能。我们希望你能利用prometheus等开源组件，达成以下目标：
1、支持Sedna服务管理及状态监控、边云协同任务的管理和状态监控（协同推理、联邦学习、增量学习）。
2、利用开源监控及可视化组件（建议prometheus+grafana），实现边云协同AI流程动态指标的采集和可视化展示。 
3、利用开源日志组件（建议loki），实现应用日志的统一管理和搜索。

1、开源组件的部署和使用手册
2、必要的代码和配置文件（例如prometheus的exporter，grafana的json配置）
3、端到端的测试用例
4、能够实时采集并可视化任务的指标、状态等信息，且界面美观。
5、能够可视化应用的日志，并支持管理和统计。

1. 了解K8s
2. 了解Golang"
"基于GO语言，实现一套面向openGauss的对象关系映射ORM框架，类似Java里面Hibernete的功能

1、基于Go语言完成openGauss的ORM框架。 2、输出相关的设计和使用样例文档。 3、完善相关的单元测试用例和功能测试用例。

1、了解openGauss的基础功能 2、熟悉Go等常用的编程语言"
"CurveAdm 是为提高 Curve 系统易用性而打造的工具，其主要用于部署和运维 CurveBS/CurveFS 集群

CurveAdm 查看服务状态时显示服务监听的所有端口
保证现有 CurveAdm 功能正常
curveadm status 输出有端口显示这一列

了解 Curve/CurveAdm 项目的部署使用
了解 Go 语言
了解 Docker 基本操作"
"Flink 目前采用一个 JobManager + 多个 TaskManager 的进程模型，其中 JobManager 进程中又包含了 Dispatcher、ResourceManager、JobMasters 等多个组件。这一进程模型在部分特殊场景下存在一些问题，例如在组成超大规模集群时存在单点可用性及性能瓶颈、在 IoT 嵌入式设备上使用时资源开销过大等。请针对这些问题，对 Flink 的进程模型进行优化改造。

基础要求：设计并开发实现 Flink JobManager 进程拆分方案，并贡献社区。
进阶要求（可选）：Flink JobManager 进程拆分方案下，Dispatcher、ResourceManager 故障作业无需重启；
进阶要求（可选）：设计并开发实现 Flink 单进程模式，并贡献社区。

学习 Flink 的进程部署模型、分布式协调机制、高可用机制"
"目标：为 RadonDB MySQL Kubernetes E2E 测试框架贡献至少一种混沌测试故障类型相关 API 及测试用例。
 
背景：RadonDB MySQL Kubernetes 是基于 MySQL 的开源、高可用、云原生集群解决方案。RadonDB MySQL Kubernetes E2E 测试框架基于 Ginkgo v2 开发，用于对 RadonDB MySQL Kubernetes 进行自动化测试。
 
详情：本项目中使用的混沌测试平台为 Chaos Mesh，Chaos Mesh 使用CRD来定义故障类型。我们只需要编写 API 来创建用于注入故障的 CR，并在测试用例中调用。目前我们的测试框架已经支持了部分故障类型的注入，可以提供参考

至少完成一种混沌测试故障类型相关 API
编写相关测试用例

MySQL
Kubernetes
Go"
"KubeSphere-DevOps 是一个云原生 DevOps 工具, 当前已经集成了流水线(基于 Jenkins), 持续部署(基于 ArgoCD)。

FluxCD 是一个 CNCF 孵化云原生 CD 工具, 是可以用于支持实现 GitOps 的工具集，用于使 Kubernetes 集群与配置源（Git 仓库、Helm、Kustomize 等等）保持同步，并且可以在配置源更新后自动同步配置，面向 Kubernetes 的渐进式交付解决方案。

KubeSphere-DevOps 已经在 3.3 版本中完成了与 ArgoCD 的对接，在 CD 选择上，对接 FluxCD 可以给用户更多的选择、适应不同的应用场景。

项目主要目标为完成对接 FluxCD 各个组件:

Source Controller:  主要作用是为其他工具提供通用的接口用于获取配置源
Kustomize Controlle :  使用声明式的方式管理 Kustomize
Helm Controller: 使用声明式的方式管理 Helm Release
Notification Controller:  通知服务，可以通过 HTTP 的方式接收时间并根据事件等级及设计资源将事件分发到外部系统（Slack、Webhook 等）
Image Automation Controllers:  用于根据镜像变更自动更新配置源


我们希望:
在 KubeSphere-DevOps 增加对 FluxCD 相关资源配置、变更操作的 API
在 KubeSphere-DevOps 控制台实现 FluxCD 多集群部署的便捷配置
在 KubeSphere-DevOps 增加对部署状态管理的的 API

掌握 DevOps、FluxCD 相关知识与理解
掌握 DevOps 相关的知识，包括但不限于: 什么是 DevOps, 为什么需要 DevOps，DevOps 实践
掌握 FluxCD 相关知识: 各个 Controller 所对应的资源含义与使用
完成 KubeSphere-DevOps 与 FluxCD 的对接
完成基于 Source Controller 所支持的配置源管理与对接
完成 Kustomize 管理 API、多集群应用差异化配置设计与实现
完成 Helm 管理 API、多集群应用差异化配置设计与实现
基于 Notifcation Controller 完成应用发布状态的管理与展示
基于 Image Automation Controllers 相关组件完成应用自动化更新的配置与管理及状态更新

Golang
Kubernetes
FluxCD
React(前端)"
"为了使Volcano易于使用和理解，你的任务是改进阅读材料。具体如下：
更新helm包并使其强大。
为用户添加安装和部署的bash脚本，以便于安装、部署和更新。注意，您应该确保脚本可以满足不同的环境，并清理所有生成的资源。
提供用户指导

完整可用的helm包

关于Volcano安装、部署和更新的健壮shell脚本

用户指南

Kubernetes
Bash"
"OpenDigger 目前已经内置了一个 JavaScript SDK，文件在仓库  /src/opendigger.js  路径下。通过这个开发工具包，用户可以快速对开源项目进行统计分析。

为了满足更多开发者的需要，我们打算在已有的 JavaScript SDK 的基础上，实现一个 Python SDK。这样的话，在 Jupyter Notebook 中就可以方便的使用 Python SDK 进行开发。

为了完成这个项目，申请者需要：

1. 使用 GitHub 仓库的源代码构建项目，并运行。（使用数据镜像和修改过支持 Node.js 内核的 Notebook 镜像）
2. 在 Notebook 中查看 handbook，使用 JavaScript SDK 进行一些分析工作。
3. 通过一些分析任务，了解数据库中表的字段的含义。
4. 在上述基础上，选择合适的工具实现一个 Python 的 SDK。

Python 语言编写的开发包

使用 Python3 进行开发
能够读取配置文件连接 clickhouse 与 neo4j 数据库
能够妥善处理异步请求"
"Kustomize 自带的 resource generator 可以非常方便地帮助用户生成资源的 yaml 文件，比如 configMap, secret 等。OpenKruise 中的 ResourceDistribution 组件能够帮助用户分发、管理 configMap、secret 资源，但是 ResourceDistribution 的 yaml 文件编写与维护很不方便，所以需要实现具备类似 kustomize generator 功能的 plugin。

实现 ResourceDistribution generator 的功能

熟悉 kubenetes 基本原理
了解 kustomize 使用及 plugin 扩展
了解 kubectl plugin 开发"
"目前，将PULL模式的成员集群注册到Karmada控制面，需要提供Karmada控制面的管理员证书，该行为带来了一定的证书泄漏风险，并且无法区分多集群管理员和单集群管理员的权限。
希望能增强Karmada的证书管理能力，达到如下目标：

1、实现用bootstrap token的认证模式注册成员集群，并自动签发证书。

2、为karmada-agent实现自动证书轮换功能，减轻运维压力并增强其安全性。

向Karmada命令行工具添加子命令，以支持注册拉模式簇。

向Karmada命令行工具添加子命令，以查看和生成Karmada控制面上的引导令牌。

将证书旋转控制器添加到Karmada控制面，以支持Karmda代理的证书旋转。

相关功能的文件和用户手册。

熟悉Golang

熟悉Kubernetes

熟悉TLS/SSL"
"
OpenPPL 是高性能深度学习推理引擎，而 LSTM、GRU 以及 OneHot 是 NLP/语音领域的经典算子，这些算子在 OpenPPL 中的支持正处于缺失抑或是未经深度优化的状态。

通过添加这些算子，可以帮助熟悉 OpenPPL 的前后端交互逻辑；通过优化这些算子，可以帮助掌握的一些高性能优化技巧，熟悉并掌握 CPU-Bound 和 I/O-Bound 的判别和优化方法，熟悉 X86 SIMD 的特性和使用方法。

你将在本次课题中提供这些算子的实现并进行性能优化，帮助 OpenPPL 打通 NLP 领域的高性能推理

在 OpenPPL 的 X86 Engine 上完成 GRU/LSTM/OneHot 算子的多线程推理支持以及优化，提供 AVX512/FMA 指令集支持，并达成一定的优化目标
基于 OpenPPL X86 Engine 中现有的 LSTM 实现进行计算优化
在 OpenPPL X86 Engine 中实现 GRU 并进行计算优化
在 OpenPPL X86 Engine 中实现 OneHot 并进行计算优化

熟悉 C++ 编程语言，掌握一定的 CPU 架构计算优化方法，掌握一定的多线程编程技术比如 OpenMP，了解深度学习基本原理和 Pytorch 的使用"
"1. 量子虚时演化是研究量子多体问题的一个有力的经典算法，但是算法本身指数复杂度的资源要求大大限制了该算法的应用。
2. 随着量子计算的逐渐兴起，人们开始探索能否在量子计算的框架下，以多项式复杂度的计算资源来实现量子虚时演化算法，从而实现哈密顿基态计算的指数级加速，求解诸多经典计算难以解决的问题
3. 然而，虚时演化算子是一个非幺正的，但通用量子计算机的量子逻辑门却都是幺正的，这意味着难以直接将虚时演化算子转化为相应的量子线路，如何实现非幺正的量子模拟是当前量子算法研究的一个热点问题

1. 实现变分线路参数的量子虚时演化算法，用于求解分子体系的基态能 2. 探索其它形式的量子虚时演化算法 3. 实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，量子计算，MindSpore"
"在seata 计算与存储分离下,redis成为炙手可热的Seata事务存储模式,但再此模式下,使用的是java+jedis(pipeline,mulit)的处理,导致在server端断电,宕机等情况下,会因为多次网络io及计算下才算一次完整动作的缘故导致如全局锁被残留时，会影响AT模式下部分数据的处理,而改为lua脚本进行时可将一系列计算+存储交由redis进行,保证了tc存储数据和争抢全局锁时的原子性,保证redis事务存储模式下的高可用,一致性

1. 中期报告前需要完成对于 Seata 的 事务存储模式的流程的梳理，熟悉相关sessionManager的功能,Redis和Lua结合的扎实知识。
2.后期报告需要完成Seata下所有Redis相关动作的Lua化,确保所有计算与存储皆在Lua脚本中执行

1.熟悉java语言
2.熟悉简单lua与redis结合使用
3.对Seata有一定的了解"
"KubeEye 旨在发现 Kubernetes 上的各种问题，比如应用配置错误（使用 OPA ）、集群组件不健康和节点问题（使用 Node-Problem-Detector）。除了预定义的规则，它还支持自定义规则。

KubeEye2.0 支持了以插件化的形式扩展监控规则。本项目即是 KubeEye 插件管理前端界面的开发。主要内容包括插件列表页、详情页开发，插件的安装、卸载、启动、停止等功能。

我们希望：
以 ts、react 技术栈并基于 KubeDesign 组件库完美还原插件列表页和详情页。
使用 Ajax 调用接口实现插件的安装、卸载、启动、停止，并通过 websocket 实时监控插件状态。

对 Docker、K8s 等容器化技术有一定的了解
掌握使用 Typescript、React 等前端流行技术开发 UI 页面
完成插件管理界面开发

avaScript、TypeScript、HTML、CSS
React
Docker、Kubernetes(背景知识)"
"背景：MegEngine Hub 中实现了常用的分类检测等算法，但是还缺少一些最新的深度学习研究领域的算法实现

需求：用 MegEngine 中，添加 CLIP、VQGAN、DALL·E、BigSleep 模型的推理代码，确保精度与其他框架中一致，并添加到 MegEngine Hub 上。

在 https://github.com/MegEngine/ 下贡献一个代码实现的 repo 并有对应的使用文档说明
模型运行与其他框架结果可对应（比如实现 CLIP，可与 https://github.com/openai/CLIP 进行模型对分）

深度学习"
"为 Databend中的 hashtable 模块添加 StringHashTable 。

StringHashTable 服务于 Key 为 String 类型的 HashTable ，然后基于Key不同的长度应用不同的数据结构作插入读取优化，在真实的数据集上测试性能提升对比。

添加 StringHashTable ：插入，查询，遍历等基本功能
Databend 的 分组聚合查询，使用新的 StringHashTable 替换 HashTable
持续优化实现，在真实场景下测试插入以及查询的性能对比

熟悉 Rust
熟悉 Git、GitHub 相关操作"
"KubeEdge 基于 Kubernetes 构建，将云原生容器化应用程序编排能力延伸到了边缘。但是，在边缘计算场景下，网络拓扑较为复杂，不同区域中的边缘节点往往网络不互通，并且应用之间流量的互通是业务的首要需求，而 EdgeMesh 正是对此提供了一套解决方案。 

1.设计文档、测试文档、用户使用手册、Demo文档完善，内容生动、易懂
设计文档：架构图、流程图、时序图
测试文档：端到端测试用例
Demo部署文档和用户使用手册
2. 所有代码符合开源标准
功能代码
单元测试代码

K8s
Golang"
"在离线混合部署作为提升资源利用率的重要手段，但由于在线业务和离线业务被部署到同一节点上会导致共享资源竞争，从而对在线业务的服务质量QoS（Quality of Service）造成影响。本项目要求对在离线业务L3 Cache与MBA 内存带宽进行动态隔离，从而保证在线业务的服务质量。

1、 容器化部署对L3 Cache与MBA 内存带宽资源敏感的在线业务（eg: clickhouse）及离线业务（eg: zip压缩）
2、 采集在线业务系统级Metrics（eg: IPC、cache misses、dTLB-loads、branch-misses等），基于指标分析判断在线业务是否满足服务质量要求（QoS抖动范围5%）
3、 在线或者离线负载压力突发情况下，要求在1s内完成对在离线业务L3 Cache与MBA 内存带宽按需隔离
4、 尽可能保障在线QoS的情况下，最大化离线的吞吐率

1、可使用go/rust语言
2、基于resctrl技术隔离
3、CPU和内存开销尽可能小"
"禅道是一款开源项目管理工具，通过每日工时统计表插件，可以实现根据禅道中任务的开始时间、结束时间、预计工时，计算出项目中所有人指定月的每一天的工作量统计。

我们希望同学可以：
1. 了解并学习禅道的使用及管理流程，对禅道的管理逻辑有更深入的理解。
2. 完成“禅道每日工时统计表插件”的开发。

1. 通过禅道每日工时统计表插件，可以在禅道中查看各个项目的指定时间段内每一天的团队成员的工作量信息。
2. 统计表显示的数据准确。
3. 页面结构良好，数据展示清晰。

熟练使用PHP语言编写程序，熟悉 Linux 系统基本命令，掌握基础的MySQL语法。"
"Karmada（Kubernetes Armada）是基于Kubernetes原生API的多集群管理系统。在多云和混合云场景下，Karmada提供可插拔，全自动化管理多集群应用，实现多云集中管理、高可用性、故障恢复和流量调度。其中多云容灾，故障恢复是很重要的一部分，涉及到集群故障的判定、Failover调度，以及资源状态的收集。

1.目前Karmada判定集群故障的方式可以优化以减少误判。需要改善现有的判定流程，使故障检测更加健壮。

2.使用Karmada部署多集群应用时，控制面是用户与多集群交互的主要途径，用户首先在控制面中创建资源，并通过传播策略下发到member集群，之后，Karmada会收集下发到各个集群的资源状态，经过聚合后在控制面中体现。
然而，当member集群故障时（因网络问题、节点宕机等），控制面上的资源状态并不会更新，仍然保持在集群故障之前的状态，导致用户无法感知该集群的应用已经故障。因此，我们希望在集群故障/恢复故障时，及时地更新资源状态，让用户实时感知到跨集群应用的当前状态。

3.需要考虑上述问题与Failover调度之间的联系。

设计解决方案（包括说明、流程图）

向社区提交PRs（合并）

提供测试结果

熟悉Golang
对Docker和Kubernetes的理解
能够使用git"
"本项目需要的编程语言为 JavaScript/TypeScript，涉及的技术栈包括 Node.js、Vue 3、esbuild 等。需要对 Element Plus 的代码有一定了解。

本项目主要的目标为优化项目结构和构建流程。
使用 monorepo 管理项目结构，并分别发包到 npm registry；
优化构建速度；
优化和简化发布版本流程

使用 monorepo 管理项目结构，并分别发包到 npm registry
优化构建速度
优化和简化发布版本流程

Node.js、Vue 3、esbuild"
"OpenStack是云计算领域知名并广泛部署的云计算基础设施。但OpenStack本身项目繁多，部署和升级难度较大，易用性较差。有一种解决方案是使用容器化部署。Kubernetes(K8S)是目前容器化领域应用最广泛的平台，越来越多的用户或企业在工作、生产环境中使用K8S，那么为什么不把OpenStack部署在K8S上呢？其实OpenStack已经通过OpenStack-helm项目支持了K8S容器化部署。OpenStack-heml通过使用helm工具提供了一系列的部署脚本。Helm是K8S生态中应用较广的K8S app部署工具。目前，openEuler并不支持OpenStack-helm。本项目目标是把OpenStack-helm引入到openEuler中。

1、引入openstack-helm、openstack-helm-images项目到openeuler中，编写RPM spec，构建对应的RPM包
2、测试引入的openstack-helm软件，保证功能正常，输出部署文档到openstack sig。
3、修改openstack-helm-image，新增openEuler容器镜像支持，输出修改PR和使用文档。

1、掌握python编程语言。对jinja、go、Dockerfile熟悉的同学优先。
2、熟练使用Linux。
3、对虚拟化、容器化有一定了解。使用（了解）过OpenStack或K8S的同学优先。"
"在实际的微服务/服务化应用中，有大量通过消息队列解耦的场景。DTM提供的二阶段消息，一方面优雅的解决了消息最终一致性的问题，另一方面，也希望通过管理后台进行动态配置，将消息队列解耦这件事情加以简化，提供更易用的方案。

因此主要设计如下：
用户发起二阶段消息时，指定topic，然后在管理后台配置topic对应的处理api，api数量为0~n。这样未来如果有其他服务想要监听这个消息，那么只需要直接在管理后台添加相关的配置即可，不再需要对应用进行修改，大大简化整体工作

二阶段消息增加topic参数
dtm服务器定时获取topic配置
二阶段消息的处理会根据topic配置调用api

熟悉消息队列解耦
熟悉微服务/服务化"
"Nacos新增规范化的2.0版openAPI接口，并增添相应的文档。

梳理并以新风格规范实现2.0版本的OpenAPI（包含服务发现模块、配置中心模块及核心模块）；
以新风格规范实现2.0版本新增的以客户端维度进行查询的OpenAPI；
在Nacos的官方文档中添加新OpenAPI的相应文档；

熟悉Java
熟悉Spring Boot优先
熟悉Markdown优先"
"VS code 是一款比较流行的源代码编辑器，将其集成到Anolis OS中可丰富龙蜥社区的应用生态，更好地服务社区开发者。

VS code仓库以及rpm包；完成基于Vscode开发用户使用文档

学习包编译流程；学习基本nodejs相关内容"
"机器人操作系统 (ROS) 是斯坦福最早 2007 年开发的一系列软件包，帮助快速开发机器人应用。如今第一代 ROS 在应用中暴露出了一些问题，但是解决这些问题会导致无法兼容以前的程序，于是 ROS 社区直接发布了第二代 ROS。ROS2 原本是运行在 Linux 上的软件包, microROS 希望能在 MCU 上使用 ROS2 的 API, 将 MCU 接入 ROS2。
这个项目则是希望能在 RT-Thread 上使用 microROS。现在 RT-Thread 已经有 micro_ros 软件包(https://github.com/wuhanstudio/micro_ros)，但是还有一些问题需要解决：UDP 通信偶尔掉包断开连接，service 相关的例程不够丰富，MCU 编译需要使用预编译的静态库 (rmw，rcl，rclc 源码不在软件包内)，还无法集成到 micro_ros 官方的编译系统提供 benchmark 结果。

提供 micro_ros 使用 UART/UDP 稳定通信的 service 例程
分离 rcl / rclc 和 rmw 的源码，不需要预编译的静态库，直接 RTT 源码编译 micro_ros
集成到 micro_ros 官方的编译系统，并提供在 RT-Thread 上的 benchmark 结果

熟悉 ROS2 的 C API
熟悉 ROS2 Stack (rcl / rclc，rmw，dds) 和对应的实现
熟悉 RT-Thread 的 UART/UDP 通信以及软件包开发"
"Prometheus 是 Kubernetes 生态中的一个开源系统监控告警解决方案，在本任务中，你需要结合 Prometheus 为 GraphScope 系统提供一套统一的 UI，来帮助监控、追踪 GraphScope 集群的运行状态。

一个 Prometheus Exporter，该 Exporter 可以是 Python 脚本，负责解析 GraphScope Store 服务日志并生成 Prometheus 可识别的日志信息
在 GraphScope Coordinator 中暴露 Http 服务，负责生成 Prometheus 可识别的日志信息
结合 Prometheus Grafana 的可视化展示页面

"
"Dragonball-sandbox是开源于龙蜥社区（OpenAnolis）下rust编写的轻量虚拟机项目，具备低开销、高隔离性、极致弹性等特点，直接落地在阿里云函数计算、ECI等云原生场景。本实验的目的是基于现有Dragonball-sandbox开源代码，实现一个用命令行参数启动虚拟机的功能。在这个过程中，学生也可以对Rust代码、虚拟化技术、开源社区协作方式等获得更深的了解。

完成用命令行启动虚拟机的功能。完成相关代码和文档。

熟悉rust语言，了解虚拟化技术。"
" Senparc.Weixin SDK 是目前市场占有率 95%+ 的 微信 .NET SDK，已支持微信全平台大部分接口，包括：微信公众号、微信小程序、企业号、微信支付、微信开放平台，等等。Senparc.Weixin SDK 同时也是中国综合排名最高的 C# 开源项目之一：https://github.com/JeffreySu/WeiXinMPSDK

1.配合社区完善相关文档更新
2.完善微信支付（V3）相关接口与文档
完善微信支付（V3）服务商接口支持；
完成微信支付（V3）国密签名验签支持；
完成微信支付（V3）相关接口单元测试100%覆盖；
完善微信支付（V3）相关功能独立sample；
书写微信支付（V3）相关功能文档；
3.完善微信SDK独立Sample
4.完善微信 CLI 工具相关接口与文档
完善微信 CLI 工具微信支付（V3）相关辅助功能支持(包含微信支付V3加密及一系列配套工具)；
完善微信 CLI 工具微信消息服务（机器人对话）模拟器；
完善微信 CLI 工具常用功能代码生成器；
完善微信 CLI 工具辅助开发调试工具；
书写微信 CLI 工具相关功能文档；

1.熟悉 C#
2.熟悉 .NET / .NET Core
3.熟悉微信开发流程 / 对微信开发感兴趣"
"在 cpuset 模式下，Kata Containers 的虚拟机 vCPU 目前是共享 CPU 资源的。本项目目标是实现 vCPU 线程和物理CPU的一一绑定，并让虚拟机 cpu 拓扑模拟物理 CPU 拓扑，从而减少在 cpuset 模式下 vCPU 线程之间的干扰。

支持在Host/Guest之间绑定vCPU的Kata Containers

了解虚拟化以及Linux cgroup，尤其是 cpuset"
"Apache Pulsar 近期将发布新版官网，为用户带来全新的内容体验。优质的内容体验离不开高效的内容开发流程，为了提升内容开发效率，该项目旨在于自动化内容开发流程，包括但不限于从代码中自动生成内容网页、通过 GitHub Actions 规范 Pull Request 内容等。

对于项目而言：
制定清晰的目标和合理的计划
为项目设计思路和实现过程等撰写方案
如期完成项目，合并代码至 Pulsar 仓库
对于学生而言：
收获有利于今后人生发展的软硬技能

项目技术要求
沟通能力和问题解决能力优秀者优先
熟悉 Java、Vue.js 和 Git 优先
有开源社区经验优先"
"在性能分析和问题定位中，常常需要对IO进行统计分析和单IO追踪分析，
传统的手段：
1）采用blktrace手段跟踪每个IO处于各个阶段的时间戳和进程等信息；
2）采用trace的方式跟踪内核态指定函数。
这两种方案存在的问题：
1）效率低对性能影响很大；
2）通过文件输出方式中间结果，1秒监控结果就可能有几十兆甚至几百兆的大小，跟踪时长有限，解析难度大；
3）结果可视化效果不好；
eBPF是一种可以在 Linux 内核中运行用户编写的程序，而不需要修改内核代码或加载内核模块的技术。简单说，eBPF让 Linux 内核变得可编程化了。eBPF程序是一个事件驱动模型。Linux内核提供了各种hook point，比如system calls, function entry/exit, kernel tracepoints, network events 等。eBPF程序通过实现想要关注的hook point 的 callback，并把这些 callback 注册到相应的 hook point 来完成“内核编程”[1]。所以基于ebpf可以实现高效地对IO栈各个阶段进行数据统计，并将统计后的数据进行可视化展示。并且能够实现在pid|时间|设备|IO|文件等维度上给出相关性分析结果。
该项目包含的特性总结如下：
1.统计单个IO从文件到落盘各个阶段的事件、时间戳、pid、io类型等信息；
2.支持对连续统计数据进行本地化保存，并支持对本地化保存数据的加载和可视化展示。
3.数据在各个pid|时间|设备|IO|文件等维度上给出统计结果，并支持相关性分析结果；

1、实现对所有设备或指定设备的IO各个阶段耗时统计，并可以给出可视化统计结果；
2、支持导出数据并提供工具进行线下分析；

1.熟悉ebpf机制；
2.熟悉内核IO栈；"
"Apache APISIX 即将迎来 V3 版本，而 Apache APISIX Dashboard 也需要对 V3 版本进行适配，借此机会，我们需要将 Dashboard 的前端部分进行重构，以解决历史问题，并带来更好的体验。

使用 TypeScript 作为主要的编程语言
梳理项目结构，制定合理的重构计划
完成重构方案中路由与页面的重构工作
协助解决项目中现存的 issue

熟悉 TypeScript、React、NodeJS，以及相关生态
能使用 Git 和 GitHub 进行协作开发
了解 React 和 NodeJS 相关生态者优先
了解 Apache APISIX 者优先"
"1. 增强layotto的java-sdk的功能，使其与go-sdk对齐。现在的java-sdk有file、lock、pubsub、sequencer、state 的API，缺少secret、config等API。
2. 完善 layotto-sdk-springboot, 将layotto的更多功能集成进spring-boot。layotto-sdk-springboot的设计目标是帮助 spring-boot 的用户低成本接入 Layotto，比如用户在代码中添加一个java注解后，就能方便的进行消息监听、收到新消息后自动调用方法。
3. 在 layotto-sdk-springboot 的基础上，开发 layotto-sdk-sofaboot, 方便 sofaboot 用户使用 layotto。

增加layotto-java-sdk的api
增加layotto-spring-boot的功能
增加layotto-sdk-sofaboot的功能

了解云原生运行时的概念
了解java和go语言"
"JuiceFS 是一款面向云原生设计的高性能分布式文件系统，架构上使用事务数据库来管理元数据，使用对象存储来存储数据。JuiceFS 目前已支持多种元数据引擎，如 Redis，MySQL，TiKV 等。FoundationDB 是 Apple 开源的分布式事务 Key-Value 数据库，也可以用来管理 JuiceFS 的元数据。

本项目希望能将两者对接起来，使 FoundationDB 成为 JuiceFS 元数据引擎的备选方案之一。

1. 实现 FoundationDB 与 JuiceFS 对接，使其能被用来管理 JuiceFS 的元数据
2. 测试并验证对接后系统稳定性，性能等，比较与已有元数据引擎的异同
3. Bonus：较深入地了解 FoundationDB 实现机制和适用场景，编写最佳实践文档

1. 基本了解分布式系统，文件系统，Key-Value 数据库
2. 熟悉 Go 语言，GitHub 的使用和协作
3. 能阅读英文文档"
"为 Universal OJ 博客系统增加功能。

UOJ 目前采用 markdown 编写博客，而回复博客则只支持纯文本。
本项目旨在增强这一部分系统，包括以下新特性：
- 站内图床。允许用户上传图片到 UOJ 站点中，以供引用。
- 评论回复功能增强。需要让评论功能也支持 markdown。
- 附件。允许博客编写者上传附件，例如 PDF 题目等。

图床和附件应当支持多种存储后端，如文件系统、块存储等。

支持在博客和评论区上传图片
支持在博客编辑页面上传附件、在博客展示页面提供附件下载
支持 markdown 博客评论

使用 PHP 进行开发
设计对应 UI"
"Hmily是柔性分布式事务解决方案，提供了TCC 与 TAC 模式。它以零侵入以及快速集成方式能够方便的被业务进行整合。在性能上，日志存储异步（可选）以及使用异步执行的方式，不损耗业务方法方法。
        Hmily XA已经完成了部分Rpc的支持，定义了XA模式的实现接口。现需要实现Hmily XA支持Spring cloud。可参考Dubbo的实现来完成Spring cloud的支持。

完成Hmily XA支持Spring cloud
Spring cloud使用 Hmily xa 可以正常commit。
Spring cloud使用 Hmily xa 可以正常rollback。

熟悉Spring cloud.
了解XA 基本概念与原理."
"OpenDigger 作为在木兰社区孵化的开源项目，承担了目前国内 GitHub 数据分析的绝大部分工作，例如中国开源年报、GitHub 数字洞察报告、中国开源发展蓝皮书、中国开源码力榜等。

除一次性的数据报告外，OpenDigger 也支持定时为下游项目提供数据生产与更新的能力，例如为 OpenLeaderboard、Hypercrx 等项目提供持续的数据更新能力。目前这部分依然是由人工手动触发脚本完成的，希望在本次项目中，将该部分的定时任务做到线上，为后续的大规模数据生产提供有效的保障。

项目需要完成：
1、与 GitHub CI/CD 流程的深度融合，实现代码更新后的实时部署
2、完成线上定时任务的自动化部署，可定时执行脚本进行数据更新操作
3、对线上任务进行监控与健康检查，服务异常需要有相应的重启与通知能力

线上可稳定运行的定时数据生成项目
与 GitHub 深度集成的自动化持续部署

熟悉 Node.js 开发流程
熟悉基本的 Linux 与容器操作
了解 GitHub 的持续部署流程"
"Flink Table Store 是一个流批统一的存储，用于在Flink中为流批处理建立动态表，支持实时流消费和实时OLAP查询。
Flink Table Store 面向更新场景提供 OLAP 的能力，大量更新数据写入 Table Store 后，后台会合并相同主键的数据，默认是保留最后一条。
我们可以引入更丰富的合并策略，其中已经引入的是PartialUpdateMergeFunction，合并时补全非NULL字段。我们可以引入更强大的合并策略，比如支持预聚合的合并。

完成该功能的开发，并贡献到Flink Table Store社区。
完成预聚合的API设计
完成预聚合的E2E测试
实现多个聚合算子
MATERIALIZED VIEW 可选

了解大数据计算相关知识，学习存储相关知识，学习Flink Table Store设计和架构"
"Serverless Devs目前拥有可观测、Edit等相关能力，但是都是零散的单页面内容，选择该题目的同学，需要具备已经的Serverless基础，以及Web应用开发基础，通过对Serverless的进一步学习，可以开发Serverless Devs UI，并贡献给社区。

针对已支持的可观测性，EDIT等相关功能进行Serverless UI的整体汇总与设计,针对设计结果，进行相关功能的开发，并贡献到Serverless Devs社区
完成 Edit 能力的支持
完成 TraceId 查询能力的支持
完成UI开发与功能对接

对Serverless有一定的了解，或者愿意学习和了解Serverless架构
对Node.js，Typescript等语言有所了解，或者具有较强能力可以快速学习Typescript语言
了解并熟悉对Github等使用方法"
"Apache Iceberg是一种开放的表格格式，专为巨大的PB级表格而设计，是目前市面上流行的三大开源数据湖方案之一。当前，openLooKeng还没有支持Iceberg,因此需要开发Iceberg connector。

1. Iceberg connector设计文档
2. Iceberg connector代码与相关测试用例
3. 性能测试结果

1. SQL、Java编程
2. openLooKeng connector原理与设计
3. 了解iceberg使用与设计"
"CanoKey 是开源的硬件密钥项目，支持 WebAuthn、OpenPGP、PIV 等多种协议，其完全开源的版本基于 STM32L432 单片机。nRF52840 是 Nordic Semiconductor 公司推出的芯片，与 STM32L432 相比多了密码运算等特性，且基于 nRF52840 的 USB 开发板更容易取得，方便了用户制作自己的开源安全密钥。本项目的预期目标是将 CanoKey 的固件移植到 nRF52840 上，使开发者可以有更多硬件选择。
 
一个适用于 nRF52840 的 CanoKey 固件

ARM 开发基础
USB 协议栈"
"F2FS文件系统压缩功能已在kernel主线使能并持续演进优化，openEuler目前还未使能。使能压缩之后，可以促进f2fs在小型存储设备的上的使用。另一方面，Linux f2fs支持的三种压缩算法存在一定的可优化空间，或者在某些场景需要引入新的压缩算法。

1、使能OLK-5.10的F2FS支持的三种压缩算法，给出性能基线数据；
2、回合Linux kernel社区未合入的补丁；
3、稳定性测试，提出改进方法或者BUGFIX优先合入OLK-5.10并同步给Linux kernel社区；
4、自己寻求价值点，为F2FS引入新的压缩算法(不作为结项考量)

1、熟练使用Linux kernel；
2、熟练C编程；
3、熟悉存储基本知识"
"PiFlow提供了100+主流大数据处理组件，机器学习组件。同时集成了微生物等领域组件。PiFlow具有多语言特性，以组件形式提供了Shell脚本执行组件、Java执行组件、Scala执行组件，支持用户输入代码完成数据处理功能。Python执行组件也已经提供，但是仅支持调用，不支持读取上游组件处理的数据并传递给下游。因为需要学生通过调研，实现Python执行组件，支持无缝衔接上下游组件数据。

Python执行器组件一个

熟悉Spark技术原理，熟练掌握Scala/Java和Python语言，了解JVM原理"
"WebAssembly 或者 WASM 是一个可移植、体积小、加载快并且兼容 Web 的全新格式。目前，wasm 技术的应用越来越广泛，并逐步扩展到边缘i算应用（例如 WasmEdge 应用）。本项目的目标是利用 WASM 的 go SDK, 完成 eKuiper SQL 调用 WASM 函数的功能，方便用户使用 WASM 函数扩展 eKuiper 的处理能力。

完成代码开发并提交PR到社区
设计文档，提交社区评审
代码实现和对应的单元测试
完成使用文档

了解或愿意学习 WASM"
"开发昇思MindSpore CPU正向算子ApplyAddSign：根据 AddSign 算法更新相关条目

1.算子功能符合要求、能力对齐标杆 2.代码满足社区规范、精度、性能等达到标准 3.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"内核使用alloc_page申请的内存不会显示在meminfo中，经常出现内存不够情况却不知道谁在使用，利用bpf工具统计内核alloc_page内存占用信息

1.统计所有alloc_pages使用的内存占用信息；
2.过滤出最多使用路径

1.熟悉bpf
2.熟悉linux内核内存管理"
"Apache ShenYu是一款高性能的API网关，社区十分活跃与友好，非常适合高校学生学习与参与,通过参与这次活动可以学习Apache项目的社区建设，后续有兴趣继续贡献，可以成为Apache Committer。

该项目是建设Apache ShenYu的官网(https://shenyu.apache.org/），包括主页设计，配图设计，博客页面设计，新闻事件页面设计，以及文档的更新。

1.设计与开发Apache ShenYu官网主页
2.设计与开发博客页面
3.设计与开发新闻页面
4.优化与书写文档

设计与开发Apache ShenYu官网主页
设计与开发博客页面
设计与开发新闻页面
优化与书写文档

熟悉与使用JavaScript
熟悉Java语言以及常见的设计模式
熟悉Spring Boot"
"AOSC 的软件包信息站现已与目前 AOSC OS 的构建系统和元数据格式严重脱节。需要一个新的网站后端与数据同步系统的实现。

实现一个全新的网站后端，可以正确地解析所有 AOSC OS 软件包的元数据。
实现一个新的数据同步后端，需要能正确地解析所有 AOSC OS 软件包元数据以及 abbs 树中的所有软件包信息。
新实现的后端需要能承受较大的请求吞吐量。

后端和同步系统需要使用 Rust 和/或 Python 实现。
需要对 AOSC OS 的基本构建和维护工具有基础了解。
熟悉 PostgreSQL 和 SQLite 数据库系统。
较为熟悉 Bash 语法。"
"LMP 项目面向 eBPF 初学者和爱好者，现已成为 eBPF 想象力孵化池，其中子项目 eBPF_Visualization 目标是提供一个易用的轻量级的 eBPF 程序管理系统，专注于 eBPF 数据存储和可视化及 BPF 程序管理编排。当前该子项目正处于方案重构阶段，需要开发者参与 web/cli 管理系统方案重构设计和落地，基础功能包括 eBPF 数据持久化存储，eBPF 程序下发及生命周期管理，与前端配合实现数据的可视化展示。

RESTful API 文档
项目代码提交到仓库
详尽的项目文档

了解 Git、Github（或Gitee）相关操作
了解 Rustful API
了解 Go Web 开发
对 eBPF 有初步的认知"
"当前Nacos的服务发现和配置管理的寻址模块是分开实现的，需要进行一定的统一及重构，并进行插件化。

1.梳理已有的寻址工作流程和能力，设计出全新的统一的寻址功能，提供插件化的能力，输出详细设计文档;
2.根据设计文档，对现有的寻址模块进行重构和开发;
3.提供插件化寻址能力的接入示例和文档。

熟悉Java
熟悉Nacos优先"
"heartbeat目前的官网为 https://hertzbeat.com. 此项目需求为对官网UI重新设计改版，对文档进行国际化(中英)。具体为下面几点：
1. 对heartbeat的官网UI重新设计改版
2. 对官网内的文档进行英文国际化

项目代码能以PR的形式合入仓库
改版实现一个美观UI的官网
国际化文档

对开源抱有热情和强烈兴趣
熟悉前端知识html css
简单英文写基础"
"KubeEdge SIG Robotics关注云机器人领域基于云边协同架构的机器人管理系统。我们希望使用开源的移动机器人和机械臂，基于KubeEdge软件组件来实现一个demo，能完成以下的任务：
1、实现完整的机器人应用，包含移动导航、机械臂操作等关键功能，并通过KubeEdge部署到仿真环境
2、定义移动机器人开柜门抓取的工作流，包含导航到目标点、开柜门、抓取物体等任务，并通过KubeEdge自动执行工作流

1. demo部署到仿真环境，并正常运行
demo的部署和使用手册
2、通过工作流自动完成导航到目标点、开柜门、抓取物体等任务
必要的代码和配置文件
端到端的测试用例

K8s
Golanq、C++
ROS
airflow"
"目前 ECharts 中的漏斗图展现形式更接近于金字塔图，我们希望能够在保留当前展现形式的前提下增加一种更接近漏斗图的模式。可以支持底端输出端展现成漏斗形状，同时支持每一级显示成不同高度。

调研相关产品的功能和接口设计，与导师讨论确定包括接口在内的设计方案，在 GitHub 上以 issue 形式发布
修改源码以实现项目要求的效果
编写测试用例，并且完成对现有测试用例的回归测试
编写文档和教程

熟悉 TypeScript 或 JavaScript
熟悉 git 操作"
"当前DolphinScheduler对于权限的管控相对比较简单，希望在进行项目和资源中心授权时增加操作权限管控来进行读写权限的分离。

针对单个项目的全部内容进行读写权限区分，对单个用户针对单个项目授权只读或者读写权限
针对资源中心的全部内容进行读写权限区分，基于当前资源中心的授权内容区分出只读或者读写权限
进行授权时前端页面增加只读和读写的授权操作

熟悉Java、Spring、Vue3、TypeScript"
"KubeVela 是 OAM 模型的标准实现，Application 为开发者提供了简单易用的接口来部署他们的服务，把复杂的基础设施能力和编排细节交给平台工程师，Application 对复杂的底层资源进行了封装，虽然降低了开发者部署服务的心智负担，但也同时屏蔽了底层资源的状态，每当开发者遇到服务部署出现问题的情况，往往会表现得束手无策。本课题需要同学利用VelaQL能力，通过Vela-Cli为用户提供一个交互友好的界面，提升Application资源的可观测性，通过本课题，同学们可以熟悉和掌握K8s和KubeVela的架构，深入了解如何基于K8s生态开发应用。

1. 设计文档 2. 资源监控面板具体实现

1.对开源抱有热情 2.有一定编程基础 3.愿意学习golang语言 4.愿意学习kubernetes 和 KubeVela"
"本项目的主要目标是利用 SQLancer 完成对 Databend 的自动测试。

SQLancer 是一款用于自动测试数据库管理系统（DBMS）的工具，以发现其实现中的逻辑错误。逻辑错误：即那些导致DBMS获取错误结果集的漏洞。

完成 SQLancer 对 Databend 的初步支持
构建合适的持续集成服务，完成打包 SQLancer 及自动测试
进一步改善实现质量，争取合并到上游 SQLancer 中

熟悉 Java
了解数据库和解析器等相关领域知识
熟悉 Git、GitHub 相关操作"
"对当前sql输入联想功能进行优化，把当前的关键字联想改为表结构联想，参考plsql developer

实现功能：对当前sql输入联想功能进行优化，把当前的关键字联想改为表结构联想，并且在选择“all”时自动填充所有表结构

1.了解数据库的基本知识，已经客户端的使用。 2.熟悉java编程开发"
"1. 量子多体问题的求解对于物质理化性质的理解以及化学反应的预测都极其重要。但是，在经典计算机上，要么是以指数复杂度的计算成本来实现多体问题的精确求解，要么是以多项式复杂度的计算成本来实现对问题的近似求解，无论哪种方法都不能满足人们的要求。
2. 量子计算作为一种新的计算模式，在对多体问题的求解上，具有超越经典计算的潜力。现有关于多体系统基态能求解的量子算法主要是基于线路参数变分(variational quantum eigensolver, VQE)的理论框架，这会面临复杂的非线性优化问题以及测量次数的直线上涨。
3. 最近，基于量子计算的量子蒙特卡洛方法的提出，为基态能的高效计算提供了一种新的思路，但是关于该算法的计算成本以及计算结果的准确性还需要做更深入的探究

1. 基于昇思MindQuantum，实现量子蒙特卡洛方法，用于求解任意量子体系的基态能 2. 实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，量子计算，MindSpore"
"在云边协同场景下，边缘与云端通过公网连接(例如WIFI，4G，5G等)，由于各种客观或主观因素，边缘节点可能与云端断开网络连接。而原生Kubernetes中的Workload(如Deployment，DaemonSet等)的升级都依赖边缘节点与云端网络连通。因此当云边网络断连状态下，如何完成边缘业务的升级成为云边协同场景下一个非常值得探索的课题。通过本题目的挑战，同学们可以深度掌握各类云原生的业务负载升级模型，以及边缘场景下边缘业务的生命周期管理实战。

基于OpenYurt云边一体化架构，设计并实现边缘应用负载的升级模型
设计适合边缘场景的应用负载管理模型，并提交相应的Proposal
实现边缘应用负载控制器，解决边缘业务升级的痛点问题

熟悉云原生相关技术，有一定的项目开发经验
熟悉Docker、Kubernetes等技术，了解Kubernetes工作负载管理模型
有Go语言开发经验
了解OpenYurt项目，对边缘云原生有浓厚的兴趣"
"把大数据常用的ambari组件引入到openEuler社区，即完成源码构建，在openEuler上安装成功，并在openEuler上成功运行。代码和spec文件需要上传到仓库，CI通过并合入。

将ambari引入到openEuler，生成rpm包能安装成功，并正常运行。

1、熟悉使用maven编译java项目。
2、熟悉java语言。"
"树莓派生态已经越来越被开发者接受和喜欢，并逐渐应用于各种嵌入式场景。

通过该项目可以学习树莓派引导和镜像制作流程，并有机会进行内核相关开发适配。

项目计划输出适配树莓派镜像构建流程代码；并最终输出并发布适配树莓派（3b, 4）的龙蜥镜像。

树莓派镜像构建流程代码
适配树莓派（3b, 4）的龙蜥镜像

精通 Linux，有一定 Linux 内核基础。"
"Delta Lake是目前市面上流行的三大开源数据湖方案之一。当前，openLooKeng还没有支持Delta Lake,因此需要开发Delta Connector。Delta Connector使用Delta Lake提供的Delta Standalone Library (DSR)来读取表元数据。

Delta Lake Connector设计文档
Delta Lake Connector代码与相关测试用例
性能测试结果

SQL、Java编程
openLooKeng Connector原理与设计
了解Delta Lake使用与设计"
"目标：将 RadonDB MySQL Kubernetes 的 NFS 备份步骤集成为一个命令。
 
背景：RadonDB MySQL Kubernetes 是基于 MySQL 的开源、高可用、云原生集群解决方案。支持一主多从高可用架构，并具备安全、自动备份、监控告警、自动扩容等全套管理功能。
RadonDB MySQL Kubernetes 支持在 Kubernetes 和 KubeSphere 上安装部署和管理，自动执行与运行 RadonDB MySQL 集群有关的任务。
 
RadonDB MySQL Kubernetes 除了可以将数据库备份到 S3 存储外，也可以将数据库备份到 NFS 存储。
 
详情：NFS 备份方式是用户在没有 S3 存储到情况下的备份方案。通过 NFS，用户挂载本地存储，自定义存储实现数据库灵活备份恢复。
 
NFS 备份，需要有三个步骤：
创建 StorageClass 与 Persistent Volumn
创建 NFS Resource 与 Service
绑定 NFS 的 IP 到 Backup Resource ，应用 Backup Resource，执行备份 Job
项目要求能自动进行上面三个步骤。

实现一个命令行工具，能一条命令执行数据库的 NFS 备份。

MySQL
NFS
Kubernetes Operator
Golang"
"Pulsar SQL是一款基于Trino、用于Pulsar主题数据分析的SQL查询引擎，用户可以通过SQL脚本从Pulsar主题中获取数据。主题压缩功能用来压缩带有 key 的消息，消息压缩后，主题将只保留 key 的最新值。

目前，Pulsar不支持查询压缩数据，这对Pulsar SQL来说是一个有用的改进。实现此功能的一些关键点是了解主题压缩过程，如何拆分主题数据（压缩部分和未压缩部分）以生成查询任务，以及读取保存在特定 ledger 中的数据。

项目验收标准
了解并能使用主题压缩和 Pulsar SQL 组件
编写该功能的设计文档
完成该功能的代码实现
添加单元测试和集成测试
编写本功能的说明文档

项目技术要求
了解 SQL 引擎工作基本原理
熟悉 Java 编程
熟悉基本的 Git 和 GitHub 操作
学习并了解 Apache Pulsar 或其它消息中间件"
"cloudpods 是一个多云管理平台，可以管理不同公有云或者私有云上的资源，比如虚拟机、IP 子网等。

其中 DNS 记录也是被管理的一种资源，本项目需要导出各个云平台的 DNS 资源记录。

实现功能，以 PR 的方式提交代码到 cloudpods upstream 仓库
1. 能够过滤选择需要导出的 DNS 记录和字段，比如只导出 A 记录，CNAME 等;
2. 能够将记录以不同的格式导出，比如 json 格式，或者 CSV 等文本格式；
3. 实现 Zone 格式文件的导出，Zone 文件是 DNS 服务器上存储的域名配置文件，根据 RFC 标准文档制定。比如导出文件 domain.com.zip，解压后得到 domain.com.default_line.zone。

了解 Go 开发，了解 DNS 相关概念"
"背景：
Airbyte是当前数据整合（Data Integration）领域非常火的一款产品。其开源设置维护了数量庞大的数据源端和目的端的连接器，以方便用户在不同数据源之间同步或传输数据库。我们需要为Airbyte贡献Doris Connector。 

需求： 
调研Airbyte连接器的开发流程，包括连接器是设计与实现、如何贡献与维护Connector。
实现Doris的Source和Destination连接器。

1. 实现Doris的Source和Destination连接器。 2. 将连接器贡献给AirByte社区。

对 Java语言熟悉。"
"目前 Nydusd 的 FUSE 和 virtiofs 两种模式是分开编译成两个不同的二进制文件，这为用户的部署和使用造成了不便。本项目目标是把 FUSE/virtiofs 两种模式融合到同一个二进制文件中，为用户提供统一的运行时接口。

重构 fuse-backend-rs 库以支持统一的 fusedev/virtiofs 编译模式
同时支持 FUSE 和 virtiofs 的 nydusd 二进制文件

容器镜像
容器运行时
FUSE 和 virtiofs
Rust"
"Nacos配置管理中包括许多SQL语句，目前只提供了MySQL版本的实现。该项目致力于构建多数据源的相应SQL（包括MySQL、Oracle等数据库）生成的插件。

梳理Nacos配置管理模块的SQL操作，抽象出一套易于扩展的SPI接口；
使用合适的设计模式将现有的配置管理SQL操作转化为插件化；
提供完善的设计文档，并添加单元测试。

熟悉Java
熟悉SQL
熟悉Nacos优先"
"背景 
ShardingSphere Parser Engine 帮助用户将 SQL 语句解析为抽象语法树，并从语法树生成对应的 SQL Statement 对象。Parser Engine 目前支持 `MySQL`, `PostgreSQL`, `SQLServer`, `openGauss` 和 `Oracle` 等多种数据库方言，为了提升对于不同数据库方言的支持度，我们需要对 Parser Engine 中未支持的 SQL 进行优化。更多关于 Parser Engine 的介绍请参考：https://shardingsphere.apache.org/document/current/en/reference/sharding/parse/。 

任务 
这个任务是为了支持解析 Oracle SQL，下面是一些具体任务列表： 
 LOCK TABLE doc 
 ALTER ANALYTIC VIEW doc 
 ALTER ATTRIBUTE DIMENSION doc 
 ALTER AUDIT POLICY (Unified Auditing) doc 
 ALTER CLUSTER doc 
 ALTER DATABASE doc 
 ALTER DATABASE DICTIONARY doc 
 ALTER DATABASE LINK doc 
 ALTER DISKGROUP doc 
 ALTER FLASHBACK ARCHIVE doc 
 ALTER FUNCTION doc 
 ALTER HIERARCHY doc 
你可以从这里获得更多关于语法解析的参考。为了完成这个任务，你首先需要了解它为什么不支持？是因为 antlr4 语法解析异常，还是因为没有实现 visit 函数？你可以使用 antlr4 插件 去帮助你分析，你可能需要访问官方文档来检查语法。 
修复问题之后，记得添加 SQL 测试用例，并且把解析期望的结果写入 期望的 XML； 
运行 SQLParserParameterizedTest 和 UnsupportedSQLParserParameterizedTest 确保没有异常； 
此外，你可以参考一些示例，来辅助完成这个任务： 
Add Oracle SQL - CREATE DATABASE LINK 
Add Oracle SQL-DROP DATABASE LINK 
完成 SQL 解析优化之后，你需要测试在 ShardingSphere 读写分离场景下，该 SQL 是否能够正常执行，并且根据 SQL 的语句，将 SQL 路由至写库或读库。完成读写分离功能的测试后，需要在 ShardingSphere 集成测试 shardingsphere-integration-test 中添加对应场景的测试用例，更多关于集成测试的信息，可以参考：https://shardingsphere.apache.org/document/current/cn/reference/test/integration-test/。 

能够对自己的代码进行测试，保证提交代码的正确性

1. 精通 java；2. 理解 Antlr4 语法；3. 熟悉 Oracle 数据库
"
"当前RocketMQ Raft模式主要是利用DLedger Commitlog替换原来的Commitlog，使Commitlog拥有选举复制能力，但这也造成了一些问题：（1）Raft模式下，Broker组内副本数必须是三副本及以上（2）RocketMQ存在两套HA复制流程，且Raft模式下的复制无法利用RocketMQ原生的存储能力。因此我们希望利用DLedger实现一个基于Raft的一致性模块（DLedger Controller），并当作一个可选的选主组件可以嵌入在Nameserver中，Broker通过与选主模块的交互完成选举以及统一的复制算法，从而解决上述问题。本题内容主要包括
 
1. 详细设计整体的解决方案
2. 为DLedger实现状态机
3. 在RocketMQ中实现DLedger Controller
4. 完成统一复制算法

1. 为题目设计整体的解决方案，产出相关文档
2. 为DLedger实现状态机，在OpenMessaging DLedger仓库被合并
3. 结合RocketMQ实现DLedger Controller，在RocketMQ仓库中被合并
4. 完成RocketMQ broker对接以及统一复制算法，在RocketMQ仓库中被合并

1. 编程语言：java
2. 熟悉RocketMQ或者其他消息队列
3. 熟悉Raft或其他共识协议"
"RT-AK是RT-Thread团队针对嵌入式AI开发的一款开源、易部署的EAI开发、部署工具链。该工具链可以轻松的实现RT-Thread OS环境下的高性能AI功能。本项目的目标是开发一套完整的智能小车车道感知系统，并将其部署到RT-Thread团队开发的嵌入式AI开发板上（Draco），实现小车基于图像识别前方车道线、前方车辆以及部分交通指示标志（如红绿灯）。该系统必须包括感知模型，至少能在开发板上通过单目摄像头进行推理运行；实际部署可选配套决策、规划和控制等模块并使得整个小车处于可以运行的状态，小车的传感器包括但不限于相机、IMU等常用传感器，这部分不影响项目完整性。

参考开源系统，给出完整的训练用数据集、神经网络模型
交通指示标志至少包括红绿灯、转向等两种指示
给出完整的AI训练代码和相关文档说明
可选的完整演示系统，包括： a) 配套的决策、规划以及控制代码； b) SIL或开发板HIL对接仿真环境(仿真器任选) c) 小车可以实现手动、自动控制的切换； d) 给出小车运行的完整的源码；

熟练掌握Pytorch/Tensorflow中的一种深度学习框架
熟练掌握RT-Thread OS和RT-AK等嵌入式AI开发、部署工具
精通AI模型的剪裁和量化，可以熟练的优化AI模型"
"hiBus 是合璧操作系统提出的一个设备端数据总线技术，通过 hiBus 本机或者远程主机上的程序可以发起远程过程调用或者订阅特定事件。  
 
hiBus 为客户端提供了 Unix Domain Socket 和 WebSocket 两种连接方式。  
 
目前，hiBus 已完成 1.0 版本的开发。现有如下增强需求：  
 
增强 hiBus 服务器，使之可以动态装载一个内建行者，并开发一个 hiBus 内建行者，提供类似 BusyBox 的命令执行能力，从而可通过 hiBus 由本机或者远程的行者执行命令，并获得命令的输出结果。比如通过执行 ls *.c 获得当前路径下的所有 C 文件列表。  

定义 hiBus 服务器端内置行者的接口
以操作函数指针的形式，定义 hiBus 服务器端动态装载内置行者的接口，该接口可用于注册一个不同于 builtin 的内置行者，并在 hiBus 中注册该行者对应的方法以及泡泡。
将 BusyBox 的功能重构为 busybox 内置行者的方法
该行者应以动态库的形式实现，并在 hiBus 启动时装载。该行者可以以远程过程的方式执行 busybox 提供的命令行功能。注意如下要点：
1、 设计对应的远程过程调用和/或事件的接口。
2、以客户端行者为单位，维护一个上下文信息，主要用来维护当前路径等 Shell 常见的环境变量。
3、所有的命令，在 hiBus 子进程中执行。子进程应切换 euid（有效用户标识符）到调用者的用户标识符；对远程主机上的行者，使用 guest 用户作为其 euid。
4、命令行支持支持重定向和管道。
5、所有命令的标准输出和标准错误，在没有被重定向的前提下，作为该过程的返回值返回给调用者。

Linux开发环境及 C/C++ 编程
MiniGUI
Unix domain socket"
"Pulsar IO 连接器支持我们轻松创建、部署和管理 Pulsar 与外部系统交互的连接器，比如 Apache Cassandra 、Aerospike 等等。 
现在，Pulsar 的 MongoDB 连接器还是 Demo 阶段，我们需要一个能跑在生产环境上的 MongoDB 连接器版本。我们需要该连接器支持 Sink 和 Source、全部数据传输和多表数据传输等。

项目验收标准
理解并使用 Pulsar Connector
编写该功能的设计文档
交付本功能的代码实现
添加单元测试和集成测试
编写本功能的说明文档

项目技术要求
了解 Pulsar IO 连接器原理
熟悉 Java 编程
熟悉基本的 Git 和 GitHub 操作
了解 MongoDB 数据库基本原理"
"目前sureness认证鉴权框架默认是基于JWT 来做无状态用户认证鉴权，但这缺少了用户统一状态的维护，导致我们不能对已经签发的token进行注销回收，或者无法实时管理监控用户的登录状态。
计划开发设计一种类似于session的后台统一用户登录状态维护管理池，在实现功能的基础上若有能力可以考虑其支持分布式session。

特性代码能以PR的形式合入仓库
良好的代码质量与完善测试用例

对开源抱有热情和强烈兴趣
熟悉Java语言
了解sureness或其它安全框架"
"speexdsp是一个专利免费/源码开源的dsp库。其包含预处理、回声消除、jitter buffer、音频重采样、定点/浮点傅里叶变换等模块。

适配OpenHarmony的构建体系
满足OpenHarmony社区代码规范
基于OpenHarmony平台通过demo/单元测试用例
提交仓库到TPC
输出本三方库在OpenHarmony下的能力，导出库对外提供的函数接口和已测试过的函数接口

C，熟悉Makefile"
"为 KubeVela 制作面向开发者以及平台级的插件功能，KubeVela 插件（addon）可以将 kubernetes 生态当中丰富的功能集成进 KubeVela 所管理的多集群的环境当中。基于 KubeVela 的 addon 体系，制作 apisix， istio，linkerd，envovy ，dapr 等相关插件，制作用户友好的各种defintion，产出关于多集群环境下服务治理的典型应用场景案例，并撰写最佳实践相关文档和demo。

产出微服务领域场景中三个典型的 KubeVela addon，优化端到端的各项体验，并最终产出一个基于微服务的典型用户故事

1.对开源抱有热情 2.有一定编程基础 3.愿意学习golang语言 4.愿意学习kubernetes 和 KubeVela"
"除了对量子纯态进行模拟的情形，我们通常还需要对密度矩阵的演化进行模拟。该任务需要完成量子线路的密度矩阵形式模拟。主要任务入下：
1、完成基于密度矩阵的各种量子门的作用，接口保证与mindquantum现有模拟器接口一直
2、完成基于密度矩阵的变分量子算法
3、完成基于密度矩阵的动力学演化、主方程求解

1、完成基于密度矩阵的各种量子门的作用，接口保证与mindquantum现有模拟器接口一致。 2、完成基于密度矩阵的变分量子算法。 3、完成基于密度矩阵的动力学演化、主方程求解相关代码。 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，量子计算，MindSpore"
"作为一个数据库，milvus 提供了 python、java、go、nodejs、cpp 和 restful SDK。
 该项目旨在为 milvus 实现一个生产就绪的 rust SDK，因为 Rust 因其速度和安全性而在数据处理、高性能计算和许多其他领域越来越受欢迎。

具有至少 90% 单元测试覆盖率的生产就绪 rust API

了解grpc和protobuf的相关知识
（加分项）掌握 Go 或 Python 其中一门语言"
"Kruise Rollout 是一个面向 K8S 的旁路式、无侵入的应用发布组件，它不仅支持用户以分批的方式发布应用、同时支持流量分批灰度、A/B Test 等诸多应用发布策略。目前该项目已支持 Deployment、CloneSet 等类型的 k8S 工作负载，对于 Daemonset 支持还有所欠缺。非常欢迎同学们一块参与 Kruise Rollout 建设！

实现 Kruise Rollout 对 DaemonSet 分批发布的支持

熟悉 Kubernetes 基本原理；
熟悉 Kubernetes DaemonSet 和 Kruise Advanced DaemonSet 代码；
了解 Kubernetes Controller 标准扩展原理及其实现；"
"本项目期望通过收集和展示 Python 的 PVM 指标，包括但不限于 CPU 使用率，内存使用量，线程/协程使用数量，垃圾回收数量等指标，并且配置在 UI 上显示，让 Python 用户能够快速直观了解 Python 应用程序的运行状态。


分布式追踪是 SkyWalking 的核心功能之一，当有了这些追踪（Traces），SkyWalking 可以分析出包括 CPM，成功率，错误率，Apdex 等的服务指标。SkyWalking 也支持直接从探针（Agent） 接受指标，所以在本任务里，我们希望 Python Agent 可以支持上报其 Python 虚拟机 (PVM) 指标，包括但不限于 - CPU 使用率 (%)，内存使用量 (MB)，线程/协程数量，垃圾回收（GC）等。

在本任务里，我们希望 Python Agent 可以支持上报其 Python 虚拟机 (PVM) 指标，包括但不限于 - CPU 使用率 (%)，内存使用量 (MB)，线程/协程数量，垃圾回收（GC）等。

较强的自主学习能力，有一定python编程基础"
"Sedna是边云协同工具，可以实现跨边云的协同训练和协同推理能力。MindSpore是端边云全场景的国内主流AI计算框架，为全场景AI的模型开发、模型运行、模型部署提供端到端能力。TinyMS是基于晟思MindSpore开发的高阶API工具。但是目前Sedna只支持sklearn的xgboost和Tensorflow、Keras。本项目旨在基于Sedna的lib开发接口，实现Sedna Python SDK对MindSpore和MindSpore 高阶API工具TinyMS 的支持。

实现代码，设计demo，跑通demo，并提交pr
代码标准符合规定的开源协议和安全编码规范
成功跑通代码，并通过测试用例
成功并入kubeedge/sedna
相关文档：使用文档、用例报告

熟悉Python
熟悉MindSpore框架或TinyMS，了解sklearn、TensorFlow、Keras其中一种
有一定的AI开发经验和框架开发经验"
"Casbin 是一个强大的、高效的开源访问控制框架，对主流语言都有相关实现，包括Python、PHP版本的Casbin。Casbin在业界具有广泛影响力，社区活跃。目前，目前PyCasbin/PHP-Casbin主库主要功能虽然相对完善和稳定，但仍然需要不断迭代演进，特别是对Python和PHP生态内各种框架、插件的集成，代码质量和性能还有调优的可能，所以我们希望对主库及其周边生态系统进行完善和优化，以增强Casbin在脚本语言Python和PHP领域的应用场景，提高外部系统接入Casbin效率和成本，进而扩大Casbin在Python和PHP领域的生态圈，使其能更好更快的发展。

对分布式存储系统ETCD的适配etcd-adapter
完善Py/PHP-Casbin的对Redis（redis-adapter）适配器
引入Casbin核心引擎Casbin Core Engine (Golang)中的新功能
对主流框架的支持增强，例如：如果在Python的Django的扩展中, 需要引入Django的Middleware, Caching, Logging, 集成Django的认证系统（authentication system）；而PHP主流框架Laravel中已有Laravel-Authz，但需要引入Laravel的Gates等
解决PyCasbin或PHP-Casbin主库以及相关仓库中的issues

熟悉Python、PHP任意一种语言即可
熟悉Git、GitHub相关操作"
"实现 MySQL 到 Nebula Graph 的数据实时同步功能，可采用 Canal / FlinkCDC / Debezium/ 等等数据同步工具实现。

Nebula 的数据实时同步能力

ava
了解 Canal 或 FlinkCDC 或 Debezium 等等数据同步工具"
"让 nebula-net 通过 .NET 的 LINQ 语法实现 select 功能，让用户不需要感知熟悉 nGQL 语法，也可以通过熟悉的 LINQ 语法对 Nebula 数据库进行查询匹配。

Nebula-net LINQ 支持

.NET"
"QMIX 是一种基于 Value-Based 的多智能体强化学习算法（MARL），其基本思想来源于 Actor-Critic 与 DQN 的结合。使用中心式学习（Centralized Learning）分布式执行（Distributed Execution）的方法，利用中心式 Critic 网络接受全局状态用于指导 Actor 进行更新。QMIX 中 Critic 网络的更新方式和 DQN 相似，使用 TD-Error 进行网络自更新。除此之外，QMIX 中为 Critic 网络设立了 evaluate net 和 target net， 这和 DQN 中的设计思想完全相符。

1.实现QMIX强化学习网络模型 2.精度、性能等相关指标达到论文标准 3.代码满足MindSpore models仓规范要求 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"通过Nacos元数据（Metadata）染色，通过标签路由，对服务实例实现基于版本号和可用区（Zone）蓝绿流量分流

对Spring Cloud Alibaba服务实现蓝绿部署，通过Http Header传递路由信息，达到流量隔离的目的
实现区域亲和性功能，优先选取给定的可用区实现亲和性，不满足则路由全体区域， 支持粗粒度和细粒度双重亲和

熟悉Spring Cloud负载均衡器、Spring Cloud Alibaba Nacos元数据埋点、Spring Matcher通配算法和Http Header全链路传递相关知识者优先。
良好的沟通和协作能力，不畏难，能在导师指导下克服困难完成题目和答辩。"
"MQTT X 是 EMQ 开源的一款跨平台 MQTT 5.0 客户端工具，它支持 macOS, Linux, Windows，并且支持 MQTT 消息格式转换。它是一款桌面端的 MQTT 测试工具，基于 Electron 并使用 TypeScript 开发，前端框架使用的是 Vue.js，数据库采用的是 SQLite。

MQTT X 采用了聊天软件的形式，用户可以快速创建连接保存并同时建立多个 MQTT 连接客户端，方便用户快速测试 MQTT/TCP、MQTT/TLS、MQTT/WebSocket 的 连接/发布/订阅 功能及其他特性。

MQTT X 目前已经支持并提供了完整的 MQTT 协议的功能测试能力，目前需要一些针对前端和网络功能方面的优化，使其更加完整易用，本项目将为 MQTT X 添加一些可自动更新版本的功能，程序内更新后显示新版本的发布日志等的功能，用户可以减少一些手动操作来更快的体验和使用到后续新版本的功能，从而提升整体的软件使用体验。

桌面客户端的自动更新功能，使用 update-electron-app，无需用户手动下载即可更新客户端程序，使用户免去重新下载和安装的步骤
更新完成桌面客户端后显示 What's new 功能，即每次更新完成桌面客户端程序时，有一个弹窗，用来显示当前最新版本的发布日志

熟悉 Vue 技术栈开发
熟悉使用 TypeScript，JavaScript
了解和使用过 Electron，或对跨平台开发技术有兴趣
了解 MQTT 协议，对物联网消息中间件感兴趣"
"基于PiFlow框架，针对流水线中各个数据处理组件的吞吐量进行监控，并提供API接口。

PiFlow吞吐量监控接口
PiFlow吞吐量监控接口测试用例

熟悉Spark技术原理及各类算子，熟练掌握Scala或Java语言。"
"1. 目前Arthas有web console，本质上还是一个web terminal。
2. 另外Arthas有一个简单的UI： http://127.0.0.1:8563/ui ，但这个只是json结果的展示

Arthas需要以现代web方式，构建一个全新的UI，所有的数据结构尽量以更友好的图形化方式展示。
需要学生有良好的web基础，有一定的设计能力。

完成Arthas新的管理UI

以现代web方式构建，工程要符合开发规范"
"Apache ShenYu是一款高性能的API网关，社区十分活跃与友好，非常适合高校学生学习与参与,通过参与这次活动可以学习Apache项目的社区建设，后续有兴趣继续贡献，可以成为Apache Committer。


该项目是将Apache ShenYu网关接受的请求日志，发送到Apache Pulsar中。需要设计请求日志实体，获取数据，调用Apache Pulsar的Java客户端进行发送（可以参考Logging-RockertMQ插件）。


1.设计日志实体类
2.通过网关插件的API上下文获取日志数据
3.调用Apache Pulsar Java Client将日志数据发送到Apache Pulsar Server
4.完成单元测试
5.完成集成测试
6.书写插件文档

设计日志实体类
通过网关插件的API上下文获取日志数据
调用Apache Pulsar Java Client将日志数据发送到Apache Pulsar Server
完成单元测试
完成集成测试
书写插件文档

熟悉Java语言以及Reactor Java
熟悉Spring Boot以及常见的设计模式
熟悉Apache Pulsar 的Java 客户端API
熟悉Junit单元测试框架
熟悉Git工作流与docker"
"对于大多数数据库来说，为了满足用户在特定场景的数据存储需求，需要支持JSON数据类型
目前MatrixOne数据库中，还不支持JSON数据类型和JQ函数；
为了提升用户使用感受，本项目目标是希望给予MatrixOne增加JSON数据类型和JQ函数的实现

实现MatrixOne数据库对json数据类型的支持，并实现jq函数
输出设计文档
输出源代码+单元测试+代码注释+功能测试用例
输出测试报告(包含性能，使用方法，功能边界)
用户文档的更新（功能描述，用法等等）

熟悉go语言，具备使用go语言进行代码开发的能力
熟悉高性能函数库，具备筛选和使用这些函数库进行项目开发的能力。"
"OpenFunction 是一个云原生的开源 FaaS 平台，旨在让开发者聚焦于业务逻辑而无需关心运行时的环境和设施。Apache APISIX 是一个开源的云原生 API 网关。本项目将结合二者，进而能够让用户通过 Apache APISIX 代理托管在 OpenFunction 之上的函数，从而触发函数的运行。

向 Apache APISIX 提交实现 OpenFunction 插件的 PR，并在经过代码评审后合并进入主干分支；
向 Apache APISIX 提交 OpenFunction 插件文档和，并在评审和合并进入主干分支；
输出一篇博客介绍 Apache APISIX 是如何集成 OpenFunction 的；

建议实现时采用小步快跑的模式，拆分若干个 PR 进行提交（小 PR 更易于评审，且效率更高）；
向 Apache APISIX 提交 PR 时，需要附上完整的测试用例覆盖；"
"Tair Modules是阿里云基于Redis开发的一系列模块，现已开源TairHash、TairZset、TairString三个模块，在交易、风控、社交等场景获得广泛应用。目前已经实现Tair jedis sdk支持java生态的业务接入，后续需要其他语言生态支持，例如开发适配Tair Modules的Go/Python/Node.js语言客户端。

基于 redis-py/go-redis/node-redis 等开源客户端实现对 Tair Module 的 API 支持。

有一定 Go/Python/Node.js 语言基础，对 Redis 有一定了解。"
"Linkis的官网基于docusaurus框架开发,目前有些页面布局不够优雅，开发指引文档/版本文档等不够完善。

本项目主要工作

官网部分页面的调整优化
中文文档文档修正以及对应翻译的校对，补充部分基础文档
官网项目代码的规范化(文件夹/文件/图片命名规范，资源路径规范) 
学习Linkis的知识，详细了解Linkis的基本原理、使用方式、库表/参数含义等，并总结分享
有余力同学可以尝试了解学习Linkis原理过程中，做一个系列的(或协助开发社区同学一起)个人源码阅读总结文档，作为开发者辅助文档 更新至官网博客栏中 

产出要求
官网项目代码/文件的规范化修正 并提交pr
官网部分页面布局的优化调整
部分基础文档修正和补充

技术要求
了解 https://docusaurus.io/框架
良好的markdown文档编写能力
基础的英语能力"
"Qiling框架是一个高级二进制虚拟框架，具有以下特性：
虚拟多平台: Windows, MacOS, Linux, BSD, UEFI, DOS, MBR, Ethereum Virtual Machine
虚拟多架构: X86, X86_64, Arm, Arm64, MIPS, 8086
支持多种文件格式: PE, MachO, ELF, COM, MBR
通过Demigod支持Windows 驱动(.sys), Linux 内核模块 (.ko) & MacOS内核 (.kext)
在独立环境中沙箱化虚拟代码
提供一个完全可配置的沙箱环境
提供了内存、寄存器、操作系统和文件系统级别API
细粒度插桩: 允许进行多种级别的hook (指令/基本块/内存/异常/系统调用/IO等)
提供虚拟机级别的API，例如保存和恢复当前执行状态
支持跨架构和平台调试功能
带有反向调试功能的内置调试器
允许动态热补丁运行时代码，包括加载的库
真正的Python框架，使其易于构建定制的安全分析工具
通常情况下，恶意软件会大量使用多线程和网络相关的系统调用，然而目前 Qiling 框架整体上没有很好的支持，一方面 Qiling 框架大多数代码都是单线程设计的，另一方面多线程本身就难以调试，因此本项目需要对软件运行底层和整体架构有着清晰的认知。

用户态多线程模拟
用户友好的交互API
可扩展的内部设计
可以随意暂停和恢复特定线程
非阻塞网络IO系统调用模拟的实现

具有Python开发能力
系统开发能力，网络(套接字)开发能力"
"目前Apache EventMesh分别支持RocketMQ作为事件存储，以及Standalone模式的内存存储，目标是基于现有api扩充EventMesh可支持的事件存储组件，即Kafka，对于Kafka事件存储的集成对接可以提高社区在事件存储领域扩展能力，挖掘更多的应用场景。

本题目主要包括如下内容：
1.熟悉现有的EventMesh项目具备的功能，能对EventMesh 的pub/sub实现有一定了解
2.对Kafka客户端与服务端的交互有一定的了解，能够使用Kafka客户端进行收发消息
3.支持基于cloudevents协议实现事件存储Kafka的pub/sub能力
4.补充相关测试用例
5.完善相关使用文档指引

文档类
提交issue到官方仓库包含实现EventMesh对接事件存储Kafka的pub/sub的详细设计
提交文档到官方仓库包含实现特性的使用说明指引
代码类
提交基于cloudevents协议实现事件存储Kafka的pub/sub代码PR到官方仓库，并合入
提交单元测试用例代码到官方仓库PR，并合入

掌握Apache EventMesh知识，能对EventMesh 的pub/sub实现有一定了解
掌握Kafka消息通信pub/sub知识，能够使用Kafka客户端进行收发消息
熟悉Java语言"
"Rust for Linux 是正在被开发的 Linux “增强功能”，该功能的正式上线时间还不明朗，但是 Rust 作为 Linux 内核开发的第二门开发语言是毋庸置疑的。本项目是尝试使用 Rust 语言来实现内核模块，例如被广泛使用的 FUSE 模块。本项目是一次大胆的尝试，用以展示 Rust 已经可以初步在 Linux 内核中被使用来实现某些内核功能。

一个使用 Rust 语言开发的内核模块；
要求该内核模块适配 openEuler 最新版本的内核。

熟悉 Rust 语言；
熟悉 Linux 内核开发。"
"KubeVela 中使用 Cue 作为 IaC 管理，在 KubeVela 的工作流当中，用户可以通过使用内置的 Cue Action 来编写 Definition。但是目前的 Cue Action 缺少版本管理，每当 Action 内部进行参数变动时，会影响到之前的用户使用。需要考虑并设计一个合理的版本管理机制，帮助用户更好地使用 Cue Action。

完成该功能的设计及开发，并贡献到 KubeVela 社区。

学习 KubeVela 的概念
学习 Cuelang 的语言机制
设计 Cue Action 的版本管理机制"
"传统的机器学习通过训练已知样本进行测试集推理，其知识限制在已知样本中。对于已知样本外的未知测试集，则无法进行有效识别，被当作已知样本处理。因此，未知样本或未知任务的识别处理将成为未来人工智能的主要研究方向。本项目旨在基于CVPR2021论文-Learning placeholders for open-set recognition进行复现，并尝试将该算法应用在缺陷检测领域。该论文提出一种数据占位符，用占位符模仿新类的出现，从而将封闭训练转化为开放训练的未知任务识别算法。

1、基于工业缺陷检测领域数据集复现
2、将该复现的未知任务识别算法合入Sedna 终身学习模块
3、未知类别的识别准确率（比如f1_score）大于0.9

1. 深度学习
2. Python"
"为了构建完善的基于openEuler的ROS2软件生态，需要将以ROS2为载体的部分目标检测算法迁移至openEuler。目标检测算法作为当前自动驾驶/AI领域关键的模块之一，能在openEuler的ROS2上运行起来有着重要意义。当前应用广泛的开源目标检测算法有很多，开源的YOLO,CNN等均用C++实现，可以作为很好的入门软件进行学习。还可以作为一个入口，扩展更多的相关软件包进入基于openEuler的ROS2软件生态。

1.选取的目标检测算法软件包以rpm包形式提交到src-openeuler对应仓库（由sig-ROS创建）；
2.自动化脚本执行目标检测算法测试数据集，并输出数据集执行结果，脚本同步上传src-openeuler对应仓库；《基于openEuler的目标检测软件移植指南》、《基于openEuler的目标检测软件测试报告》，报告覆盖ROS安装与基础功能测试、规范性自检、功能性测试、测试结果，以word形式存放到代码仓库的doc目录。

1.熟悉ROS2，可以进行基本的ROS2软件开发；
2.了解目标检测/pytorch/VSLAM算法
3.熟悉C++编程语言，熟悉CMake;
4.熟悉linux"
"Nydus 项目与社区其他开源项目在构建，运行时生态的集成，例如 CRI-O, nerdctl, Docker 等。

nerdctl convert 支持 Nydus
提升 Nydus 与主流公有云服务的兼容性
Nydus 与主流公有云镜像中心兼容性
Nydus 支持主流公有云 OSS
提升主流容器运行时对 Nydus 的支持
CRI-O 支持 Nydus
Nydus docker graphdriver 改进

容器镜像
容器运行时"
"karmada是业界主流的云原生多云容器编排平台，实现了跨Kubernetes集群运行云原生应用程序。

在本项目中，我们需要针对karmada通过常用的性能分析工具来分析当前karmada在管理编排多集群应用时的性能瓶颈，并针对性能瓶颈进行优化。

基础要求：使karmada能够管理100+ Push模式的集群和500+ Pull模式的集群。
进阶要求：使karmada能够管理500+ Push模式集群和2000+ Pull模式集群。
卓越要求：使karmada能够管理1000+ Push模式集群和4000+Pull模式集群。

性能瓶颈分析报告。

设计文件：架构图、流程图、序列图。

测试文档：端到端测试用例。在不影响功能的情况下获得明显的性能增益。

所有代码都符合开源标准：功能代码、单元测试代码

熟悉Golang

对Docker和Kubernetes的理解"
"SOFARegistry的客户端目前采用长连接与其中一台 Session 相连，随后会用这根链接注册和订阅服务，在注册中心进行运维期间，客户端会断链重连到别的机器上，经过一轮滚动升级，就会造成 Session 上链接分布的不均衡，一是数据不均衡，二是推送压力不均衡，严重的时候会造成单机热点，影响推送的效率。

由于长连接快速检测节点宕机的机制，主动断链会造成节点数据下线，因此客户端链接的稳定性也是一个很重要的考虑。

对服务发现来说，发布和订阅对链接稳定性的要求不同：
- 对发布，链接断开会造成服务数据下线
- 对订阅，会造成轻微的数据推送延迟，延迟时间通常是重连间隔

可以考虑以下方案解决此问题

一致性 hash 主动重连

由于发布和订阅对链接稳定性的要求不一样，发布更加要求稳定，而订阅会服务端压力影响更大
- 发布和订阅独立两根链接
- 发布依然保持目前的连上后就不会主动断开
- 订阅采用一致性hash的方式寻址自己应该连到的节点，当注册中心自身节点列表发生变化的时候计算出新的节点，确认是否重连到新session上
- 需要考虑大规模重连对注册中心自身的影响，比如添加随机延迟进行重连
- 订阅可以带上内存中数据的版本号发送给新的Session，Session进行数据版本对比，避免没有必要的数据推送

实现自动均衡的客户端和服务端的设计方案文档
实现自动均衡的客户端和服务端的Pull Request

熟悉Java
了解注册中心与服务发现"
"系统中设置多个默认网关，向外发送DNS请求报文，出现DNS报文的原IP地址与路由选择的网络接口不匹配

1、解决方案验证有效
2、解决方案得到Linux主线社区的肯定，并接纳或者计划接纳合入主线仓

1、熟悉Linux内核路由工作机制
2、了解Linux内核社区贡献机制和流程"
"openGauss数据库本身有外围的工具gs_dump等程序可以实现导入导出，本项目期望在数据库内部通过函数的方式也实现相同的功能

1 实现为插件 2 导出文件需要确保事务一致性 3 导出/导入文件后需要确保主备一起导入

1 了解数据库事务的基本实现 2 了解基本的linux文件系统知识 3 具备熟悉c/c++的能力"
"当前Seata采用的私有协议进行RPC传输，增加gRPC协议传输的支持，TC，RM，TM在传输协议上增加一套gRPC协议传输的实现。

1. 完成gRPC的适配。
2. 配合gRPC的验证完成对应的seata-sample。

1. 有一定的java基础 ；
2. 了解netty 和 gRPC;"
"Project C CPU 调度器 对 Linux 5.15 LTS 分支的支持

移植最新的Project C CPU Scheduler实现到linux-5.15.y-prjc-lts分支

提交应该符合社区现有的代码风格/格式
提交应该通过必要的测试"
"PilotGo是社区原生孵化的运维管理平台，用于提升大规模集群运维管理的效率。
PilotGo计划2022年推出v1版本及v2版本，其中v1版本提供基础的OS运维功能，完成度较高；v2版本提供插件功能及第三方插件。
插件模块用于对接第三方组件，扩展运维平台的功能。
插件模块需要实现的功能：
对插件的管控
包括插件的安装、卸载、升级、管理形式等
运维平台基本功能对第三方插件的支持
平台提供基本的集群信息及基本功能，如主机信息、批次信息、远程执行功能等，插件模块需要考虑如何将这些基本功能封装成接口，提供给第三方插件使用。同时需要考虑插件前端如何嵌入到平台当中。
权限管控及审计要求
提供给第三方插件的平台功能需要对接权限模块和审计模块，插件功能运行需要通过平台进行权限审核及审计跟踪，不允许插件绕过平台对其他机器进行操作。
工作内容：
设计并实现一个符合要求的插件方案
提供一个插件示例

1.符合实际使用要求的插件方案描述文档
2.实现文档所设计的插件方案
3.实现一个实用的插件功能，如mysql、redis等应用集群的管理。

1.linux环境基本能力
2.后端：golang，前端：VUE"
"针对SpinalHDL库中现有Stream相关的基础模块验证主要采用仿真验证带来的测试状态空间覆盖不明确问题，针对性增加相应的形式化验证代码提高其生成硬件设计的稳定性。

【产出标准】：

1、实现Stream类型通用形式化验证函数；

2、实现StreamFifo、StreamFifoCC类型模块形式化验证案例（需本项目开发的通用形式化验证函数）；

3、实现StreamFork、StreamJoin类型模块形式化验证案例（需本项目开发的通用形式化验证函数）；

4、实现StreamArbiter、StreamMux、StreamDeMux、StreamDispatcherSequential类形式化验证案例（需本项目开发的通用形式化验证函数）；

合格标准：上述验证案例均需通过cover, bmc, prove三类验证。


【技术要求】：

1、具有同步数字逻辑设计思想，完成过VerilogHDL设计者优先；

2、具有面向对象程序设计思想，使用过一门面向对象程序设计语言；

3、使用过git进行版本管理；

4、具有一定的英语阅读和交流能力；

5、具有较好的自学能力和自我管理能力；

SpinalHDL
Formal Verification
Scala
Verilog"
"实现MaxKey与前后端分离项目提供SDK，包括vue和React的SDK,提供集成指南
开发vue前端的SDK，能与MaxKey进行集成
开发React前端的SDK，能与MaxKey进行集成

vue前端的SDK
基于vue前端的SDK
提供与MaxKey集成指南
React前端的SDK
基于React前端的SDK
提供与MaxKey集成指南

熟悉React前端框架
熟悉Vue前端框架
其他技术要求
熟悉TypeScript语言
熟悉单点登录及相关协议
熟悉HTML,CSS,JS
熟悉Java开发语言
对开源有热情和强烈兴趣"
"通过openLooKeng查询hive数据源数据，例如当执行sql是select count(*) from table时，需要表所有数据取回，取回数据均为无用数据，浪费网络带宽。当把count、max、min这种推到hive数据源执行时，只需要读取表元数据信息即可，从而减少数据传输，使得openLooKeng执行时间缩短。

支持count、max、min算子下推到hive
输出对应文档说明

SQL、Java编程能力
数据库内核引擎相关技术"
"secGear是面向计算产业的机密计算安全应用开发套件，旨在不同的硬件设备上提供统一开发框架，让用户不感知底层各种机密计算架构和接口的差异，目前secGear支持Intel SGX硬件和ARM Trustzone(安全os支持iTrustee)。
SGX提供了sgx protected fs, Trustzone提供了安全存储，本项目开发secGear安全文件系统接口，封装SGX和Trustzone，对用户提供统一接口。

1、secGear统一安全文件系统接口功能正常
2、安全文件系统接口测试用例

1、掌握C语言。
2、了解机密计算的优先"
"提供不同版本的多个 Kubernetes 集群的统一 API，比如一个 API 可以同时 CURD 1.17 版本和 1.23 版本的集群资源。

以 PR 的方式提交代码

掌握 Go ，了解 Kubernetes 相关概念"
"在过去十年中，道路提取是遥感领域的一项基本任务，这一直是研究的热点。 本文提出了一种语义分割神经网络，称为D-LinkNet，该网络采用编码器-解码器结构、空洞卷积和预训练编码器进行道路提取任务。该网络使用LinkNet架构构建，并且在其中心部分具有空洞卷积层。Linknet结构在计算和存储方面非常有效。空洞卷积是一种功能强大的工具，可以在不降低特征图分辨率的情况下扩大感受野。在CVPR DeepGlobe 2018道路提取挑战赛中，该网络在验证集和测试集上的最佳IoU分数分别为0.6466和0.6342。

1.实现DLinkNet语义分割网络模型 2.精度、性能等相关指标达到论文标准 3.代码满足MindSpore models仓规范要求 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"ChaosBlade 已经实现了部分机器资源故障场景、应用服务故障场景、容器服务故障场景，现需要满足精细化控制能力，此项目包含三个故障场景实现，三个都需要完成：

场景一：CPU 场景精细化实现
chaosblade 目前 CPU burn 是跑死循环的实现，请提供一种 CPU burn 算法，如 PI、 CRC16、FFT 来丰富 cpu burn 的场景，满足精细化控制 CPU 使用的需求；

场景二：HTTP 请求相关故障注入
chaosblade 已经能够支持 Java 客户端的 http 请求相关的故障注入，但是其他应用语言无法支持，所以需要提供一种通过代理抓包的方式，通用的 HTTP 故障注入方式，满足对于 HTTP 服务消费侧和服务提供侧故障模拟，比如模拟响应码，注入延迟等故障。

场景三：文件系统访问延迟、读写失败
目前文件相关故障都是基于文件本身实现，比如删除文件、篡改文件等。现需要基于文件系统实现支持文件读写延迟与失败。

完成CPU负载精细化控制
完成 HTTP TCP 请求错误码、延迟故障注入
完成文件系统访问延迟、失败故障场景

使用 PI, CRC16, and FFT 等算法实现CPU负载模拟
使用TCP抓包拆包方式实现HTTP故障模拟
使用对文件系统进行操作模拟文件读写延迟、失败"
"该项目利用LLVM tablegen为PICORIO 2.0构建了一个周期精确的性能模型，并在LLVM中使用了一个指令调度优化模型来实现性能增强。embench被用作评估性能的基准。
LLVM项目是模块化和可重用编译器和工具链技术的集合。https://llvm.org/.它是当今最流行的编译器基础结构之一。它将高级语言编译成LLVM-IR，然后使用RISC-V后端将IR编译成可以在机器上运行的RISC-V汇编/机器代码。
为了优化性能，可以进行特定于体系结构的后端优化，指令调度就是其中之一。LLVM提供机器调度程序过程，将架构的tablegen成本模型作为输入，并根据中指定的延迟重新排序指令

利用LLVM tablegen为PICORIO 2.0构建周期精确模型，以实现性能增强。

LLVM中的启发式调度算法和设计权衡报告

RA前指令调度和RA后指令调度性能影响的报告。

调度程序实现和性能分析报告

性能提升不低于15%"
"openLooKeng支持sql子查询下推到数据源执行(sub-query pushdow)，利用该能力可以减少openLooKeng与数据源之间的数据传输量，提升sql语句的端到端执行效率。由于openLooKeng与数据源的语法、数据类型表示的差异，高效的生成下推到数据源的子查询语句成为算子下推特性的关键环节，请对openLooKeng算子下推流程进行分析，并做算法、工作流程优化，提高查询执行效率。

1. 项目设计文档
2. 优化效果测试报告

1. 数据库原理基础
2. JAVA、SQL编程技术
3. 开源openLooKeng/presto/trino引擎使用"
"背景：
Apache Doris 中大多数作业的执行（如导入、查询等）等都是在分布式环境下执行的。我们需要有一个Tracing框架来跟踪这些任务在分布式环境中的执行情况。以查询为例，用户希望能够查看查询的整个执行过程中，各个阶段的耗时和一些指标的统计，以便能够快速的定位到慢节点，或根据统计指标进行查询优化。当前，Doris提供Profile来展示查询任务的各阶段统计指标，但Profile的采集方式和数据输出格式无法很好和现有的APM系统做对接，是的数据的展示、告警等操作无法方便的实现。
另一方面，通过兼容OpenTracing方案，可以将Doris作为企业数据链路中的一环，使得企业能够方面的完成整个数据链路的分布式追踪。

需求：
1. 调研OpenTelemetry和SkyWalking等APM系统的集成方案，产出tracing数据的存储、展示、告警方案。
2. 在Doris中引入OpenTelemetry项目，能够支持查询或导入作业的追踪
3. 进一步细化Tracing指标，能够支持节点级别、算子级别的Tracing指标统计。

能够通过某一APM系统展示Doris中查询作业的Tracing指标。

对 C++ 和 Java 语言熟悉，有APM或Tracing系统的开发或使用经验。"
"背景：
Apache Doris 中大多数作业的执行（如导入、查询等）等都是在分布式环境下执行的。我们需要有一个Tracing框架来跟踪这些任务在分布式环境中的执行情况。以查询为例，用户希望能够查看查询的整个执行过程中，各个阶段的耗时和一些指标的统计，以便能够快速的定位到慢节点，或根据统计指标进行查询优化。当前，Doris提供Profile来展示查询任务的各阶段统计指标，但Profile的采集方式和数据输出格式无法很好和现有的APM系统做对接，是的数据的展示、告警等操作无法方便的实现。
另一方面，通过兼容OpenTracing方案，可以将Doris作为企业数据链路中的一环，使得企业能够方面的完成整个数据链路的分布式追踪。

需求：
1. 调研OpenTelemetry和SkyWalking等APM系统的集成方案，产出tracing数据的存储、展示、告警方案。
2. 在Doris中引入OpenTelemetry项目，能够支持查询或导入作业的追踪
3. 进一步细化Tracing指标，能够支持节点级别、算子级别的Tracing指标统计。

能够通过某一APM系统展示Doris中查询作业的Tracing指标。

对 C++ 和 Java 语言熟悉，有APM或Tracing系统的开发或使用经验。"
"Casdoor是一套基于基于OAuth 2.0 / OIDC协议的统一身份认证（单点登录）系统。其支持多种第三方登录方式，如QQ、微信、Google, GitHub等。Casdoor具有Web管理界面，可以用来管理用户、角色、权限（基于Casbin）。Casbin社区目前采用QQ群（中文），Gitter（英文）进行社区交流，交流渠道比较有限。我们打算开发一个同时面向Casbin开发者和用户的官方社区：casnode，并采用Casdoor单点登录系统来对接。

扩展架构，添加更多的第三方登录支持
支持Casbin权限管理
解决Casdoor主仓库&相关仓库中的issues
解决Casnode&相关仓库中的issues

熟悉React、Javascript语言（前端）
熟悉Golang语言（后端）
熟悉Git、GitHub相关操作"
"WebAssembly (wasm) 是一种新的编码方式，可以在现代的网络浏览器中运行。让 LCUI 支持编译为 wasm 的目的主要有两个：一个是降低 LCUI 的体验成本，只需用浏览器打开网页即可快速体验 LCUI 示例程序的运行效果。另一个是便于以后添加 JavaScript 和 TypeScript 语言绑定。

研究 WebAssembly 相关资料以及 Qt、ImGui 等同类项目的 wasm 支持方案，完成技术文档。
添加相关的构建配置，使 LCUI 能够成功被编译为 wasm。
添加 wasm 相关支持代码，使得 LCUI 的示例程序能够在浏览器中响应用户鼠标、键盘的输入并输出图形界面。

熟悉 C 或 C++ 语言
了解 JavaScript 语言
了解 CMake、XMake 等任意构建工具的基本用法"
"为了构建毕昇编译器生态，毕昇编译器已融入openEuler yum源，并持续迁移各个领域的应用，在迁移过程中存在和其他编译器的兼容性问题需要解决。

1、毕昇编译器无法识别的选项类兼容性问题 支持毕昇编译器以下选项的识别，并打印告警提示用户已使用毕昇编译器支持的选项或者忽略该选项。
A、-ip 选项 选项功能：Enables additional interprocedural optimizations for single-file compilation 说明：该选项不支持，直接屏蔽该选项 告警屏蔽方式：Warning: unsupported option '-ip', ignore it.
B、-assume byterecl 选项 选项功能：Determines whether units for the OPEN statement RECL specifier (record length) value in unformatted files are in bytes or longwords (four-byte units) 说明：该选项不支持，直接屏蔽该选项 告警屏蔽方式：Warning: unsupported option '-assume byterecl', ignore it.
C、-fdec 选项 选项功能：Enables extensions and other features that mimic the default behavior of older compilers (such as DEC) 说明：该选项不支持，直接屏蔽该选项 告警屏蔽方式：Warning: unsupported option '-fdec', ignore it.
D、-convert big_endian/-convert little_endian 选项 选项功能：Generate big-endian/little-endian code 说明：支持同功能选项-mbig-endian/-mlittle-endian，自动使用该选项替换上述选项 告警替换方式（以big-endian为例）：unsupported option '-convert big_endian', use '-mbig-endian' instead.
要求：实现支持高扩展性，后续如需添加更多屏蔽/替换选项时，可以轻松通过加表项等方式实现。
2、毕昇编译器目前无法支持的功能类兼容性问题
A、-print-multi-os-directory 选项 选项说明：Print the path to OS libraries for the selected multilib 参考说明：毕昇编译器已有实现类似选项-print-multi-directory，且GCC支持该选项 https://gcc.gnu.org/onlinedocs/gcc/Developer-Options.html#Developer-Options 要求：实现选项相关功能，正确打印相关路径
B、部分intrinsic的不完全支持 Intrinsic列表： i) __builtin_longjmp/__builtin_setjmp：不支持长跳转intrinsic ii) __builtin_prefetch：预取intrinsic不支持变量类型的入参 用例： #include <stdbool.h> void prefetchAddress(const void *address, bool forWrite) { if (__builtin_constant_p(forWrite)) { __builtin_prefetch(address, forWrite); } } 错误： error: argument to '__builtin_prefetch' must be a constant integer __builtin_prefetch(address, forWrite); ^ 要求：正确实现支持上述intrinsic功能，保证逻辑正确
C、-aux-info filename 选项 选项说明：Output to the given filename prototyped declarations for all functions declared and/or defined in a translation unit, including those in header files https://gcc.gnu.org/onlinedocs/gcc/C-Dialect-Options.html#C-Dialect-Options 要求：实现选项相关功能，输出编译单元内函数声明
3、开发过程可以使用开源llvm 12.0.1版本进行，过程中形成的源码patch等，请上传对应clang/llvm仓库

1、掌握编译器的使用，如GCC、LLVM的使用；
2、熟悉编译器源码的架构和调试方法；
3、掌握编程语言C、C++和Fortran"
"如今UOJ作为学校OJ和个人OJ被很多用户使用，每个OJ都有大量自有题目，OJ间题目的共享成为一个新的需求。远程OJ已有vjudge作为一个成熟的平台被广泛使用，因此本项目关注的是「通用的数据传输与共享系统」，传输后的题目将在新OJ进行本地评测，方便与UOJ的其他功能联动（例如作业管理等），而不是单纯为了提交评测与组题比赛。
综上，本项目希望为UOJ构造出一套通用的数据传输与共享系统。

完成关于题目的导出与导入的接口
实现题目拥有者关于其数据共享管理的UI
设计一套格式转化系统，允许通过其他开源OJ（例如LOJ）向UOJ传输数据

具有相关语言的开发经验
了解OJ平台的业务逻辑"
"3D物体的表征形式多种多样，其中一个比较典型的方法是3D点云，即某个坐标系下的点的数据集，相比于文本、图像，其包含了物体更加丰富的信息，包括三维坐标 X，Y，Z、颜色、分类值、强度值、时间等等。3D物体一个比较典型的应用场景就是元宇宙，其中存在着大量的数字3D模型。精确建模与理解这些虚拟物体可以帮助我们更好的实现对3D模型进行分类，搜索，以及管理。

目前我们已经对一些3D物体模型的预训练模型进行了封装，并且支持对模型的微调（Finetune），使得用户可以更加便捷的将这些模型应用到实际生产环境中。

为了更好的适应具体使用场景，针对预训练模型的微调通常会使用表征学习。表征学习（Representation Learning）是深度学习的一个分支，其广泛应用于工业界，它通过训练深度学习模型优化输入数据的向量表示，以适应相似度计算、检索、推荐等不同应用。将深度表征学习与3D模型数据结合可以将3D物体的特征更好的展现出来，以此支持各个领域下对3D物体数据的搜索需求。

本项目旨在集成更多针对3D物体的神经网络模型，并实现对不同模型的统一管理。

调研并实现目前SOTA的3D点云编码网络
实现3d点云数据的预处理，支持对不同模型的快速训练
需要能够撰写完整的文档，单元测试和集成测试

对深度学习/表征学习有基本理解
熟练使用和掌握python
熟练使用和掌握pytorch等深度学习框架"
"DLedger 为基于 raft 协议的分布式一致性框架， RocketMQ 的 Raft 模式使用了 DLedger 作为底层存储引擎。当前一主两从的部署模式下，从节点资源利用率低，存在较大的资源浪费，因此我们希望实现 multi-raft， 即单台节点上同时存在多个独立的 raft group，通过 preferred leader 方式将主节点分布在不同的节点， 从而充分利用每台节点资源
学习 raft 实现原理、DLedger 实现和使用方法。
为 DLedger 实现 multi-raft 支持
在 RocketMQ 中集成 multi-raft ，实现多 commitlog，将 topic 分配到不同 commitlog
与此同时，对于有余力地选手，还可以帮助项目实现SSL加密传输功能，快照功能等高阶能力。

产出 multi-raft module， 能够通过PR形式提交并通过社区审核
实现SSL 传输加密功能，支持单向，双向验证模式

单元测试不低于80%
支持30%以上资源利用率提升
支持SSL通讯"
"Apache SkyWalking 是一个热门的可观测性平台，随着机器学习近年来愈发火热，AI 在生产环境的实践也变得成熟可用起来。在可观测性领域里，主流商业平台都在积极支持并且推广他们的 AI 引擎。 SkyWalking 也即将开始其 AIOps 之旅，作为功能的基石，我们想要从指标异常检测开始，为 SkyWalking 带来智能告警能力。 人工配置的告警规则为了达到细粒度的观测往往异常繁琐，再加上当前将业务逻辑开发与运维重新分离的趋势，我们不能期待所有运维工程师对项目本身有深入的理解。 最重要的是，手动配置的告警规则只能针对过去已知的异常形态，而无法抽象发现新的异常。

因此，我们在本项目的目标是通过机器学习配合统计学方式从由 SkyWalking 收集且聚合的关键性运维/业务指标 (metrics) 中学得动态告警基线和阈值。检测的范围应和当前的静态告警规则相当。通过在生产环境中训练的模型，我们将新收集的指标数据流和模型预测的未来指标形态/阈值作比较，对于异常实现告警 （在模型检测到异常后加入额外步骤可以帮助我们减少误报率）。SkyWalking 的 GitHub 讨论中有一份详尽的关于本项目的提案，请在申请项目前进行讨论。

在数据理解的基础上完成机器学习模型的研究和设计，在真实数据集上实现和评估模型，完成的工作应与完整的文档合并到Sky Walking上游存储库中。

有一定的 Python 基础，对机器学习有一定了解。"
"TairHash是基于redis module开发的一种hash数据结构，和redis原生的hash数据结构相比，TairHash不但和原生hash一样具有丰富的数据接口和高性能，还可以为field设置过期时间和版本，这极大的提高了hash数据结构的灵活性，在很多场景下可以大大的简化业务开发。TairHash提供active expire机制，即使field在过期后没有被访问也可以被主动删除，释放内存。本项目旨在优化TairHash的过期算法，提升过期数据清理效率，降低内存开销。

优化TairHash过期算法，提升过期效率，降低10%的内存开销

有一定c++语言基础，对Redis和module有一定的了解"
"Nix 是以函数式编程语言去声明，可重复构建的，且信赖的包管理和操作系统。
Julia2Nix 项目旨在为 Julia 编程语言提供友好的 Nix 的接口和探索可能性，方便以 Nix/NixOS 为生态基础的开发者和用户轻松且方便地使用 Julia 生态。

本项目的核心功能在于将安装 Julia 包和项目所需要的内容以 Nix 的形式进行打包，并借助 Nix store 进行存储和分发

基于 Nix 的方式实现 Julia 数据的可重复构建和可重复分发
提供必要的函数功能将 julia2nix 编译到 Nix Store 中
用 Nix 构建 Julia 包以及 Julia 自身

了解 Julia 语言
（加分）了解 Nix 的构建模式"
"目前 OpenMLDB 支持 Java/Python SDK。这两者在底层其实都是通过调用同一套 C++ APIs 来实现。但是目前 C++ APIs 并没有抽象成为一个可以供开发者友好使用的 SDK。在这个项目中，你将重新整理目前的 C++ APIs，通过合理的重构，发布一个面向外部开发者友好的 OpenMLDB C++ SDK。

分离出 C++ SDK 需要的头文件，放到 include/sdk 目录里
编产出 C++ SDK 的静态库文件
补充 C++ SDK test cases
补充 C++ SDK 相关文档

熟悉 C++ 编程以及相应的编译技术"
"异步执行是大部分现代运行时都支持的功能，WamEdge 也提供了异步执行 Wasm 模块的特性。Java本身也提供了对异步操作的一些抽象，本项目需要结合两部分特性来实现Wasmedge Java SDK Async 特性，包含： 
熟悉 WasmEdge 的异步API 
抽象出一套在 Java SDK 层面的异步API 
基于JNI 实现这些 API

按照社区编码规范要求，完成特性编码
提供编码示例和文档
提供完善的测试用例

1. 熟悉 Java 和 C 语言编程
2. 熟悉 JNI 接口和编码
3. 熟悉 Gradle 和 CMake 的使用"
"Golang 原生的 Plugins 机制实现存在着一系列问题，比如：
1.  要求 Core 和 Plugins 的 Go 编译器完全一致；
2.  要求 Core 和 Plugins 的外部依赖的版本完全一致；
3.  Plugins 只能动态编译。
这一系列的限制使得 Plugins 机制非常难用。比如对于一个 core-plugin 架构的应用来说，往往 plugin 是在独立的仓库里，或者是由不同的工程师开发的，他们要花很大的精力来满足上述条件。目前 DevStream 也面临着这样的问题，导致插件的生命周期和 core 完全绑定，无法独立迭代。

基于 gRPC 协议开发一个轻量级的生产可用的 core-plugin 跨应用双向通信框架，这个框架应该是通用的，所有需要应用双向通信的项目都可以使用。
 
一些注意点：
1.  测试覆盖完备，要实现生产级别可靠必须经过较完备的测试，ut 覆盖率高；
2.  日志完备，方便调试问题；
3.  性能优异，轻量级；
4.  容易使用，文档详细。

一个功能完备，生产级别可用的基于 gRPC 的通用轻量级应用间双向通信框架

一定的 Golang 开发能力，熟悉 gRPC 编程"
"Tomcat是由Apache软件基金会属下Jakarta项目开发的Servlet容器，实现了对Servlet和JavaServer Page的支持，并提供了作为Web服务器的一些特有功能；本项目需要对Tomcat应用进行性能调优，目标性能提升5% ~ 10%。

分析&选择benchmark
输出tomcat基线性能报告
对应用进行调优，性能在基线的基础上提升5%以上
输出可在A-Tune上执行的自动化调优脚本

有linux操作系统开发基础
掌握基本的性能调优方法
对A-Tune调优功能有所了解"
"Dubbo 拥有多种治理规则，如基于标签路由等，这些规则都是基于 Dubbo Admin 中心化进行管控。目前 Dubbo Admin 需要独立部署一个中心化的集群作为服务端，同时对配置中心等进行连接。
本题目希望将 Dubbo Admin 的 API 迁移到 Dubbo QoS 中，将 Dubbo Admin 变成一个静态的资源部署，以此来达到不需要部署 Dubbo Admin 的后端程序即可对集群进行管控的目的。

Dubbo QoS 支持暴露集群管控 API
Dubbo Admin 网页支持连接到任意一台 Dubbo QoS 服务端进行管控

熟练使用 Java 语言
熟练使用 Vue
了解 Dubbo 基础原理"
"MLOps是一种与现有 DevOps 流程和工具相结合并针对ML生命周期管理进一步优化的自动化流水线，提供高度自动化的任务编排、执行、监督服务，对ML任务中数据接入、验证、处理、特征分析、模型训练、验证与部署等流程进行解耦，对数据、特征、模型、应用提供独立版本控制，使得数据科学家/算法研究员、ML 工程师和应用开发人员都能以相同的节奏有效协作和工作，缩短模型开发部署、迭代周期，提升AI应用落地效率。
基于云原生的MLops流水线平台需满足应用容器化、面向微服务架构、支持容器编排调度、资源可弹性和声明式API等特性。

1、提供完整的ML生命周期管理自动化流水线，覆盖数据接入、验证、处理、特征分析、模型训练、验证与部署等流程。
2、提供高度自动化的任务编排、执行、管理服务，设计使用友好的用户界面。
3、提供数据、特征、模型、应用独立版本控制能力，用户可基于特定版本触发流水线服务。
4、平台设计需满足应用容器化、面向微服务架构、支持容器编排调度、资源可弹性和声明式API等特性
5、平台支撑2+ AI服务落地，提升模型部署、迭代效率300%。

k8s/go"
"背景：
Apache Doris 的列统计信息仅存储了 ndv。在推断谓词的选择率上，尤其是数据分布不均匀时，误差较大。所以，需要引入列的等深直方图这一统计信息进行更精确的 cost 评估，从而使得优化器能推断出真正的 best plan。
需求：

1. 利用现有统计信息收集框架，实现对列等深直方图的统计数据的收集（仅需要支持手动触发收集）。收集过程需要保证不能影响集群的正常任务执行。
2. 改造现有统计信息存储框架，使其支持列等深直方图统计数据的存储。
3. 支持查询列等深直方图数据。
4. 实现基于列等深直方图，推导谓词选择率的逻辑，并正确被统计信息推导框架使用。

借助列等深直方图，推导出更精确的谓词选择率，协助优化器推导出更好的查询计划。最终 Apache Doris 在 TPC-H 测试集下查询性能提升。借助列等深直方图，推导出更精确的谓词选择率，协助优化器推导出更好的查询计划。最终 Apache Doris 在 TPC-H 测试集下查询性能提升。

对 C++ 和 Java 语言熟悉，了解SQL的解析、优化和执行原理"
"Milvus 从 2.1.0 版本开始支持字符串数据类型。Milvus目前使用 Succicnt Trie 和开源的 Marisa Trie 实现字符串索引。我们相信仍有改进的空间，并希望字符串索引类型具有更好的性能和更多的功能（例如 FM-Index）

将性能更好的排序字符串索引类型引入Milvus
（加分项）字符串索引可以支持其他功能，例如正则表达式

扎实的算法和数据结构知识
（加分项）了解succinct数据结构
（加分项）了解 lucene 和其他字符串搜索库"
"RT-AK是RT-Thread团队针对嵌入式AI开发的一款开源、易部署的EAI开发、部署工具链。该工具链可以轻松的实现RT-Thread OS环境下的高性能AI功能。本项目的目标是设计一套完整的、轻量化的模型库，该模型库应包括当前主流的AI模型，方便使用者直接借用库中AI模型，或方便开发者参考模型库，开发个性化的AI模型。整个项目依托RT-Thread团队推出的嵌入式AI开发板Draco(开源社区会提供硬件)，最终实现至少始终主流AI模型在Draco开发板上的部署。 

提供完整的model zoo列表，至少包括10种主流的AI模型
开发完整版本的AI模型，在模型库中称为标准模型
针对Draco开发板的特点，对模型进行优化和剪裁，开发简化版本的AI模型，在模型库中称为优化模型
针对模型库中的AI模型，提供tensorflow和pytorch两个版本的训练文件

熟练使用Pytorch/Tensorflow，同时对主流AI模型有清晰的认识
基本掌握深度学习模型优化、剪枝等方面的知识
熟练掌握嵌入式的开发
熟练使用RT-Thread OS"
"目前，在Volcano社区中存在一些已知的bug并停止了功能增强PRs。您的任务是尽可能多地参与社区，以帮助解决这些错误并继续这些已停止的功能。

工作包括但不限于：
代码优化
文件改进
错误修复
功能实现
代码审查

PRs解决列出的错误
PRs增强列出的功能

Kubernetes
Go"
"目前 OpenMLDB 尚未支持 Go SDK。随着 Go 使用群体的快速增长，提供一个 Go SDK 将会是一件非常有价值的事情。在这个项目里，你将会参照 OpenMLDB 现有的 Java SDK，高优实现其中的核心 API。

参照 Java SDK 和 Go SQL 标准接口，实现所需要的核心功能，至少实现如下接口： Open, ExecContext, QueryContext, QueryRowContext
整理相关文档，附上使用说明和样例
添加接口的 UT 测试

熟悉 OpenMLDB SDK 所需要的基础操作
熟练掌握 Go，可以高质量独立开发 Go SDK"
"基于java语言为DataStudio添加UI颜色切换功能

1、参照DataStudio源代码中的颜色设置，利用Eclipse RCP的特性实现颜色切换。 2、代码改动尽量集中，满足社区编码规范，提供单元测试用例。 3、代码改动需合入DataStudio项目。 4、提供设计文档（包含修改说明）和测试文档。

1.了解数据库的基本知识，已经客户端的使用。 2.熟悉java编程开发"
"【背景描述】openEuler国密能力构建
【需求描述】支持使用SM2_SM3算法对EFI文件进行签名/验签，可考虑如下方案：
1.基于pesign实现国密签名；
2.引入sbsign并实现国密签名；
3.自行设计签名程序实现国密签名。

1.功能验证：使用国密证书完成EFI文件签名/验签；
2.标准满足：签名格式满足相关标准定义；
3.代码规范：如果基于开源软件进行改造，需要满足符合开源软件已有编码规范。

1.环境要求CPU架构：x86_64/aarch64
2环境要求OS版本：openEuler 22.03/22.09"
"Skywalking PHP是一个用 C 编写的 PHP 扩展库，遵循 Apache SkyWalking 的 tracing 和 metrics 格式收集上报数据。目前该扩展已经支持包括但不限于cURL, PDO, Mysqli,gRPC,Redis等项目或框架的支持，本次项目目标是为每一个特性添加开关，让使用者灵活配置他们关注的指标

本地创建开发环境
熟悉每一个特性的代码，并找到切入点
为每一个特性添加开关

较强的自主学习能力，了解或愿意学习 C 语言和PHP扩展"
"Linux的lockdep可以实现死锁检测的功能，但是lockdep的开销大，无法在release版本中使用，这就导致出现死锁问题后，必须在实验室编译出debug版本进行复现，效率低不说，而且还不一定能复现问题。如果能有一种方法，以较低的开销实现死锁检测的方法，能够用到release版本中，则可以大大提升死锁类问题的定位效率

针对内核中的锁，设计出一种轻量级的持锁跟踪，且在异常状态时（比如长时间获取不到锁、死锁、hungtask等）可以自动获取到当前系统关键任务的持锁情况

1、熟练使用Linux kernel，熟悉linux各种锁机制；
2、熟练C编程；"
"Inclavare Containers是由阿里云和蚂蚁集团主导研发，并联合Intel等合作伙伴打造的业界首个面向机密计算场景的开源容器运行时。Inclavare Containers目前已经是CNCF sandbox项目之一。Inclavare Containers抹平了机密计算的高使用门槛，为用户的工作负载提供多种不同的 Enclave 形态，在安全和成本之间提供更多的选择和灵活性。后续需要在Anolis OS上进行适配，出包，并且基于Github CI/CD 完成集成测试等工作。

完成Inclavare Containers在Anolis OS上的功能适配
完成Inclavare Containers在Anolis OS上的出包
学习Github Action并完成 CI/CD 集成测试。

对操作系统和安全感兴趣，熟练掌握Linux
有一定的C语言基础
了解出包流程和集成测试流程"
"测试粒子方法是电磁学中一种基础研究方法，常见于研究带电粒子在给定电磁场中的运动状态。

TestParticles.jl 是一个针对测试粒子的常微分方程求解器，直接对接 DifferentialEquations.jl 提供的接口。目前该项目有一个基础框架和少量测试例子，有待进一步完善。 
对物理感兴趣的学生，可以添加具体的算例；对数值计算感兴趣的学生，可以通过本项目熟悉Julia中常微分方程求解的成熟方法，并深入探索和挖掘DifferentialEquations.jl的功能。

实现新的测试粒子算法

有物理学相关背景
了解 Julia 语言和数值计算"
"集群稳定性对分布式系统非常重要，通过开发一块可视化大屏来实时展示 Nebula Graph 的关键监控指标变化，从而让运维人员对系统的线上运行情况一目了然。

该项目旨在为 Nebula Graph 集群监控设计并开发出高性能、高颜值的可视化监控大屏，兼容主流大屏尺寸。

可视化大屏实现

前端可视化"
"在一个从商业数据库迁移到 openGauss 的项目中，业务 SQL 中可能会使用到部分原数据库系统提供的工具包。
这些工具包中的功能可以在 openGauss 中通过已提供的系统接口，SQL或者过程性语言来获得对等的功能性实现。
本项目希望通过使用 openGauss 中的自定义函数功能，在 openGauss 库中实现兼容能力。

本项目希望通过使用 openGauss 中的自定义函数功能，在 openGauss 库中实现以下各个函数和存储过程。 对于其中涉及到的部分确实无法实现的函数或存储过程，需明确给出无法实现的原因。 可参考Oracle数据库的实现形态。 DBMS_DEBUG DBMS_DESCRIBE DBMS_SESSION UTL_FILE

1. 熟悉PL/pgSQL代码编写"
"Nebula Flink Connector 是一款帮助 Flink 用户快速访问 Nebula Graph 的连接器，支持从 Nebula Graph 图数据库中读取数据，或者将其他外部数据源读取的数据写入 Nebula Graph 图数据库。

通过增强 Nebula Flink Connector，提供 SQL Connector，熟悉 SQL 的用户也可以快速上手图数据库 Nebula。

nebula-flink-connector 的 SQL Connector

Java"
"把大数据常用的impala组件引入到openEuler社区，即完成源码构建，在openEuler上安装成功，并在openEuler上成功运行。代码和spec文件需要上传到仓库，CI通过并合入

将impala引入到openEuler，并正常运行，tar包、patch、spec文件合入到仓库

将impala引入到openEuler"
"对openeuler,opengauss等组织下的仓库或者与社区基础设施相关的单一仓库进行备份，并且实现定期同步最新的代码

1.实现仓库的代码完全备份
2.根据commit信息变化定期刷新已经改变的仓库
3.实现可配置可扩展
4.成员和权限管理
5.仓库pull requests和issues备份

1.熟练使用golang编码
2.熟悉k8s部署和配置文件代码化"
"Casbin采用独特的PERM模型语法（model）来实现强大、灵活的访问控制。Casbin Golang版本作为Casbin的第一个语言实现，拥有最多的用户以及最先进的feature。我们希望在Casbin Golang上： 1）增强Casbin语法的表达能力，满足用户多样化的策略制定需求； 2）优化Casbin在大规模规则集上（百万以上）的策略评估性能。 Casbin.NET是Casbin的.NET版本，它需要及时跟踪Golang Casbin主库的最新feature并移植到.NET版本中来。并维护.NET特有的生态

增强Casbin语法的表达能力，满足用户多样化的策略制定需求
跟踪Casbin-Go最新特性与BUG修复，并同步到Casbin.NET，如重构的RoleManager:Casbin.NET#250
完善Casbin.NET的特有生态, 完善现有的aspnetcore中间件：https://github.com/casbin-net/casbin-aspnetcore;
完善Casdoor.SDK的.NET版本: https://github.com/casdoor/casdoor-dotnet-sdk 及相关示例应用
解决Casbin-Go和Casbin.NET以及相关仓库中的issues：Casbin-Go & Casbin.NET

熟悉C#语言，同时了解Go语言更佳
熟悉Git、GitHub相关操作"
"Easy-Es是国内首款ElasticSearch(简称ES)搜索引擎ORM框架,显著降低了ES的使用门槛,即便是不会ES语法的小白也可快速上手,实现相同功能与原生查询相比平均可帮助开发者节省3-5倍代码量.

Easy-Es已完成对地理位置GEO检索及其它常规检索的支持,并且已提供各类排序功能.现需要实现提供按照地理位置坐标由远及近排序的接口,接口可参考及仿照我已经实现的几种排序接口,另外我也会随时提供在线支持和指导.

需求实际意义:提供此接口后,可方便框架使用者借助此接口提供的能力,快速开发出类似外卖,打车,社交等应用中最常被用到的搜出附近指定公里数范围内的店铺/司机/陌生人并按照距离由远及近排序.

实现Easy-Es地理位置排序接口
可通过该接口完成对地理位置坐标按由远及近排序

了解springboot
了解ElasticSearch搜索引擎基本概念"
"背景：目前 MegEngine 作为用户的最底层，很多情况下崩溃，会将栈暴露在 MegEngine 中，但是很多情况是由于用户环境里面的其他程序踩踏了 Lite 的内存，因此看上去是崩溃在  MegEngine 中。


需求：lite 计算支持一种debug 模式，这种模式通过 env 控制（模式配置需要在 caller 调用发生调用任意 LITE API 之前就完成，所以需要和API 本身解绑），在这种模式下模型的执行会 fork 一个单独的进程，并执行，这时候就和用户的进程进行了隔离，避免内存被踩踏的情况发生。

能让 MegEngine 推理服务和 Lite 接口 caller 分别运行在不同的进程，进程间通信高效

主流操作系统创建进程
高效的进程间通信"
"为了构建完善的基于openEuler的ROS2软件生态，需要将以ROS2为载体的部分激光导航算法迁移至openEuler。激光导航算法作为当前自动驾驶/AI领域关键的模块之一，能在openEuler的ROS2上运行起来有着重要意义。当前应用广泛的开源激光导航算法有很多，开源的gmapping,move_base等均用C++实现，可以作为很好的入门软件进行学习。还可以作为一个入口，扩展更多的相关软件包进入基于openEuler的ROS2软件生态。

选取的激光导航算法软件包以rpm包形式提交到src-openeuler对应仓库（由sig-ROS创建）；
自动化脚本执行激光导航算法测试数据集，并输出数据集执行结果，脚本同步上传src-openeuler对应仓库；《基于openEuler的激光导航软件移植指南》、《基于openEuler的激光导航软件测试报告》，报告覆盖ROS安装与基础功能测试、规范性自检、功能性测试、测试结果，以word形式存放到代码仓库的doc目录。

熟悉ROS2，可以进行基本的ROS2软件开发；
了解激光导航/VSLAM算法；
熟悉C++编程语言，熟悉CMake;
熟悉linux。"
"Apache ECharts 中，graph/tree 这样的图支持缩放平移。在一些应用中，放得较大时需要同时有全局的概览，以及能在全局概览上操作更新缩放窗口范围。所以希望实现“缩略图组件”来支持这种交互。“缩略图组件”和直角坐标系上的“区域缩放组件（dataZoom）”有一点类似性，但是区别是“缩略图组件”是二维的。

调研相关产品的功能和接口设计，与导师讨论确定包括接口在内的设计方案，在 GitHub 上以 issue 形式发布
修改源码以实现项目要求的效果
编写测试用例，并且完成对现有测试用例的回归测试
编写文档和教程

熟悉 TypeScript 或 JavaScript
熟悉 git 操作"
"目前，如果想参与 OI Wiki 的编辑，就需要 clone 整个仓库进行构建，我们希望在即将上线的基于 Gatsby 的网站中，支持在线编辑 markdown 文档。由于我们使用了一些 remark 插件，Github 自带的 markdown 预览功能相比之下比较匮乏。我们编写了基于 VSCode 插件实现的在线预览插件，希望你在本项目中可以将其完善，提供同步预览等功能。

与目前编码风格保持一致，尽量以 Typescript 为主要编程语言
实现在线编辑插件
协助解决目前项目中存在的 issue

前端开发的相关知识（HTML/CSS/Javascript/Typescript/React）
能使用 Git 进行协作开发
熟悉 remark 工具链者优先"
"Stratovirt中提供了相关的trace工具，但是之前的代码中并没有使用trace工具记录相关必要信息。因此需要在代码关键部位增加对应的trace描述，并且保证增加trace之后不影响原有性能表现。

1、关键点代码trace的记录
2、增加trace前后的性能对比记录

1、熟悉rust语言
2、熟悉虚拟化基本原理"
"Stratovirt中提供了相关的trace工具，但是之前的代码中并没有使用trace工具记录相关必要信息。因此需要在代码关键部位增加对应的trace描述，并且保证增加trace之后不影响原有性能表现。

1、关键点代码trace的记录
2、增加trace前后的性能对比记录

1、熟悉rust语言
2、熟悉虚拟化基本原理"
"CFLOW-AD是一个无监督实时异常检测模型，在无监督的情况下，我们没有异常样本用来学习，而算法的基本上假设是异常点服从不同的分布。CFLOW-AD运用了标准化流框架用于定位和检测异常点，它还包括了编码器和解码器来判断误差。这个方法在算力和存储方面更加经济高效，模型比传统方案缩小了10倍，但效果在AUROC检测指标中高了0.36%，在定位任务中，相比原方案的AUROC和AURPRO指标高出了1.12%和2.5%。

1.实现CFLOW-AD无监督异常检测模型 2.精度、性能等相关指标达到论文标准 3.代码满足MindSpore models仓规范要求 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"本项目基于优麒麟操作系统，制作一款协助用户打包上传个性化主题的UI工具，并帮助用户在使用过程中了解熟悉系统主题。该项目可以让用户体验到优麒麟的高度个性化，从而达到使用系统时的趣味性和观赏性。

该工具需运行流畅，UI界面美观大方，符合UKUI设计风格
该工具能够合理协助用户制作个性化系统主题，其中包含壁纸、光标、图标、系统样式等
该工具能够将用户素材与配置按照规范制作成DEB包
该工具实现上传功能

熟悉Linux操作系统，了解系统主题概念
了解QT、C++开发"
"背景：目前 MegEngine 开发时没有没有进行 apple aarch64 macos 操作系统的适配，MegEngine 并没有发布适配 apple aarch64 macos 的安装包。随着 apple aarch64 macos 电脑越来越多，此需求日益剧增。

需求：在 MegEngine 中适配 apple aarch64 macos，完成 MegEngine apple aarch64 macos 安装包发布。

在 apple aarch64 macos 上，产出 MegEngine 的 wheel 安装包。
L0: MegEngine 在 apple aarch64 macos 上可本地编译通过。
L1: 包具备分发性，可安装到其他 aarch64+ macbook 上，且能正常运行。
L2: 安装后能训练一个模型。

编译
macos"
"BGMProvider是为毕昇JDK生态提供国密TLS协议Java实现，它包括 jca、jsse、tomcat-adaptor等模块。目前BGMProvider jca模块实现的国密相关算法依赖于bouncycastle。为了将来更好地扩展，需要将BGMProvider和bouncycastle解耦，并且在BGMProvider上实现国密相关算法。【需求描述】在BGMProvider上实现国密相关算法
实现SM2/SM3/SM4/HmacSM3/SM3WithSM2 国密算法；
实现国密证书解析相关的算法

实现SM2/SM3/SM4/HmacSM3/SM3WithSM2国密算法以及相关功能测试用例；
BGMProvider与bouncycastle解耦，去除与bouncycastle相关类的依赖；

熟悉掌握Java语言；
熟悉JDK Service Provider机制，熟悉TLS协议；"
"实现SeaTunnel自己的指标系统，需要包含抽象接口来定义不同的指标数据传输方式的抽象，同时使用该抽象实现1-2种具体指标传输方式（HTTP接口，Prometheus等）。指标包含SeaTunnel数据指标以及通过接口获取的底层引擎指标（Spark和Flink），从而为用户提供统一的指标获取方案。
SeaTunnel层面指标应该至少包含任务信息，运行时间，算子并行度等简单指标。

完整的方案在社区讨论且获得社区认可
项目能够合并到社区主库

数据同步监控领域知识"
"Milvus 在 2.1.0 版本之后支持批量加载，用户可以通过调用批量加载 API 将大型输入文件（npy 或 json）数据批量加载到 Milvus 中。我们想丰富这个功能，做一个单独的批量加载项目，既做简单的批量加载，又可以实现数据校验、数据清洗和数据类型转换等功能。

一个功能齐全的批量加载工具

扎实的算法和数据结构知识
掌握分布式系统知识
（加分项）了解 numpy、json、parquet 数据格式"
"DPDK是Linux平台下的高性能用户态网络协议栈，Rust异步编程是非常适合IO密集型应用的编程框架。本项目要求采用Rust异步编程方式实现DPDK的API编程接口封装，使得Rust开发者可以在Linux平台上开发DPDK应用。

1、用Rust异步编程方式实现DPDK编程API接口的封装；
2、完成Rust实现的DPDK编程接口文档。

1、熟悉Rust编程语言；
2、熟悉Rust异步编程；
3、熟悉DPDK开发高性能网络应用。"
"目前Arthas主要是单机的诊断支持，目前社区对集群管理功能需求强烈。

因此，考虑实现一种支持大规模集群管控的方式，基本实现原理如下：

1. 在应用服务器上，启动一个常驻的Native Agent
2. Native Agent可以考虑用rust/java GraalVM/go 等实现
3. Native Agent负责连接远程管理平台，接收管理平台的Attach命令，负责中转Arthas的执行命令和结果
4. 管理平台添加对Native Agent的支持

完整的Native Agent项目
agent支持动态attach java进程
基本的后端管理能力

Native Agent对安全性，资源消耗比较高
Native Agent支持TLS的方式连接到管理平台
Native Agent需尽可能的减少对环境的依赖和资源消耗"
"我国正在加快建成海洋强国，走向深远海成为国家战略需求之一。面向海洋科考、海洋环境探测、智能化水上交通等需求，急需提高水上/水下船只、渔网、浮标、漂浮物、礁石、水生物等目标检测识别能力，从而支撑水面无人艇等智能化船舶对江河湖海等复杂水面环境下各种目标的检测和识别，提升其路径规划、避障等自主航行能力；还可以支撑水下潜航器进行水下目标的自主识别、抓取等作业，加速水下潜航器等水下装备的自主作业应用。以真实水面图片为数据集，涵盖多种水面场景典型相似目标，如水面舰船、浮标、水下浮筒、缆绳等，需要通过此数据集，设计并输出模型，尽可能提升模型在测试集上的检测性能。
本任务要求基于昇思MindSpore，选择或设计深度学习网络模型，通过AI方法对水上水下数据进行处理，检测和识别

1.基于昇思MindSpore实现水上水下目标识别案例 2.案例具有良好的识别效果、代码符合社区规范 3.并输出对应的技术博客、帮助别人学习和使用案例 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"当前 Seata AT模式 SQL 语法支持了insert/update/delete的简单操作，以及MySQL的insert into on duplicate key update语法，期望可以对实现InsertOrUpdateExecutor的基类以及为其实现包括 insert ignore into, replace into, insert select, oracle IGNORE_ROW_ON_DUPKEY_INDEX 在内的语法支持，

1. 中期报告前需要完成对于 Seata 的 AT 模式的流程的梳理，熟悉 DMLExecutor 和 UndoLogManage 的原理和流程，输出PDF/思维导图(具体形式不限)流程图，完成对 SelectOrUpdate 的抽象。
2. 终期报告前需要完成至少3个 SelectOrUpdate 的语法的支持。

1.熟悉java语言；
2.对seata有简单的了解；"
"OpenYurt为边缘节点提供了离线情况下的自治能力，能利用缓存的数据，在本地处理kubelet等边缘组件的请求，保证其正常运行。目前这些自治能力还未经过充分的验证和测试。随着社区的发展和新特性的加入，这部分缺失为项目的稳定性埋下隐患。在本课题中，首先会对OpenYurt现有的e2e测试框架进行调整，使开发者能更方便地利用这些基础设施添加测试用例，然后为OpenYurt添加针对边缘自治能力的测试，在测试过程中发现的问题可以尝试解决或者报告给社区。

提升OpenYurt自治能力，优化现有的e2e测试框架
完善边缘自治能力的e2e测试用例
提交OpenYurt当前自治能力的测试报告

熟悉常见的e2e测试框架，了解云原生生态
有Go语言开发经验
了解ginkgo和gomega等测试框架
对OpenYurt有较强学习兴趣"
"StratoVirt是计算产业中面向云数据中心的企业级虚拟化平台，实现了一套架构统一支持虚拟机、容器、Serverless三种场景。StratoVirt在轻量低噪、软硬协同、Rust语言级安全等方面具备关键技术竞争优势。
错误处理是StratoVirt中重要的组成部分，不仅要满足逻辑的正确性，同时要做到可维可测，即软件发生错误后开发人员或者用户可以根据错误信息或日志快速定位到根本原因，并且在代码的实现上要尽量做到简洁和优雅。
目前StratoVirt中的错误处理使用了第三方库error-chain，此库可以做到不同类型错误的自动转换和链接，但是活跃度日趋减弱，已经被rust官方移入rust-lang-deprecated。因此，需要找到社区在功能、可靠性、稳定性、活跃度方面符合要求的新的库替换error-chain。

调研目前社区活跃的第三方错误处理库的优缺点，提交调研报告。
将现有StratoVirt项目中使用的error-chain替换成经过调研后选择的最优的库，替换后不影响StratoVirt现有功能和可维可测性。

熟悉Rust语言"
"Alexa Voice Service （AVS）协议是亚马逊开发的，用于设备端（亚马逊Echo音箱等）与服务端之间的相互通信的协议。 AVS 协议具有通用和协议扩展性强等优点，被其他厂商（小米、百度、腾讯和阿里巴巴等）广泛使用或借鉴。

通过为 Wechaty 增加 AVS 协议的支持，就可以让 Wechaty 开发者通过 Wechaty 直接和 AVS 兼容的设备（智能音箱等）通讯。从而可以实现用户通过语音、触控和按钮使用 Wechaty 开发者提供的服务，极大的增加了 Wechaty 的适用范围。

实现一个简单的 AVS 协议服务器框架
该框架支持 AVS 所用的 HTTP/2 协议
框架具有良好的可扩展性
能够很方便的支持 context 和 event 的解析和处理
为下发指令提供简单易用的脚手架功能
实现 AVS 协议服务器和 Wechaty 的适配服务
将 AVS 服务器收到的信息经过适配向 Wechaty 服务发送过去
接受来自 Wechaty 发送的消息，并经过适配后下发给 AVS 设备端
打通简单场景下的 AVS 兼容的设备与 Wechaty 服务的双向通讯
新建一个 wechaty 服务，提供诸如报时等简单的服务
使用 AVS 服务器框架搭建 AVS 服务器，使之能够正确的处理报时等请求的context 和 event上传和解析，并能够正确的下发对应的响应指令
利用 AVS 和 Wechaty 的适配功能，将 AVS 设备端的报时请求转换并转发至 Wechaty 服务，并将 Wechaty 服务返回的响应转发并转发 AVS 设备端

熟悉 HTTP
熟悉 HTTP 的 header 和 body 结构，以及 POST 和 GET 方法
熟悉 HTTP 抓包分析技术
熟悉 Python
熟悉 Python 语言
熟悉常见的 Python 服务器设计模式
熟悉 Wechaty
熟悉 WeChaty 的基本概念
熟悉 Wechaty 服务的搭建"
"Pixiu 是一款开源的 Dubbo 生态的 API 网关和 接入 dubbo 集群的语言解决方案。作为 API 网关形态， Pixiu 能接收外界的网络请求，将其转换为 dubbo 等协议请求，转发给背后集群；作为 Sidecar，Pixiu 期望可以代替代理服务注册到 Dubbo 集群，让多语言服务接入 Dubbo 集群提供更快捷的解决方案。Pixiu 网关多一个主要能力是提供流量管理能力，本题目需要学生继续完善流量管理能力，支持多协议超时设置，超时优雅返回能力，提供流量分发的能力，尝试基于此来构建金丝雀测试、蓝绿发布、故障注入等服务运维能力。

提供浏览分发的 Filter
对接 pixiu admin，动态根据不同比率进行流量分发
支持多协议超时返回机制

对 go 语言有一定了解
了解一般请求流量分发机制"
"可视化当前数据页面的展示，能够图形化的展示表/索引的格式、存储的内部格式，帮助大家理解内部的格式和问题定位

1、根据表和索引的元数据信息，参照pagehack工具对页面的解析逻辑，可视化展示openGauss的表和索引页面格式。 2、输出相关的设计和使用样例文档。 3、完善相关的单元测试用例和功能测试用例。

1、了解openGauss的基础功能、逻辑架构，了解页面存储格式 2、熟悉C/C++开发，熟悉linux上图形界面的开发"
"用户在启动DolphinScheduler服务后，可以使用demo-tool程序预置工作流demo，包括但不限于简单的shell任务、逻辑组件任务（switch、dependent、subprocess、condition）、参数传递等功能， 引导用户更方便地使用DolphinScheduler。

预置工作流demo的tool程序
服务启动脚本添加 init模式
工作流demo包括但不限于shell任务、逻辑组件任务（switch、dependent、subprocess、condition）、参数传递等

熟悉Java、Shell"
"现在 Pulsar 的事务缓存由一个快照进行恢复，该快照是一条 entry。当中止事务数量过多时，快照的大小将超过单条 entry 大小的限制。在这种情况下，我们应该使用多个快照来防止在超过 entry 大小时无法使用快照。

项目验收标准
编写该功能的设计文档
实现 Pulsar 事务缓存的多快照功能并推送 PR
添加单元测试进行验证
编写本功能的说明文档

项目技术要求
了解事务原理
熟悉 Java 编程
熟悉基本的 Git 和 GitHub 操作
熟悉 Apache Pulsar 或其他消息中间件"
"openEuler 使用 pam 做为操作系统的认证模块，普通登陆，ssh登陆等等都会使用pam进行认证。但是pam的配置非常复杂，并且支持可插拔特性，导致运维管理员去配置认证策略非常复杂。期望提供一款易用的dde桌面应用，简化密码策略配置

1.支持密码策略配置
2.支持dde桌面，风格适配dde桌面

1.开发语言不限 c/c++/go/python
2.熟悉linux pam配置"
"dbeaver(https://github.com/dbeaver/dbeaver)是一个流行的开源图形化数据库操作管理工具，增加对于openGauss数据库的兼容支持。

对openGauss进行如下适配： 1. dbeaver现在驱动管理默认下没有openGauss数据库,增加openGauss数据库适配并支持org.opengauss驱动; 2. dbeaver适配openGauss后并新增openGauss job 创建/删除/查询/启动/停止功能; 3. dbeaver适配openGauss分区表,可以在表的详情下查询分区列表并在生成正常DDL语法查看

1. 了解openGauss基本操作，了解openGauss中job和分区表的原理及操作方式; 2. 对于原开源Java代码具备阅读和修改的能力"
"社交软件的种类日渐丰富，大量的信息穿插在各种社交软件之中，频繁的在不同APP间切换更会使得我们晕头转向，无效信息+频繁切换无形中损耗着我们的余闲。目前以微信、企业微信、WhatsApp三者为例，希望能够将不同APP中的关键信息统一汇总到微信上来查阅及回复，方便我们能够仅在微信上就能处理不同来自不同APP的消息，从而达到提升效率的问题。

前期：通过 Wechaty 对接微信、企业微信、WhatsApp
利用 Wechaty 的能力实现这三类社交APP基础类型消息的收发功能
中期：以上三者应用间的消息实现互通
通过消息的转发调度方案，使得企业微信和WhatsApp的消息可以汇总到微信上
后期：支持分时间段选择接收消息的社交软件
支持通过配置来选择任一社交软件来作为消息的汇总终端

熟悉并使用 Wechaty 实现消息收发
针对不同社交 APP 选择对应的 puppet 依赖模块实现消息收发的功能
编写调度程序打通三类 APP
通过创建多个 Wechaty 实例来实现 APP 的打通
通过会话方式配置时段及消息接收的终端信息
提取会话内容生成对应用户自定义配置文件实现选择时段及汇总消息的终端"
"微分方程在科学的各个领域有广泛应用，包括预测力学和流体动力学的运动以及描述化学反应、生态学的生态系统平衡、金融学的市场动态和流行病学的疾病传播。在许多情况下，寻找非线性微分方程组的解是具有挑战性的，需要先进的数值技术。本任务是要求使用mindquantum对在物理、化学上有广泛应用的微分方程进行求解。

1、对微分方程进行建模，实现求解微分方程的变分量子线路，求出模型参数；2、探索相关的应用； 3.代码需要有适当的注释； 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，量子计算，MindSpore"
"NoneBot2 为用户提供了命令行脚手架──`nb-cli`，辅助用户更好地上手项目以及进行开发。nb-cli 主要包括：创建项目、运行项目、安装与卸载插件、部署项目等功能。随着 NoneBot2 Beta 版本的发布，脚手架功能存在一定的定位不明确、功能体验不佳。本项目旨在重新设计 nb-cli 功能框架，完善功能，优化用户体验。

设计 nb-cli 功能框架
明确各功能模块
设计用户交互模式
完成 nb-cli 主要功能代码
项目管理
插件管理
其他
同步更新使用文档

熟悉 Python 命令行交互代码编写
熟悉 NoneBot2 框架功能
熟悉 NoneBot2 项目组织方式"
"分布式强化学习强依赖多进程之间的交互。飞桨分布式架构提供了基础的模块如RPC通信、异步流水执行器等，我们希望开发者可以在飞桨原生框架上进行二次开发扩展，支持飞桨分布式强化学习训练。

飞桨PaddlePaddle：以百度多年的深度学习技术研究和业务应用为基础，是中国首个自主研发、功能完备、 开源开放的产业级深度学习平台，集深度学习核心训练和推理框架、基础模型库、端到端开发套件和丰富的工具组件于一体。

基于飞桨框架研发的RL训练架构代码合入github/PaddlePaddle/Paddle/develop
提供一个经典RL算法的示例，能够调用飞桨RL分布式训练框架，跑通训练

熟悉 C++
熟悉 RPC
熟悉 RL"
"基于PiFlow框架，改造PiFlow代码，将PiFlow-Server、PiFlow-Web拆分为三个镜像，通过编排实现PiFlow项目的容器化快速部署。

三个容器镜像，基于docker-compose和kubernetes的编排文件

熟悉大数据知识，了解容器技术，Scala"
"为支持openEuler和OpenHarmony两大社区生态互通，实现边端设备的协同，需要将OpenHarmony上已有的设备认证hichain模块（仓库名为deviceauth）迁移到openEuler社区。进而支持欧拉和鸿蒙之间的设备认证，以支撑分布式软总线等模块的使用。

1、将OpenHarmony的deviceauth模块迁移和运行在openEuler上，支持点对点的设备认证能力
2、支持分布式软总线对deviceauth的接口调用，打通欧拉和鸿蒙之间的设备认证

1、熟悉OpenHarmony和openEuler的开发
2、熟练C编程
3、了解对称、非对称加密、秘钥交换等原理"
"github是全球最大的开源软件项目托管平台。随着开源项目数量日益增长，优秀项目的推荐能力成为了连接开源项目与开发者的重要桥梁。本任务根据用户的行为（star和fork）为用户推荐感兴趣的项目。使用towhee完成完整的数据采集、处理和模型算法，并最终以微服务的方式为用户提供github项目推荐服务，力争打造一款造福广大开源爱好者的实用工具。

Github项目推荐服务
Towhee支持推荐算法

扎实的机器学习算法知识和实际数据科学经验"
"TDengine 整体服务由 server 和 client 端组成。Client 端承担了读写请求的解析、拼装、序列化、分布式访问、meta 缓存等重要职责。在高并发高吞吐的访问过程中，这些功能的实现方式，将会决定 TDengine 的性能效果。因此本次项目将会通过学习TDengine client 的代码结构，通过 BPF 等工具，引入 Tracing，对每个核心技术点进行Performance Analysis/Research/Coding/Testing，落地高性能的实现方式，从而提升 client 的整体性能。你将会有机会优化整个时序物联网行业的能效。

client 代码分析报告，包含代码架构图，功能清单，调用链关系
目标优化功能的性能分析报告
主流技术点的调研、分析与对比报告
编码设计与编码实现
测试方案、测试用例、对比测试报告
项目总结报告

熟悉各类排序算法、字符串匹配、正则表达式
熟悉队列、哈希、堆、栈等数据结构
熟悉 Protobuf 等各类序列化技术
熟悉 Linux 内存分配原理及机制
熟悉同步/异步、阻塞/非阻塞等网络概念，熟悉 socket 编程
掌握至少1种 C 的 unit test 方法"
"Emacs，距今已经有45年的发展历史的“编辑器”，在这45年内，全世界最顶级的黑客在贡献自己的智慧和想象力，一起构建了Emacs这个伟大的开发者工具生态。Emacs的劣势也是因为它太古老了，导致在多线程和图形扩展能力已经无法跟上时代的步伐。EAF是在保留Emacs古老的黑客文化和庞大的开发者插件生态前提下扩展Emacs的多线程和图形渲染能力，实现Live In Emacs的理想。因此，本项目的目标是基于Vue.js和SMTP，IMAP/POP3，通过EAF将Elisp和JavaScript连接起来，实现一个图形表现力强的邮件客户端。需要同时了解Emacs，Python和Vue.js图形开发的黑客来报名参加。 

基于Vue.js实现图形界面，使用SMTP，IMAP/POP3实现邮件客户端
在符合Emacs键盘操作习惯的前提下，用键盘收发邮件
拥有邮件客户端的基本功能，具备发送邮件，读取邮件等功能
优先确保在Linux和Gnome/KDE能成功运行，时间允许下可以调试Windows/macOS平台

熟练使用Linux和GNU Emacs
熟悉ELisp或类似Lisp方言"
"Casbin采用独特的PERM模型语法（model）来实现强大、灵活的访问控制。Casbin Golang版本作为Casbin的第一个语言实现，拥有最多的用户以及最先进的feature。我们希望在Casbin Golang上： 1）增强Casbin语法的表达能力，满足用户多样化的策略制定需求； 2）优化Casbin在大规模规则集上（百万以上）的策略评估性能。 jCasbin是Casbin的Java版本，它需要及时跟踪Golang Casbin主库的最新feature并移植到Java版本中来。同时维护Java特有的生态

增强Casbin语法的表达能力，满足用户多样化的策略制定需求
优化Casbin在大规模规则集上（百万以上）的策略评估性能
跟踪Casbin-Go最新特性并移植到jCasbin，如实现WatcherEx:casbin#943
维护完善jCasbin的Java特有生态，如实现Play框架中间件：jcasbin#104
解决Casbin-Go和jCasbin以及相关仓库中的issues：Casbin-Go & jCasbin

熟悉Golang或Java语言
熟悉Git、GitHub相关操作"
"Serverless Devs作为Serverless领域的专业开发者工具，致力于在Serverless应用全生命周期发挥作用，随着时间的发展，一方面，Serverless Devs已经可以支持诸多厂商的FaaS产品，但是对于BaaS产品的支持比较薄弱；另一方面，Serverless Devs 应该对生态集成有更为深入的探索，例如资源创建和管理相关操作要交给Terraform等。所以本题目要求同学：
学习和了解Serverless，Serverless Devs相关知识，并完成阿里云API网关、CDN、OSS等组件的设计和开发;
参与调研和设计Serverless Devs与Terraform结合点，并开发出Serverless Devs Terraform组件；

Serverless Devs BaaS 组件开发
开发完成API网关组件，贡献到社区
开发完成OSS网关组件，贡献到社区
开发完成CDN网关组件，贡献到社区
输出3篇关于API网关组件、CDN组件以及OSS组件的文章，进行社区布道
Serverless Devs Terrafrom组件开发
产出 Serverless devs 与 Terraform结合具体方案
针对产出方案，并涉及相关组件和功能，贡献到社区

对Serverless有一定的了解，或者愿意学习和了解Serverless架构
对Node.js，Typescript等语言有所了解，或者具有较强能力可以快速学习Typescript语言
了解并熟悉对Github等使用方法"
"参考 The Document System (https://documentation.divio.com/) 以及基于 MkDocs (https://github.com/mkdocs/mkdocs/) 实现一个对用户更加友好简单的中文文档系统，其中包括：介绍（Introduction）、使用指南（Tutorial）、应用实践（How-To Guides）、API文档（Reference Guides）、常见问题和解答（Explanation/FAQ）等五个部分模块。

完成介绍模块
包含安装、基本概念介绍、整体架构介绍等
完成使用指南模块
包含好友、群聊、好友关系、标签、小程序、FileBox 等模块
完成应用实践模块
包含如何启动 Token Service、如何编写插件、如何保证机器人的鲁棒性、如何与第三方包嵌入
完成API文档模块
从代码中生成API文档，同时也需要完善代码中的 docstring
完成常见问题模块
检索常见问题并给出解决方案

基于 MKDocs 编写文档
实现文档的基本上呈现，没有明显错误
使用 mkdocstring 生成 API 文档
将多个项目的 API 文档都整合到一起"
"分布式训练作业中通常涉及到多机通信，不同的训练框架&训练角色配置对应不同的通信策略，比如：
1) PS-Worker：PS与Worker之间会以AllReduce的形式通信，PS之间不会互相通信；或者PS-Worker有分片通信的策略，单个PS与某些Worker交换参数；
2) 纯Worker：以RingAllReduce的方式环状通信；
3) Master-Worker：单Master节点与多个Worker节点之间通信；
...
针对不同的作业及其通信策略，如果能将互相通信的Pod调度在同一台机器上，用本地通信代替跨机通信提升通信效率，可以达成以下目标：
1) 定义出不同的通信策略，用户可以指定，也可以在开启featuregates后注入默认值；
2) 针对每个Job，构建对应的亲和性方案，创建每个Pod时分别注入不同的亲和性规则；
3) 对比开启前后的训练效果，对通信密集的作业是否有提升，给出测评报告；

定义出不同的通信策略，用户可以指定，也可以在开启featuregates后注入默认值（合理的用户API和使能开关）；
针对每个Job，构建对应的亲和性方案，创建每个Pod时分别注入不同的亲和性规则；
对比开启前后的训练效果，对通信密集的作业是否有提升，给出测评报告；

了解Kubernetes基本原理，KubeDL的整体架构和工作原理
对深度学习框架的通信模式有基本的了解，以及对优化手段也有明确的认知
能够根据设计方案，有优秀的编码能力和单测覆盖度，最后也能根据实现结果给出详细的测评报告"
"数据库中SQL函数可以大致分为以下几类：内部函数、系统生成的函数、用户定义的函数(UDF)，其中用户定义的函数是指由用户通过CREATE FUNCTION显示创建并命名的函数 ，其语义也由用户自己确定。

本任务包含的功能点：
1. PolarDB-X支持CREATE FUNCTION 创建UDF
2. UDF同时注册到CN和DN，确保关联UDF的计算尽可能下推到DN；不能下推的计算将发生在CN侧；
3. 支持一些系统视图，可以方便查询和管理已注册UDF

PolarDB-X支持CREATE FUNCTION 创建UDF
UDF同时注册到CN和DN，确保关联UDF的计算尽可能下推到DN；不能下推的计算将发生在CN侧；
支持一些系统视图，可以方便查询和管理已注册UDF

熟悉Java语言、了解UDF"
"背景 : 
Apache ShardingSphere 是一套分布式数据库中间件生态产品，除了提供数据分片功能，帮助用户搭建分布式数据库集群外，还提供数据加解密、SQL 审计、分布式权限、影子库、数据库管控等功能。借助ZooKeeper 及 Etcd，ShardingSphere 为用户提供了分布式数据库集群治理的功能，作为全球人气的数据库开源项目，越来越多社区用户希望 ShardingSphere 可使用 Nacos 进行分布式治理，即通过 Nacos 的 CURD 和事件通知来完成 ShardingSphere 集群下状态和规则同步。本项目主要完成该功能模块的研发、测试和交付，具体任务如下所示。 
 
任务 : 
这个任务目前是集成 Nacos 注册中心，下面是一些具体任务列表 :  
ShardingSphere 引入 Nacos 依赖 
在 shardingsphere-cluster-mode-repository-provider 工程下创建 shardingsphere-cluster-mode-repository-nacos 
定义 Nacos 的配置项 
新增 NacosInternalLockHolder 并内部实现 Lock 接口 
实现 ClusterPersistRepository 接口 
通过 SPI 默认加载该实现类 
给 ClusterPersistRepository 接口的实现增加必要的单元测试 
更新 shardingsphere-example-generator 模块，引入 Nacos 
更新 ShardingSphere 官方文档 
10 . 增加 Nacos 的测试用例 (https://github.com/SphereEx/auto-test)，验证 ShardingSphere-Proxy 集群之间配置共享 
参考 : 
你可以参考 Etcd 或 ZooKeeper 模块，来辅助完成这个任务：  
shardingsphere-cluster-mode-repository-etcd  
shardingsphere-cluster-mode-repository-zookeeper-curator 
 
测试 : 
完成集群模式集成 Nacos 之后，你需要在本地 ShardingSphere-Proxy 集群中进行简单测试 : 
首先确保 ShardingSphere 集群中每个计算节点可以正常的启动 (https://shardingsphere.apache.org/document/current/en/quick-start/shardingsphere-proxy-quick-start/) 
在单 Proxy 中创建逻辑数据库，此时在集群中其它计算节点均可以查看到所创建的 DATABASE 
通过 DistSQL(https://shardingsphere.apache.org/document/current/cn/user-manual/shardingsphere-proxy/distsql/syntax/rdl/resource-definition/) RDL 新增资源，此时新增的资源应同步至其它计算节点

ShardingSphere-Proxy 集群模式可通过 Nacos 注册中心完成各个计算节点的状态同步及配置和元数据的同步

1. 精通 Java； 2. 熟悉 Nacos；3. 理解锁机制"
"MatrixOne项目致力于打造一款极简的超融合异构云原生数据库，通过融合OLTP，OLAP，流计算等多种引擎，使得用户在大部分场景中都可以通过单一数据库满足一定规模及复杂度的业务，降低开发者的选型及运维成本。

MatrixOne哈希表的实现好坏直接关系到数据库的查询性能。MatrixOne目前使用的哈希表，是不区分数据基数的通用方案。对于低基数的情况，其性能并不如专门优化的方案。本任务的目标是为MatrixOne实现一个专为低基数场景优化的哈希表。

提升MatrixOne查询在低基数场景下的性能
完成项目的设计，开发和测试
输出设计文档
源代码+单元测试+代码注释
功能测试用例
测试报告（包含性能，使用方法，功能边界）
输出和完善用户文档（功能描述，用法等等）

具备用go语言开发的能力，且能阅读C++代码
熟悉计算机体系结构
熟练阅读英文技术文档"
"飞桨支持多子进程DataLoader数据加载并发加速通用能力，我们希望开发者在数据预处理易用性和通用扩展功能上进行优化开发，支持DataPipes系列链式预处理API和如解压、解码、RFC等通用功能。

飞桨PaddlePaddle：以百度多年的深度学习技术研究和业务应用为基础，是中国首个自主研发、功能完备、 开源开放的产业级深度学习平台，集深度学习核心训练和推理框架、基础模型库、端到端开发套件和丰富的工具组件于一体。

1. 支持map-style和iterable-style数据集对应的DataPipes系列API，支持map、shuffle、batch、filter等功能
2. 支持文件解压、文本解码、本地/远程文件操作等通用扩展能力

1. 熟悉Python编程
2. 熟悉多进程编程"
"背景：
Doris 当前支持 Hive、Iceberg、Hudi（在研）等外部数据源的访问和查询。而用户对外部数据源的访问有更高的要求，如：
1. 统一的元数据管理，能够灵活的访问外部数据源的元信息、并通过同步、缓存等机制进行高效访问。
2. 对数据源的多种数据存储性能进行访问，如Hudi支持Snapshot Query等。
3. 优化外部数据源的数据访问性能，如增加缓存机制、异步IO线程等等。 

需求： 
1. 调研Hudi的Snapshot Query功能，并支持Doris通过JNI进行Hudi的数据访问。
2. 调研统一元数据管理框架，重点调研并设计元数据的权限管理功能。Doris当前的元数据层级为 Database-Table两级结构，并且权限管理也是对应这两层结构。如果引入统一元数据管理框架，则需实现Namespace-Database-Table三级结构，而相应的权限管理也要做出调整。

1. Doris支持Hudi的Snapshot Queries 2. 完成元数据的权限管理功能设计

对 Java语言熟悉，有数据湖和JNI开发经验。"
"当前opengauss_exporter 已经可以对数据库信息进行采集，并通过grafana进行展示，本项目需要多节数据库内核已经支持的anomaly_detection模块，进行可视化输出，提供运行状态及资源使用的预测能力。

1、不影响当前exporter正常运行，可以兼容原exporter; 2、了解anomaly_detection模块（https://opengauss.org/zh/docs/2.0.0/docs/Developerguide/%E6%A6%82%E8%BF%B0-43.html），与exporter相结合; 3、作为一个可选项，由客户决定是否开启预测功能

1、了解Prometheus + grafana 监控体系; 2、熟悉openGauss数据库日常使用; 3、具备golang编码能力"
"Apache APISIX Ingress controller 是一个使用 Apache APISIX 作为数据面的 Kubernetes Ingress controller 实现。Gateway API 旨在通过许多供应商实现并具有广泛行业支持的富有表现力、可扩展和面向角色的接口来发展 Kubernetes 服务网络。

使 APISIX Ingress controller 可以使用 Gateway API 中的 TCPRoute 配置 4 层流量代理；
完整的 e2e test case.

需要熟悉基于 Kubernetes 的 controller 开发；
有一定的 Go 开发经验"
"一种基于深度学习的一种轻量级的目标分解网络，它可以从不同背景的单个输入图像中平滑地处理动态人像。MODNet 由三个相互依赖的分支 S、D 和 F 构成。它们分别通过一个低分辨率分支来预测人类语义（SP）、一个高分辨率分支来聚焦纵向的边界细节（DP），最后一个融合分支来预测 Alpha Matte （αp）。总之，MODNet 提出了一个简单、快速且有效实时人像抠图处理方法。该方法仅以 RGB 图像为输入，实现了场景变化下 Alpha 蒙版预测。

1.实现MODNet语义分割网络模型 2.精度、性能等相关指标达到论文标准 3.代码满足MindSpore models仓规范要求 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"Apache Wayang[1]是一个元处理框架：您可以通过Apache Wayang的API之一指定您的数据处理应用程序，然后Apache Wayang将选择经典处理框架的最佳配置，例如Java Streams或Apache Spark，来运行您的应用程序。最后，Apache Wayang还将执行，从而隐藏不同的特定平台API并协调平台间通信。

这种方法旨在使数据工程师和软件开发人员摆脱了解不同数据处理系统、其API、优缺点的负担；协调和整合不同处理平台的复杂性；以及绑定到固定处理平台集时的灵活性。到目前为止，Apache Wayang已经内置了对以下处理平台的支持：

Java 8 Streams
Apache Spark
GraphChi
Postgres
SQLite

本主题要求能够完成Spark、Postgres和SQLite的E2 E测试开发，并且您需要能够使用真实的容器环境来完成这些处理平台的自动测试。这一过程要求您对Docker和测试容器[2]以及Github操作有一定的了解，这不是强制性的（讲师将指导您，但仅当您对自动测试感兴趣时）

完成Spark的e2e测试

完成Postgres和SQLite e2e测试

能够与Github Activo集成

这个过程要求您对Docker和测试容器以及Github操作有一定的了解，这不是强制性的（讲师会指导您，但只有当您对自动测试感兴趣时"
"用于容器场景的堆叠文件系统(overlayfs)将几个文件系统通过层次(upper layer、lowerlayer)的方式组合在一起，容器对upper文件层可读写，lower文件层是只读层；在当前的实现，写文件触发整个文件从lower layer拷贝到upper layer，性能开销以及page cache开销大。

1. 在overlayfs中实现基于block的COW机制, 代码到达内核合入的标准。
2. 在容器环境中，结合典型测试集(sysbench)测试性能数据
3. 技术文档：设计描述与性能测试分析。

1.内核文件系统
2.容器
3.C语言"
"mica 是一个 Spring Cloud 微服务开发核心工具集。基础工具类、验证码、http、redis、ip2region、xss 等组件开箱即用。

任务说明：
mica-openapi 是对 springdoc-openapi 增强，目前只做了依赖，添加了更好用的 knife4j。

任务步骤：
完成 swagger 配置，具体配置项可参考 mica-swagger。
可配置通用 header 和 oauth2 认证。
knife4j 目前需要添加配置才可以展示，检测到 knife4j 添加默认的 env 配置。

完成 springdoc 基础配置，具体配置项可参考 mica-swagger。
可配置通用 header 和 oauth2 认证。
knife4j 目前需要添加配置才可以展示，检测到 knife4j 添加默认的 env 配置。
完成配置文档和使用文档

熟悉 spring boot stater 自动配置和配置项
了解 swagger 和 springdoc
了解 mica 相关组件"
"A-Tune是一个基于AI算法的性能调优工具，可以帮助用户进行自动化的操作系统调优或应用调优，实现性能提升；A-Tune本身包含了atuned和atune-engine两个服务，其中atuned服务为本项目的重点：atuned中同时包含了由gRPC框架实现的客户端与服务端两部分，本项目目标是将客户端与服务端拆分开，使二者在部署时不需要相互依赖，实现客户端与服务端分节点部署

实现atune-adm与atuned的解耦，使二者在部署时不需要相互依赖，实现分节点部署
编写对应的测试用例，对拆分后的结构进行测试

1、熟练掌握go语言
2、熟悉gRPC框架"
"openEuler Embedded中的软件包的.bb文件来源纷杂，有的为自身编写的，有的是间接从上游如poky, OpenEmbedded等实现中修改而来，为了日后的维护和对接其他工具，有必要对软件包的格式进行约束。因此本项目的目的是实现一个通用且具有自身风格的软件包模板

openEuler Embedded当前支持软件包.bb文件可根据该模板进行统一整改
有利于实现软件包自动转换

熟悉Yocto框架、原理
熟悉嵌入式Linux开发"
"Apache Pulsar对发往broker的消息引入了大小限制。目前，Pulsar的Java客户端支持了消息分块的功能，使得Pulsar在生产者中能够将消息分成多个小块并在消费者中将它们组装起来，以支持大消息的处理。但是Pulsar的Go客户端并不支持这个特性。本项目将在Go客户端中添加对大消息处理的支持。

按照要求完成项目要求的功能、单元测试及文档开发
编写一份方案来描述你的设计
在Pulsar Go客户端上实现消息分块的功能并推送PR
添加单元测试以进行验证
添加关于这个特性的文档

需要掌握三个技术要求
熟练 Go 语言编程
熟悉Apache Pulsar或其他消息系统者优先
熟悉使用 Git 和 Github 者优先"
"openEuler Embedded主要面向嵌入式场景，当前还未支持RISC-V架构，本项目的目标是依托openEuler社区和其他开源社区打通RISC-V在openEuler Embedded的支持，并在QEMU或RISC-V常见开发板上进行演示

在openEuler Embedded中集成RISC-V的构建（32和64），能够在QEMU或者RISC-V常见开发板上进行部署演示

基本熟悉Yocto框架
熟悉嵌入式Linux开发"
"WebAssembly(Wasm) 是近几年从 Web 领域诞生并快速出圈的一项虚拟机指令格式，是一种可移植的、语言无关并兼容 Web 的全新格式，支持在浏览器和非 Web 环境运行不同语言编写的应用程序。MOSN 是一款主要使用 Go 语言开发的网络代理 (类似 Envoy、Nginx)，融合了大量云原生通用插件，为服务提供了多协议、模块化、智能化、安全的代理能力。如何为这些插件提供一个安全隔离的运行环境，甚至支持不同语言编写的插件，成为了一个非常具有挑战性的课题。Wasm 技术和 Proxy-Wasm 规范的诞生为解决上述问题提供了一种全新的思路。本题目将基于 MOSN 中已有的 Wasm 框架，适配开源社区专门为网络代理场景提出的 Proxy-Wasm v2 规范，使 MOSN 具备运行符合 v2 规范的 Wasm 插件的能力。

为 MOSN 适配社区 Proxy-Wasm v2 开源规范
具备运行符合 v2 规范的 Wasm 插件的能力
(可选) 支持 Wasm 发起异步 Http Call 等高级特性
总结整个开发流程和遇到的问题，并产生文档介绍 MOSN Wasm 框架的工作原理

熟练使用 Linux 操作系统
使用 Go 语言进行开发
具备对新兴技术的快速学习能力"
"metadata具体指服务分组、服务版本、服务名、方法列表、方法参数列表、超时时间等信息，目前dubbo-go metadata 模块实现并不完善，代码实现及功能实现都有很大优化空间，需要参考java实现，制定一套完整的元数据结构。完成 cli 工具对元数据的获取、展示与调用。

和 dubbo java 版本 metadata 兼容
通过metadata 获取服务的信息
尝试使用 dubbo-go-cli通过metadata拿到服务信息发起服务调用

学习现有rpc框架中的解决方案（如 grpc 中的 reflection 包）
优化dubbo-go metadata 代码逻辑
熟悉go语言"
"Vineyard是一个分布式数据管理引擎，Vineyard依赖元数据服务来实现在多个节点之前的同步状态（例如数据在多个节点上如何分布，等等），并为上层的应用程序提供一个分布式数据对象的全局视图。当前Vineyard依赖etcd作为元数据服务的后端，etcd为vineyard的元数据服务提供了高可用性和强一致性。但是很多时候，在一些对强一致性要求没有那么高，并且部署一个多副本的etcd集群并不是很容易的情况下，其他的一些例如redis的键值存储引擎是一个常用的典型方案。

在这个任务中，候选人负责实现Vineyard元数据服务队更多后端存储引擎的支持。元数据服务设计到的操作包括get、put、list、delete，以及建立一个流来持续的订阅后段存储引擎上的来自集群中其他Vineyard节点对metadata的更新，并使得这些更新在当前节点上以一个正确的顺序生效。

候选人首先需要完成一个上手任务来熟悉Vineyard中的元数据服务
候选人需要在已有的一个相对可扩展的接口上实现至少对redis和kine的支持

候选人需要熟悉C++编程
候选人最好有一些分布式编程方面的基础，并且最好熟悉etcd和redis"
"子查询是Gremlin查询中的重要功能，它允许用户在一个查询中调用一个“内部查询语句”来方便地实现一些复杂的功能。

关于子查询两种执行方案的实验报告
判断子查询最优执行方案的启发式规则"
"experimental/simd是一个为C++显式数据并行编程提供零开销C++类型的库，该库已经被包含进GCC官方的libstdc++库。我们正尝试将其移植到Clang/LLVM官方的libcxx库中。该项目需要完成对X86、ARM、PowerPC等多平台simd指令的支持，需要建立完善针对不同平台不同环境的测试框架。

多平台测试框架设计文档
LLVM/Clang内部多平台测试框架代码实现
测试需覆盖simd库所有外部接口
在X86、ARM、PowerPC上均能编译运行测试框架

熟练使用C++，熟悉C++模板元编程及C++11/14/17新特性。
了解libstdc++/libc++库的使用与开发流程。
具备SIMD指令集相关基础知识，了解至少一种SIMD指令集及其intrinsic（SSE、AVX、AVX512、Arm Neon、PowerPC AltiVec）。
具备基本的Linux操作基础和基本的git操作基础。"
"OpenSumi 是一款帮助开发者快捷搭建 IDE 产品的框架，其特点之一便是可以通过一套代码在多端（本地客户端和 Web 端）运行，丰富的底层能力为开发者在研发各类垂直场景能力提供了有力支持，但目前框架在文件操作上依然依赖了传统的 1 对 1 的通信结构，无法在本地客户端及 Web 端中实现跨窗口的文件操作，本课题希望参与课题的同学能够深入到框架底层，同时汲取业界优秀方案的优点，通过底层源码改造的方式，为 OpenSumi 底层搭建一套可跨端实现的跨窗口文件操作方案。

将 OpenSumi 相关文件操作抽象为一个可自定义的服务层，能在不同端下实现不同的跨窗口文件操作
详细的功能集成及使用文档

学习 OpenSumi 框架机制
熟练掌握 NodeJS
具备一定的 TypeScript 及 React 编码能力"
"Vagrant 是一种用于在单个工作流中构建和管理虚拟机环境的工具。凭借易于使用的工作流程和对自动化的关注，Vagrant 缩短了开发环境的设置时间，提高了生产平价性；Vagrant 是为每个人设计的，是创建虚拟化环境的最简单、最快捷的方式！
vagrant可方便地管理各种类型的虚拟机，包括virtualbox、hyper-v、docker、vmware、kvm。它是vmware/virtualbox/hyperv等虚拟化管理工具的上层集成式管理工具、虚拟机自动化配置工具、虚拟机批量管理工具。支持Windows、MAC以及Linux。

1、引入vagrant，vagrant-libvirt，vagrant-hostmanager，vagrant-lxc
2、在openEuler上使用rpmbuild工具完成RPM打包
3、在openEuler Gitee软件仓库中创建vagrant，vagrant-libvirt，vagrant-hostmanager，vagrant-lxc软件仓库，并提交对应Spec文件
4、可以在openeuler上使用vagrant批量创建虚拟机，覆盖aarch64，x86_64架构

1、熟练使用Linux操作系统
2、熟悉rpmbuild打包，可以使用obs构建
3、熟悉虚拟化libvirt，qemu等"
"在操作系统中，线程是一个独立的运行单元，一般认为每个线程是独立运行的；但是在实际应用中，经常出现一个业务功能需要多个线程协同处理，这时候线程和线程之间存在逻辑上的关联关系，经常出现线程之间的唤醒与被唤醒。线程的每次“交互”需要内核调度模块参与，一次完整的交互，内核调度模块需要参与选核，入队列，更新负载信息，选任务等流程。系统中如果线程比较多（有数千个线程）,线程负载比较小的场景下，会导致内核调度开销比较大，而且线程之间交互的效率比较低（线程B需要入队列，等待CPU资源，导致runable的时间比较长）。 在《The Case for Thread Migration- Predictable IPC in a Customizable and Reliable OS》这篇论文中讲述了一种新的线程切换思路：执行实体与调度实体分离，在同步IPC场景中，线程之间发生切换，只切换执行实体不切换调度实体，从而提升IPC的通信效率，降低调度开销。通过测试，这种技术可以使得同步IPC的效率提升近10倍。 执行实体与调度实体分离的技术适用于微内核架构，在linux系统中并不适用，主要因为linux系统在设计之初就将执行实体与调度实体融合成一个结构体：task_struct, 经过多年的开发，task_struct结构体已经散布到linux内核的各个模块中，此时拆分执行实体和调度实体，工作量大，难度高，质量难以保障。 我们可以重新审视执行实体和调度实体分离的技术原理，在线程交互时，切换执行实体而不切换调度实体，本质上是利用了原任务的剩余时间片来运行新任务，bypass调度，降低了内核调度开销，同时原任务直接切换到新任务时，新任务不用重新入队列等待CPU资源，这时没有尾时延（runnable时间），大大提升线程交互的效率。这种往往用在同步线程模型中（原任务进入休眠，新任务执行）。 我们将原任务直接切换到新任务，bypass调度的技术命名为direct-thread-switch, 这里强调下，bypass调度的前提必须是利用原任务的剩余时间片，否则会打破CFS调度的公平性。需求描述】
在Linux环境下实现direct-thread-switch功能，线程切换模型如下，上一个任务进入休眠状态，直接切换到下一个任务进行运行，上一个任务的剩余时间片和调度属性交换给下一个任务，切换到下一个任务继续运行； 不能打破系统的公平性，同时不能破坏dfx；
基本的软件模块包括： 1、内核线程切换方法（direct-thread-switch） 2、基于Google futex_swap patch验证内容： 1、对比有无direct-thread-switch的futex_swap在CPU调度开销大小； 2、验证有无direct-thread-switch的futex_swap在E2E的效率上提升的空间； 验证说明：系统环境需要有1000个运行线程（用于衡量runable的时间）；
【环境要求】
CPU架构：x86_64/aarch64
OS版本：OLK-5.10

1、实现相关的功能代码，功能验证OK；
2、输出完整的设计方案及测试用例；
3、代码符合clean code标准；

1、熟练掌握linux调度器的原理；
2、熟练掌握c语言及内核编程规范；"
"SWCK是基于 Kubebuilder 开发的 Operator，部署在 Kubernetes 环境中，为用户提供自定义资源（CRD）以及管理资源的控制器（Controller），用户可以基于该平台使用、升级和维护 SkyWalking 相关组件。BanyanDB 是为 SkyWalking 设计的云原生数据库，该项目需要在 SWCK 中为 BanyanDB 设计 CRD 以及 Controller 模块。

在SWCK中添加BanyanDB的CRD以及Controller

较强的自主学习能力，有一定编程基础，愿意学习kubernetes和Go语言"
"由于DS日志不方便真实定位问题，需要将打印日志进行规范及优化

整理出DS打印日志规范指导文档，并提交到文档库
将master/worker/api模块按照规范文档进行落地并提交到开发分支

熟悉 Java 语言"
"在嵌入式场景下，内存和flash等资源紧张，往往要通过内核裁剪进行镜像小型化来满足业务需求。内核裁剪的策略通常是优先裁剪掉体积大而又不重要的特性，在这个过程中就对各个特性及CONFIG控制的镜像体积可视化提出了诉求。

1、编写python或shell脚本实现如下需求。
a. 支持用户指定编译的架构和编译工具链
b. 支持用户输入原始的config配置文件，脚本基于此config配置进行解析
c. 支持用户在不输入config配置文件的情况下，脚本能基于仓库全量CONFIG进行解析
2、执行脚本，能够输出日志，描述各个CONFIG可裁剪的镜像体积。 例如：./parse_config ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- -i base_config -o xxx.log

1、内核编译
2、python/shell脚本语言"
"Dragonfly 是 CNCF 里处于孵化中的  P2P 传输项目。在 Dragonfly 项目中，P2P 协议与传输优化是核心内容之一，包括传输协议优化、稳定性优化以及协议安全性提升等等，在这之中有许多需要我们去做的，不仅仅只有 P2P 协议本身，还涉及内核优化、Go 语言性能提升等各个方面。

参与 P2P 传输协议与性能优化，在CPU、内存、高并发、流量传输&限流多方面之一至少提升 20% 以上的性能
独立参与 Go 社区讨论与反馈，主要涉及蜻蜓的在 zero copy、 ktls 相关的优化

有 Go 语言、Kubernetes 等云原生领域的基础，最好对 Go 本身和内核相关性能优化有深厚兴趣"
"SM3是中国定义的哈希算法，coreutils是GNU/linux的基础软件工具包，coreutils工具包已经支持了sha256sum, md5sum这一类用于计算哈希的工具，虽然最新的版本通过cksum -a sm3形式支持了SM3算法，由于用户习惯，以及版本原因，OpenAnolis社区仍然需要一款sm3sum工具，用于计算SM3哈希摘要，需要保持跟md5sum这类工具使用习惯的一致性。

完成sm3sum工具的开发，测试与出包，在风格上需要保持跟md5sum的一致性

扎实的C语言功底"
"目前openEuler内核TCP压缩功能使用proc节点来配置哪些端口开启压缩功能，无法做到精细化管理。譬如，实现单向压缩，或者通过TCP四元组精确匹配哪些流需要压缩等。本任务提供基于内核接口给BPF程序来控制压缩功能是否开启，进一步通过EBPF程序来编写压缩管理策略。

1.内核的TCP_COMP_TX/TCP_COMP_RX选项用于BPF程序开启发送方向/接收方向压缩功能，客户端和服务器断通过TCP三次握手协商是否开启压缩，以及是发送/接收方向压缩。
2.编写使用该接口的demo程序，通过匹配四元组来开启单项/双向压缩。例如基于sockops的BPF_SOCK_OPS_STATE_CB功能，在TCP_SYN_SENT/TCP_SYN_RECV事件上根据策略来设置是否开启压缩。
3.代码合入指定仓库指定分支
4.提供测试报告，确定测试符合预期

1、熟悉linux内核ebpf机制
2、熟悉Linux内核TCP协议
3、熟悉内核压缩解压缩机制
3、遵守linux代码规范"
"Karmada是业界主流的云原生多云容器编排平台，实现了跨Kubernetes集群运行云原生应用程序。

在本项目中，我们需要针对Karmada进行集群规模的性能压测，设计Karmada性能测试的观测点，模拟大规模集群的环境测试当前Karmada能承载的集群上限。

详细测试计划

使用脚本测试

完成性能测试报告

熟悉Golang

熟悉Kubernetes

熟悉Karmada"
"目标：
BitBucket 是最流行的代码托管平台之一，收集它的数据可以使 DevLake 为 BitBucket 用户提供 Git 相关的数据分析应用。

收集的数据范畴：
Git (repos, commits, refs)
PRs (prs, pr review data, etc.)

给DevLake增加一个插件

爱学习，有 Golang 编程基础，对 Git 有基本了解"
"目前Nacos已经与服务网格的标准Istio完成了基本集成工作。该课题致力于完善与优化服务网格生态，完成Nacos支持统一数据面协议(XDS协议），优化Nacos与Istio之间的节点增量推送，进一步提升Nacos在服务网格生态中的地位。

设计Nacos支持XDS协议的详细设计文档，并完成模块开发；
针对当前Nacos与Istio之间的节点全量推送的性能问题，以增量推送的方式进行优化设计；
在Nacos的官方文档中添加服务网格生态的相应文档。

熟悉Java
熟悉Golang
熟悉XDS协议优先
熟悉Istio优先"
"在嵌入式场景下，内存和flash等资源紧张，往往要通过内核裁剪进行镜像小型化来满足业务需求。内核裁剪的策略通常是优先裁剪掉体积大而又不重要的特性，在这个过程中就对各个特性及CONFIG控制的镜像体积可视化提出了诉求。

1、编写python或shell脚本实现如下需求。
a. 支持用户指定编译的架构和编译工具链
b. 支持用户输入原始的config配置文件，脚本基于此config配置进行解析
c. 支持用户在不输入config配置文件的情况下，脚本能基于仓库全量CONFIG进行解析
2、执行脚本，能够输出日志，描述各个CONFIG可裁剪的镜像体积。 例如：./parse_config ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- -i base_config -o xxx.log

1、内核编译
2、python/shell脚本语言"
"操作系统在调度任务运行时，有很多流程，如给任务选核、选出下一个运行的任务等，这些开销也是cpu的负载的一部分。在真实业务场景下，为了提升CPU的使用率及响应速度，使用了很多优化调度开销的手段，如协程等。为了统计调度系统的性能，需要统计出调度系统各个步骤所花费的时间

1、实现工具可以准确的统计各阶段的时间（包含选核、入队、send ipi、handler ipi、 idle唤醒+schedule、context switch）、
2、各个阶段在所有阶段中的比例

1、熟悉linux的基本知识和调度原理"
"JuiceFS 是一款面向云原生设计的高性能分布式文件系统。当程序运行出现问题的时候，无论是内部错误还是外部使用方法上的错误，一般都需要开发人员从命令参数，运行环境，执行日志等多个维度来综合判断原因。而这些维度的信息收集与分享都比较繁琐，本项目希望通过添加 doctor 子命令的方式来提高排查问题的效率。

1. 实现 doctor 子命令，其功能包括收集并分享多维度的有助于排查问题的运行时信息
2. 收集的信息可以通过网络分享到特定通道

1. 基本了解分布式系统，文件系统，Key-Value 数据库
2. 熟悉 Go 语言，GitHub 的使用和协作"
"A-Tune是一个基于AI算法的性能调优工具，可以帮助用户进行自动化的操作系统调优或应用调优，实现性能提升；本项目目标为实现A-Tune集群调优，在现有的tuning功能下实现多节点同时调优

1. 实现多节点调节不同参数
2. 实现多节点调节相同参数
3. 实现多节点调节相同参数且结果不同

1. 有linux操作系统开发基础
2. 熟练使用go语言"
"1.经典隐马尔可夫模型是对时序数据建模的一个强有力的工具，在各个领域里都有广泛的应用，但是近年来新提出的量子隐马尔可夫模型具有更低的复杂度。
2. 相比于经典的隐马尔可夫模型，量子隐马尔可夫模型求解速度快，精度高的特点，根据经典的EM算法思想，实现对量子隐马尔可夫模型的参数求解。
3.本任务的要求是用量子隐马尔可夫模型对离散的数据序列进行建模（离散的数据序列可以是来自真实的系统或者是通过经典隐马尔可夫模型生成），并求出量子隐马尔可夫的模型参数。利用量子线路进行似然函数的求解，再通过经典优化方法找出最优值。
4.由于量子隐马尔可夫模型中的算符是非酉的，但是量子计算是幺正的，所以如何实现非幺正的量子计算是求解该问题的一个难点。

1. 实现对来自经典的数据或量子系统的数据进行建模分析，求出模型参数，并做后续可能的应用，如预测问题等。 2.代码需要有适当的注释； 3.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，量子计算，MindSpore"
"NoneBot2 在早期提供了基于网页的 nonebot-plugin-test 插件，无需平台适配接入即可对机器人进行测试，方便了开发者直观的感受机器人文本交互功能。我们希望提供一款基于命令行的适配器/驱动器，用于无平台适配接入、可以运行机器人的场景进行功能体验或测试。

设计命令行与NoneBot通信模式
直接调用/HTTP/WebSocket
设计命令行交互界面
实现相应适配器/驱动器
同步更新使用说明文档

熟悉 Python 命令行交互代码编写
熟悉 NoneBot2 框架功能
熟悉 NoneBot2 项目组织方式"
"熟悉DTK库函数，设计vtk可视化接口，代码风格统一
实现vtk可视化接口，将现在物理仿真结果的格式进行统一设计，从而满足所有仿真结果的可视化
基于目前只实现二维弹性形变，将它扩展到三维，扩展到塑性形变。将代码风格统一，实现通用的FEM求解器
有限元法启发式求导很难。使用自动求导库，解决计算速度慢的问题，引入GPU或并行计算框架cuda或libtorch
求解弹性形变问题。开发可视化demo，使用VTK库，并提供2-3个用例，撰写使用文档

C++及CMAKE工具链
阅读论文，并实现有限元求解数学模型
自动求导库torch
并行计算库，cuda 等
计算机图形学，可视化"
"Apache ECharts自5.2.0版本引入了groupId以构建数据集之间的层级关系，并借助全局过渡动画实现了“点击父级数据项，下钻查看对应的子级数据可视化”的交互操作。但上述操作目前仅支持一层下钻，继续点击子级数据项将无法继续下钻。我们希望类似的交互操作能够被运用到具有多层关系的复杂数据集中，以能够在任一层级数据中均能完成下钻或上卷操作，并准确展示新层级上的数据。

调研相关产品的功能和接口设计，与导师讨论确定包括接口在内的设计方案，在 GitHub 上以 issue 形式发布
修改源码以实现项目要求的效果
编写测试用例，并且完成对现有测试用例的回归测试
编写文档和教程

熟悉 TypeScript 或 JavaScript
熟悉 git 操作"
"通过兼容层可以使目前正在使用FreeRTOS的工程师快速转入RT-Thread，让他们可以继续沿用FreeRTOS的编程经验来使用RT-Thread，在使用过程中逐渐向RT-Thread过渡，以降低其学习门槛。
此外通过兼容层也可以让之前基于FreeRTOS编写的应用程序和模块可以无缝地在RT-Thread上运行。 

实现RT-Thread对FreeRTOS API的兼容
代码内部符合RT-Thread编写规范
API符合FreeRTOS命名规范
最大限度保证FreeRTOS开发的程序可以无缝、无感对接到RT-Thread
有完善的README说明文档

之前使用过FreeRTOS。了解FreeRTOS内核源码，熟悉API及其特性
使用过RT-Thread，了解RT-Thread内核 API
对这两种操作系统的相同之处和不同之处有自己的看法和理解"
"iSulad当前的事件管理机制实现不是很友好，需要对齐进行重构，以实现更好的设计，并且提供更高的性能。

1、代码符合isulad代码规范；
2、高质量的设计文档；
3、高效、优雅的架构设计；
4、完成模块设计 --- 输出设计文档并合入iSulad社区；
5、完成模块开发 --- 代码合入iSulad社区；

1、Linux基本知识；
2、较好的C语言能力；
3、熟悉docker/containerd源码；"
"目前 OI Wiki 内容在各位好心人的贡献下已经涵盖大部分板块的内容，但不可否认，内容的质量参差不齐。这是贡献门槛低导致的必然结果。目前我们采用的是贡献者提交 pr，管理员审核的形式。但管理员的审核标准各不相同，贡献者的语言风格也千差万别，导致很多时候页面的组织没有逻辑统一。尽管有好心人会自发对页面进行格式统一化的工作，但终究难逃咕咕的结果，并且在 refactor 的过程中会掺杂贡献者本人的主观考量。不难想象，以后可能又有好心人把曾经 refactor 过的页面再按照自己习惯的逻辑结构再来 refactor。虽然OI Wiki的确是主要靠好心人发电走到今天，但我还是不得不说，我们需要减少无效贡献。这是这个提案的初衷。
每个人的阅读习惯是不同的，有人喜欢硬干精确的数学符号定义，有人喜欢循序渐进式的情景引入，有人不喜欢大篇公式符号，有人不喜欢大篇啰嗦文字。因此为了迎合大部分人的需求，很多时候我们会往一个算法的描述中加入许多解释，例题，拓展等。这也就导致了文章结构的破坏。如果想要重组逻辑，不可避免地要删去一些内容，但这又会带来争议，或者被后来的好心人再加回来。如何在不过度提高的贡献门槛也不“得罪”参与贡献的好心人的同时完成 Wiki 质量的提升？
既然线性的、系统性的逻辑结构难以维护，那么我们可以打破线性，打破系统性。OI Wiki 的每一篇文章本质上是一篇说明文，涉及到的表述方式无外乎说明文的表达方式。而读者的阅读习惯可以理解为对表达方式的偏好。那么我们就给段落标记对应的表达方式，让每个段落的作用变得确定——也就是“语义化段落”。这样一来就可以基于段落的标记实现页面内容的个性化调整，以更好地迎合多样化的需求。同时语义化段落既可以规范贡献内容，又不会给贡献者带来较大的制约，也可以更好地帮助管理员理解贡献者的内容，提出更客观的建议，减少无效贡献。

梳理现有内容中的段落逻辑结构
给段落标记对应的表达方式

具有文档 / wiki 维护经验
能使用 Git 进行协作开发
热爱算法与数据结构"
"随着嵌入式应用的复杂性越来越高，对存储空间的需求也越来越高。有时甚至需要几十、上百兆的存储空间，这时选用Nor Flash作为存储设备就不太合适了，价格低廉的Nand Flash就变成了一种更好的选择。
在RT-Thread上可以基于逻辑块管理组件（LPM），管理多种存储设备（NOR Flash、Nand Flash），目前LPM组件已经支持了多块NOR Flash的管理，希望在此基础上再增加上Nand Flash的支持。
希望可以做到：

完善 LPM 组件对 NAND Flash 的支持，可以提供一套接口供Nand Flash 对接。
对接 LPM 组件到RT-Thread MTD Nand 设备框架上，只要对接到RT-Thread 设备驱动框架上的 Nand Flash 设备，都可以无缝的接入到LPM组件。
欢迎有更多的想法，如果能支持EMMC更好了。

完善 LPM 组件对 NAND Flash 的支持，可以提供一套接口供Nand Flash 对接
对接 LPM 组件到RT-Thread MTD Nand 设备框架上，只要对接到RT-Thread 设备驱动框架上的 Nand Flash 设备，都可以无缝的接入到LPM组件
可以基于一款硬件平台(可使用ART-Pi)，制作完整演示示例，包括：Nand Flash支持，及对应的读写性能参数

熟练掌握RT-Thread操作系统
熟悉Nand Flash的特性"
"KubeEdge-Sedna开源的边云协同终身学习范式能够基于云侧知识库中的多个历史任务，处理边侧到来的推理任务。该范式希望通过多任务学习、知识库持久化及更新等方式解决边缘AI领域的核心挑战：小样本与数据异构。生成对抗网络（Generative Adversarial Networks，GAN）已被广泛用于解决小样本与数据异构两个挑战。近年来，分布式GAN扩展并加速了GAN的训练，现有的分布式GAN网络旨在训练出某一类判别器，生成单一类别的虚拟数据。然而，现实生活中存在需要同时训练多种类别的判别器的应用，例如图像转换与机器人巡检。本项目拟通过将分布式GAN框架进行扩展，在服务器端和边缘设备上分别增加全局生成器和本地判别器，为边云协同终身学习设计基于多任务的GAN模型，在边缘设备上同时训练多个类别的判别器，并能够解决现有分布式GAN训练框架下的通信和内存占用问题。

1、分布式多任务生成对抗网络架构实现：基于现有的SGDA架构（服务器端配置生成器，边缘设备配置判别器），实现服务器端配置全局生成器和全局判别器，不同边缘节点上配置不同的本地生成器和本地判别器；
2、设计并实现以减少总体GAN训练时间和服务器内存占用为目标的服务器任务负载调度算法和边缘节点任务负载调度算法。
对于相同GAN网络，相较于SGDA架构及其调度算法，减少至少10%的总体训练时间，减少至少15%的服务器内存占用；
3、实现一套使用分布式多任务生成对抗网络系统的APIs
设计可用的服务器全局生成器和全局判别器配置API，设计可用的边缘节点本地生成器和本地判别器配置API，设计任务调度算法API。

熟悉Python 编程
熟悉Linux系统"
"Kubernetes 是云原生领域的容器编排系统，内部原理复杂但对外界使用者透明。其中pod是kubernetes 项目的原子调度单位，因此，容器级别的数据监测是 Kubernetes 集群中十分重要的一环。当容器出现资源占用过多、性能下降等问题时，现有的工具只能得到 Pod 对应的进程网络传输报文数、网络状态等总体情况，而不能定位到问题出现在哪个阶段，并存在检测效率低、性能差等问题。
本题目要求基于 eBPF 实现内核级别的细粒度数据采集。首先要求从 Linux 内核中提取到网络相关的系统调用，并与具体 Pod 关联，在此基础之上，需要对 Pod 内容器进行进程/线程粒度的的网络数据采集和处理，并映射到用户态 Pod 进行可视化展示，所有功能需要对接到社区项目LMP中。

完整项目代码一份
详细的中文文档
对接到Linux内核之旅社区项目LMP（Linux显微镜）中

了解 eBPF 技术
了解 Linux 内核网络协议栈
了解 k8s
有一定的 C、golang 编程能力"
"为了使Volcano易于使用和理解，你的任务是改进阅读材料。具体如下：
添加更多关于Volcano作业API的介绍和用户指南，包括生命周期管理、作业插件等。

添加更多关于队列API的介绍和用户指南，包括资源划分、配额管理等。

添加更多关于poggroup API的介绍和用户指南，包括基本功能和如何与操作员合作。

添加更多关于设备插件的介绍和用户指南。

提供Volcano Rest API和SDK的列表。

提供Volcano关键功能和用户指南的列表。

将上述文档以中英文上传至github存储库和官方网站

关于Volcano作业API的介绍文档

关于Volcano作业插件的用户指南，包括ssh、env和svc

关于队列API的介绍文档

关于podgroup API的介绍文档

关于设备插件的介绍和用户指南

关于Volcanorest api和sdk列表的文档

关于Volcano关键功能和用户指南列表的文档

Kubernetes
English"
"Serverless Devs拥有诸多的功能和组件，但是更希望有一些针对性的案例可以对开发者和用户更友好，助力大家可以更快速的完成体验，所以选择该题目的同学，需要了解Serverless架构，参与开发和设计体验案例。

按照Project开发完成音视频处理类的案例
完成Project中的图片水印应用
完成Project中的Markdown与图床工具应用
完成Project中的大文件上传应用
完成Project中的文本关键词检索应用
完成Project中的OSS文件解压应用
对应用文档进行规范化整理（具体规范社区会议会进行讨论）
对Serverless有一定的了解，或者愿意学习和了解Serverless架构

对Node.js，Typescript等语言有所了解，或者具有较强能力可以快速学习Typescript语言
了解并熟悉对Github等使用方法"
"基于sedna边云协同终身学习已有的基础核心能力，完成如下任务：
1. 基于KubeEdge Dashboard来集成终身学习系统服务的管理及状态监控、终身学习Task的管理及状态监控、终身学习知识库的管理及状态监控；
2. 基于Prometheus来实现终身学习动态指标的采集和可视化展示；
3. 基于开源日志管理工具来实现应用日志的统一管理和收索；

1. 功能完善的sedna插件；
2. 功能完善的应用案例和文档；

1. 需要了解golang、python等编程语言；
2. 需要了解基于k8s的云服务开发技术；"
"完成 TDengine 的 Visual Studio Code 插件开发，使用此插件中可以进行 TDengine 数据库连接、查询、插入等常规操作。

可以正常使用的 Visual Studio Code 插件，通过此插件实现 TDengine 数据管理，并将源码提交至 TDengine 的 GitHub 仓库
完整的软件设计文档及功能列表
完整的部署文档及使用说明

编程可以选择：TypeScript/JavaScript 进行开发
基本功能要求：
通过界面配置数据库连接参数
导航栏可以查看数据库、数据表列表
双击数据表可以在主界面显示数据表内容，并可以对列进行排序
主界面可以执行 SQL 语句并显示结果
可选功能要求:
实现导入/导出，支持 SQL、CSV 等多种格式
主界面可以添加数据"
"mica-mqtt 是基于 java aio 网络框架 t-io 实现的低延迟、高性能的 mqtt client 组件和 mqtt broker 服务。

项目任务描述：
mqtt session 可用来存储 mqtt 客户端的订阅关系、服务端大于0的qos消息暂存等。
在服务端可设定默认的 session 超时时间。
mqtt 客户端断开连接时将 session 转存到 caffeine cache 中。
mqtt 客户端再次连接时如果 caffeine cache 中存在对于的 session 则先恢复。
考虑 mqtt 5.0 session 的支持。
具体步骤大致如下：
DefaultMqttServerProcessor 中放开注释的 session 代码片段。
MqttServerAioListener 中添加是否清除 session 逻辑。
单机使用 caffeine，断开时将 session 转存到 caffeine 中。IMqttSessionManager 中早已预留相关接口。

完成 mica-mqtt 单机版的 session 管理
输出相关使用和配置文档

了解并熟悉 mqtt 协议
了解 mqtt session 作用和原理
了解 caffeine cache 的使用
熟悉 mica-mqtt 开源项目"
"据21年12月发布的边缘AI研发落地生态挑战调研报告，“提供公开数据集、预处理和基线代码，构建Benchmark”的建议在总体、边缘AI方向的工业界、学术界和在校学生中票数均排名第一，比例分别为82.18%、92.98%、87.10%、86.67%，并且显著高于其它建议。

本项目旨在为Benchmark提供可视化工具，帮助用户洞察算法性能，分析算法改进方向，为算法性能提供美观易懂的支撑材料。届时需提供测试报告可视化工具，完成指定场景和算法的测试及测试报告输出，并支持已有报告的公开存储和展示。

1. 提供社区标准的测试报告可视化工具（可以选型已有开源项目或者自主开发，需提供源码）
2. 完成指定场景和算法的测试及测试报告输出
3. 提供一种方法，支持已有报告的公开存储和展示，社区参与者可以方便查阅。

1. 了解主流机器学习原理，熟悉机器学习常用指标和指标计算方式
2. 熟悉数据分析与数据可视化理论
3. 编程基础扎实、有前后端开发经验"
"目前Seata支持了自定义协议格式参考 https://github.com/seata/seata/issues/893，需要进一步支持TXC/GTS 产品的通信协议，在seata-server侧能够无缝兼容2种通信协议并且支持TXC/GTS 的事务消息处理，以达到使用TXC/GTS  client的用户也可以通过 txc-client 使用 seata-server 提供的分布式事务服务。

1. 完成 GTS 协议的适配和文档；
2. 完成 GTS 事务消息的适配和事务处理逻辑；
3. 完成以上适配的seata-sample 验证。

1. 熟悉Java；
2. 了解 Seata 和 Netty；"
"OI Wiki 是一个编程竞赛知识整合站点，提供有趣又实用的编程竞赛知识以及其他有帮助的内容，帮助广大编程竞赛爱好者更快更深入地学习编程竞赛。然而，算法与数据结构知识迭代更新较快，仍有很多 OI Wiki 尚未涉及的内容。本项目目标是选定若干新颖有趣的 topic，并将其引入 OI Wiki。寻找有趣的 topic 可以参考 Issue 中的 Iteration Plan，e-maxx-eng， AlgoWiki ，以及 NOI 考纲等资料 。

编写完整而易于理解的文档，能使初学者快速了解到算法或数据结构的主要思想
使用 C / C++ 完整实现所选的算法数据结构
设计 testcase
协助解决目前项目中存在的 issue

能使用 Git 进行协作开发
熟悉 C / C++
热爱算法与数据结构"
"HertzBeat 是一款易用友好的云监控系统。无需Agent，拥有强大自定义监控能力。
目前支持的自定义监控协议有 HTTP协议，SSH协议，JDBC协议，用户可以通过这些协议只需要配置yml就能适配一款自己想要的监控类型。比如，通过JDBC协议，用户可以通过写SQL来采集想要的指标数据。
【在HertzBeat支持JMX协议通用自定义监控能力，并适配两款JMX应用类型监控】此项目需要参考hertzbeat原有协议的基础上，新增支持JMX通用协议，使其支持自定义监控能力。并对支持JMX监控的监控应用进行适配，比如 tomcat, jetty等。
在支持JMX协议完成后若有能力，可以适配promethus协议，使heartbeat能通过promethus协议来采集promethus exporter暴露出来的指标数据接口，集成promethus生态中的指标采集能力。

特性代码能以PR的形式合入仓库
支持herztbeat拥有JMX协议监控能力
支持两款JMX监控应用类型

对开源抱有热情和强烈兴趣
熟悉Java语言
了解Hertzbeat或监控系统"
"题目名称：Apache RocketMQ 官网重构升级
 
题目描述： 
1. 目前RocketMQ 官网的界面不够简洁优雅，发布文档不够友好，因此社区尝试使用https://docusaurus.io/ 来替换现有的框架，使得官网更加美观漂亮，且具有文档版本管理能力。
2. 目前RocketMQ Repo工程中存在一些文档，但这些文档有些并没有随着代码和PR一起及时更新，也有一些内容是不完全，比如说对broker参数的解释，RocketMQ 5.0 pop消费功能等，同时这里也包括一些英文文档。本题主要是去重构Github Repo中的英文文档和中文文档，包括：
1）利用https://docusaurus.io/ 框架生成新的官网
2）学习Apache RocketMQ知识，详细了解RocketMQ原理、使用方式、参数含义等
3）利用所学知识，用详细的图片和文字重构已有的 RocketMQ Github 文档内容，包括用户手册、原理解析，部署流程，参数解释等，总体上可以形成一个上较好的用户和开发者文档，并放置到该新官网。
4）有余力的情况下将中文文档翻译成英文。

使用https://docusaurus.io/框架生成新的官网
对 RocketMQ Github文档内容（大部分已经有了）进行完善补充，包括用户手册、原理解析，部署流程，参数解释等，并放到官网
将中文文档翻译成英文，并提交PR

详细了解RocketMQ原理、使用方式、参数含义等
RocketMQ5.0 Pop消费的原理
了解 https://docusaurus.io/框架"
"BanyanDB是一款面向跟踪场景的数据库。其主要功能是搜集，分析并存储Metric，Logging和Tracing产生的数据。由于数据库使用gRPC作为其原生的交互协议，而其对终端用户是不友好的。故该项目的贡献者需要提供一款命令行工具通过访问 BanyanDB 的 API 来管理内部资源和数据

将代码提交给Banyan DB的repositoy。CLI工具可以成功构建和运行

有Go使用经验"
"Arm Virtual Hardware是基于云端的虚拟开发平台，为应用程序开发人员提供虚拟的基于 Arm 的 SoC，同时虚拟了内存和外围设备，为敏捷软件开发（包括CI/CD、DevOps和MLOps工作流）提供快速便利的开发和测试环境。
AliOS Things 是阿里云IoT事业部发布的面向IoT领域的、高可伸缩的物联网操作系统。拥有弹性内核rhino，和丰富的云端一体的IoT组件，以及HaaS Python/JS框架以支持利用Python/JS语言进行开发。目前已被广泛应用于智能音箱、IP摄像头等智能家居、安防等领域。

Github上AliOS Things的仓库，包括能够在Arm Virtual Hardware上运行演示应用所需要的源代码、配置文件和说明文档 本项目的目标是将AliOS Things移植到Arm Virtual Hardware提供的基于Cortex-M55 CPU+Ethos-U NPU的虚拟IoT平台上，并顺利运行以下演示应用：
1. “Hello World”
2. 通过MQTT协议连接阿里云
3. 基于TFLMicro的AI演示程序

有较好的 C++ 功底
有较好的操作系统理解
基本的Docker操作
了解IoT基础结构
对AI算法，深度学习有一定的了解"
"深度学习模型部署过程中，我们希望可以快速地对模型进行压缩和推理加速，离线量化是一种常用的压缩加速方法。

OpenPPL 团队一直致力于异构平台的推理加速，我们已经支持 Turing 系列显卡和多种 DSP 的 INT8 量化推理。面对大量模型的多平台量化部署需求，一款支持多平台量化部署的工具必不可少，OpenPPL Quantization Tool (PPQ) 应运而生。

本课题通过 OpenPPL QuantTool (PPQ) 离线量化工具完成视觉/语言模型多平台部署。

完成视觉/语言模型多平台量化部署，精度损失小于 0.5%，并产出对应 benchmark
视觉模型（分类，检测，分割，超分）/ 语言模型在 pplnn int8, TRT int8, snpe 上的部署

熟悉 Python, C++ 等编程语言，了解深度学习基本原理
了解视觉/语言模型基本原理；
了解模型多平台量化部署的流程"
"目前主流的oauth2认证授权服务器都以单server的形式提供服务，spring security 也开发了 Spring Authorization Server替换已经过时的Spring Security OAuth2.0。我们计划参照spring最新开源的Spring Authorization Server，作为server提供token签发，认证，注销，刷新等端点和scope授权，客户端注册等功能，在sureness的基础上设计开发一款简易的oauth2 server。

特性代码能以PR的形式合入仓库
一款简易的oauth2 server

对开源抱有热情和强烈兴趣
熟悉Java语言
了解sureness或spring security或spring oauth2 server"
"ROW(Read Over Write)是一个开源的Linux IO调度器（未进内核主线），主要用于注重用户体验的移动设备上。请考虑在OpenEuler内核上实现一个类ROW的调度器，针对读写混合场景赋予读/同步IO更高的优先级下发IO请求，提升读/同步IO的性能。由于当前内核已经支持BLK-MQ（多队列）可以考虑基于MQ框架实现调度器接口功能(包括请求入队、下发、完成处理等)，当前可以仅考虑读、同步写、普通写3种IO场景，参考ROW队列或自定义各IO队列的优先级。

（1）代码需要模块的宏隔离，减少侵入式修改影响
（2）代码提交到openEuler开源社区
（3）提供对应的文档说明设计思路，测试数据（FIO等benchmark与其他调度器的性能对比数据)

1、熟悉Linux存储栈（fs/block层)
2、理解IO调度原理、ROW/MQ等IO调度器"
"DolphinScheduler支持各种各样的作业，比如Python、Shell等，其中一个很基础的功能就是收集这些作业创建的Yarn Job的application id。现在的实现方式是用一个正则表达式从作业的日志中解析，但这并不是一个完美的实现方式，本课题的任务就是用一种新的方式去自动收集、报错Yarn Job的application id信息，当然了，必须对用户透明，即对用户创建的作业无侵入。

自动收集、报错Yarn Job的application id信息
必须对用户透明，即对用户创建的作业无侵入

熟悉 Java, Yarn, Hive, Spark SQL, AOP"
"RVV规范批准后，发布了RVV的软件仿真框架和RTL设计。鉴于RVV设计的复杂性及其配置的组合，开发人员和用户都需要一个黄金测试套件来验证各自RVV实现和仿真的正确性。因此，RIOS实验室介绍了该项目，并为RISC-V基金会做出了贡献。在本项目中，您将设计一个RVV测试生成器，以帮助验证RISC-V矢量处理器的模拟器或ASIC设计的功能。

您在该项目中的贡献最终将被纳入RISC-V国际基金会的官方RISC-V知识库

该项目分两个阶段。

在第一阶段，我们将为RVV编写恒定测试套件生成器，该生成器在给定固定RVV配置的情况下自动生成相同的测试流。这将有助于调试并确保开发人员所需的再现性。

在第2阶段，我们将扩展测试生成器以生成随机向量测试，以覆盖RVV设计的转角情况。

学习目标：

1.RVV指令集架构

2.向量处理器是如何工作的？

3.RVV的正式验证

4、测试生成和验证模型

5、高级随机测试生成框架设计

一个功能齐全的RVV测试生成器，可以连接RISCOF测试基础设施。

产生随机RVV测试流的随机测试生成器，应可配置。

生成的测试应符合RVV标准的覆盖点

应验证生成测试的正确性，并通过Sail/Spike测试。"
"背景：MegEngine 作为训推一体框架，其在 Arm 上的推理性能也非常重要，目前 MegEngine Arm 推理性能经过 benchmark 在业界处于第一梯队，主要优化方式是在Arm上支持 NC4HW4的layout，Layout 的详细解释见：知乎回答（https://www.zhihu.com/question/337513515 ），目前反卷积 Forward 算子中没有支持这种 Layout 形式优化，希望通过支持这种 Layout 达到优化性能的目的。

需求：在 ArmCommon 中 ConvolutionBackwardDataImpl 中支持 NC4HW4 layout 的计算，使得 ConvolutionBackwardDataImpl 可以在 NC4HW4 的 layout 下完成计算，并且性能不差于目前的 NCHW layout。

代码规范
相同 shape 下，性能超过目前 nchw

反卷积计算原理
Arm neon 优化"
"secGear是华为自主研发的机密计算框架，通过将计算隔离到基于硬件的受信任执行环境以保护运行态数据，并且将不同处理器架构的机密计算方案的差异在软件层面抹平。secGear在Base Layer、Middleware Layer、Service Layer三层分别实现了统一的接口，开发者只需调用这些接口即可使用机密计算相关功能。国家商用密码是国家商用密码管理办公室指定的一系列的密码标准，即已经被国家密码局认定的国产密码算法，旨在保障金融，医疗等领域的信息传输安全。目前，国内在大力推广国密算法，因此本项目要求基于secGear实现SM2数字签名算法、SM4分组密码算法、SM9标识加密算法和ZUC祖冲之密码算法四种国密算法。

1、基于secGear实现SM2数字签名算法；
2、基于secGear实现SM4分组密码算法；
3、基于secGear实现SM9标识加密算法；
4、基于secGear实现ZUC祖冲之密码算法；

1、熟悉掌握Linux命令及应用程序部署流程
2、对机密计算具有一定认识
3、熟悉掌握secGear框架的开发流程
4、熟悉掌握C、C++等编程语言
5、熟悉 Git 等代码版本管理工具
6、基于可选框架的后端开发"
"OpenSumi 为 IDE 的底层框架，不仅提供了可以运行远程容器的 Cloud IDE 版本，也提供了本地桌面版，甚至还提供了无需后端容器，直接将 IDE 运行在纯浏览器的 Lite 版本。本题目会基于 OpenSumi Lite 版本，实现一个对接 Github OpenAPI 的 Code Review 模块，支持在 IDE 模式下来对 Github 的仓库进行代码评审。

将 CodeReview 及代码服务抽象为模块，并且和 Github 对接，最终在 opensumi.com 集成该包含评审代码功能的 IDE Lite 组件
详细的功能集成及使用文档

学习 OpenSumi 框架机制
学习 Github API 文档
熟练掌握 NodeJS
具备一定的 TypeScript 及 React 编码能力"
"CernVM-FS 是欧洲核子中心研发的基于 HTTP 的只读文件系统，它优秀的缓存性能令它成为软件分发的优秀载体，被大科学仪器如江门中微子实验等采用。CernVM-FS 的官方创建了 Debian 软件包，但是不符合 Debian 社区的官方标准。你的任务是制作符合 Debian 官方标准的 CernVM-FS 软件包，包括服务端和客户端，方便在 Debian 系统上快速部署科学软件。

完成符合 Debian 要求的 CernVM-FS 包，并被 Debian 官方采纳。

有一年以上 Debian 使用经验；
熟练使用 Git；
了解 Debian 包管理器原理。"
"Redis支持使用monitor命令来监听对数据的操作，但是目前monitor功能比较基础，只能够监听所有的数据操作，无法支持对指定IP、命令、key等级别的过滤。同时由于Redis单worker的设计方式，monitor命令监听所有命令对性能有很大损耗，在功能和性能上都不能完全满足用户需求。该题目旨在对monitor命令进行较高维度的扩展，结合Redis ACL功能，实现对ip/user/command/command category/key/pattern等过滤，使得monitor filter能够满足用户丰富的审计需求。

实现monitor filter功能，能够对指定ip/user/command/command category/key/pattern等条件过滤

熟练掌握C语言，对Redis有一定的了解"
"Buddy Compiler 是一个领域特定编译器基础设施，其中中间表示（IR, Intermediate Representation）层级需要领域特定的多层编译抽象支持。我们在技术路线上拥抱MLIR生态（MLIR是多层中间表示的编译基础设施）。本项目致力于为 Buddy Compiler 提供通用矩阵乘法算子的设计与实现。项目需要在Buddy Compiler 工具链中使用特定算法实现向量化的通用矩阵乘法和卷积优化Pass，并完成性能评估。

通用矩阵乘法优化Pass
卷积优化Pass
性能评估
（探索）将MLIR向量优化集成到现有深度学习推理框架中的方法

基础的 MLIR 背景知识
基本的向量化经验
熟练使用C++
了解矩阵乘法和卷积的优化方法
基础的 LLVM 中端开发经验/了解"
"本项目期望通过 Telegraf 收集系统的指标，比如 CPU 使用率、内存使用率和系统负载，上报数据到 SkyWalking OAP，并且配置在 UI 中展示。通过该项目你能够深入了解 SkyWalking 的 Receiver 插件开发。

在 Apache SkyWalking 中实现 Telegraf receiver 插件

较强的自主学习能力，有一定编程基础，愿意学习 Java 语言"
"OpenChaos 框架借鉴了混沌工程的理念，通过建立预期模型和模拟各种故障模拟，检测分布式基础设施在故障下是否仍然符合预期的检测指标，建立分布式基础设施承受生产环境中湍流条件能力的信心。本题主要内容是将 OpenChaos 对接 RabbitMQ与Elasticsearch ，支持在对其测试中注入故障的能力。
学习 Openmessaging OpenChaos 知识，了解 OpenChaos 原理、使用方式、参数含义等。
实现 OpenChaos 的 RabbitMQ/Elasticsearch  Driver，支持对 RabbitMQ/Elasticsearch  进行故障注入与特有分析模型。

driver 设计文档
实现rabbit 故障模型和分析模型，添加事务模型
实现ElasticSearch 故障模型和分析模型，实现查准与查全分析模型
代码覆盖率不低于85百分

单元测试用例不低于80%
能够通过图表进行结果展示"
"Vineyard是一个针对大数据分析工作流设计的内存数据管理引擎，管理着分布式在多个节点的分布式数据集（矩阵、表、图等），实现了跨计算引擎的零拷贝共享。在一些实际案例中，整个工作流涉及到的数据量可能会超过集群机器物理内存的大小，同时一部分数据并不是总是被用到，可以被交换到磁盘中（或者诸如OSS、S3这样的远程对象存储中），来暂时释放被占用的内存，并且这些数据在之后被用到的时候可以从磁盘（或远程对象存储）中重新加载回来。这样的机制成为“Spill”。

在这个任务中，候选人负责在Vineyard中实现如上描述的Spill的机制。候选人需要与mentor一起协作设计一个算法，来选择一些合适的Object作为Spill的对象，举个例子，Spill是不能将此时上层应用程序正在使用的数据也从内存中驱逐。基于如上描述的Spill机制的实现，候选人需要进一步在Vineyard中实现Checkpoint机制，Checkpoint会将某一个时刻整个Vineyard中的所有对象都导出到磁盘或者远程存储，这些导出的结果能够在之后被用来恢复Vineyard的状态。Checkpoint机制也是实现系统容错的基础之一。

在Vineyard中实现Spill的支持，需要支持Spill到本地盘，并且设计一个一致的、可扩展的接口，来支持Spill到本地盘或者远程对象存储
复用实现Spill过程中的一些功能，实现对Checkpoint的支持

候选人需要熟悉C++编程
候选人最好有一些关于分布式计算相关的经验"
"视觉小说是一种电子游戏，是有声读物的衍生产品。它通常以文字为主，辅助以图像与语音。游戏流程呈树状，并根据玩家的选项不同有着不同的路线。这样的游戏创作比较复杂，有一定的门槛。本项目希望以新兴的编程语言 Rust 为主，从头开发一个高扩展性的、创作友好的视觉小说引擎。

跨平台：至少支持 Windows、Linux、MacOS 桌面平台；
一个良好定义的、创作友好的视觉小说描述格式（例如 JSON 或者 YAML），要求该格式可以使用一般的文本编辑器编辑，如 VSCode；
一个嵌入在视觉小说中的脚本语言及引擎，可以是现有脚本语言或者自创语言；
基础的国际化（i18n）支持，至少提供简单的切换文本语言的功能；
一个基于 WebAssembly 的扩展系统，扩展应该能被脚本语言使用；
一个基于命令行的视觉小说前端；
一个 GUI 的图形化视觉小说前端。

Rust 开发；
编译原理；
WebAssembly 开发；
跨平台 GUI 相关技术，可以是 Qt 或者网页前端技术。"
"RDMA是常用于超算中心和高端存储领域的高性能网络协议，RDMA在内核的驱动主要包括两部分，一部分是对接用户态Verbs编程接口，另一部分是对接RDMA硬件设备。本项目要求用Rust实现RDMA内核驱动，需要包括上述两部分功能。

1、用Rust实现RDMA的内核驱动里跟上层用户态Verbs API接口对接的模块；
2、用Rust实现RDMA的内核驱动里跟RDMA硬件适配的模块。

1、熟悉Rust编程语言；
2、熟悉Rust在Linux内核编程Rust for Linux；
3、熟悉RDMA协议栈；
4、熟悉RDMA的Verbs编程接口。"
"毕昇Fortran编译器是一款基于classic flang的高性能Fortran编译器，支持Fortran编程语言的编译和运行，提供强大的数值计算和数据处理能力，在科学计算领域应用前景广阔。str_copy是一个实现字符串拷贝功能的动态库函数，本项目是对该动态库函数进行内联，预期提高编译器字符串拷贝的性能。

1、以patch的方法提交代码，实现str_copy内联。
2、场景有性能提升。

1、掌握C语言。
2、了解汇编的同学优先"
"昇思MindSpore CPU正向算子开发 + C++ infer函数实现: ParallelConcat
在第一维中连接张量, 将输入张量与第一个维度一起连接。
Concat 和 ParallelConcat 之间的区别在于，Concat 要求在操作开始之前计算所有输入，但不要求在图形构建期间知道输入形状。并行 concat 将在输入可用时将其复制到输出中，在某些情况下，这可以提供性能优势。

输入：
values (tuple, list) - 一个元组或输入张量的列表。这些张量的数据类型和形状必须相同。数据类型为数字，但 float64 除外。
输出：
张量，数据类型与值相同。

1.算子功能符合要求、能力对齐标杆 2.代码满足社区规范、精度、性能等达到标准 3.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"Project C CPU 调度器对Linux LTS 5.10 分支的支持。

移植最新的Project C CPU Scheduler实现到linux-5.10.y-prjc-lts分支

提交应该符合社区现有的代码风格/格式
提交应该通过必要的测试"
"JuliaImages 是 Julia 下进行图像处理的一个标准生态。目前存在 QRCode.jl 用于二维码的编码将用户数据以二维码格式导出，需要再添加二维码的解码支持从而允许用户导入来自外部世界的二维码。

本项目将使用 Julia 语言重新实现一个二维码解码器，包括但不限于：

- 实现模拟场景下的二维码解码支持，即：没有过多信息损失的，容易定位的二维码图片
- 实现复杂场景下的二维码图片的提取和解码支持，即：一般光照和弱光照环境下手机拍摄的照片

二维码解码器支持
编码器输出结果的解码支持
编码器输出结果加上一定噪声和信息损失的解码支持
编码器输出结果加上一定旋转和变换后的解码支持
拍摄条件良好的真实场景图片的二维码定位和配准
拍摄条件一般的真实场景图片的二维码定位和配准

熟悉 Julia 语言
了解编码和解码的一般理论
了解图像处理的基本手段"
"SkyWalking Infra E2E 是下一代端到端测试框架，开发者无需编程，只需编写一个 YAML 文件即可实现设置、调试和验证 E2E 测试。但是目前的测试用例验证模块在执行验证操作和输出结果方面还比较粗糙，因此需要进行一些优化，帮助用户更好地使用该工具。具体而言，执行验证操作方面，目前是串行执行测试用例，且若一个用例失败就不会继续执行；在输出结果方面，在执行测试用例过程会产生大量的输出，且缺少对验证结果概括性的输出，对用户不够友好。

支持非 fail-fast 方式执行测试用例
支持并发执行测试用例
优化验证过程的输出，包括合并重试信息、以简洁清晰的方式输出验证结果
1 和 2 功能对应的使用文档

较强的自主学习能力，有一定编程基础，愿意学习 Go 语言"
"Sentinel 是阿里巴巴开源的，面向云原生、分布式服务架构的高可用治理组件，主要以流量为切入点，从限流、流量整形、熔断降级、系统自适应保护、热点防护等多个维度来帮助开发者保障微服务的稳定性，目前已有 Go/Java/C++/Rust 原生版本。当前 Sentinel 正在朝着 2.0 云原生智能化的方向演进，其中一个重要的部分就是 云原生服务自愈决策中心组件 (Cluster Policy Brain)。Brain 设计可以针对任意流量稳定性的场景做一些控制的策略，这里面包括但不限于：分布式流控、访问控制、流量清洗、服务权重调整/调度等。

Brain 期望基于 Sentinel Go 实现，作为弱中心化的独立云原生组件，对外提供分布式流控、并发控制、自适应过载保护等服务自愈能力。Sentinel Go SDK 配合 brain 来做实例级别和集群级别的策略控制，其中一些策略控制（如 Sentinel 现有的单机流控、熔断）等还是在 SDK 侧进行判断，但是策略由 brain 自动生成（或经传统 rule CRD 手动配置）。Cluster Policy Brain 需要贴近云原生生态，支持声明式的配置，同时提供统一的标准接口对外透出 gRPC endpoint 提供服务。

基于 gRPC 抽出 Sentinel 标准策略接口及通信层实现，以便 SDK 与 brain 进行通信与策略判断
设计 Sentinel 标准策略接口，给定 policy descriptor（如接口名、参数、调用上下文信息），返回相应的策略（如请求正常通过，拒绝部分比例等）
结合 gRPC-go 实现 Sentinel 策略接口的通信层，供 brain 及 Sentinel Go 使用，建议采用 bidirectional streaming RPC 模型
Sentinel Brain 项目搭建骨架，并开发基础的分布式流控、并发控制能力，基于上述标准接口对外提供服务，可独立运行
Sentinel Go SDK 适配 brain gRPC service，并适配 Sentinel 规则 CRD
提供通用的 Kubernetes workload 部署指南

熟悉 Go 语言，对分布式系统、微服务、云原生相关技术有一定了解和实践；熟悉 Kubernetes, gRPC, Istio 等技术为佳"
"Milvus 是一个世界级的分布式向量数据库。我们希望通过引入 WebAssembly 将 UDF 添加到 Milvus 来进一步丰富它。
该项目分为两部分：1）实现一个UDF框架，支持创建和删除function utility，并且支持运行web assembly。2）植入一些UDF触发点并实现一个关于UDF如何工作的小demo。

一个完整的 UDF 框架
一个针对此框架的demo

GoWasmer 或其他用于 Go 的 Web 程序集运行时
强烈建议了解其他数据库如何实现 UDF"
"目前，sofa tracer依赖于开放式跟踪版本0.22.0。这个版本已经过时很长时间了，我们需要更新到官方推荐的稳定版本。此外，我们需要提供一个API层来适应Opent电测法

1、 升级opentracing版本至release-0.33.0

2、 适配https://opentelemetry.io/docs/migration/opentracing/

3、 提供集成文档和指南

测试用例和快速入门指南

集成文档

java"
"libvirt是一套用于管理硬件虚拟化的开源API、守护进程与管理工具。此套组可用于管理KVM、Xen、VMware ESXi、QEMU及其他虚拟化技术。openEuler操作系统当前使用的是libvirt 6.2.0版本，希望能够引入libvirt 8.2.0版本，能够兼容openEuler的接口。

1、构建成功libvirt-8.2.0 rpm包，基本功能正常
2、回合openEuler libvirt-6.2.0版本社区补丁

1、掌握C编程语言
2、熟练使用Linux
3、对虚拟化有一定了解"
"Dragonfly 项目中，基于机器学习针对不同场景寻找最优节点打分规则，为待调度节点寻找最优父节点。对当前场景所遇到的调度问题带来的下载瓶颈进行数据收集、数据分析、建模、算法调研、监控及优化。构建面向下一代的更加智能的 P2P 调度算法。

完整参与 P2P 节点调度算法实现，并在现有场景下比现阶段基于规则调度算法，提高 P2P 网络内各节点下载效率、利用率以及稳定性。

学习基于 P2P 的文件分发协议 学习机器学习调度算法"
"Nacos支持实时感知K8S的服务上下线信息，并获取其服务元数据，并将这些信息同步到Nacos的CMDB模块。最终效果为，用户通过Nacos标签查询接口指定标签条件，即可查询到满足要求的实例列表。

Nacos实时感知K8S服务上下线信息，并同步到Nacos的服务发现模块；
Nacos实时感知K8S的Endpoint上下线信息，并同步到Nacos的实例模型中；
Nacos在实例同步时，支持将预配置的指定标签元数据同步到Nacos的CMDB模块。

熟悉Java
熟悉Nacos优先
有K8S运维经验者优先"
"多机器人系统已经成为机器人技术行业的发展趋势,多机器人系统比单个机器人具有更好的鲁棒性,有着更广阔的应用空间，计算机仿真通过模拟多机器人系统在环境中完成任务的过程,从而验证多机器人协调与控制的正确性与有效性。
基于Gazebo添加一个开源的园区模型，在里面添加多款机器人进行协作完成整个园区的巡检任务。
1.机器人类型：无人机、轮式机器人、多足机器人等；
2.仿真器：gazebo；
3.协作呈现不限于巡检场景。

所有代码符合开源标准
支持机器人类型不少于2种
基于gazebo, 机器人之间是通过协作完成的任务

ros
gazebo
python、shell"
"Duo 是一个为 Rust 应用提供 logging 和 tracing 两种能力的简单易用的可观测性方案。传统的可观测性方案功能强大（比如 ELK，jaegertracing 等），但是部署和维护异常复杂，duo 的定位是提供相对较少但足够完善的可观测性功能，但是部署和运维异常简单。不过目前 duo 的数据全部是存储在内存中，程序退出后数据全部都会丢失。这个项目就是为了给 duo 增加数据持久化的能力。考虑到 duo 的定位是简单易用，我们的持久化方案暂时不考虑数据库之类的方案，而是借鉴 Redis 成熟且久经考验的 RDB 和 AOF 方案。此次任务需要实现任意一种类似 Redis 的 snapshots 或 append-only files 的持久化方案。

有一个可以跑通的 duo 数据持久化的 demo，并且 demo 能够很好工作

熟悉 Rust 编程语言，了解 async/await, tokio, tracing 等异步编程知识
熟悉 Redis RDB 和 AOF 两种持久化方案"
"在交互式查询引擎中，对于带有过滤条件的查询，计算会从存储中读取数据后进行过滤。由于目前我们采用的是 share-nothing 架构，计算和存储在同个进程，所以这种方式不会引入性能问题。但是后面我们计划向计算存储分离的架构演进，这样就需要把过滤条件下推到存储，从而减少数据计算和存储之间的数据交互。

存储支持带有过滤条件的查询 (包括行过滤和列过滤)
使用带有过滤条件的存储接口重新实现现有计算逻辑

会使用 Rust 语言"
"Apollo ConfigService 数据库里的 Release 表随着配置发布次数增加，Release 表所占空间会越来越大，直至超出限制的最大值，除此之外，还会降低 Release 表的 IO 响应时间。实际上 Release 表中，历史比较久远的数据，是可以被清理掉的。
期望封装一些 api，让用户可以通过 api 来手动清理 Release 表；
在 api 的基础之上，在 Portal 模块添加管理界面，支持用户通过界面来查看 Release 表的指标，并进行手动清理；
在 api 的基础之上，在 Portal 模块添加管理界面，支持用户配置 Release 表的清理策略，如只保留最近 1 年的记录，或者只保留最近 100 次的记录等等。

1. 实现一个用户友好的管理界面（管理员权限），支持配置 Release 表的清理策略，用户也可以在界面上进行手动清理
2. 完善的单元测试
3. 设计文档和使用文档

熟悉 Java 开发语言、熟悉 Spring Boot 、熟悉Spring Data JPA和MySQL、对微服务体系有一定了解，如RPC、有前端开发经验，如 Html、Angular JS 等"
"为了采集openEuler官网的用户行为数据，以便后续进行数据分析，构建一个SDK工具包，并集成到openEuler官网，通过调用SDK提供的接口采集数据并上报到指定服务端。

1、设计并实现数据埋点方案，输出SDK
2、支持自定义埋点
3、完成SDK的接口文档

1、熟练使用JavaScript,Go,Python等一种或多种编程语言
2、熟悉数据埋点的设计思路
3、熟悉从前端埋点到数据上报的全流程"
"飞桨支持GPU多stream、多线程数据并发加速方法，目前仅支持ImageNet图像分类数据集任务，扩展新的数据格式需要实现对应的数据集读取、数据集解码OP。计算机视觉任务中，一个视频往往包含上百帧的图像，因此视频模型的数据读取、预处理计算量很大，视频模型对数据预处理并发加速的需求也很高，本任务基于飞桨已有的GPU多stream、多线程DataLoader扩展视频分类模型TSN的数据读取、预处理任务

PaddleVideo是飞桨官方出品的视频模型开发套件，旨在帮助开发者更好的进行视频领域的学术研究和产业实践。

1. 参考PaddleVideo中实现的TSN DALI loader，实现基于飞桨GPU DataLoader的TSN数据预处理
2. TSN模型训练端到端速度不低于使用DALI loader的90%

1. 熟悉C++、Python
2. 熟悉CUDA编程
3. 熟悉多线程编程"
"卷积网络常用于分析二维和三维形状的时空数据，由于许多数据源本身是稀疏的，如果对这种稀疏数据采用稠密的卷积计算来实现卷积网络，那么该卷积网络的性能会很低效，因此我们需要实现稀疏的卷积计算算子来处理稀疏数据。PaddlePaddle目前已经实现了三维的稀疏卷积，我们期望开发者可以开发稀疏的Conv2D以支持二维的卷积计算，并对Conv2D进行极致的性能优化。

飞桨PaddlePaddle：以百度多年的深度学习技术研究和业务应用为基础，是中国首个自主研发、功能完备、 开源开放的产业级深度学习平台，集深度学习核心训练和推理框架、基础模型库、端到端开发套件和丰富的工具组件于一体。

1. 性能优于当前版本，并至少优于一个其他深度学习框架
2. 代码合入github/PaddlePaddle/Paddle/develop
3. 对已有的模型进行精度和性能验证

1. 熟悉 C++
2. 熟悉 CUDA
3. 熟悉 Python"
"目前，开发者若想让Hypercrx在GitHub页面中一个新的位置上添加一个新图表，Ta需要：实现图表组件，在视图中引入图表组件，分析GitHub页面的DOM结构后在锚点处注入视图。观察已有的文件和代码，发现这3步常常杂糅在一起，欠缺一致性，这对后续的维护和开发都是不友好的。因此，我们希望你能设计一套机制来解决这个问题，并在机制设计完成后，利用该机制重构已有文件结构和代码。

任务1。设计“锚点-视图-组件”机制（Anchor-View-Component机制），使图表组件的开发和维护更加友好。

任务2。根据设计好的AVC机制，重构已有文件和代码。

2个任务的具体要求之后会在相应的issue中给出。另外，当Summer2022开发阶段开始后，为了更好地了解中选者的项目进度，我们希望你能在指定issue中，以每两周一次的频率更新你的进展。

最后，欢迎前往项目仓库的Discussions栏与我们交流！

AVC机制及相应文档（以仓库Wiki的形式）
用AVC机制重构已有文件结构和代码

了解Chrome Extension的开发方式
熟悉Hypercrx的工作机制
熟悉TypeScript
熟悉Git和GitHub"
"近一年来，Apache APISIX 新增了多个插件，目前已支持 70+ 插件。在 apisix.apache.org 增加了文档站的支持后，由于文档整体数量较多，在内容质量的呈现方面却有些滞后。之前中文文档的内容编写者众多且风格不统一，部分内容也会出现细节性的错误等，所以目前 APISIX 中文技术文档的内容上依然有很大的优化空间，我们希望在文档可读性和内容准确性上呈现出更好的一面。

该项目主要是对目前 Apache APISIX 官网文档最新版本的中文内容进行调整，涉及 Plugins 插件内容下 Security 和 Traffic 两个模块中的内容（共计 19 篇；如有项目优先级调整，则更换为同插件目录下 Obeservability 模块内容，共计 21 篇）。

文字量上翻译成中文篇幅短的预计不到 1000 字/篇，篇幅长的大概在 2000-3000 字/篇左右。算上预热期在内，4 个月完成 20 篇文档，大概每周可进行一篇文档的调整与输出，在时间上对于学生来说还算比较宽裕。

阅读并熟悉 APISIX 英文技术文档后，对中文技术文档的内容产出有一定思路。完成目前中文技术文档的内容重构与优化，保证内容符合社区写作标准且格式统一，内容通俗易懂同时对 APISIX 项目初学者友好，最重要是保证内容的准确性。最终发布至 Apache APISIX 官方文档站供开源爱好者参考使用。

熟练使用 Markdown、Git 与各类编辑器和 GitHub 网站。
需要了解 APISIX 项目是什么、有用什么用、使用这些插件可以完成哪些场景等。"
"在云原生场景中，为了便于对微服务进行流量治理，常常将与网络流量相关的认证、鉴权、服务发现、服务治理等相关功能封装为sidecar模式进行实施，以便全面接管微服务应用的上下行网络请求流量。但由于引进了新的组件，不可避免地造成了性能上的损失，特别是在 RPS 极高的情况下，sidecar 的性能指标甚至会成为限制微服务的重要瓶颈。
由于先前所述的原因，在应用中需要维持 sidecar 的轻量化，很难在其内部进行数据抓取和暴露，所以通过高效的 eBPF 手段在内核态进行全面监测必将是最优的选择。因此，本题目将基于 sidecar 模式下的业务调用逻辑和网络通信规律，基于 eBPF 实现 sidecar 和业务容器之间网络栈调用关系；并在此基础上实现 CPU、内存等热点资源消耗情况的数据采集和展示，所有功能需要对接到社区项目LMP中。

完整项目代码一份
详细的中文文档
对接到Linux内核之旅社区项目LMP（Linux显微镜）中

了解 eBPF 技术
了解 Linux 内核网络协议栈
了解 k8s
有一定的 C、golang 编程能力"
"通过开发者技能描述或者经验描述信息中，提取到关键的技术能力，形成用户的技能标签；在实际应用中可以对课题或者问题做针对推荐。技能关键词包括编程语言类，领域类，技术框架类等

1、可以选择性使用无监督学习（TF-IDF,TextRank,LDA主题模型等），有监督学习（关键词分类器等）等方法进行实现对比，选择最优的方案。
2、工具库自行选择，需要支持中英双语。
3、词典支持添加新词，例如：图像处理，机器学习，操作系统内核
4、支持自定义技能关键词

1、输出开发者技能标签（包括自定义技能关键词），准确率达到95%
2、输出多个方案的结果对比

熟悉NLP相关知识，了解常用的NLP库
熟练使用python3编写代码"
"当前 Apollo 支持 properties 格式的比对功能，可以比对不同环境、不同集群的两个 Namespace 的差异。通过这种方式用户可以直观的查看配置环境间的差异。但是目前还不支持文本类型的 Namespace 比对能力，例如：yml、xml、json 格式的。所以期望支持其它文件类型格式的比对功能。

1. 对非 properties 格式的 namespace 支持文本比较功能，高亮显示不一致的行
2. 完善的单元测试
3. 设计文档和使用文档

熟悉 Java 开发语言、熟悉 Spring Boot 、熟悉Spring Data JPA和MySQL、对微服务体系有一定了解，如RPC、有前端开发经验，如 Html、Angular JS 等"
"openEuler官网搜索优化
openEuler社区官网:https://openeuler.org的搜索模块，虽然可以根据关键字搜索，但是当前搜索命中率不高，也不能根据用户喜好进行精准搜索。并且数据量过大，可能会出现检索困难的情况。
请根据实际情况，对现有的搜索服务进行优化(建议使用记录搜索行为，优化搜索的方式)

1、搜索命中率达到80%以上
2、可以根据词组进行搜索，也可以根据词组中的某个文字进行搜索
3、支持根据搜索喜好进行优先级排序
4、支持搜索服务自学习并自动持续优化搜索排序
5、支持使用拼音搜索中文
6、对现有的openEuler搜索服务进行优化，设计并实现优化代码，并提交代码到openEuler仓库

1、熟悉java, springboot ,elasticsearch
2、熟悉网站埋码，用户画像。
3、熟悉搜索引擎技术、搜索引擎算法"
"Code Review 是软件研发协作中的重要一环，大家在代码提交后都需要等待 Reviewer 的 Review；同时当Reviewer 提交了“修改建议”后，PR/MR 的提交者还需要根据“修改建议”相应更新自己的代码。在这个过程中可能代码提交者等了半天也没有人来 Review，或者 Reviewer 提交了“修改建议”后等了半天也没有看到提交者修改。所以各方及时收到“动作通知”，高效完成自己的“Review/Fix”工作是非常重要的。

开发一个 Code Review 机器人，通过 helm 部署，可以通过 API/Webhook 的方式获取 GitHub/GitLab 上的Pull-Request/Merge-Request 动态，然后分析当前 Code Review 是被谁阻塞了，进而将消息发送到飞书群中，艾特相应人员“及时处理”。

1.  多项目的支持：cr-bot 应该能配置多个项目；
2.  多飞书群支持：不同的项目开发人员可能在不同群组中；
3.  不考虑一个项目的开发人员分布在不同群里；
4.  支持对接 GitLab 和 GitHub 两种代码托管平台；
5.  默认支持将消息通知到飞书群，但是考虑好程序拓展性，方便以后对接“钉钉”等其他通讯工具；
6.  通知不是一次性的，如果“责任人”一直不响应，则可以持续通知，比如20分钟、1小时、5小时、1天等时间节点可以重复通知，且通知语气可以逐步强烈，甚至抄送给群管理员；
7.  GitHub/GitLab 上的账号和飞书中的账号对应关系可以通过配置文件方式传入；token 等配置可以通过环境变量方式传入。

一个通用的开源软件开发过程 Code Review 机器人程序
实现对 Code Review 流程中阻塞角色的周期性提醒能力
支持同时管理多个项目，多个开发群，实现群与项目的 1-N 映射
能够对接 GitLab 和 GitHub 两种代码托管平台
容器化部署，helm chart 包格式封装，能够通过 helm install 简单部署

一定的 Golang 开发能力，了解容器化，GitHub，GitLab，Code Review 协作流程等"
"用 ceph 实现 layotto 的 file API 组件，并通过 SOFABoot 调通。

首先熟悉layotto的架构设计，基于现在的file接口实现ceph文件系统（此处需要调研layotto的file组件的可移植性以及ceph文件系统，判断当前的layotto接口能否满足ceph文件系统）
通过sofaboot和layotto打通，可以通过sofaboot应用调通layotto的file接口。


对于ceph文件系统的实现，需要先调研当前ceph文件系统所具有的能力以及layotto当前的file接口能否满足需求。当前的file接口比较简单的，可能需要做拓展。同时要考虑文件系统的可移植性，即能满足不同文件系统之间的无感迁移。

对于sofaboot和layotto的打通，可以通过sofaboot工程调用layotto的接口，将sofaBoot的中间件能力下沉到layotto中去

CEPH文件系统的调研文档产出
调研一下CEPH文件系统和当前Layotto文件接口，产出两者适配的文档
实现ceph文件系统实现，代码合并到master分支
sofaboot调通layotto的接口，sofaboot工程使用layotto，实现文件操作

了解云原生运行时的概念
了解 java 和 go 语言"
"背景：PolarDB PostgreSQL中核心数据结构，运行期内存，以及数据库进程分布在不同的NUMA Node上，导致跨频繁的跨NUMA远程访问内存。

方案：对PostgreSQL核心数据结构架构升级，使得一个用户数据库进程的CPU和相关内存聚集到单个NUMA Node上，减少跨NUMA。

PolarDB PostgreSQL能够感知NUMA，提升数据库在众核下的并发性能

对C语言熟悉，了解CPU架构"
"为了构建基于openEuler的HPC应用生态，需要将目前广泛使用的开源HPC应用迁移到openEuler。OpenLB项目为lattice Boltzmann方法提供了一个c++的实现，该包足够通用，可以解决大量的传输问题，例如计算流体动力学。源代码是公开的，并以易于阅读的模块化方式构造。可以快速实现简单的学术测试问题和高级工程应用程序。它还可以很容易地扩展以包含新的物理实验。

1、OpenLB的X86和ARM配置文件创建并归档至hpcrunner社区templates目录
2、自动化脚本执行OpenLB用例，并输出用例执行结果，脚本上传test目录
3、《基于openEuler的OpenLB软件移植指南》、《基于openEuler的OpenLB软件测试报告》，报告覆盖规范性自检、功能性测试、性能、精度测试结果，以word形式存放到代码仓库的doc目录。
4、若适配过程中有patch文件或者第三方依赖安装包产生，请上传至porting或者package目录。

1.掌握HPC相关技术，如MPI使用、openmp使用；
2.掌握编译技术，如GCC使用、Clang使用、解决编译报错的能力；
3.掌握编程语言，Fortran、C/C++；
4.掌握Python语法、Shell语法。"
"Redis在主从全量复制阶段使用RDB文件来作为数据快照进行传输，但是生成RDB快照对Redis运行有较大影响，包括fork引起的latency spike、子进程生成RDB的时间、快照生成时间内replica-output-buffer的内存消耗，这些都会对Redis运行的稳定性产生不利因素。同时Redis支持AOF，也即将数据修改操作实时追加写入AOF文件，但是AOF文件目前没有在主从复制中使用。该题目旨在利用Redis的AOF文件来进行主从全量复制的优化，充分发挥AOF文件的特征和作用，通过记录全量同步时的AOF文件偏移量，使其能够作为数据快照进行复制传输，避免生成RDB快照带来的影响。

实现基于AOF的主从全量复制功能

熟练掌握C语言，对Redis有一定的了解"
"软件供应链安全是要保证软件的安全，如何通过软件供应链来确保软件供应链安全，
就与软件物料清单（SBOM）有关。该需求是基于开源项目https://github.com/anchore/syft进行二次开发，
需要对openeuler系统相关版本的所有rpm包源码进行处理，并输出对应格式SBOM。

1、完成对 anchore/syft 开源项目的二次开发，能处理.rpm文件格式，并能像支持其他格式一样进行输 出；
2、能对openeuler系统相关版本的所有rpm包源码进行处理；
3、支持json、text、cyclonedx-json、spdx-json等多种格式，并把数据存储到数据库，方便后续处理。

1、掌握golang/Python编程语言；
2、熟练使用Linux；
3、熟练使用MySQL/MongoDB数据库；
4、基于openEuler系统开发；
5、对软件供应链安全有了解。"
"LibcarePlus是一个通用的用户态热补丁框架，它可以被用来对Linux可执行程序或者动态链接库打补丁，而不需要重启应用程序。本项目为libcareplus关键特性开发UT用例，以保证libcareplus的关键功能。

1、libcareplus关键特性有用例覆盖；
2、组件代码覆盖率达到80%及以上；

1、精通编译原理；
2、熟悉linux ELF文件结构；"
"dtm是一个支持多种事务模式，多语言，多存储引擎的分布式事务框架。mongo是一种流行的数据库存储，支持nosql、事务、大数据。dtm希望能够支持将全局事务进度存储到mongo，满足更多用户的需求。

支持将全局事务进度存储在mongo

熟悉Go
熟悉数据库事务"
"Milvus 是我们坚持“重新定义数据科学”愿景下，持续打造的先进的向量数据库。它为数据科学家们提供了更好的组织和管理数据的方式，以及丰富的数据管理纬度。
为了让 Milvus 用户更直观的理解和管理 Milvus 中的数据，我们希望为它增加一个简单的控制面板，能够更直观的展示和进行基础的数据管理操作。

为 Milvus 增加一个基础功能完备的工具界面，界面中包含程序关键信息，如：collection schema、segment allocation... 让用户能够在这个工具界面中完成相关的数据的管理操作。

前端基本功扎实，对于前端框架有一定的了解，熟悉基本的数据可视化方案。
（加分项）了解 Go 和 WebAssembly"
"本项目包含工作内容：

扩展DeepRec对模型格式类型的支持，当前DeepRec支持导出模型为checkpoint，但不同用户存在着若干其他格式的需求，比如导出为LevelDB、Redis、RocksDB可以加载的格式，此外支持可查看Variable参数的工具，包括查看EmbeddingVariable的某个特征值的查找。

支持导出LevelDB可加载文件， 完成LevelDB可以加载的导出格式 完成用户使用文档
支持导出Redis可加载文件，完成Redis可以加载的导出格式 完成用户使用文档
支持导出RocksDB可加载文件，完成RocksDB可以加载的导出格式 完成用户使用文档
完成文件查看工具，可查看Variable/EmbeddingVariable值，及具备基础的查看、搜索功能
项目技术要求

熟练掌握C++
熟练掌握Python
能够在导师的指导下熟悉并理解DeepRec相关的代码并完成开发
对搜索、推荐、广告领域有兴趣
对深度学习稀疏模型训练/预测引擎有兴趣"
"基于openEuler构建一站式大数据体验平台，至少包括Apache Kyuubi、Apache Spark、Apache Flink：
Apache Kyuubi是一个Serverless SQL的平台，可以对接Spark、Flink等大数据平台。
Apache Spark是一种多语言引擎，用于在单节点机器或集群上执行数据工程、数据科学和机器学习。
Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行状态计算。
通过构建大数据体验平台发现并完善openEuler在大数据场景的不足，打造基于openEuler的大数据开源解决方案的雏形。

1、完成基于openEuler构建大数据体验平台（至少包括Apache Kyuubi、Apache Spark、Apache Flink）。
引入基于openEuler的Kyuubi、Spark、Flink的容器镜像，Dockerfile提交至openEuler官方容器镜像仓，并完成x86/Arm架构的发布。
对不满足条件的操作系统软件包进行升级和添加，并上传至：https://gitee.com/src-openeuler
2、在Apache Kyuubi社区上线基于openEuler的大数据体验平台。
3、基于openEuler Mooc Studio上线大数据体验平台的课程，通过课程完成构建步骤的教学（例如安装依赖、一键部署、demo运行等）。

1、掌握java/scala编程语言。对Dockerfile熟悉的同学优先
2、熟练使用Linux。
3、对容器化有一定了解。使用（了解）过Spark、Flink、Kyuubi的同学优先。"
"基于泰晓科技 Linux 技术社区研发的 Cloud Lab 和 Linux Lab 开源开发环境，从 0 开始完成一款 RISC-V 产品的设计、开发和制作，开放全过程。

需要完成 RISC-V 的产品文档、原理图设计、PCB 设计、PCB 生产制造文件、3D 外壳设计和软件功能开发。

该项目旨在面向新兴的 RISC-V 处理器架构，完成并开放从硬件设计、系统开发到 3D 建模的全过程，整个过程尽量采用开源开发环境和工具，从而降低技术门槛和经济门槛，进而吸引更多的同学和工程师关注 RISC-V 生态。

RISC-V 产品文档
RISC-V 产品原理图设计
RISC-V 产品 PCB 设计与制造
RISC-V 产品 3D 外壳设计与制作
RISC-V 产品软件功能设计与开发

有项目文档编写经验，能熟练绘制硬件框图，软件流程图更佳
有 Linux 使用经验，熟悉 Linux Lab 更佳
电子专业、电子工程专业、物联网专业、有电子兴趣或爱好的学生
有 PCB 设计软件经验，熟悉 KiCad 更佳
有 CAD 设计软件经验，熟悉 FreeCAD 更佳
有 Linux 下 C/C++ 软件开发或 gcc 调试经验，有开源或参与 Linux 下软件开发更佳
有愿意学习的心，有学习的动力，能坚持下去学习。"
"openEuler Embedded主要面向嵌入式场景，当前没有基本的嵌入式图形协议栈，因此本项目的目标是依托openEuler社区和其他开源社区打通openEuler Embedded的嵌入式图形协议栈，并在QEMU或者树莓派4B上进行演示，建议图形协议栈的具体组成为（Wayland+QT)

1.openEuler Embedded中集成嵌入式图形协议栈, 建议Wayland+QT的组合
2.在QEMU或者树莓派4B上进行演示

1.基本熟悉Yocto框架
2.熟悉嵌入式图新协议栈（Wayland+QT)
3.熟悉嵌入式Linux开发"
"在实际生产环境中不断出现overlayfs没有真正卸掉的出现了诸如quota统计数据持续增长等问题。对于现网环境目前没有好的办法去界定该类情况。overlayfs在实际使用过程中是有很多限制但是并没有在代码层面直接做限制，所以在使用过程会出现操作错误引入的一些奇怪的问题，往往这类问题表露出来的现象是比较奇怪的，定位起来比较耗时。基于这样的背景overlayfs的维测功能需要增强。
初步构想：
在“/sys/fs/“目录下增加overlayfs的目录，目录下记录各个挂载点的挂载信息，只有overlayfs被真正卸载掉目录下对应的目录才会删除。

1.按照设计实现功能；
2.输出测试用例；

1.使用C语言编程；
2.熟悉overlayfs挂载和卸载流程；
3.熟悉kernelfs的实现；"
"StratoVirt当前还不支持vhost-user-blk磁盘，需要对接SPDK，支持vhost-user-blk磁盘

1、支持标准虚机配置vhost-user-blk磁盘启动，支持正常读写。

1、熟悉rust语言
2、熟悉虚拟化基本原理
3、熟悉SPDK"
"OpenID-Connect 是一套基于 OAuth2.0 协议的轻量级规范，OpenID-Connect 允许客户端基于授权服务器或身份提供商（IdP）进行的身份验证来验证最终用户的身份，并获得用户的相关信息。Apache APISIX Dashboard 支持以 OpenID-Connect 协议对接其他身份提供商，例如 Okta，Auth0 等平台，从而实现无需在控制面保存账号密码即可轻松登陆。

向 Apache APISIX Dashboard 提交支持 OpenID-Connect 协议功能的 PR，并在经过代码评审后合并进入主分支。
向 Apache APISIX Dashboard 提交OpenID-Connect 协议测试的 PR，完成对接其他平台的测试，并在经过代码评审后合并进入主分支。
向 Apache APISIX Dashboard 提交功能使用文档，并在评审和合并进入主干分支；

建议实现时采用小步快跑的模式，拆分若干个 PR 进行提交（小 PR 更易于评审，且效率更高）；
向 Apache APISIX Dashboard 提交 PR 时，需要附上完整的测试用例覆盖；"
"背景 
ShardingSphere Parser Engine 帮助用户将 SQL 语句解析为抽象语法树，并从语法树生成对应的 SQL Statement 对象。更多关于 Parser Engine 的介绍请参考：https://shardingsphere.apache.org/document/current/en/reference/sharding/parse/。 

任务 
具体任务列表如下： 
 ALTER INDEXTYPE doc 
 ALTER INMEMORY JOIN GROUP doc 
 ALTER JAVA doc 
 ALTER LIBRARY doc 
 ALTER LOCKDOWN PROFILE doc 
 ALTER MATERIALIZED VIEW doc 
 ALTER MATERIALIZED VIEW LOG doc 
 ALTER MATERIALIZED ZONEMAP doc 
 ALTER OPERATOR doc 
 ALTER OUTLINE doc 
 ALTER PACKAGE doc 
 ALTER PLUGGABLE DATABASE doc 
你可以从这里获得更多关于语法解析的参考。为了完成这个任务，你首先需要了解它为什么不支持？是因为 antlr4 语法解析异常，还是因为没有实现 visit 函数？你可以使用 antlr4 插件 去帮助你分析，你可能需要访问官方文档来检查语法。 
修复问题之后，记得添加 SQL 测试用例，并且把解析期望的结果写入 期望的 XML； 
运行 SQLParserParameterizedTest 和 UnsupportedSQLParserParameterizedTest 确保没有异常； 
此外，你可以参考一些示例，来辅助完成这个任务： 
Add Oracle SQL - CREATE DATABASE LINK 
Add Oracle SQL-DROP DATABASE LINK 
完成 SQL 解析优化之后，你需要测试在 ShardingSphere 读写分离场景下，该 SQL 是否能够正常执行，并且根据 SQL 的语句，将 SQL 路由至写库或读库。完成读写分离功能的测试后，需要在 ShardingSphere 集成测试 shardingsphere-integration-test 中添加对应场景的测试用例，更多关于集成测试的信息，可以参考：https://shardingsphere.apache.org/document/current/cn/reference/test/integration-test/。

能够对自己的代码进行测试，保证提交代码的正确性

1. 精通 java；2. 理解 Antlr4 语法；3. 熟悉 Oracle 数据库"
"项目描述
本项目以MatrixOne开源分布式HSTAP数据库以及开源流式分布式存储Pravega为核心搭建一套端到端的智慧园区数字化系统，包括视频采集、传输、模型推理、数据清洗、存储、分析及可视化等功能模块。在系统实现的基础上，同时为MatrixOne实现Blob数据类型，丰富MatrixOne支持的数据类型。
主要包含以下几大功能模块：

摄像头
持久化流存储Pravega
Pravega介绍：Pravega 为连续和无界数据提供了一种新的存储抽象—— 流（Stream），它是一种持久的、弹性的、仅追加的、无限制的字节序列，具有良好的性能和强一致性。
使用Pravega，可以摄取实时数据流进行分析。今天，实时流无处不在。来自手机、社交媒体流、视频、传感器、无人机等的数据都是连续且无限的（“实时流”）。
Pravega 的弹性架构可以实用于各类场景。它可以处理海量的实时数据，有助于从飞船发射中摄取数据；它可用于促进智慧城市中更有效的交通流，或将大型商业建筑项目与设计效果图进行比较以确保其准时和准确。
而这仅仅是开始， Pravega可用于任何行业，适用于任何涉及实时流数据的用例。
视频推理模块
高性能数据库MatrixOne
可视化WebUI

1. 完成项目的设计、开发和测试
2. 实现MatrixOne对Blob数据类型的支持
3. 端到端demo展示

1. 具备Golang/Python开发能力
2. 具备多目标检测算法能力
3. 熟练英文读写能力"
"目前RT-Thread支持BTSTACK, nimble等开源蓝牙协议栈，目前都是基于特定开发板和芯片，要求能够基于协议栈的host层，选择一款开源的蓝牙协议栈，建议nimble（也可以选择btstack等，其他的需要提前沟通）。 目前有一些软件包提供参考。可以跑在rt-smart上面，也可以跑在STM32上面，要尽可能的通用方便。
如果能够把上层mesh剥离出来单独软件包，更佳。

对于nimble蓝牙协议栈，要能适配大部分的RT-Thread上的bsp开发板，只要开发板支持UART，就要能够支持蓝牙协议栈搭配蓝牙control卡片
要求对接RT-Thread的驱动层，比如UART
达到能够在大部分平台上，通过menuconfig配置之后，接上串口蓝牙板就可以跑example。

蓝牙调试能力
蓝牙基本概念熟悉
蓝牙各种example的了解
对HCI层有一定了解"
"OpenFunction 是一个云原生的开源函数即服务（FaaS，Functions-as-a-Service）平台，旨在让用户专注于他们的业务逻辑，而不必担心底层运行环境和基础设施。用户只需要以函数的形式提交业务相关的源代码，即可将服务按需运行在集群中。

OpenFunction 0.6.0 的发布带来了许多值得关注的功能，包括函数插件、函数的分布式跟踪、控制自动缩放、HTTP 函数触发异步函数等。同时，异步运行时定义也被重构了。核心 API 也已经从 v1alpha1 升级到 v1beta1。

0.6.0 版本中有两个重要的功能是基于函数框架的支撑来完成的，它们分别是：
函数插件：在 OpenFunction 的函数 CRD 中，允许用户定义在主体（Main）函数运行前/后执行的插件（Plugin）函数，并在函数运行时依靠函数框架保障插件的运行及其运行关系。您可以参见此案例中的插件定义来初步了解。
函数可观测：第二项重要的功能是使用 SkyWalking 为 OpenFunction 提供可观测能力。类似的，这些功能也需要函数框架的支持来使得 SkyWalking 可以正确的构建函数关系和追踪链路。
目前 OpenFunction Go Function Framework 是完整支持上述两项功能的，我们期望在本项目中使得 Node.js Function Framework 也具备这两项能力。所以，本项目的目标：升级现有的 OpenFunction Node.js Function Framework（函数框架），使之对齐 OpenFunction 0.6.0 两大主体功能 —— 函数插件和可观测能力。

为 Node.js Function Framework 新增函数插件和可观测能力支持
为新增功能编写对应的测试用例、样例函数和使用说明
产出您关于 OpenFunction、Node.js Functions Framework 的认知与理解

Node.js
Kubernetes
OpenFunction
Cloud Native Buildpacks"
"在工业控制、机器人控制领域中越来越多使用Linux操作系统，但Linux系统在实时性方面天然不具备优势。为了改善Linux实时性，基于eBPF技术，研发出一个探针型的工具用于分析造成中断较高的原因，便于内核程序员对症下药。通过解决有限高延迟路径，从而达到让Linux在多种高负载场景下仍然能够长期保持可接受范围内的延迟。

1、探针工具对中断的关闭时长进行检测，精度需要达到纳秒级别
2、探针工具能够根据阈值参数进行数据过滤，输出结果只需包含关闭时长大于该阈值的数据，抓取内容包括使用该中断的进程相关信息，如调用栈、持有锁、文件、socket等敏感信息
3、通过调用栈、持有锁、文件、socket的关系，构成一幅进程（包含内核线程）关系图，以延迟时长作为图的权，并能实时显示最长加权路径。

1、可使用C/python语言
2、基于eBPF技术
3、CPU和内存开销尽可能小"
"CurveBS对接PFS时支持了单个卷的共享挂载，但是并没有限制各个挂载点的读写权限，需要支持读挂载和写挂载及读写权限转换。

支持挂载卷时指定读写权限（读写、只读）。
限制同一时刻只能有一个挂载点持有读写权限，其余挂载点只能进行只读操作。
支持读写权限的动态变更，在一个挂载点释放读写权限后，其余只读挂载点可以申请获取读写权限。

熟悉Curve代码中相关逻辑的处理流程，并根据需求进行修改，完成单元测试，合入Curve仓库。
熟悉C++软件开发，熟悉gtest等相关单元测试框架。
熟悉linux上的编译，调试命令，如gcc，gdb等。"
"mica-mqtt 是基于 java aio 网络框架 t-io 实现的低延迟、高性能的 mqtt client 组件和 mqtt broker 服务。

项目任务描述：
了解并熟悉 mqtt 协议，需要了解 mqtt 共享订阅使用场景和原理。
为 mica-mqtt 服务端实现共享订阅。
共享订阅有两种方式：
(1)共享订阅：订阅前缀 $queue/
多个客户端订阅了$queue/topic，发布者发布到topic，则只有一个客户端会接收到消息。
(2)分组订阅：订阅前缀$share/<group>/
多组客户端订阅了$queue/group1/topic、$queue/group2/topic...，发布者发布到topic，则消息会发布到每个group中，但是每个group中只有一个客户端会接收到消息。

为 mica-mqtt 实现服务端共享订阅
输出相关使用和配置文档

熟悉 mqtt 协议
了解 mqtt 共享订阅的使用场景
熟悉 mica-mqtt"
"利用内核ebpf机制，实现通过ebpf修改寄存器的接口并给出demo，后续基于该工作，可以进一步通过ebpf实施内核故障注入方案。

1、参考bpf_override_return接口(位于kernel/trace/bpf_trace.c)，编写用于修改其他寄存器的ebpf helper接口
2、编写使用该接口的demo程序，用于修改函数调用的入参寄存器
3、代码合入指定仓库指定分支
4、提供测试报告，确定测试符合预期

1、熟悉linux内核ebpf机制
2、熟悉arm或x86函数调用ABI
3、遵守linux代码规范"
"图像风格迁移的目标是在保持原始内容的同时，通过风格参考来渲染具有艺术特征的图像。与用于其他视觉任务的视觉Transformer相比，我们的 StyTr^2 包含两个不同的Transfomrer编码器，分别为内容和风格生成特定于域的序列。在编码器之后，采用多层Transformer解码器根据样式序列对内容序列进行风格化。此外，我们分析了现有位置编码方法的不足，提出了尺度不变且更适合图像风格迁移任务的内容感知位置编码（CAPE）。与最先进的基于 CNN 和基于flow的方法相比，定性和定量实验证明了所提出的 StyTr^2 的有效性。

1.实现StyTr^2 风格迁移网络模型 2.精度、性能等相关指标达到论文标准 3.代码满足MindSpore models仓规范要求 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"NCF（ NeuCharFramework）是一整套可用于构建基础项目的企业级通用框架，严格遵循 DDD 设计模式，包含了基础的缓存、数据库、模型、验证及配套管理后台等等系统基础要件，高度模块化，具有高度的可扩展性和耐操性。 NCF 支持容器化和微服务部署，也支持单体应用部署。

完善基于 Dapr 的微服务架构
1、进一步完善 Dapr 集成
2、进一步完善 NCF 的事件机制
3、进一步完善 NCF 的模块化体系
完善基于微服务的前后端分离架构
1、完善基于 Vue/Anuglar 等模块的基于微服务的模块化架构
2、集成更多可选的框架
完善应用市场
1、完成新版本应用市场的构建
2、上线模块应用市场

了解分布式或微服务架构
了解 DDD、Dapr 等术语或相关开发经验
了解前端框架，如Vue、Angular 的基本运作机制
了解目前流行的前端框架的基本运作原理和开发过程"
"构建一个完整的主题商店应用。该应用需要能够达到为用户提供快捷定制 Element Plus 主题的功能。

一共有三个功能点：

1. 能够提供界面能够让用户对特定变量的值进行更改。

2. 用户在进行更改后应该可以对更改的内容进行预览，检查更改。

3. 用户可以将自己的主题进行导出并使用。

能够提供界面能够让用户对特定变量的值进行更改
用户在进行更改后应该可以对更改的内容进行预览，检查更改
用户可以将自己的主题进行导出并使用

Vuejs
CSS 4
前端开发"
"Buddy Compiler 是一个领域特定编译器基础设施。本项目致力于为 Buddy Compiler 提供领域特定的编程语言通用的编译器前端。我们在技术路线上拥抱MLIR生态。MLIR是多层中间表示的编译基础设施。MLIR 在中间表示层面给领域特定编程语言提供了强有力的支持，但是当前MLIR没有给领域特定的编程语言提供通用的编译器前端。本项目希望在 Buddy Compiler 中利用Antlr，Flex，Bison等框架提供一套通用的面向MLIR的领域特定编程语言前端，并以图编程语言或PDDL作为应用实例。

编译前端框架选择
前端框架输出和MLIR的连接
添加一种DSL作为示例（图编程语言或者PDDL）

编译原理基础知识（尤其是前端部分）
前端工具经验（Antlr, Flex, Bison, etc）
MLIR 基础知识"
"cloudpods 是一个多云管理平台，可以管理不同公有云或者私有云上的资源，现在已经支持阿里云、OpenStack、VMware 等平台的纳管。

Proxmox 也是一个常用的虚拟机管理平台，现在需要将 Proxmox 平台的虚拟机等资源对接到 cloudpods 多云管理平台。

实现功能，以 PR 的方式提交代码到 cloudpods upstream 仓库
1. 将 Proxmox 的虚拟机、网络和存储资源纳管到 cloudpods 平台，实现只读操作；
2. 实现虚拟机资源的创建、删除操作；
3. 编写纳管 Proxmox 对接文档。

了解 Go 开发，了解云计算相关概念"
"神经搜索特指使用人工神经网络模型的搜索系统。很多常见的搜索应用，比如以图搜图，听声辨乐，都需要神经搜索。在神经搜索系统中，所有的文件会通过人工神经网络被表示为一个向量并存储在索引中。当用户进行搜索时，用户的查询目标也会被表示为一个向量。通过比较查询向量与索引向量的相似度/距离，我们可以找到最为匹配的文件。

基于神经网络的搜索通常需要在短时间内查询到最相似的文件。这依赖于近似最近邻搜索（Approximately Nearest Neightbour Search），简称ANN搜索。作为一个前沿研究领域，学者们已经提出很多高效的ANN算法。Redis数据库目前已经支持基于图的ANN搜索算法：HNSW，该算法能够最大程度的达到检索召回率和检索时间的平衡。

DocArray作为JinaAI神经搜索全家桶的底层模块，能够帮助开发者快速开发者快速搜索系统。在DocArray中，我们已经支持了多种向量数据库作为存储后台，如ANNLite，Weaviate，Qdrant以及Elasticsearch。为了帮助Redis社区的开发者，我们希望支持Redis数据库作为DocArray的存储后台，帮助用户高效的进行向量检索。

需要在DocArray中集成Redis作为存储后台
代码有完整的文档及单元测试、集成测试
需要在DocArray中产出Redis ANN搜索的基准。即使用基于Redis的查询速度/召回率对比我们已经支持的存储后台，结果将发表在我们的比较基准页面

需要开发者对DocArray，Redis以及背后基于HNSW的ANN搜索算法有一定理解。"
"Gazelle缺少示例程序，既可作为编程使用用例给开发者参考，又可作为功能测试工具。示例需要覆盖各种网络编程模型以及各种posix网络接口。由于很多开发环境没有多余网卡给Gazelle使用，所以希望利用dpdk的ring PMD设备实现收发环回，在大部分环境都可以实现示例使用测试。

1、支持TCP、unix非阻塞通讯；
2、支持多线程网络IO复用模型，线程之间相互独立。TCP的listen、epoll、read、write、connect等接口都在同一线程内。connect连接数可配；
3、支持多线程网络非对称模型，一个listen线程，若干个读写线程。listen线程和读写线程使用poll/epoll监听事件;
4、支持recvmsg、sendmsg、recv、send、getpeername、getsockopt、epoll_ctl等posix接口;
5、网络通讯报文采用问答方式，丢包或者内容错误则报错并停止通讯。报文内容有变化，长度可配；
6、支持dpdk的ring PMD设备实现收发环回，也可配置成使用网卡通讯（可选要求）
7、使用参数控制网络模型，posix接口，是否收发环回，作为服务端还是客户端等
8、开源标准TCP benchmark测试报告

1、支持TCP、unix非阻塞通讯；
2、支持多线程网络IO复用模型，线程之间相互独立。TCP的listen、epoll、read、write、connect等接口都在同一线程内。connect连接数可配；
3、支持多线程网络非对称模型，一个listen线程，若干个读写线程。listen线程和读写线程使用poll/epoll监听事件;
4、支持recvmsg、sendmsg、recv、send、getpeername、getsockopt、epoll_ctl等posix接口;
5、网络通讯报文采用问答方式，丢包或者内容错误则报错并停止通讯。报文内容有变化，长度可配；
6、支持dpdk的ring PMD设备实现收发环回，也可配置成使用网卡通讯（可选要求）
7、使用参数控制网络模型，posix接口，是否收发环回，作为服务端还是客户端等
8、开源标准TCP benchmark测试报告
项目技术要求"
"本项目基于 Cloud Lab 开源项目开发一套 CTF 训练实验环境：pwn lab，专门为 pwn 方向的选手入门设计，确保可以在 Windows，Linux，MacOS 等操作系统上更加轻松、快捷地部署 pwn 环境，并且提供快捷命令更换 glibc 版本以及部署部分经典 pwn 题目。

为 CTF 选手 pwn 环境提供完善的做题环境
可以在本地快速部署 pwn 题目
使用命令快速更换 glibc 版本以适应不同题目环境
撰写开发手册和使用文档并录制使用演示视频

Linux 基本操作
熟悉 Cloud Lab 并在此基础上开发
熟悉 pwn 题目的各种环境
熟悉 pwn 题目的靶场"
"项目背景
目前Linkis作为计算中间件，对接底层数据引擎。用户可以根据已有的标准接口实现新的引擎，或则对已有的引擎物料包(引擎启动需要依赖的jar包和配置文件) 进行版本升级。对应物料包的安装部署，需要用户手动上传至服务器指定目录，进行部署安装。对于引擎物料是否安装成功，以及该引擎物料包是否可用，需要用户在后台手动验证，流程繁琐。

本项目主要工作
支持引擎插件物料通过管理台界面进行上传到服务器上，并通过已有物料管理接口上传至hdfs系统中
支持引擎插件物料资源的更新、查看
支持对某引擎插件的进行基础可用性的验证
对应前端界面的开发
完成功能对应的使用文档/对应代码的单元测试编写

代码功能上
管理台能够对引擎物料资源进行管控
管理台能够对引擎可用性进行一键验证
对应前端界面的开发
对应的使用文档/对应代码的单元测试编写

技术栈
Java/Scala
了解HDFS
VUE的基本页面开发"
"开放集群管理（OCM）是一个社区驱动的项目，专注于Kubernetes应用程序的多集群和多云场景。在这个项目中，开放API正在发展，用于集群注册、工作分配、策略和工作负载的动态放置等等。

布局概念用于动态选择一组集群，以便更高级别的用户可以将Kubernetes资源复制到成员集群或运行其高级工作负载。例如：

作为集群管理员，我只能对在Amazon Web Services（AWS）上创建的集群进行一些配置。

作为一名应用程序开发人员，我可以将工作负载部署到具有最多可分配内存的集群。

在OCM中，上述调度功能由布局提供。

在本项目中，拓扑感知调度的要求是支持扩展策略。扩展策略用于控制工作负载如何在集群故障域（如区域、分区和其他用户定义的拓扑域）中分布。例如，使用扩展策略，用户可以首先将工作负载尽可能多地分布到具有不同区域的集群，然后将工作负载尽可能多地分布到具有不同区域的集群。工作量的不均匀分布程度是可配置的。

我们希望您与OCM开发人员和社区合作，为该项目提供提案。提案应包括API设计和放置控制器如何使用API。该提案需要在OCM社区会议上进行最终审查。此外，您需要根据提案交付一个原型。原型应支持拓扑扩展策略，此外，您需要考虑在大型（数千）集群环境中的性能和扩展能力。

通过本项目，您可以了解OCM如何管理大规模Kubernetes集群，以及Kubernetes和OCM布局的调度技术。此外，您还可以体验在开源社区工作的乐趣。希望你喜欢这个项目，并选择它！

与OCM社区和开发人员合作，提交该项目的提案。提案应包括API设计和放置控制器如何使用API。

基于上述设计方案，交付一个原型以支持拓扑扩展策略。

Golang
Kubernetes
Scheduling"
"量子机器学习的常用方法是通过计算目标哈密顿量期望对含参数量子线路中各参数的导数信息从而更新量子线路参数，使得模型获得更好的精确度/准确度。量子机器学习中，一般训练集中包含许多样本数据。如何利用多核处理器并行的计算不同样本哈密顿量期望对参数的导数是个重要问题。本任务要求基于MindQuantum现有的梯度计算功能，提升梯度计算的性能1倍以上。

1.新的梯度计算模块，运行时间需要小于原模块的一半； 2.代码需要有适当的注释； 3.说明文档需要描述具体的加速策略 4.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，量子计算，MindSpore"
"构建/移植基于openEuler的一站式机器学习开发体验生产平台，功能包含数据采集、数据清洗、数据存储、特征工程、模型训练、模型管理、模型推理等，支持对接mindspore、tensorflow、pytorch等至少两种框架。
通过构建机器学习开发体验生产平台发现并完善openEuler在人工智能场景的不足，打造基于openEuler的人工智能解决方案，降低在openEuler上进行人工智能开发成本。

1、构建/移植基于openEuler构建机器学习平台，支持x86_64和aarch64；
2、机器学习平台包含数据采集、数据清洗、数据存储、特征工程、模型训练、模型管理、模型推理等能力；
3、至少支持mindspore、tensorflow、pytorch等主流框架的两种；
4、基于构建的平台完成ML、DL、RL典型应用demo覆盖全流程；

1、掌握python/js/java等编程语言。对Dockerfile熟悉的同学优先
2、熟练使用Linux。
3、熟练使用tensorflow、pytorch、mindspore等一个或多个框架。
4、掌握ML、DL、RL等类型基本算法原理，如SVM、KNN、RNN、Q-Learning；"
"Apollo 目前有一个系统配置页面。但是，它对用户不友好，例如，除了参考配置指南之外，无法知道可以配置哪些配置，也不知道已经配置了多少配置。且只支持 Portal 的系统配置管理。期望提供一个用户友好的系统配置管理模块，能够按 ConfigService 、Portal 模块显示所有系统配置，且能够添加编辑。

实现一个用户友好的页面（管理员权限），以表格+分页的形式展示 apollo 系统配置的 Key，Value 和 Comment，支持对配置进行新增和修改操作
完善的单元测试
设计文档和使用文档

熟悉 Java 开发语言、熟悉 Spring Boot 和 Spring Data JPA、对微服务体系有一定了解、有前端开发经验，如 Html、Angular JS 等、熟悉容器、Kubernetes 等云原生技术"
"Kata Containers 目前只支持 V1 版本 Linux cgroups。本项目目标是为 Kata Containers 添加 cgroups v2 支持，从而让 Kata Containers 在只支持 cgroups v2 的系统上也可以正常工作。

能在宿主机上运行的 Kata Containers shim程序

需要熟悉Linux系统以及cgroup"
"针对海量向量数据的搜索，无论是工业界还是学术界都做了大量的研究。由于精确的向量搜索在海量数据的场景下搜索时间过长，所以目前的常见做法，是在向量上建立近似搜索索引。学术上我们称之为近似最近邻搜索 ANN （ Approximate Nearest Neighbor Search） 问题，通常都是通过牺牲搜索精度来换取时间和空间的方式从大量样本中获取最近邻。

根据 Benchmark 上的ANN算法的基准测试结果，基于图结构的 HNSW 算法在查询速度和精度上优于其他ANN算法。但是HNSW算法本身的主要问题就是对内存占用较大，限制了其可以索引的数据大小。

目前我们开源向量索引产品 AnnLite 核心近似搜索算法是基于HNSW来实现，并在此基础上提供了更加丰富的功能（例如支持前置过滤近似查询）。为了使得 annlite 能够具备更强的竞争力和实际应用价值，我们希望能够进一步对HNSW算法进行改进和优化。

需要hnsw支持向量量化 quantization 技术，减少内存占用的同时能够加快向量距离的计算
对hnsw的图索引结构进行改进，在相同数据索引大小的情况下，进一步减少图规模大小
升级前置条件过滤引擎，减少前置过滤耗费的时间
需要能够撰写完整的文档，单元测试和集成测试。

开发者需要对ANN算法有比较深入的理解
可以熟练使用C++编程语言"
"nfs client 可通过 /proc/net/rpc/nfs 文件输出统计信息，nfs server 可通过 /proc/net/rpc/nfsd 文件输出统计信息，如：调用 read, write 等方法的次数，但现在的nfs统计信息中没有包含时间信息（如 client 调用 read 等方法的耗时）。nfs 性能分析时，时间的统计信息将会很有帮助，故增加每个方法调用的最大、最小、平均耗时时间。

nfs client 的 /proc/net/rpc/nfs 文件输出增加几行，如针对 nfsv4： proc4delmax: 69 100 80 ... 总共69个方法，第一个方法最大耗时100ms，第二个方法最大耗时80ms proc4delmin: 69 60 50 ... 总共69个方法，第一个方法最小耗时60ms，第二个方法最小耗时50ms proc4delavg: 69 80 70 ... 总共69个方法，第一个方法平均耗时80ms，第二个方法平均耗时70ms
nfs server 的 /proc/net/rpc/nfsd 文件输出增加几行，如针对 nfsv4： proc4delmax: 76 50 40 ... 总共76个方法，第一个方法最大耗时50ms，第二个方法最大耗时40ms proc4delmin: 76 30 20 ... 总共76个方法，第一个方法最小耗时30ms，第二个方法最小耗时20ms proc4delavg: 76 40 30 ... 总共76个方法，第一个方法平均耗时40ms，第二个方法平均耗时30ms

使用C语言编程；
熟悉 nfs 环境搭建、使用；
了解 procfs 的实现；"
"众所周知，一套设计良好的单元测试保证了开源项目的质量和可维护性。本项目重点在于加强Alluxio应用客户端的测试覆盖率和关键功能的正确性保障。我们希望通过本项目的任务，使得Alluxio开源项目的单元测试质量（unit test）得到进一步补充、完善和加强，通过单元测试保障已有功能，为未来的优化和拓展铺平道路。

针对Alluxio数据编排开源项目的单元测试功能进行优化和完善
至少包含三个以上优化和完善点

Java 编程
分布式系统
单元测试"
"昇思MindSpore CPU正反向算子 + bprop函数开发和实现：包含Dilation2D、Dilation2DBackpropFilter、Dilation2DBackpropInput
计算 4-D 输入和 3-D 过滤器张量的灰度膨胀。
输入张量的形状为 [batch, in_height, in_width, depth]，过滤器张量的形状为 [filter_height, filter_width, depth]，即每个输入通道都独立于其他通道进行处理，并具有自己的结构函数。输出张量的形状为 [batch, out_height, out_width, depth]。输出张量的空间维度取决于填充算法。

1.算子功能符合要求、能力对齐标杆 2.代码满足社区规范、精度、性能等达到标准 3.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"GO2Sky 是一个用 GO 编写的 SDK 库，遵循 Apache SkyWalking 的 tracing 和 metrics 格式收集上报数据。
本项目希望通过收集 GO 运行时的指标，包括但不限于垃圾回收，CPU 使用率，内存使用量，线程/协程使用量，堆栈使用量等指标，并配置在UI上显示，增强 GO 运行时的可观测性，让用户能够更直观的了解应用程序的运行状态。

收集垃圾回收、协程、线程、CPU、内存和堆栈相关的指标
将收集到指标发送到 SkyWalking OAP
配置 dashboard 并在 UI 上展示

较强的自主学习能力，了解或愿意学习 Go 语言"
"在当前 APISIX Dashboard v2 中提供基础的用户名密码认证方式，没有权限管理方案。因此我们需要实现一个认证及权限框架，它用于对这些模块非侵入式扩展。

实现认证、权限框架
实现一种认证、权限示例
完善开发文档

任务需要进行拆分，使用 GitHub PR 逐步进行
开发内容需要配合测试用例及文档"
"通过在离线混合部署部署是提升资源利用率的重要手段，该场景下关键需要保障在线业务的服务质量（QoS）。本项目要求通过系统指标对在线业务的QoS进行量化拟合。以在线业务独立运行时QoS=100分作为基线，实时量化QoS分数，分数范围为[0-100]。
由于不同类型的在线业务特征不同，量化关系式也会不同，因此本项目需要工具有一定的适应性。

1.程序可以采集OS指标、硬件指标、eBPF等，但要能处理部分指标采集不到的情况（如vm下采集不到硬件指标）。
2.程序QoS量化时间间隔精度高于1s，即毎秒钟最少输出一个量化值。
3.假定在线业务以容器化部署，指定容器cgroup路径作为输入。

1.可使用go/rust语言
2.CPU和内存开销尽可能小"
"openEuler Embedded主要面向嵌入式场景，嵌入式场景对性能、底噪等要求苛刻，因此对语言的要求很高，当前的主流编译型编程语言为C/C++。Rust作为一门新兴的系统级编程语言，主打安全、性能，效率，是C/C++的强有力挑战者。因此，本项目的目标是依托开源社区在openEuler Embedded引入Rust编译器支持，并在QEMU或者树莓派上演示使用Rust编写的用户态程序。

1.在 openEuler Embedded 上引入Rust编译器支持。
2.编写、编译一个Rust程序，并在 openEuler Embedded QEMU/树莓派上演示。

熟悉YOCTO框架
基本熟悉Rust语言"
"基于云边协同架构的行人Re-ID是Sedna支持的新示例特性，能够实现在源视频中持续识别、跟踪、搜索用户提供的目标人员，并推送出包含搜索结果视频到流媒体服务器。由于各业务模块对AI模型实现了灵活支持，需要为用户提供AI算法实际性能测试 ，为系统实际搜索效果提供参考。

为Sedna Re-ID特性开发简单易用的自动化性能测试功能，基于开源数据集自动化简易测试报告，需包含体现行人目标识别、跟踪、重识别算法性能的技术指标；
编写说明文档

熟练掌握Python, 了解Golang；
熟悉Pytorch框架，熟悉AI算法开发及其性能测试，有实践经验；"
"本项目分为两部分来探索 Sentinel Go 在 Mesh 层及网络层的流量治理能力。
（1）期望利用 Envoy WASM 扩展机制，结合 Sentinel Go 版本，基于 proxy-wasm-go-sdk 实现 Envoy WASM Sentinel 流控插件，可以支持现有 Sentinel Go 的所有能力，支持通过 Sentinel CRD 标准方式配置规则，并确保 Sentinel 自身性能损耗不会很大；
（2）期望结合 eBPF 实现 Sentinel 拦截插件，探索在底层进行端口、IP、流量维度的流量控制能力，并对 Sentinel Go 进行一定的性能优化与轻量化来满足底层控制的需要。

基于 Sentinel Go 与 proxy-go (github.com/tetratelabs/proxy-wasm-go-sdk) 实现 Envoy WASM extension，支持针对 HTTP 流量及 gRPC 服务进行流量治理，并支持通过 Sentinel CRD 标准方式配置规则
基于 Sentinel Go 结合 eBPF 实现 Sentinel 拦截插件，探索在底层进行端口、IP、流量维度的流量控制能力，并对 Sentinel Go 进行一定的性能优化与轻量化来满足底层控制的需要

熟悉 Go 语言，对分布式系统、微服务、云原生相关技术有一定了解和实践
熟悉 Envoy, eBPF, Linux 内核相关技术为佳"
"在TEE/Enclave中运行软件TPM，保证软件TPM访问的数据不会透出到TEE/Enclave之外，解决虚拟化场景中vTPM的后端安全问题。

实现eTPM技术原型

熟练掌握C编程语言
对TPM工作原理比较了解，有TPM相关的开发经验"
"Multi-Gen LRU 是关于内存回收策略优化一个特性，根据谷歌测试，借助MGLRU，kswapd CPU使用率降低了40%，在75%内存占用时减少了85%的后台误杀情况，在50%的内存占用时降低了18%的渲染延迟，该特性目前已合入linux-next分支，现需要将该特性回合到openEuler中，通过该项目可以对linux内存回收机制有进一步的理解。

1、将linux社区Multi-Gen特性合入到openEuler5.10内核
2、相关的bugfix合入到openEuler5.10
3、使用压测工具（如fio，stress）构造内存压力，测试Multi-Gen LRU在kswap cpu使用率方面的优化情况

1、熟悉linux内核内存管理
2、熟悉git的基本操作
3、熟悉linux内核开发
4、熟悉linux代码规范"
"KubeEdge SIG Robotics关注云机器人领域，特别是基于云边协同架构的机器人管理系统，但目前缺乏可视化的、面向机器人的监控功能。我们希望借用prometheus等开源组件实现对机器人的监控，在KubeEdge SIG Robotics提供的机器人虚拟机仿真环境中完成以下任务：
1、硬件监控，除了CPU、内存，还包括传感器
2、自定义指标监控

开源组件的部署和使用手册
必要的代码和配置文件
端到端的测试用例
监控指标完成20+，界面美观
监控时延小于3s

了解K8s
了解Golanq、C++
了解ROS"
"KubeOS是在openEuler社区孵化，基于openEuler的容器操作系统（简称为容器OS），KubeOS是面向云原生场景，专为容器和集群运行而设计的轻量化操作系统。目前KubeOS已支持在虚拟机的部署，并提供虚拟机镜像的构建工具，本项目期望是开发工具来支持KubeOS在物理机部署。

1、开发工具（使用shell或者go语言）支持KubeOS可以在物理机部署。
2、保证KubeOS原有升级功能正常。
3、输出设计文档及使用文档。

1、熟悉shell或者go语言
2、了解Linux安装及启动流程
3、了解Kubernetes"
"背景：
ShardingSphere 现有的未支持的 SQL Parser 测试引擎是 `org.apache.shardingsphere.test.sql.parser.parameterized.engine.UnsupportedSQLParserParameterizedTest`，测试用例在：`src/main/resources/sql/unsupported/unsupported.xml`。

我们需要创建一个全新的动态测试引擎，名称暂定 `DynamicLoadingSQLParserParameterizedTest`。
它可以动态的从 MySQL[1] 和 PostgreSQL[2] 中读取测试用例并断言兼容性。

实现步骤：
1. 从 MySQL 和 PostgreSQL 的官方 GitHub repo 中读取测试用例；
2. 创建用于 @Parameterized 测试的数组；
3. 运行 `SQLParserEngine.parse()` 去尝试解析 SQL；
4. 断言解析结果；
5. 捕获不支持的 SQL 异常；
6. 记录并打印异常计数和信息；最终目标是没有异常，但现阶段还达不到，请不要直接断言解析错误，导致 `mvn install` 失败；
7. 请定义测试引擎为整合测试（IT），并且只在 GitHub Action 运行，单元测试的常规 `mvn install` 请不要依赖网络环境。

符合 ShardingSphere 代码规范，且达到以下要求：
1. 自动化加载全量的 MySQL 和 PostgreSQL 测试集，并且可以在30分钟之内运行完成；
2. 自动通过 GitHub Action 运行，每天晚上定期运行一次；
3. 不兼容 SQL 报表。

熟悉 Java 和 Junit"
"A-Tune-UI是作用于A-Tune项目的前端可视化界面，由浏览器打开，可以查看A-Tune的历史调优信息等内容；本项目的目标是实现从web界面下发tuning调优命令的功能

实现web界面上下发调优命令
实时回显调优结果

熟练掌握python、js语言
了解go语言及vue框架
有linux操作系统开发基础"
"当前Nacos-CoreDNS模块只支持以短连接方式访问Nacos服务端，本题目致力于让该模块支持以gRPC连接Nacos服务端。

设计出Nacos CoreDNS模块支持gRPC的方案，输出详细设计文档；
根据设计文档，对Nacos CoreDNS模块进行开发；
提供新Nacos CoreDNS模块的使用示例和文档。

熟悉Golang
熟悉Nacos优先
熟悉CoreDNS优先"
"KubeKey 是一个 Kubernetes 集群部署工具，可以实现一键部署 Kubernetes 集群，并且支持 Kubernetes 集群的扩展和维护。但是 KubeKey 流程执行步骤较多流程较长，如果 KubeKey 在执行过程中出现预期外的情况导致执行中断并失败，用户只能排查问题并重新开始执行 KubeKey 。

为此我们需要为 KubeKey 提供阶段运行（Phase Run）功能来帮助用户在排查完问题后，可直接延续之前执行失败的进度手动分阶段执行完剩余流程。

KubeKey 采用流水线式，模块化的架构，方便开发者任意组合、拆分各功能模块。

本项目旨在根据现有的 KubeKey 架构基础上，根据功能划分拆分当前命令流水线，强化各个模块的独立性。可参考 Kubeadm phase run 的效果，最终形成各个功能模块可独立运行，实现阶段运行功能。

KubeKey Phase Run 功能
KubeKey Phase Run 相关命令
KubeKey Phase Run 测试用例和相关文档
产出您关于 KubeKey 的理解

Golang
Kubernetes
Linux"
"可靠性和可用性是每个 MQ 系统最重要的两个特性，通过Message Track Trace我们应该查看完整的消息链接，快速找到进程消息传递失败的根本原因，并且可以查询到很多参数值，例如发送成本时间、消费成本时间、存储在 broker 中的时间等等，当服务端压力过大或者存储紧张的时候，我们可以通过命令临时关闭轨迹消息进行降级。Apache RocketMQ在RIP-6中已经实现了消息轨迹的功能，针对CPP客户端，基本的轨迹功能已经实现，需要进一步实现临时降级策略。本题目的目的就是要在CPP客户端实现轨迹降级策略，主要包括：
 
1.学习Apache RocketMQ知识，详细了解RocketMQ原理、使用方式
2.掌握Apache RocketMQ中轨迹消息特性原理和代码
3.在社区中提交Issue，完成相关代码，review后被社区合并

文档类
详细设计文档
测试报告
使用说明书
代码类
官方仓库提交Issue
官方仓库提交实现代码PR
官方仓库提交单元测试用例代码PR

掌握Apache RocketMQ知识，详细了解RocketMQ原理、使用方式
掌握Apache RocketMQ中轨迹消息特性原理和代码
熟练掌握和使用C/CPP，熟悉Java语言
熟悉Linux，RPC通信等基础知识和原理"
"Casbin和Casdoor是Casbin社区的出色项目，他们的官网和文档都是使用Docusaurus框架进行搭建，文档翻译是使用CrowdIn在线翻译平台进行众包翻译，随着项目的不断发展，文档与代码会存在一定的落差。文档是软件的重要组成部分，改进文档提升用户体验是不可或缺的部分。

同步Casbin以支持的语言的management API和rabc API到Casbin文档中的API模块
改进Casdoor文档整体体验，梳理Casdoor各个功能，对文档内容和布局进行优化
对Casbin、Casdoor文档进行英译汉，当前进度80%左右，目标进度100%
（有时）撰写、编辑Casbin社区推广（如Casbin官方微信公众号）文章

热爱并有能力撰写技术博客、文章
了解Git、GitHub相关操作
了解Casbin、Casdoor的工作原理"
"从配置项管理界面到配置项修改后的持久化到配置中心的功能，完成关键Seata关键参数的控制台修改，配置下发和配置生效流程。

1. 配置管理界面。
2. “修改配置”的接口开发，调用Configuration.putConfig接口方法，发布新的配置值。

1. 熟悉Java开发。
2. 能够参照Seata现有前端代码完成可配置化界面的前端代码编写。"
"开发Swift版本的Casbin，支持iOS App、Swift服务器端应用等生态。或实现Casdoor单点登录系统大前端应用 ios、安卓、flutter、uinapp、小程序等sdk的开发

实现 Casbin 的 Swift 版本，或设计前端友好的casdoor api,完成安卓，ios，flutter，uniapp，小程序的sdk
解决 SwiftCasbin 主仓库&相关仓库中的 issues：https://github.com/casbin/SwiftCasbin/issues

熟悉 Swift/Dart/Java/Kotlin/js 语言的一种，或熟悉 iOS/andriod/flutter/小程序/uniapp框架中的一种
熟悉 Git、GitHub 相关操作"
"Sedna是边云协同AI框架，ModelBox是AI应用框架。本项目基于Sedna构建一个高频的端到端的端云协同应用案例，并使用ModelBox格式打包该应用。

1、功能完善的应用案例
2、基于Sedna和ModelBox实现

1、C++编程语言
2、Go编程语言
3、AI开发经验"
"基于C、C++语言和开源的LLVM框架，在Clang前端的抽象语法树(Abstract Syntax Tree，AST)识别出典型的矩阵乘操作，并将矩阵信息以Metadata的形式添加在LLVM IR上。

1、自定义包含矩阵乘信息的metadata，矩阵信息如矩阵大小、是否转置等重要信息。
2、以个人仓库形式提交代码，实现基于Clang AST，识别出典型的矩阵乘操作，并将识别信息添加至LLVM IR，并添加端到端测试UT。

1、熟练掌握C、C++语言
2、对编译器前端有一定了解，熟悉前端的流程，尤其是AST
3、熟悉开源Clang、LLVM的整体框架，对源码有一定的理解
4、熟练使用Linux"
"在操作系统中，全局最大打开文件数是是有限制的，但是cgroup级别的对于打开文件数目前是没有限制的；为了避免某些异常行为导致一些cgroup中打开文件数过多，从而中断了其他cgroup中的业务，所以需要对于cgroup级别进行打开文件数的上限的限制；misc cgroup子系统是5.13内核引入的一个限制和追踪某些资源的子系统。所以将misc cgroup子系统回合到5.10内核并且利用misc子系统对于cgroup级别打开文件数进行限制。

实现相关的功能代码，功能验证ok；
输出完整的设计方案及测试用例；
代码符合clean code标准；

熟练掌握cgroup的原理；
熟练掌握c语言及内核变成规范；"
"在校园网管理中，很多时候我们需要看某个网站/服务器在学校不同地点、不同运营商网络出口下的访问质量，分别到不同机器上手工测试并汇总常常会带来巨大的人工成本，在 <https://ping.chinaz.com/> 或者类似的网站上我们可以很方便的看网站/服务器在全国各地访问的情况，但是可惜网站的主体和客户端都不是开源的。本项目计划建设一个可自己搭建的分布式网络测量系统，架构为控制端 + 多个测量 agent。

建设一个可自己搭建的分布式网络测量系统，控制端 + 多个测量 agent
控制端提供 Web 界面，接收测试指令、发给测量 agent、收集并展现测量结果
控制端对不同级别的用户有权限控制（比如普通用户不能开放 TCP 端口扫描功能）
测量 agent 启动后连接到控制端，接收测试指令、进行测试、返回测试结果
测量 agent 隶属于多个组，可以按照组选择运行测量指令
测量 agent 由 docker 封装部署，预计数量在 N*10 量级
测量功能包含多节点 ping、DNS 解析、http/https get、TCP 端口连接测试、TCP 端口扫描、traceroute，具体可以参考相关网站的功能，功能方便扩展

掌握网络编程语言
拥有 Web 开发能力"
"题目描述：Apache RocketMQ Connect Clickhouse实现
支持Apache RocketMQ Connect Sink到Clickhouse
1、学习Apache RocketMQ Connect知识，详细了解RocketMQ Connect原理、使用方式、参数含义等
2、根据Connect Api实现RocketMQ到Clickhouse数据同步的Connector
3、在社区中提交Issue，完成相关代码，review后被社区合并

文档类
输出详细设计文档
提交测试报告
输出使用说明书
代码类
提交Apache RocketMQ Connect Sink到Clickhouse的代码，生成PR
提交测试用例代码
提交使用samples代码

熟练掌握Java语言编程
对connector中sink/source有所了解"
"Sea Tunnel是一个由源、转换、汇插件组成的高性能、分布式、海量数据集成框架。海底隧道中有很多插件，每个插件都有多种参数，我们需要在CI/CD中使用E2 E（端到端）测试来保护插件质量。

目前，海底隧道有一个包含一些基本测试用例的E2 E模块，用于测试海底隧道数据管道是否可以在Flink和Spark engine上成功运行。在本任务中，我们希望我们的e2e模块能够覆盖大部分连接器测试，包括kafka、mysql、elasticsearch等。

完成电流源和接收器插件的e2e测试。

较强的自学能力，曾使用过Java、Flink、Spark、Docker更佳。"
"目前新增/修改的工作流在上线前很难验证工作流配置是否正确，只能通过在线上环境执行来验证，所以有必要支持测试环境执行任务。
数据源中心支持配置测试环境源，线上环境源可绑定一个测试环境源。任务执行及工作流执行支持“是否测试”选项，选择测试时，Worker节点在任务执行前，自动替换线上环境源为绑定的测试环境源，再配合Worker分组实现线上、测试环境的隔离，最终达到支持测试任务的目标。

数据源配置页面增加线上、测试选项，支持绑定测试源
工作流执行页面、任务执行页面新增线上、测试选项
Master节点、Worker节点解析执行环境标识，替换数据源为测试数据源
工作流实例、任务实例页面增加执行环境标识

熟悉Java、Spring、VUE3"
"BackupAndRestore callback 是具有故障自动备份和恢复功能的Callback方法。
基于当前MindSpore的Callback机制，实现该方法，具体功能可参考 Tensorflow。

1.实现BackupAndRestore Callback方法、补齐MindSpore相关功能 2. 相关能力对标标杆、场景支持完备 3.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"目前 IoTDB 中原始的分组聚合查询 group by 语句仅支持根据时间序列数据的时间戳进行分组聚合查询。 
另外，IoTDB 中的用户自定义函数 UDF 目前仅支持了根据时间序列数据的时间戳以及固定点个数进行开窗处理来满足用户针对不同场景的需求。 
然而，在诸如 Flink 等系统，还允许用户使用会话窗口来处理数据。 
本项目旨在扩展 IoTDB 的原始 group by 查询与用户自定义函数 UDF 的聚合分组方式，希望支持如下 5 开窗分组种类： 
Time Window: 根据时间戳分组开窗。 
Count Window: 根据点数分组开窗，将连续的每 k 个数据点分为一组，每次向前滑动 n 个点位。 
Session Window: 根据会话时间段分组开窗。根据时间序列数据所表现出来的活动会话进行分组。例如工业场景下，设备并不总是连续运行，将设备每次接入会话所产生的数据作为一组来分组。 
State Window: 根据连续稳定值进行分组。时间序列数据在一段时间内如果保持在某个值的上下范围内浮动，在这个阈值内，将值大致相同的连续数据点归为一组。 
User-defined Window: 根据用户逻辑自定义开窗

1. 调研与需求文档。调研 Flink 等引擎的查询窗口切分定义以及实现方法。
2. 设计文档。包括 IoTDB group by语句, 用户自定义函数框架下的实现方式，有哪些接口，如何调用。
3. 设计实现。实现聚合查询窗口切分框架。实现 IoTDB 的 group by 语句的五种聚合查询方式。实现 IoTDB 的用户自定义函数 UDF 五种开窗方式。
4. 性能报告。对比使用代码生成技术前后，各类查询的性能。
5. 测试。编写单元测试/集成测试，测试驱动保证代码正确性。
6. 编辑用户手册，提示模块用法。

熟练掌握Java编程
了解数据库的基本知识"
"随着 WebAssembly 越来越多地被用作服务端应用程序的 Runtime，WebAssembly 应用程序（例如 serverless 函数和嵌入式函数）需要访问关系数据库。 这可以通过与数据库服务器的 socket 连接来完成。 但是，WebAssembly 还不支持 POSIX socket API。 这意味着 MySQL 的标准 Rust（或 JavaScript）连接器将无法在 WebAssembly 中正确运行。

 
WasmEdge 为 WebAssembly 提供了自己的 networking socket 扩展。 使用 WasmEdge Rust 和 JavaScript SDK，开发者可以编写高性能和非阻塞 I/O 应用程序，包括数据库连接器。 用于 networking socket 的 WasmEdge Rust SDK 类似于 Tokio 的低级 API。

 
在这个项目中，参与者将利用 WasmEdge Rust SDK 实现 MySQL 数据库的连接器。 最终的交付物应该类似于 MySQL 的官方 Rust 连接器。

有一个能在 MySQL 上运行创建、更新、读取和删除语句的 demo，并且 demo 能够很好工作

熟悉C、C++、Go和Rust
愿意通过本项目学习Rust"
"对于本项目的使用者而言，常会有这样一些需求：
我想直接透过一个操作完成安装配置，而无需提前准备一些基础的系统环境
我想将在线评测系统的实例随身携带、启动，以便于在一些场景中快速使用 而可启动的演示光盘则能够满足上述的需求。 其本质是将整套服务提前部署于 Linux 系统结构内，然后制作成映像文件。
本项目目前使用 Ubuntu 发行版作为我们的服务承载，我们希望能够将项目部署于最新的 LTS 版本上； 并且由于携带用户界面的发行体积通常较大，我们希望能够在保留基本图形组件的前提下尽可能减除不必要功能，确保其以小体积实现大作用； 同时需要根据本项目的目标群体适当增加部分预安装的应用程序。

构建基于 Ubuntu 22.04 的光盘映像
光盘映像的基本介绍和使用说明文档

熟悉基本 Linux 命令操作
了解使用 apt 等软件包管理命令
能够启动一套 LAMP 服务"
"一、项目目标
实现时序数据标签模型元数据的管理。

二、项目背景
时序数据库领域有几种常见的数据模型，一种是 Influxdb 等采用的标签模型，在互联网监控场景中使用较多；一种是 IoTDB 使用的物联网树型模型，在物联网设备管理时较为方便。树型模型和标签模型在使用上有一定的转换方式，但是这样的转换方式在一些场景下并不高效。因此，本项目拟在 IoTDB 中实现一套原生的标签模型管理方案，并探究与树形模型的结合方案。


三、项目详情
Apache IoTDB（物联网数据库）是一体化收集、存储、管理与分析物联网时序数据的软件系统。 Apache IoTDB 采用轻量式架构，具有高性能和丰富的功能，并与Apache、Hadoop、Spark和Flink等进行了深度集成，可以满足工业物联网领域的海量数据存储、高速数据读取和复杂数据分析需求。

完成标签模型方案的设计
完成标签模型方案的实现
完成标签模型的模块级测试以及系统级测试，并生成测试报告

熟悉Java编程
了解K-V存储
了解倒排索引"
"StarFive是赛昉科技生产的一款RISC-V架构的单板计算机，本项目计划基于StarFive开发板，制作RISC-V版本的优麒麟系统镜像，并且在基础镜像的基础上，完成一定程度的启动优化以及电源管理的适配。

完成适配StarFive开发板的优麒麟系统镜像制作，能够正常安装、启动，能够正常运行图形界面。
基于上述镜像，有针对性的进行系统启动速度以及性能优化（包括systemd服务裁剪，内核裁剪等），并且实现系统正常的电源管理功能（关机，重启，睡眠，休眠等）。

熟悉Linux操作系统，了解常见的桌面环境，熟悉Debian系发行版的包管理机制。
了解RISC-V相关社区发展动向。
了解基于u-boot，opensbi的开发板镜像制作流程，了解Linux内核交叉编译相关知识。
项目成果仓库"
"自动驾驶是边缘AI的重要落地应用之一，如何协同边云资源以对自动驾驶应用提供支持成为一个重要课题。自动驾驶对边缘AI推理性能有比较高的要求。首先，考虑到汽车移动的特性，自动驾驶的汽车面临的场景纷繁复杂，适用的任务也是未知的，需要动态地根据任务关系更新联合推理方案；其次，自动驾驶对实时性有比较高的要求，这要求我们能够在精度和延迟上取得平衡。 KubeEdge-Sedna开源的边云协同终身学习范式能够基于云侧知识库中的多个历史任务，处理边侧到来的推理任务。然而目前终身学习多任务开源的版本只考虑了分配单个任务后实时推理。近期文献指出，分配多个联合任务的方式进行推理，能够显著提高推理的性能 。本项目旨在基于Sedna从框架层面支持多任务联合推理，孵化下一代自动驾驶应用。这里的任务更多指相同标签空间但不同特征空间的任务。

在社区提供的数据集上复现文献[1]的工作并将这一特性集成到Sedna中
[1] Li Z, Ren K, Jiang X, et al. Domain Generalization using Pretrained Models without Fine-tuning[J]. arXiv preprint arXiv:2203.04600, 2022.
（可选）研究基于Sedna终身学习范式的任务联合推理策略更新方法，并集成到Sedna中；
（可选）研究基于Sedna的决策模型和基模型的异构并行机制。

1. 熟悉传统机器学习、深度学习相关技术原理、常见算法，熟悉Pytorch等深度学习框架;
2. 对目标检测、车道线检测、图像分类等CV任务（一个或多个）有一定的了解；
3. 对边缘计算、终身学习等相关技术有一定的了解。"
"应用中会遇到很多损坏的文件， 我们需要扩展f2fs的工具通过inode号迅速定位到损坏文件，并输出损坏文件在盘上的布局信息。

fsck 发现有损坏的inode，根据inode号，dump出 损坏inode的文件磁盘布局。重点指出inode损坏在哪里，方便后续debug。

使用C语言编程；
了解文件系统基本实现；"
"目前 IoTDB 表达式查询采用的是经典的火山模型。其计算过程大致为： 
对输入表达式进行语法解析，将表达式转换为内存表示结构表达式树 
将内存表示结构表达式树转换为有向无环图的计算结构 Transformer 
将数据读入计算结构 Transformer 进行计算 
这样操作的问题在于，使用类火山模型计算的计算结构 Transformer 在求表达式的值时容易会 
导致生成大量的调用堆栈、需要进行大量不必要的 type infer，有时还会导致出现重复的代码实现。 
例如，对根节点求下一个值需要调用根节点的 evaluate()，接着根节点会调用子节点的  
evaluate()，直到将 evaluate() 传递到叶节点。 
又例如，表达式树的一个节点是 a，由于不知道 a 的数据类型，读取 a 的值时我们需要对 
a.TSDataType 进行 switch 操作，后续对于 a 的每一个值，表达式树都需要对 a 的 
数据类型进行 switch，造成不必要的开销。 
本项目的目标是使用代码生成技术实现对表达式的高效计算。 
通过动态编译表达式，可以使得表达式的计算扁平化，减少表达式求值时的逐级调用和重复调用， 提高 IoTDB 分析语句的的执行效率。

需要使用代码生成技术实现对表达式的高效计算。使用代码生成技术实现 MPP 框架中 TransformOperator / ScanOperator / FilterOperator 等。

1. 调研对比文档。调研 Flink / Presto 等引擎的动态代码实现方法，通过比对设计原理和实测性能的方式，对比各个动态代码生成框架的优劣。
2. 设计文档。包括动态编译的实现方式，有哪些接口，如何调用。
3. 设计实现。动态编译替换现有 MPP 系统部分功能。
4. 性能报告。对比使用代码生成技术前后，各类查询的性能。
5. 测试。编写单元测试/集成测试，测试驱动保证代码正确性。
6. 编辑用户手册，提示模块用法。

熟练掌握Java编程，具有良好的编程习惯
了解Java代码生成的工具及基本原理，或具有较强的学习能力"
"这个工具可以帮助开发者回答以下问题：

列出作者人数最多的文件；
列出作者人数最少的最大文件；
在哪个工作日，代码在版本库中停留的机会最大；
按平均代码年龄排序的文件；
按时间、按工作日、按作者、按特定子目录的提交量和代码行分布；
列出修改次数最多的文件；
等等。

给DevLake增加一个插件

爱学习，有 Golang 编程基础，对 Git 有基本了解"
"OpenMLDB 目前缺少一个在线数据库的高效数据导出工具。该数据导出工具在程序调试、数据备份等场景下具有很大的用处。在这个项目中，你将开发一个相对独立的数据导出工具，可以高效的对于某一个在线数据库中指定的数据表格进行导出。该导出工具将会基于解析 OpenMLDB 的 binlog（protobuf 格式），来实现快速的数据导出。

连接数据库获取指定表的元数据信息，如表 id, 分片信息等
根据表的元信息获取数据表的存储路径，然后到对应目录下读取 snapshot 和 binlog 文件，解析并解码出每一行数据，然后把结果存储到指定的位置上
构建易用且高性能的数据导出工具
补充相关说明使用文档

使用任一的支持 protobuf 解析的编程语言进行开发（如使用 C++，可以复用部分 OpenMLDB 的现有解析代码）"
"OpenDigger 可以支持开放一个 Nodejs 开发环境，和一些内置的分析函数帮助用户分析开源软件的相关指标。

已实现的分析函数在仓库 /src/metrics 路径中可以看到。OpenDigger 计划实现一批 CHAOSS 项目中已发布的一些指标，每一个计划实现的指标都以一个 issue 的形式在仓库  issue 列表中进行追踪，具体可见https://github.com/X-lab2017/open-digger/issues 下以 [Metrics] 为开头的 issue 列表。

本项目的内容包括：
1. 参考 /src/metrics 下已有的分析函数，实现 issue570 - issue577 中的相关指标
2. 连接到 Clickhouse 数据库，在 nodejs 环境下测试运行

基于TypeScript语言编写的CHAOSS指标函数

使用Plotly可视化运行的文档示例"
"KubeEdge-Sedna于21年6月发布了业界首个边云协同终身学习范式，包括相关样例和katacoda免费试用环境。该范式能够基于云侧知识库中的多个历史任务，处理边侧到来的推理任务。据21年12月发布的边缘AI研发落地生态挑战调研报告，“提供公开数据集、预处理和基线代码，构建Benchmark”的建议在总体、边缘AI方向的工业界、学术界和在校学生中票数均排名第一，比例分别为82.18%、92.98%、87.10%、86.67%，并且显著高于其它建议。本项目旨在基于Sedna边云协同终身学习范式构建自动化性能测试功能，帮助算法开发者们构建视觉检测类边缘AI应用，以验证并选择最匹配的相关算法。需基于开源数据集实现预处理和后处理（包含体现工业质检/巡检算法性能的数据清理及测试技术指标），并编写基准测试规格文档。

标准规格文档，需包括支撑特性、支撑场景、技术指标、基线算法说明和使用指南
预处理及后处理算法代码，包括数据清理与指标计算
一个或以上的基线算法代码

深度学习
Python
KubeEdge-Sedna"
"OpenFunction 是一个云原生的开源函数即服务（Functions-as-a-Service）平台，旨在让用户专注于他们的业务逻辑，而不必担心底层运行环境和基础设施。用户只需要以函数的形式提交业务相关的源代码，即可将服务按需运行在集群中。

OpenFunction 作为一个 FaaS 平台，实现了对“函数”这一基础业务单元的生命周期管理。在设计中我们使用到了用于完成“函数”到“应用”的 OCI 镜像构建的组件 Shipwright（以及用于完成构建流水线的 Tekton）；用于负载同步函数的引擎 Knative；用于实现事件驱动机制的 KEDA；用于实现应用分布式响应能力的 Dapr 和用于实现“函数”入口机制的 Ingress Nginx。

目前， OpenFunction 基于 Dapr + Keda 实现了异步函数运行时。OpenFunction 的异步运行时将代码中调用 Dapr 的部分抽象了出来，用户可以通过简单的配置即可完成对 Dapr 的调用。这种方式减少了新用户学习的成本，但是对于 Dapr 的老用户会有一定的不适应。且会增加原有的 Dapr 应用函数化的成本。因此 OpenFunction 需要一种新的运行时，其可以直接运行 Dapr 应用，同时可以借助 Keda 的能力实现自动伸缩。

OpenFunction 弹性应用运行时支持直接运行 Dapr 应用，支持设置 Dapr 组件，如果组件不存在，OpenFunction 会自动为应用创建组件。用户可以通过注解实现对 Dapr 的控制。 

OpenFunction 弹性应用运行时支持通过 Keda 实现应用的自动伸缩。

详细设计文档
代码
完整的测试用例和测试代码

Kubernetes
OpenFunction
Dapr
Keda
Golang"
"Dubbo/Triple 协议 Benchmark 工具搭建，参考其他开源benchmark实现，需要直观的感受不同协议下的吞吐和延迟的对比。根据工具优化不同协议的性能，比如优化拷贝，调整参数设置或者调整网络模型。

能够针对两个不同的协议输出各自的性能指标
产出优化后的rt和tps 提升报告

熟练掌握 Go 语言
能够了解基础的压测指标"
"选择一个具有代表性的开放时序数据集（如天气、股票、天文、地震），编写从数据源定期同步数据的脚本，进行数据建模，编写典型的查询语句、通过可视化软件（如 Grafana）进行展示。

项目设计文档，包括产品设计和技术方案设计
开放数据集同步脚本
建模文档、创建数据库表的 SQL 文件
典型的查询 SQL 文件
对接数据可视化软件，可以进行数据的可视化展示

TDengine 数据库建模和查询的基础知识
建议选择 Go、Python 语言
选择一个流行的开源可视化软件，如 Grafana"
"在QUIC协议中，每个连接都拥有一组连接标识符或（即CID），每个CID都可以标识该连接，每个终端都可以独立选择自己的CID供对端使用。CID的基本功能是用来在底层（UDP，IP层）的地址发生变化时，仍能够使得QUIC连接内的数据包被送达正确的终端。当不需要用CID路由到正确的终端时，可以使用零长度CID。本项目的目标就是为 XQUIC 新增 零长度CID 的支持。

新增XQUIC对零长度CID的支持；
提供完善的测试用例；

学习QUIC协议中的CID机制；"
"OpenYurt作为平台级边缘云原生项目，涉及到云原生和边缘计算两个领域。OpenYurt结合云原生生态系统，向下对接异构的边缘计算资源，包括CDN、ENS以及边缘IoT设备，向上提供标准的边缘资源及业务管理接口。为了屏蔽OpenYurt的复杂性，使很多边缘计算领域开发者能够快速上手OpenYurt平台，社区提供了OpenYurt体验中心，该中心以开箱即用的方式快速为开发者提供用于开发测试的OpenYurt集群。随着OpenYurt社区的快速发展，在云原生和边缘计算两个领域中，有越来越多的优秀项目在OpenYurt上集成，包括OpenYurt社区衍生的项目：Yurt-App-Manager、Raven、Node-Resource-Manager，以及一些三方的项目Edgex Foundry、EMQ ekuipper、OpenVINO、Prometheus等。未来，为了便于这些项目能够快速上体验中心，体验中心需要设计并实现一种通用的应用对接标准。所有项目按照这个标准提交到OpenYurt体验中心即可快速运行。通过本题目的挑战，同学们能更好的学习到云原生、边缘计算、Web开发等相关技术，接触到更加丰富的云原生在边缘计算领域的应用场景，深入地理解云边端一体化的价值。

设计并实现OpenYurt体验平台中应用市场模块
参考社区主流的服务接入机制像Open Service Broker，设计应用与OpenYurt平台的对接方案
实现OpenYurt体验中心的应用市场管理功能，提供标准化的应用管理接口，包括应用的发布、下线、升级等

了解云原生生态，有项目开发经验
熟悉Web开发的相关语言与框架
有Go语言开发经验
对OpenYurt有较强学习兴趣"
"在实际生产环境中，将业务部署在k8s集群中，有些场景需要对数据进行持久化存储，当存储数据量暴增，就需要对数据进行智能化管理，比如动态扩容，数据备份等操作，这也会进一步加大对数据存储、管理的需求；在存储方面，ceph提供基于块，文件，对象的实现方式，这对以后进行扩展、管理等操作会更便捷。

1.基于openEuler系统，使用openEuler社区的dev_ceph搭建存储集群。
2.基于openEuler系统，搭建k8s集群。
3.在ceph-mgr中的dashboard组件中增加接口，完善或实现创建存储池，文件系统，mds服务、文件夹等功能。
4.在k8s集群中开发存储插件，通过插件可以调用ceph的相关资源，并将插件打成rpm包。
5.在k8s中搭建一个简易服务，使用cephfs提供的文件作为后端存储。

1.熟练掌握python、go语言。
2.对k8s，ceph有一定的了解。
3.熟练使用Linux。"
"Karmada（Kubernetes Armada）是基于Kubernetes原生API的多集群管理系统。在多云和混合云场景下，Karmada提供可插拔，全自动化管理多集群应用，实现多云集中管理、高可用性、故障恢复和流量调度。

本课题要求基于 docusaurus 来实现 Karmada 官网（含文档）的国际化支持，并完成中文文档的翻译。

1. 社区已经启动docusaurus框架集成工作（详见https://github.com/karmada-io/website/pull/31），待该工作完成后需要进一步完善国际化文档架构设计；
2. 翻译karmada仓库中现有英文文档（https://github.com/karmada-io/karmada/tree/master/docs）至中文，并提交到website仓库。

支持i18n

将文档翻译成中文

熟悉Golang

熟悉Kubernetes"
"基于ResearchOps平台建设社区问答&资源推荐机器人解决方案，构建社区知识图谱，提供API查询、社区FAQ问答、相似Issue/问题推荐等服务，文档类问题分钟级回复

1、输出社区问答知识图谱/知识库。
2、提供用户友好的使用界面。
3、问答机器人需满足基本交互功能，准确识别聊天内容并快速反馈。
4、对于文档/API查询类问题，准确反馈对应资源。

知识图谱/NLP/对话管理"
"Apollo 目前有一个简单的用户管理页面，不过功能比较简单，只能基于单个用户进行添加或修改，对用户不太友好。例如无法知道系统中当前有多少用户，也无法对他们进行禁用/启用的操作。期望提供一个用户友好的用户管理模块，能够显示系统中的所有用户，系统管理员可以选择一些用户进行操作。

1. 实现一个用户友好的页面（管理员权限），以表格+分页的形式展示 apollo 系统中的所有用户，支持对用户进行新增、修改、禁用、启用等操作
2. 完善的单元测试
3. 设计文档和使用文档

熟悉 Java 开发语言、熟悉 Spring Boot 和 Spring Data JPA、对微服务体系有一定了解、有前端开发经验，如 Html、Angular JS 等、熟悉容器、Kubernetes 等云原生技术"
"LMP 项目面向 eBPF 初学者和爱好者，现已成为 eBPF 想象力孵化池，其中子项目 eBPF_Visualization 目标是提供一个易用的轻量级的 eBPF 程序管理系统，专注于 eBPF 数据存储和可视化及 BPF 程序管理编排。其功能包括：eBPF程序管理、eBPF 程序所采集数据管理和可视化等。
本题目要求对系统的前端页面进行视觉与交互优化，并优化 eBPF 程序采集数据的展示效果。

重构网站 UI 显示效果和交互逻辑
使用 AntV/G2Plot 统计图表库将 eBPF 程序采集的数据进行可视化展示，针对不同eBPF程序采用不同图表进行展示

了解 Git、Github（或Gitee）相关操作
了解 Rustful API
熟悉 Vue 或 React 框架，了解 TypeScript"
"目前 IoTDB 支持基于 Java 开发实现的用户自定义函数（UDF）。用户在开发 UDF 时，需要遵循如下流程： 
在 Java 项目中引入 IoTDB 的依赖。 
遵循 IoTDB 定义的 UDF 接口进行开发。 
将 UDF 编译成 Jar 文件后，手动部署到 IoTDB 集群的各个实例中。 
通过 UDF 运维命令注册并加载 UDF。 
该流程虽然能基本满足 UDF 的开发与部署，但存在以下问题： 
首先，UDF 运行环境无法做到有效的安全隔离，恶意用户可以在 UDF 实现中通过调用系统函数对 IoTDB 服务甚至是操作系统本身进行攻击。 
其次，实际使用中，UDF 的开发部署流程较长，对于业务侧的用户，在开发完 UDF 之后，需要 DBA 协助将 Jar 文件手动部署到各个集群中。当后续集群出现扩容时，DBA 还需要将其他节点的 Jar 文件手动拷贝到新的节点。这类操作十分不利于在弹性环境下自动执行。 
本项目的目标是，利用其他轻量级的编程语言或者外部函数运行服务，实现可配置的轻量安全的 UDF 运行环境。

需要对现有的 UDF 功能与需求总结分析，并设计出函数运行环境的接口；通过调研其他脚本语言（如 JavaScript / Lua）在 Java 中的运行方案以及外部的函数运行环境（如 OpenFunction)，给出不同运行环境的实现以及性能对比。

1. 调研对比文档。调研 Java 中调脚本语言代码的方案，以及调用 OpenFunction 的方案，从运行性能、安全性、开发友好程度等维度和现有的 UDF 开发部署机制对比。
2.设计文档。
2.1 整体架构设计。
2.2 UDF 运行时接口设计。
2.3 UDF 管理 SQL 设计。
2.4 基于脚本语言 UDF 开发接口设计。
2.5 基于 OpenFunction 开发接口设计。
3. 功能实现。
3.1 UDF 运行时接口抽象。
3.2 UDF 管理功能扩展实现。
3.3 基于脚本语言 的 UDF 运行时实现。
3.4 基于外部运行时 OpenFunction 的 UDF 运行时实现。
4. 性能报告：通过常用的 UDF 查询场景，对比基于脚本语言、OpenFunction、和原有的 UDF 运行时的执行性能。
5. 测试。编写单元测试/集成测试，测试驱动保证代码正确性。
6.使用文档。
6.1 UDF 开发说明文档。
6.2 UDF 管理操作文档。

熟练掌握 Java 编程，掌握面向对象编程的设计思想，具有测试驱动编程的开发思维。
了解数据库的基本知识。
了解 Kubernetes 基本原理与使用。"
"Advanced Packaging Tool（apt）是Linux下的一款安装包管理工具，由debian社区开发维护。apt 命令提供了查找、安装、升级、删除某一个、一组甚至全部软件包的命令。当apt安装软件包遇到依赖冲突时，会进行提示，但是有时候依赖错误发生在较高的深度时，无法准确提示依赖冲突的根源。本项目希望对apt工具进行改进，能揭示深层依赖冲突。

完成apt安装软件包时提示完整依赖冲突的功能，完成相关代码和文档
修改apt源码中关于依赖冲突的单元测试并执行，验证能够输出完整依赖冲突

熟悉C++"
"当前，OI Wiki 引用了很多例题、代码和测试数据。为了方便代码在线运行和代码 CI 功能的实现, 我们需要将代码, 测试数据与文档分开存储。本项目需要学生提出一种统一的存储格式, 可以方便代码在线运行, 代码 CI, 多语言代码展示等功能的后续实现。

与目前编码风格保持一致，尽量以 Typescript 为主要编程语言

前端开发的相关知识（HTML/CSS/Javascript/Typescript/React）
能使用 Git 进行协作开发
熟悉 remark 工具链或 gatsby 者优先"
"OpenMLDB 目前的英文文档较为不完善，并且经过几次产品迭代，没有严格的校对和验证。因此在这个项目中，我们需求进行一次对比最新中文文档做一次严格的功能和描述验证，改进相关的英文描述，达到产品级别。

熟悉 OpenMLDB 的使用方式
验证现有英文文档内容的正确性
产出完整可上线的高质量英文文档

 扎实的英文技术文档阅读和翻译能力，有相关英文技术文档翻译经历者优先
Markdown 编写能力
鼓励提交英文项目申请书"
"ShardingSphere Parser Engine 帮助用户将 SQL 语句解析为抽象语法树，并从语法树生成对应的 SQL Statement 对象。Parser Engine 目前支持 `MySQL`, `PostgreSQL`, `SQLServer`, `openGauss` 和 `Oracle` 等多种数据库方言，为了提升对于不同数据库方言的支持度，我们需要对 Parser Engine 中未支持的 SQL 进行优化。

这个任务的目的是解决这个文件中的不支持解析的语句，下面是一些具体任务列表： 
LISTEN 
LOCK 
MOVE 
NOTIFY 
PREPARE TRANSACTION 
REASSIGN OWNED 
REFRESH MATERIALIZED VIEW 
REINDEX 
RESET 
SECURITY LABEL 
TRUNCATE 
UNLISTEN 
你可以从这里获得更多关于语法解析的参考。为了完成这个任务，你首先需要了解它为什么不支持？是因为 antlr4 语法解析异常，还是因为没有实现 visit 函数？你可以使用 antlr4 插件 去帮助你分析，你可能需要访问官方文档来检查语法。 
修复问题之后，记得提交一些 SQL 测试用例，并把解析结果写在 XML 中。 
运行 SQLParserParameterizedTest 和 UnsupportedSQLParserParameterizedTest 去确保没有异常。 
此外，你可以参考一些示例，来辅助完成这个任务： 
support alter foreign table for pg/og 
support alter materialized view for pg/og 
完成 SQL 解析优化之后，你需要测试在 ShardingSphere 读写分离场景下，该 SQL 是否能够正常执行，并且根据 SQL 的语句，将 SQL 路由至写库或读库。完成读写分离功能的测试后，需要在 ShardingSphere 集成测试 shardingsphere-integration-test 中添加对应场景的测试用例。

能够对自己的代码进行测试，保证提交代码的正确性

1. 精通 java；2. 理解 Antlr4 语法；3. 熟悉 PostgreSQL 数据库"
"openEuler小程序是一款为openEuler开源社区提供会议预定服务的微信小程序。社区各个SIG的maintainer可在小程序
上预定SIG会议，预定后的会议会在小程序和openEuler官网上呈现。如果预定的会议设置了自动录制，还会在会议结束后
生成录像，自动上传到B站。
openEuler小程序后端采用Django + uwsgi + MySQL的框架开发，实现了会议、活动等模块50+个接口。
目前，openEuler小程序已支持预定zoom会议和WeLink(蓝版)会议。
请调研飞书、腾讯会议、华为云会议（一个或多个）等会议管理相关接口(预定会议、取消会议、编辑会议、获取会议参会者信息、查询会议录制信息等)，并接入openEuler会议预定小程序

接入的第三方会议完全适配openEuler小程序
输出接入新的第三方会议的测试用例

熟悉Django开发流程
熟练使用python3编写代码"
"Milvus 是一个世界级的分布式向量数据库。我们知道 Milvus 还不支持 map/set/list 等一些数据类型。我们希望丰富 Milvus 以支持更多有用的数据类型。

Milvus 支持更多有用的数据类型，如无符号整数、map、set 和 list。

扎实的算法和数据结构知识
掌握基本的数据库知识
（加分项）掌握解析器知识"
"操作系统上承载着各种应用软件，一旦操作系统发生故障，可能导致重大事故。因此，快速、准确检测出操作系统中潜在的异常具有重要的意义。本项目通过实时采集操作系统中的各种性能指标（如：CPU利用率、内存利用率、网络延迟等），利用智能检测算法，准确分析操作系统是否发生了异常。本项目会提供相关数据集以及测试流程，开发者需搭建完整的检测流程，并设计高效、智能的异常检测算法。

1、搭建完整的检测流程
2、设计高效、智能的异常检测算法

1、熟悉python，包括常用的numpy、pandas的操作
2、熟悉一些常用的异常检测算法"
"RapidJSON是一个用于C++的JSON解析器和生成器。
1）RapidJSON 小而全。它同时支持 SAX 和 DOM 风格的 API。SAX 解析器只有约 500 行代码。
2）RapidJSON 快。它的性能可与 strlen() 相比。可支持 SSE2/SSE4.2 加速。
3）RapidJSON 独立。它不依赖于 BOOST 等外部库。它甚至不依赖于 STL。
4）RapidJSON 对内存友好。在大部分 32/64 位机器上，每个 JSON 值只占 16 字节。它预设使用一个快速的内存分配器，令分析器可以紧凑地分配内存。
5）RapidJSON 对 Unicode 友好。它支持 UTF-8、UTF-16、UTF-32 (大端序／小端序)，并内部支持这些编码的检测、校验及转码。例如，RapidJSON 可以在分析一个 UTF-8 文件至 DOM 时，把当中的 JSON 字符串转码至 UTF-16。它也支持代理对（surrogate pair）及 ""\u0000""（空字符）。

适配OpenHarmony的构建体系，参考https://gitee.com/openharmony/docs/blob/OpenHarmony-3.1-Release/zh-cn/device-dev/subsystems/subsys-build-standard-large.md
满足OpenHarmony社区代码规范，参考https://gitee.com/openharmony/docs/blob/OpenHarmony-3.0-LTS/zh-cn/contribute/%E8%B4%A1%E7%8C%AE%E4%BB%A3%E7%A0%81.md
基于OpenHarmony平台通过demo/单元测试用例
提交仓库到TPC
输出本三方库在OpenHarmony下的能力，导出库对外提供的函数接口和已测试过的函数接口

C，C++，熟悉Makefile"
"拟优化相关功能如下：        
创建卷时，当需要分配的容量（segment）不足时，阻止新的卷的创建， issue https://github.com/opencurve/curve/issues/1059
分配卷的容量时，使用的分配相关的容量值与统计工具的容量值需要统一，issue https://github.com/opencurve/curve/issues/1058
curve块存储运维工具curve_ops_tool显示容量命令需要优化，如显示集群space时，需要按逻辑池去显示， issue https://github.com/opencurve/curve/issues/1055
其他相关优化

pr的方式提至curve仓库 https://github.com/opencurve/curve/pulls
简要方案设计，可以以issue的方式提至https://github.com/opencurve/curve/issues
代码开发，需符合curve遵循的代码规范，补充单元测试，并单元测试覆盖率通过，CI测试通过，并经过curve项目组code review完成合入。

具备以下技术能力：
熟悉C++软件开发，熟悉gtest等相关单元测试框架，能够完成单元测试等工作。
熟悉linux上的编译，调试命令，如gcc，gdb等。
了解curvebs的单机部署，能完成相关的功能测试。
了解curvebs集群容量管理方式，容量分配策略，集群扩容等相关内容"
"使用分层存储来存储压缩的数据，可以节省成本，并避免 BookKeeper 群集带来的影响。主题压缩可以读取所有压缩的数据，以及最后一次压缩后的新增数据。如果大量主题启用了主题压缩或处理大体积的压缩数据，则压缩任务将对 BookKeeper 群集产生影响。如果能充分利用分层存储的优势，那么压缩数据就可以直接从分层存储中读取，BookKeeper 集群也就能提供更可靠、更稳定的服务质量。

项目验收标准
编写一份方案来描述你的设计
实现本项目的 MVP 最小可用原型
实现本功能并推送 PR
添加本功能的单元测试

项目技术要求
熟悉 Java 语言编程
熟悉使用 Git 和 Github
熟悉存储相关的基础理论"
"目前 Apache ECharts 的折线图只能为整个系列使用同样的线段属性，如果要实现部分折线是虚线的效果，就需要通过多个系列组合使用来达到视觉上等价的效果。但这种方案不易于理解和使用，希望能够为折线图内置支持一个系列多种线段属性的效果。

调研相关产品的功能和接口设计，与导师讨论确定包括接口在内的设计方案，在 GitHub 上以 issue 形式发布
修改源码以实现项目要求的效果
编写测试用例，并且完成对现有测试用例的回归测试
编写文档和教程

熟悉 TypeScript 或 JavaScript
熟悉 git 操作"
"GraphX 是一个 Spark API，它用于图和分布式图的计算。

基于 GraphX 实现从 Nebula Graph 里读取子图操作后进行图计算，实现局部数据分析。

子图的图计算

GraphX
Java
Scala
Spark"
"Tengine 现有的 reqstat 打点统计能力相对比较简单，难以更加精细的了解 Tengine 运行的状态，需要扩展当前能力，并跟现有云原生相关产品相结合。通过本项目，可以让学生对 Tengine 原生模块编写、大规模高性能网关领域的开发工作有较为深入的理解

使用原生模块实现可定制化的 Metric 打点统计功能，可灵活配置打点统计范围，支持规模化
完成相关测试用例，性能压测以及相关文档（中英文双版本）
设计 API 接口可供其他模块统计
实现 exporter 可对接 Prometheus

熟练掌握 C 语言，对 Tengine 和 Prometheus 有一定了解"
"Arthas切换到新的支持markdown格式的文档系统
1、调研一个新的支持md格式新的文档信息，可参考VuePress。
2、将调研结果落地实践包含动态构建、文档发布、上线新的arthas官网。

完成新的文档系统并上线

尽量保证原有的链接不变，样式美观大方，支持自动化构建"
"基于云边协同架构的行人Re-ID是Sedna支持的新示例特性，能够实现在源视频中持续识别、跟踪、搜索用户提供的目标人员，并推送出包含搜索结果视频到流媒体服务器。

基于Sedna Re-ID特性开发一个端到端的样例，场景不限。基于Sedna提供的k8s部署接口、Lib开发接口实现。需要理解边云协同技术，在ReID推理的场景下，发挥出协同的优势。

1. 说明文档：场景描述、实现方案、部署方案、效果截图、算法选型说明、测试报告
2、实现代码：符合开源风格

1、熟练掌握Python, 了解Golang；
2、熟悉Pytorch框架，熟悉AI算法开发及其性能测试，有实践经验；"
"目前，ApacheAPISIX没有一个非常有用的配置文件工具来分析CPU或内存，开发人员只能使用基准测试或打印日志来分析ApacheAPISIX。
使用eBPF为ApacheAPISIX创建配置文件工具，使用eBPF捕获ApacheAPISIX中的Lua调用堆栈信息，并将其绘制成CPU火焰图。

使用eBPF捕获和解析Apache APISIX中的lua调用堆栈信息，对其进行汇总并生成cpu火焰图。
利用eBPF同时捕获和解析C和Lua混合调用堆栈信息，对其进行总结，生成cpu火焰图。
支持获取在Docker中运行的Apache APISIX进程
支持获取Apache APISIX Openresty luajit 32/luajit 64模式

熟悉Lua/C
对eBPF和Openresty有一些了解。
对profiling有一定了解"
"为了构建基于openEuler的HPC应用生态，需要将目前广泛使用的开源HPC应用迁移到openEuler。Scanorama利用了全景拼接的算法，将来源于不同技术的单细胞的datasets进行整合。

1、scanorama的X86和ARM配置文件创建并归档至hpcrunner社区templates目录。
2、自动化脚本执行scanorama用例，并输出用例执行结果，脚本上传test目录。
3、《基于openEuler的scanorama软件移植指南》、《基于openEuler的scanorama软件测试报告》，报告覆盖规范性自检、功能性测试、性能、精度测试结果，以word形式存放到代码仓库的doc目录。
4、若适配过程中有patch文件或者第三方依赖安装包产生，请上传至porting或者package目录。

1.掌握HPC相关技术，如MPI使用、openmp使用；
2.掌握编译技术，如GCC使用、Clang使用、解决编译报错的能力；
3.掌握编程语言，Fortran、C/C++；
4.掌握Python语法、Shell语法。"
"重构 Dolphinscheduler 资源中心的读写逻辑
描述
目前资源中心读写 HDFS/S3/本地目录 通过在数据库表中 t_ds_resources 记录文件/文件夹目录来实现文件记录，但是在用户初始化DS或者用户在DS的外部修改了第三方存储的内容的时候DS无法进行实时同步，希望能够与第三方存储的内容保证实时同步（调用第三方的API对文件增删改查）

DS 不存储资源中心中文件的路径，对于资源中心的读写全都通过调用第三方API实现，只保存任务实例依赖到的内容路径于数据库用于文件删除校验
实现现有的资源中心的所有功能，其中包括 文件/文件夹 增删改查，任务实例调用资源中心
后端API文档

了解 Linux 系统，对 Linux 文件管理有一定的熟悉
了解 HDFS/S3 组件，能够较快速的根据官方文档学习API的使用
熟悉 Java 语言"
"完成dbt-openGauss适配插件，并在dbt社区新增支持openGauss的文档。

1. 完成dbt-openGauss插件，并根据https://docs.getdbt.com/docs/contributing/testing-a-new-adapter完成测试 2. 完成基于dbt-openGauss的插件的demo，并合入到opengauss仓库。 3. 将dbt-openGauss adapter支持文档合入到https://github.com/dbt-labs/docs.getdbt.com

1. 了解openGauss基础功能 2、 熟悉Python语言"
"seata控制台功能，是1.5版本后的重大特性功能，这是为用户展示事务信息，锁信息，及后续手动处理异常事务的管理入口。目前seata控制台逻辑和server耦合在一个模块中，需要将console模块独立出来。server 模块和 console 模块通过 openAPI 进行通信交互和数据获取。

1. seata console 控制台模块和seata server服务端从代码架构层面分离，支持独立部署。
2. console通过http方式与server端交互数据；
3. 需要考虑权限安全问题；
4. 提供接口文档；

1.熟悉java语言；
2.对seata有简单的了解；"
"sealer是CNCF沙箱项目。

一种工具，用于将应用程序的所有依赖项和kubernete封装到云图中，通过云图将此应用程序分发到任何位置，并在一个命令中在任何集群中运行。

sealer支持kubeadm初始化集群，我们称之为运行时，sealer将在功能上支持多运行时，如支持k0s k3s。。。
```

来自k0s

复制mysql。

CMD kubectl apply-f mysql

```

sealer build-t k0s mysql集群。

sealer运行k0s mysql群集

然后sealer将在kubernetes上初始化mysql集群。

Souce代码和e2e测试，k0s和k3s云图

熟悉kubernetes和golang"
"昇思MindSpore SparseApplyProximalAdagrad CPU正向算子开发 + C++ infer函数实现：
根据近似 adagrad 算法更新相关条目。与 ApplyProximalAdagrad 相比，输入了一个额外的索引张量。
accum+=grad?gradprox_v=var?lr?grad?1accum√var=sign(prox_v)1+lr?l2?max(|prox_v|?lr?l1,0)
var、accum 和 grad 的输入符合隐式类型转换规则，使数据类型一致。如果它们具有不同的数据类型，则将较低优先级的数据类型转换为相对最高优先级的数据类型。

1.算子功能符合要求、能力对齐标杆 2.代码满足社区规范、精度、性能等达到标准 3.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"完成制作下面 12 个 C/C++ 包进入 Xmake 官方包仓库

完成 wolfssl, apr, PDCurses, grpc, zydis, modm 库进入官方仓库
完成 gdk-pixbuf, xtensor-io, git-crypt, thrust 库进入官方仓库
完成 v8 包在 windows 上的编译
完成 quickjs 包 port 到 windows，并能正常运行

熟悉和了解 Lua 的基础语法
熟悉和使用过 Xmake，了解 Xmake 的基本使用
熟悉 C/C++ 相关的编译链接相关的基础知识"
"昇思MindSpore CPU正向算子开发：ExtractVolumePatches，包含CPU正向算子开发 + C++ infer函数实现：
从输入中提取patches并将它们放在“depth”输出维度中。 extract_image_patches 的 3D 扩展。

1.算子功能符合要求、能力对齐标杆 2.代码满足社区规范、精度、性能等达到标准 3.实现相关功能，相关评估指标符合要求，代码合入社区

深度学习，python，MindSpore"
"microbench 是一套处理器指令级性能测试框架，源自 RISC-V Linux 内核剖析计划，由泰晓科技 Linux 技术社区研发。

该套件初衷是用于评估新兴处理器 RISC-V 的实际性能，目前已经支持 RISCV64, X86_64, Aarch64, ARMv7, MIPS64 等架构，并覆盖了数条基础指令，相关结果可用于评估和改善处理器设计，也可辅助系统或软件底层性能优化。

本次项目旨在进一步完善该测试套件，包括新增更多处理器架构支持，尤其是国产处理器架构；扩展测试指令集，提升测试范围；并增加基础算法测试用例进而反应处理器的流水线、多发射等特性。

新增 1-2 款新的处理器架构支持
覆盖更多的基础指令，比如加减乘除等指令
新增多个基础算法测试用例，方便反应处理器的流水线、多发射等特性
测试结果需要同步提交到 logs/ 目录下
需要撰写相应的使用或分析文档并开展线上视频分享

Linux 基本操作
熟悉 C 语言
了解算法基础知识
了解处理器基本工作原理"
"DataX 是阿里巴巴研发的异构数据源离线数据同步工具，而 Nebula Graph 是 vesoft.Inc 研发的开源分布式图数据库。

基于 DataX 实现 Nebula Graph 的 reader 和 writer 插件，可方便用户图数据库使用者实现数据同步。

nebula 支持 DataX

Java
了解 DataX"
"Index tree是Linux常用的索引数据结构，诸如Linux文件系统用B+ tree实现文件索引，而且Index tree的性能往往是系统性能瓶颈。本项目要求用Rust语言在多线程场景下，实现支持并发操作的Index tree，为了提高throughput和降低latency，而且出于性能考虑，Index tree的并发操作要求是lock-free。

1、支持并发查找，修改
2、支持范围查找

1、熟悉Rust语言
2、熟悉Btree B+tree数据结构"
"Reactive Stream 提供了一套标准的异步流处理 API， 在能够让应用写出事件驱动的程序的同时，也通过 backpressure 的方式保证了节点的稳定。Triple 协议在通信协议层面为 Dubbo 框架增加了流式场景的支持，在此基础上能够实现上层包括大文件传输和推送机制的业务需求。但目前的用户 API 较为原始，需要用户实现 StreamObserver 。而 Reactive Stream 作为反应式编程的事实标准，反压策略也能最大程度的保证处理大规模流数据时不会产生 Buffer Overflow 。Dubbo + Reactive Stream Stub的组合模式可以给用户带来最方便的流式使用方式以及全链路异步性能提升。
目标 Dubbo Compiler 的 code generator 支持生成 Reative Stream Stub API ，如 reactor / rxjava ，提供相应使用文档和实例，支持 backpressure。

Dubbo Compiler 的 code generator 支持生成 Reative Stream Stub API ，如 reactor / rxjava
提供相应使用文档和实例

熟练使用 Java 语言
了解 Reactive Stream 模式"
"Kubernetes 中 secret 是 namespace 层级的资源，在实际的使用过程中经常会遇到需要在多个 namespace 之间共享 secret 的需求，在多个 namesapce 下去创建 secret 或是逐一编辑，会带来许多重复工作。

为此我们需要增加一个可以在多个 namespace 之间共享 secret 的功能实现，该功能可以作为 KubeSphere 的一个插件进行集成。

KubeSphere 4.0 采用了可插拔架构，便于功能拓展与服务集成。

本项目旨在使用 KubeSphere 插件框架，借助 React/Golang 技术栈，构建一个完整的插件应用，该插件允许用户在 KubeSphere 上创建 secret 资源，并在多个 namespace 之间共享，包括但不限于具体的前后端实现。

插件前端实现
插件后端实现
插件镜像

React
Helm
Docker
Kubernetes
Golang(可选)"
"morphling采用client-server结构对服务容器在不同配置下的性能做出评估，client端需要根据server端提供的服务进行定制：服务访问方式（http、grpc call .etc）、request流量的并发控制、服务性能评价指标（tps、tps/(容器资源规格成本) .etc）。这些配置目前由client端容器镜像提供定制化配置，本项目旨在提供通用的client端镜像和标准化的配置接口，为不同场景下的压测机提供定制化配置。

在morphling框架下，扩展微服务压测客户端框架，通过plugin提供通用可配置的微服务性能测试API
在框架层面，为morphling的client端提供服务压测的逻辑控制API（压测步进逻辑、测试终止条件等），产出为base docker image
在base docker image的基础上，在morphling crd层面提供通用的client端配置接口，包括但不限于： sync/async 的压测流量模式; 优化目标的RegExr定义：e.g. 优化目标是 maximize tps/容器资源规格成本，如何定义成本: 成本=cpu core*0.1 + gpu cards*0.5; 相关指标包括容器资源(cpu\gpu\mem)、服务性能指标(qps\error rate\tail rt)、优化目标的RegExr定义，在Prometheus metric的指标暴露
在base docker image的基础上，为popular service提供开箱即用的性能测试数据集benchmark，方便用户在没有足够压测流量准备的场景下，对服务进行标准化测试，包括但不限于：AI 推理任务benchmarks：MNIST database (Modified National Institute of Standards and Technology database)、General Language Understanding Evaluation (GLUE), .etc；CPU 子系统测试工具SPEC CPU2017等涵盖的benchmark
在用户定义的优化目标指标(qps\rt\resource cost)之外，对接popular performance evaluation works，从旁路收集数据，提供全面的性能测试报告，包括但不限于：服务容器资源利用率: cpu util\gpu sm util\.etc；底层硬件监控指标：cpu throttle\cpi\.etc； 首先以例如Prometheus-Grafana 的方式提供指标；其次可以进一步深入分析该服务容器的资源性能瓶颈等insight，输出分析报告

了解Kubernetes基本原理，Morphling项目的整体架构和工作原理
Client-server 结构的服务性能测试框架，JMeter等常用服务测试工具
能够根据设计方案，有优秀的编码能力和单测覆盖度，最后也能根据实现结果给出详细的测评报告"
"1. KubeEdge SIG Robotics正在关注机器人应用开发套件；
2. 学生可以基于该套件完成一个端对端的vSlam应用，主要是指用RGBD相机解决机器人定位和建图问题。
3. 当用相机作为传感器时，我们要做的，在提供的仿真世界中根据一张张连续运动的图像，利用算法推断相机的运动，以及周围环境，完成端对端开发。
4. 在尊重原作者声明权限的前提下，建议参考已有的开源项目，比如 ORB-SLAM2。

标准规格文档
端对端的算法
设计方案

Python
ros"

"ARM PMU(Performance Monitor Unit)，性能监测单元，可以收集关于处理器和内存的各种统计信息。在虚拟机内，开启PMU特性，可以有效帮助开发和维护人员分析虚拟机性能，完成系统优化。在vCPU初始化时，开启PMU特性
将PMU添加到arm fdt/acpi表
使用StratoVirt PMU特性，可以监视虚拟机性能。

输出特性设计文档
为 StratoVirt 实现监测虚拟机性能特性(PMU)
输出特性使用文档，展示性能监测结果

熟悉 Rust 编程语言
了解操作系统，虚拟化技术"
"基于openGauss的openGauss-OM项目,将当前仅支持的xml格式修改为兼容yaml/conf/properties配置文件,减少用户的配置；同时支持帮助命令辅助生成各类配置文件的模板减少用户修改项

1、参照openGauss-OM实现的xml格式内容解析方式。 2、代码改动尽量集中，满足社区编码规范，提供单元测试用例。 3、代码改动需合入openGauss社区。 4、提供设计文档（包含修改说明）和测试文档。

1、了解openGauss的基础功能 2、了解openGauss-OM的使用方式 3、熟悉python等常用的编程语言"
"NoneBot2 为用户提供了详细的文档介绍，辅助用户更好的上手项目以及进行开发。文档分为基础与进阶两个部分。基础部分帮助新用户快速上手开发，主要包括：安装 NoneBot2、使用脚手架、创建配置项目、使用适配器、加载插件、定义消息事件、处理消息事件、调用平台 API等。进阶部分向已经熟悉开发流程的用户介绍更多高级技巧，主要包括：NoneBot2 工作原理、定时任务、权限控制、钩子函数、跨插件访问、单元测试、发布插件等。目前文档对于用户而言过于费解，导致用户难以理解 NoneBot2 开发。本项目旨在优化文档内容，使其更加通俗易懂，不让文档成为用户上手的阻碍，同时完善进阶内容，让有更复杂需求的用户，同样能从文档中受益。

文档通俗易懂
附有适当的图片指引（如：asciinema）
内容完整，由浅入深
适当的界面美化，合理分配布局

熟悉文档结构组织与语言表达
熟悉 NoneBot2 框架功能
熟悉 NoneBot2 项目组织方式"
"Buddy Compiler 是一个领域特定编译器基础设施，其中中间表示（IR, Intermediate Representation）层级需要领域特定的多层编译抽象支持。我们在技术路线上拥抱MLIR生态（MLIR是多层中间表示的编译基础设施）。本项目致力于为 Buddy Compiler 提供数字语音处理的多层编译抽象。项目需要选择 1-3 个数字语音处理操作，完成相应 DAP (Digital Audio Processing) Dialect Operation，C/C++ 接口，完整应用示例，性能评估。

数字语音处理操作对应的 DAP (Digital Audio Processing) Dialect Operation
数字语音处理操作对应的 C/C++ 接口
数字语音处理操作对应的完整应用示例
数字语音处理操作对应的性能评估

熟练使用C++
基础的 MLIR 背景知识
基础语音处理背景知识"
"buddy编译器是一种特定于域的编译器基础结构，其中包括一个单独的专用方言，用于使用MLIR执行图像处理操作。这种方言被称为DIP（数字图像处理）方言。它已经支持一些非常基本的图像处理操作。本项目旨在使用MLIR为DIP方言中的形态学转换添加支持。开发的操作应得到测试和基准的支持，以将获得的输出与图像处理中现有的最先进实现进行比较和基准测试。

用于在buddy MLIR项目的DIP（数字图像处理）方言中执行形态学操作的MLIR操作。具体转换可能包括侵蚀、膨胀、打开、关闭、形态梯度、顶帽和黑帽。

上述操作的专用测试。

将创建的操作与图像处理中现有最先进的实现进行基准测试。

优秀的C/C++技能

对MLIR及其工作的基本理解

图像处理"
"全志 D1 是一款基于 XuanTie C906 RISC-V 核心的 SoC。本项目将对该芯片进行 U-Boot 的主线化开发工作。

完成该芯片的基本 U-Boot 功能，能够启动 Linux，并将相关上游代码进行整理以提交。
如 U-Boot 本体成功完成，尝试基于其实现 SPL，及实现显示支持。

编译交叉工具链（可使用现成工具）。
使用 Git 代码管理（使用 commit, rebase 等操作）。
编写 C 语言代码（能参照现有代码编写新设备的驱动代码）。
使用英语与上游项目或社区交流（编写提交信息 [commit message]，在邮件列表上接受补丁审阅 [patch review]）。
了解 RISC-V 指令集（能看懂 GCC 输出的汇编代码）。"
"开放集群管理（OCM）是一个社区驱动的项目，专注于Kubernetes应用程序的多集群和多云场景。在这个项目中，开放API正在发展，用于集群注册、工作分配、策略和工作负载的动态放置等等。

分布式跟踪是一种观察请求在分布式云环境中传播的方法。分布式跟踪通过使用唯一标识符标记交互来跟踪交互。当事务与微服务、容器和基础设施交互时，该标识符将保留在事务中。

Open Telemetry是工具、API和SDK的集合。使用它来检测、生成、收集和导出遥测数据（指标、日志和跟踪），以帮助您分析软件的性能和行为。

分布式跟踪的概念起源于微服务框架。开发人员可以将“跟踪上下文”插入服务实例之间的请求流中，这些服务将以“跟踪”或“跨度”的形式将其活动上载到集中的跟踪存储中。因此，管理员不仅能够可视化服务拓扑图，还能够可视化细粒度统计信息，例如每个实例的时间成本等。

在本项目中，我们可能会将分布式跟踪引入一个场景，其中多个Kubernetes集群在“中心辐射”范式中工作——一个“中心”Kubernetes集群是向其他工作负载“辐射”集群发送任务/处方的总体主管。在每个Kubernetes集群内，可以有一个或多个“操作员”，该操作员是一个控制器，从集群订阅事件，并在收到通知后不断协调/处理相应的资源。与请求跟踪类似，我们将在集群中向Kubernetes操作员的工作流中注入“跟踪上下文”，因此操作员每次协调资源时，也会将“跟踪”记录上载到远程存储器。然后，“中心”集群中的总体管理员将能够清楚地可视化集群之间发生的交互流。

在我们的项目中，我们将首先利用开放遥测技术，将分布式跟踪引入OCM的核心组件，开放遥测技术既是该技术的规范，也是该技术的实现。开放遥测代理（或“收集器”）应作为插件自动安装到OCM环境中，这些代理将从OCM组件收集活动，并将其推送到远程存储。


基于OCM的插件框架开发“开放遥测”插件
（可选）从收集的轨迹可视化多集群操作员工作流

Golang
Kubernetes"
"Qiling框架是一个高级二进制虚拟框架，具有以下特性：
虚拟多架构: X86, X86_64, Arm, Arm64, MIPS, 8086
支持多种文件格式: PE, MachO, ELF, COM, MBR
通过Demigod支持Windows 驱动(.sys), Linux 内核模块 (.ko) & MacOS内核 (.kext)
在独立环境中沙箱化虚拟代码
提供一个完全可配置的沙箱环境
提供了内存、寄存器、操作系统和文件系统级别API
细粒度插桩: 允许进行多种级别的hook (指令/基本块/内存/异常/系统调用/IO等)
提供虚拟机级别的API，例如保存和恢复当前执行状态\
支持跨架构和平台调试功能
带有反向调试功能的内置调试器
允许动态热补丁运行时代码，包括加载的库
真正的Python框架，使其易于构建定制的安全分析工具
考虑到Qiling框架所带来的丰富功能让人应接不暇，种类多样的API对初学者还不够友好，我们希望为Qiling框架实现一个终端UI界面，从而大大降低Qiling框架的使用难度。

为Qiling框架设计基于终端的UI操作界面
具有友好的终端交互界面
能够支持绝大部分Qiling框架功能
完成项目的设计、开发、测试并提供使用文档

具有Python开发能力"
"Milvus 是一个世界级的分布式向量数据库。我们想添加一个很棒的人脸识别的demo来展示 Milvus 的能力，并逐步教用户如何在现实生活中的 AI 应用中使用 Milvus。

打造一款优秀的，功能齐全的人脸识别的Milvus Bootcamp项目

扎实的深度学习和计算机视觉知识"
"Hypercrx有两大职能，其一是作为Hypertrons的前端，其二是可视化X-lab开放实验室提供的基于GitHub全域日志分析得到的数据。此项目同时涉及到这两个职能。

任务1。Hypercrx在Repo页面运行时会尝试获取该Repo的.github/hypertrons.json中的部分信息，从而调整相关配置。现在我们希望实现一个功能：当Repo维护者在hypertrons.json中添加一个名为“repo_banner_text”的键值对后，安装了Hypercrx的用户就能在Repo页面看到一个横幅，横幅中滚动播放着“repo_banner_text”中的文字。

任务2。我们曾经基于Anichart.js实现了动态柱状图（见#221），用于展示项目贡献者的活跃度变化情况。但在实际应用中，我们发现Anichart.js存在诸多缺陷，并且数据来源也存在不足之处，所以我们暂时下架了该功能。经过调研，我们认为Echarts具备实现动态柱状图的能力，希望你能利用Echarts使动态柱状图重出江湖。

任务3。该任务与项目2有关联。我们希望在项目2的中选者完成“AVC机制”的设计后，你能用此机制将两个React组件注入到GitHub页面中。在此之前，你可以模仿现有的旧方式将组件注入到页面中预览效果。

3个任务的具体要求之后会在相应的issue中给出。另外，当Summer2022开发阶段开始后，为了更好地了解中选者的项目进度，我们希望你能在指定issue中，以每两周一次的频率更新你的进展。

最后，欢迎前往项目仓库的Discussions栏与我们交流！

设计并实现React组件ScrollingBannerText
设计并实现React组件DynamicBar
遵循“AVC机制”将两个组件注入到GitHub页面中

了解Chrome Extension的开发方式
了解Hypercrx的工作机制
熟悉HTML、CSS、JavaScript、TypeScript
熟悉Echarts
熟悉Git和GitHub"
"目前 Flink 的 Source 原生不支持限流，基于Flink Source的 CDC 连接器也无法实现限流功能，当并发从上游数据库读取数据时存在风险，本题目通过在 Flink Source上提供限流功能，CDC 连接器适配后，便可实现读取数据时限流。

学习 Flink CDC 技术原理，在开源社区设计并实现通用的 CDC 数据源限流方案，提升 Flink CDC 在大规模数据业务场景下的稳定性。
在 Flink 社区 完成 Source 数据限流 API 设计
基于限流 API， 在Flink CDC 社区实现 MySQL CDC 数据限流功能

学习 Flink，CDC，数据集成等相关技术，学习 Flink CDC 的技术架构和实现。"
"目标：支持 python java 等语言的 remark 插件，以及支持对 LaTeX 格式的数学公式进行格式化

目前 OI-Wiki 仓库中使用的代码语言包括 C/C++, Rust, Java, Python 等等，但是我们目前只对 C/C++ 语言编写了格式化插件，调用clang-format进行了格式化。希望你能编写remark插件，来格式化其他的语言。另一方面，由于LaTeX数学公式的语法较为复杂，目前市面上暂时还没有LaTeX公式的格式化器，我们还希望你能编写LaTeX公式的格式化器。

实现 python java 等编程语言的格式化插件
实现数学公式的格式化
协助解决目前项目中存在的 issue

前端开发的相关知识（HTML/CSS/Javascript/Typescript/React）
能使用 Git 进行协作开发
熟悉 remark 工具链者优先"
"设计并实现KubeEdge在边缘场景的测试用例，提升KubeEdge项目的测试覆盖，保障项目的稳定性。

设计kubeedge在边缘离线时的可靠性用例
设计kubeedge在边缘离线自治的可靠性用例

了解KubeEdge的使用场景，了解测试框架"
"作为Serverless应用全生命周期管理工具，Serverless Devs目前还是以命令行的形式存在，故在开发态的支持比较弱。选择该题目的同学，需要了解Serverless Devs相关内容以及具备基本的业务开发能力，完成Serverless Devs的VSCode插件设计与开发。

完成Serverless Devs 的插件开发并贡献给社区
按照需求https://github.com/Serverless-Devs/Serverless-Devs/discussions/444，完成功能开发
完成与FC组件的对接

对Serverless有一定的了解，或者愿意学习和了解Serverless架构
对Node.js，Typescript等语言有所了解，或者具有较强能力可以快速学习Typescript语言
了解并熟悉对Github等使用方法"
"Tarantool目前使用了多个虚拟机：
2种操作模式下的Lua JIT（Lua字节码解释器和生成本机代码的JIT跟踪）；

SQL引擎的SQLite派生VM代码称为vdbe
Vdbe没有提供最佳性能，并且看起来与塔兰托代码库的其他部分不一样。GSo C 2021的一个项目探索了用于SQL引擎速度改进的LLVM JIT工具-用于塔兰托DQL的LLVM JIT引擎

人们应该拿起这个项目，使其功能完整，性能基准，并对一般情况进行微调。

Tarantool SQL使用JIT代码生成来执行算术运算和聚合函数

与VDBE中的解释相比，分析查询（即TPC-H）速度更快"
"Lua-JIT是Tarantool 的心脏，它的稳定性与Lua-JIT的稳定性密切相关。但问题的统计数据表明，我们在生产中使用塔兰托，通过LuaJIT[1]捕捉到了bug。我们需要降低此类错误的概率，并在Tarantool 发布周期中引入更多的Lua JIT生成性测试。

测试的一些想法是：

使用现有Lua脚本语料库进行变形测试。

使用Lua语法和塔兰托嵌入函数的内省自动生成脚本。

使用嵌入式错误注入引擎（参见src/lib/core/errinj.c）或使用具有LD预加载的外部库在内存分配中进行故障注入

CI中的额外模糊目标"
"由于 Idea 更新迭代频繁，现有 xmake-idea 插件编译存在很多的废弃 API 使用警告，并且最新 CLion 版本也不再支持，因此需要做一些更新支持

并且需要新增一些配置选项用于支持最新版本的 Xmake 的配置

- 兼容最新版本的 CLion
- 移除所有废弃的 API 使用，并且在不影响功能的前提下，使用新的 API 进行替代
- 配置面板增加一个工具链切换的配置选项
- 更新现有配置中，平台，架构的选项列表
- 检测 xmake.lua 改动自动更新生成 CMakeLists.txt 和 compile_commands.json 文件

兼容最新版本的 CLion
移除所有废弃的 API 使用，并且在不影响功能的前提下，使用新的 API 进行替代
配置面板增加一个工具链切换的配置选项
更新现有配置中，平台，架构的选项列表
检测 xmake.lua 改动自动更新生成 CMakeLists.txt 和 compile_commands.json 文件

熟悉 Kotlin, Java
了解基本的 Idea 插件开发流程
熟悉 C/C++ 的编译构建
熟悉 Clion 的使用"
"完善XQUIC 网络诊断、故障排查工具需要 完善XQUIC的CI/CD能力 并 将XQUIC日志转换为标准qlog格式并在qvis上可视化；
当前在Github Actions中查看单个测试用例运行结果较麻烦，希望集成到 Travis CI 或其他平台，能够分别查看各用例运行情况。
了解QUIC协议(draft-ietf-quic-transport, draft-ietf-quic-http)，掌握qlog标准(draft-ietf-quic-qlog-main-schema, draft-ietf-quic-qlog-quic-events, draft-ietf-quic-qlog-h3-events)，将XQUIC日志转换为标准qlog格式，利用qvis平台(https://qvis.quictools.info)将qlog日志进行可视化

对于刚接触XQUIC的新用户来说，当前QuickStart Guide还不够Quick，本项目旨在优化该文档，让用户以最简单和最快的方式完成项目构建和运行体验；

将XQUIC日志转换为标准qlog格式； 正确在qvis平台(https://qvis.quictools.info)展示Sequence、Congestion、Multiplexing、Packetization、qlog stats；
学习CI/CD框架的工作原理与配置方式，将XQUIC集成到Travis CI 或其他平台上，快速清晰地查看测试用例运行情况；
简洁明了的QuickStart文档，任何人可以快速上手完成项目构建和功能体验，无任何歧义和不符合预期的地方；

学习QUIC协议及XQUIC日志实现； 学习qlog标准并学习使用qviz平台 ;
学习 XQUIC 的构建方式及测试流程； 了解 CI/CD；"
"MNN是淘系技术自研的全平台轻量级高性能深度学习引擎。它已支持TF、Torchscript、ONNX、TFLite、Caffe等模型格式。本项目希望将MNN模型格式与TVM IR打通互转，从而支持MNN模型可被TVM进一步优化；对于动态形状的模型，由MNN经过resize步骤后转至TVM，进一步编译优化

完成MNN - TVM IR互转
贡献至MNN Github 开源社区
产出技术文档

熟悉C++、Python语言
了解TVM
对深度学习引擎、高性能计算有兴趣
（可选）对MNN推理引擎有使用经验"
"基于 Apache APISIX 的 xRPC 框架实现 dubbo 2 协议的代理功能，需要能根据配置动态路由，并增强其可观测性。

支持根据配置（service_name \ version 等）进行动态路由
可以在日志中记录当前请求的相关参数，如 service_name 等等
为上述功能提供详尽的文档

能够跑通多个 dubbo 官方的示例
能够有充分的测试覆盖"
"OI Wiki 有着长达五百余行的格式手册和一百余行的 htc，这些文档包含了详细的项目要求。但是这些文档很长，一条条手动检查耗时很长，并不现实。参考其他项目的选择，我们需要制作一套工具，尽可能的检查是否满足了要求，如果可能，可以更进一步实现自动修正。

完成基础的文档格式、辅助数据和提交信息的检查
进一步可以添加 CI 和 Git Hook 集成
进一步可以帮助完善格式要求及文档
进一步可以实现自动修正

熟悉 Bash、Perl、Python 和 TypeScript 中的一门或几门语言
能使用 Git 进行协作开发"
"一般来说，物联网平台提供安全可靠的设备连接通信能力，支持设备数据采集上云，规则引擎数据流转和云端数据下发设备端。此外，也提供方便快捷的设备管理能力，支持设备定义，数据结构化存储，和远程调试、监控、运维。本项目的目标是通过开源的MQTT物联网平台框架（如Thingsboard，EMQ等），配合云服务器，手动打造一台支持HaaS Python接入的简易物联网云平台。

 HaaS Python是阿里云IoT团队最新研发的一套低代码编程框架，兼容MicroPython编程规范，依托HaaS平台软硬件积木提供AI、支付、蓝牙配网、云连接、UI等物联网场景常用的能力，从而解决了物联网应用开发难的问题。

在HaaS硬件上实现HaaS Python轻应用接入到该物联网平台
至少支持一种数据通讯格式，比如MQTT（版本3.1），同时支持CoAP、http2则更佳。
支持基本的产品创建、设备创建、设备管理等，功能可以参考阿里云物联网平台。https://help.aliyun.com/product/30520.html

至少熟悉一种数据通信协议，MQTT"
"MNN是淘系技术自研的全平台轻量级高性能深度学习引擎。目前MNN Model Hub已带有一定数量的模型（https://market.mnn.zone/s/#/modelmarket/list/）。
此项目希望参与的同学阅读CV、NLP、ASR等SOTA论文，将其中模型转为MNN格式并贡献至MNN开源社区

开源之夏MNN项目选题论文、完成要求与申报提示：

类别1. 分类、分割、语言、视频类经典或最新模型
论文参考：
（1）MobileNet   v3；分类模型mobilenet的结构优化，用于上手练习。
（2）<Training   Deep Networks for Facial Expression Recognition with Crowd-Sourced Label   Distribution>；情绪识别。
（3）mobileNext   <Rethinking Bottleneck Structure for Efficient Mobile Network   Design>；分类模型结构优化。
（4）bert-squad   <BERT: Pre-training of Deep Bidirectional Transformers for Language   Understanding>；语义理解模型。
（5）ALBERT   V1<ALBERT: A Lite BERT for Self-supervised Learning of Language   Representations>；语义理解模型。
（6）ALBERT   V2；语义理解模型。
（7）<Masked   Autoencoders Are Scalable Vision Learners>；CV自监督学习方法。
（8）ConvNext   <A ConvNet for the 2020s>；卷积网络在视频领域从被transformer超过到反超。
（9）GPT-2,   https://openai.com/blog/better-language-models/；语义大模型 gpt-2比gpt-3小,可在PC   GPU或高端手机运行, 参考onnx   https://github.com/onnx/models/tree/main/text/machine_comprehension/gpt-2。
（10）<SparseTT:   Visual Tracking with Sparse Transformers>；视觉追踪。
必选任务：复现论文转化为MNN模型,提交社区
进阶任务：典型输入，在自己机器或手机上得到推理耗时、功能指标
高阶任务：修改代码，更新模型，加速推理

类别2. 神经渲染，三维重建，部分需要写代码复现
论文参考：
（1）<NeRF:   Representing Scenes as Neural Radiance Fields for View   Synthesis>；开创性方法，复杂场景神经渲染合成指定视图。
（2）<MINE:   Towards Continuous Depth MPI with NeRF for Novel View   Synthesis>；基于nerf，单张图片重建。
（3）<Mip-NeRF   360: Unbounded Anti-Aliased Neural Radiance Fields>；360度全景图 神经渲染三维重建。
（4）<Ref-NeRF:   Structured View-Dependent Appearance for Neural Radiance   Fields>；提升真实性的神经渲染。
（5）<Block-NeRF:   Scalable Large Scene Neural View Synthesis>；大场景神经渲染。
必选任务：复现论文转化为MNN模型,提交社区
进阶任务：典型输入，在自己机器或手机上得到推理耗时、功能指标
高阶任务：修改代码，更新模型，加速推理

类别3. 点云，场景
论文参考：
（1）RepSurf-U   <Surface Representation for Point Clouds>；从三维点云重建表面的模型，极轻量。  
（2）PointMLP   <Rethinking Network Design and Local Geometry in Point Cloud: A Simple   Residual MLP Framework>；从三维点云重建表面的模型，极轻量。
（3）<READ:   Large-Scale Neural Scene Rendering for Autonomous Driving>；大场景合成，用于自动驾驶仿真。
必选任务：复现论文转化为MNN模型,提交社区
进阶任务：典型输入，在自己机器或手机上得到推理耗时、功能指标
高阶任务：修改代码，更新模型，加速推理

类别4. 难度高,分值大, 20选1即可! GPU推理加速。
（1）AStitch: Enabling a New Multi-Dimensional Optimization Space for Memory-Intensive ML Training and Inference on Modern SIMT Architectures；优化算子间的数据通信,优化加速推理；
必选任务：原文在tf上实现,复现其结果。
进阶任务：典型输入，在自己GPU或手机上得到推理耗时、功能指标
高阶任务：在 tvm或mnn开源代码上实现此方案
（2）Design Principles for Sparse Matrix Multiplication on the GPU；设计GPU的稠密与稀疏矩阵乘法,加速推理；
必选任务：复现其结果。
进阶任务：典型输入，在自己GPU或手机上得到推理耗时、功能指标
高阶任务：在 tvm或mnn开源代码上实现此方案

添加CV、NLP、ASR等领域SOTA MNN模型（10+）
贡献至MNN Github开源社区
产出技术文档

熟悉Python语言
对深度学习引擎有兴趣
（可选）对MNN推理引擎有使用经验"
"ShardingSphere-Proxy 是 ShardingSphere 产品中作为代理中间件出现的产品。现阶段 Proxy 缺乏在 kubernetes 中部署和自动运维的能力。Operator 作为 kubernetes 中可以帮助运维人员去解决一些特定的应用的自动化处理流程的工具，可以帮助 Proxy 更好的实现在 kubernetes 环境或者云环境上的部署和自动运维的能力。

能够完成在Operator中对ShardingSphere-Proxy 的全生命周期管理。

熟悉 Kubernetes Operator"
"Tiny SQL 是一个分布式关系型 DBMS 学习系统，由 Talent Plan 社区根据著名的 Ti DB 开发而成。

它主要涵盖解析器、只读数据库、插入和更新、优化器和 MPP 模块。

已有1500多名来自WW的学生完成了学习。

该项目将通过包括新知识、文档、实验室和测试用例来改进 Tiny SQL。

需要关系 DBMS 实现和围棋技能的知识，良好的技术写作技巧是加分项。

完成所列出issue的Stage 1~4， Stage 5 is a plus

完成所列出issue的Stage 1~4， Stage 5 is a plus"
"Xdelta3是一种优秀的、被广泛使用的差量更新算法，它在操作上既有对新文件和旧文件的差分又有对产生的patch包进行压缩，我们将产生patch包的过程统称为加密，而将合成新文件的过程统称为解密。Xdelta3和经典的压缩算法LZ’77一样，也是将source file划分成一个个不相交而又连续的window，然后进行加密和解密。

适配OpenHarmony的构建体系
满足OpenHarmony社区代码规范
基于OpenHarmony平台通过demo/单元测试用例
提交仓库到TPC
输出本三方库在OpenHarmony下的能力，导出库对外提供的函数接口和已测试过的函数接口

C，熟悉Makefile"
"Z是禅道（禅道项目管理软件）的DevOps命令行工具，使用它可轻松完成禅道以及DevOps的相关操作。它支持查看和操作禅道项目集、项目、产品、执行、需求、任务、Bug；支持创建合并请求以及本地代码合并执行流水线检查；支持执行禅道流水线，查看流水线任务日志。

我们希望同学可以：
1. 了解和学习禅道的使用流程，达到熟悉禅道中各个模块功能的使用。
2. 完成“通过在开发环境安装Z工具后，在提交代码时可以对git commit和git push命令进行监听，通过Z工具创建评审信息，并发送评审通知”的任务。

1. 可以在Linux环境下，通过命令行的形式，与禅道系统进行通信。
2. 可以监听git命令，或通过Z工具模拟git命令，进行代码commit和push时触发自动化测试流程，并提交评审信息到禅道。

Linux基础
PHP"
"Redis目前采用单worker线程模型，由于其全内存存储，对于复杂度较低的查询请求有非常高的并发处理能力，但是对于复杂度较高的请求仍需要消耗大量计算资源，同时会导致其他所有请求排队影响性能。该题目旨在开发快慢分离系统，实现thread offloading of slow operations。

实现慢查询的异步执行

熟练掌握C语言，对Redis有一定的了解"
"窗口函数是流式计算的核心概念之一，也是开源边缘流式计算引擎 eKuiper 常用的功能之一。eKuiper 实现了几种常见的时间窗口和计数窗口，但是目前对于较长时间的窗口的优化仍较为欠缺。流式计算窗口的使用场景多种多样，业界和学术界已有较多的研究和优化方案。本项目的目标是对任一窗口函数的性能和资源占用进行优化。完成项目可以帮助开发者更深入地理解流式计算，大数据领域和数据库SQL引擎等方面的通用知识并应用于今后的工作学习中。

针对一种或几种窗口进行优化，并提交PR到 eKuiper 社区
完成调研方案
完成至少一种优化并提交源代码和单元测试
更新使用文档

了解或学习流式处理"
"背景：

1. istio 是 ServiceMesh 方向上一个非常火热的解决方案，默认使用 envoy 作为数据面。
2. mosn 作为一个对标 envoy 的另一种数据面实现，也可以跟 istio 集成，作为 envoy 的一种替代方案。
3. layotto 作为 Application Runtime 的一种实现，基于 mosn 开发，期望可以结合 Service Mesh 跟 Application Runtime 两种思想。

任务描述：

既然 istio 可以集成 mosn ，且 layotto 跟 mosn 是一体的，因此本次的任务是把 layotto 作为数据面跟 istio 进行集成，以服务调用为例，在应用通过 layotto 的 invokeService API 去调用目标服务时可以直接复用 istio 强大的治理能力，比如流量控制、故障注入等等。

layotto 之前就已经可以跟 istio 1.5.x 集成，由于落后当时的 istio 版本太多，最终没有合并到主干，本次任务希望可以集成 1.10.x 之后的istio。

用 layotto 替换 istio 中的 envoy 作为数据面部署
通过 layotto 发起的服务调用可以复用 istio 强大的流量治理能力

可以使用Go语言进行编程
了解 istio 集成数据面的原理
了解 istio 各种流量治理能力的用法"
"secGear是面向计算产业的机密计算安全应用开发套件，旨在不同的硬件设备上提供统一开发框架，让用户不感知底层各种机密计算架构和接口的差异，目前secGear支持Intel SGX硬件和ARM Trustzone(安全os支持iTrustee)。
本项目为secGear选择已有开源的或开发一个测试框架，并开发UT用例，以防护secGear的功能正常。

1、集成测试框架，可在不同平台上运行。
2、关键特性有用例覆盖。

1、掌握C语言。
2、熟悉cmake、UT测试的同学优先。
3、了解机密计算的优先。"
"用Joomla建立一个多语言系统非常容易。您可以使用多种内容语言发布内容，并将其相互关联。

挑战之一是使所有翻译保持最新。如果你有一篇用英语、德语、中文和印地语创作的文章，你通常会将所有文章内容对齐。但是如果你更新英文文章，现在会发生什么？编辑也不太可能会说所有其他语言来更新它们。所以其他译者必须意识到他们的文章已经过时，这样他们才能更新。

在项目结束时，在编辑多语言内容时，应该可以将其标记为“新内容”。这样做会将相关内容标记为“过时”，直到更新为止。应该可以过滤此状态。在列表视图中，应标记过时的语言。此外，应该可以看到（通过diff view？）更新过时语言时主语言的变化。

开发人员需要很好地理解Joomla结构，尤其是设置多语言页面，包括创建多语言项及其关联。PHP和数据库知识是必须的，如果开发人员能够进行基本的前端开发（HTML、JS、CSS），这也是一个加分"
"ChaosBlade 包含故障注入工具,通过部署 chaosblade-operator 实现云原生故障场景注入，KubeVela 是一个现代软件交付平台，可让您在当今的混合多云环境中更轻松、更快速、更可靠地部署和操作应用程序。KubeVela 提供自定义扩展组件 Addon 的能力 ，可以很好的在应用生命周期内调用执行。

现需要完成将 ChaosBlade 作为 KubeVela Addon 组件集成到 KubeVela 中，支持 chaosblade-operator 部署，通过创建 trait 实现故障注入，并将测试结果上传到 prometheus 中，在 KubeVela grafana中看到注入情况。

基于 KubeVela 组件规范完成 ChaosBlade Addon 组件扩展
实现故障注入指标导入到 Prometheus 中
实现在 KubeVela 提供的 Grafana 控制台中展示

熟悉 Kubernetes Operator"
"重构 Tengine 社区文档，现有地址 http://tengine.taobao.org/。项目内容包括熟悉Tengine使用，重新组织文档结构，补足QuicStart文档，已经常见场景的文档化。通过本项目，可以让学生对 Tengine、网关领域应用场景的有一个全面的理解。

重新设计文档结构，使社区文档结构清晰
简洁明了的 QuickStart 文档，包括 环境准备、编译、部署、镜像化、常见问题排查，开发者可以快速上手
整理社区 FAQ
常见场景的文档化，如服务发现、健康检查常见使用

熟练掌握 C 语言，对 Tengine 有一定了解
英文基础较好，文档写作能力较强
对web框架有一定了解"
"目前基于RISC-V生态和应用场景逐渐完善，尤其在低功耗AIOT场景，我们希望开发者基于Paddle Lite推理引擎，在RISC-V硬件上能够充分发挥架构特点，在经典模型上取得较高性能。

Paddle Lite 是一个高性能、轻量级、灵活性强且易于扩展的深度学习推理框架，定位于支持包括移动端、嵌入式以及服务器端在内的多硬件平台。

基于RISC-V指令集在Paddle Lite实现常用OP
使用mobilenetv1和resnet50模型完成性能分析与验证

熟悉 C++"
"openEuler gopher[1] 用于采集OS进程/线程粒度运行态数据（比如网络TCP数据、磁盘I/O数据等），gopher所采集的数据、应用自身的KPI数据两者通过特征训练可以得出不同应用对应不同特征向量。
特征向量的准确性，可以直接决定应用性能卡顿故障识别的准确度。传统的手段：应用性能卡顿问题通常需要系统级专家会诊，使用各种不同的工具采集不同数据，由专家综合各方面信息结合专业知识得出定位结果，定位过程耗时耗力。openEuler gopher是采用eBPF技术的一款结合专家经验的数据采集器，其默认会采集系统内大部分影响应用性能的大部分性能类、异常类数据，比如I/O时延、TCP RTT/重传、off-cpu、内存等等。其采集粒度达到进程/线程粒度，采集数据可以通过prometheus exporter上送至prometheus。

应用范围：推荐mysql、memcache、Redis。（参赛者也可以选取一款自己熟悉的，且比较普及的开源软件
应用卡顿故障类型：网络类（丢包、时延、重传、乱序等）、磁盘I/O（时延、IO带宽等）、CPU（负载等）几类故障（包括但不局限，问题类型越多，评分越高）
特征向量：应用类型、应用负载（QPS/TPMC等）、故障类型、故障注入方法、特征向量（普罗内的KPI、特征向量系数（比如相关性）
验证方法：对系统进行故障注入，并对相关指标进行异常检测，相关性top5的指标可正确检测出异常事件即为合格。
异常检测方法：3-sigma、vae模型（推荐）等。
异常事件判定：固定时间（<10min）内检测出3次异常即判定为1次异常事件。
产出内容：特征向量、验证报告
[可选]gopher新增/修改采集数据：参赛者在实现过程中识别出gopher采集数需新增/更新时，可以自己贡献代码至openEuler gopher项目[3]或者直接提交issue，由openEuler社区工程师评审后修改合入。

熟悉linux系统操作；
熟悉特征向量训练的常见AI算法；
熟悉应用（参见应用范围）性能测试方法；
熟悉故障注入方法[2]，包括网络故障注入、CPU压力注入、磁盘I/O时延故障注入等；"
"einsum 是一个通用性很强的op，可以用简洁的形式表达多种计算；在 Paddle Lite 移动端推理中，高效实现 einsum 算子，适配 Arm CPU，OpenCL等设备。

Paddle Lite ：一个高性能、轻量级、灵活性强且易于扩展的深度学习推理框架，定位于支持包括移动端、嵌入式以及服务器端在内的多硬件平台。

在 Paddle Lite 上实现 einsum 算子的开发 (必需支持 Arm CPU，可选支持 OpenCL)

熟悉 C++"
"Dragonfly 是 CNCF 中用于文件分发的P2P产品，可以有效支撑海量规模的P2P文件下载。Dragonfly各个子系统间的通信框架是支撑整个P2P文件下载效率性能的核心，通过它连通了各个系统间的交互，保证系统间的高效通信和故障迁移。对于整个系统的正常执行起到zhi观众高

完整参与通信框架的研发，并且通过性能压测获得30%以上的性能提升

通信框架的可用性需达到 99.9% 以上"
"实现Sentinel各种规则的灵活粒度配置以及提供一定的熔断限流可观测能力

实现 Sentinel 各种规则灵活粒度配置，可以不再依赖 Sentinel 动态数据源，直接利用 Spring Cloud 的动态刷新能力，能直接对资源或者路径配置流控，降级等规则。
对Spring Cloud Alibaba服务进行多方位，多细粒度的熔断，结合Nacos配置中心进行动态熔断规则变更
对Spring Cloud Alibaba服务熔断时候，通过调用链方式进行实时界面化追踪，有助于脱离日志分析， 即见即所得的分析各种熔断信息

暑期6~9月期间保证每周有至少有40个小时参与项目。
熟悉 Spring Cloud 动态刷新原理，对 Sentinel 的特性比较熟悉。
了解Nacos注册中心和OpenTracing、Prometheus和Jaeger等链路追踪组件。
良好的沟通和协作能力，不畏难，能在导师指导下克服困难完成题目和答辩。"
"了解系统的状态总是很重要的。目前，重要信息遍布整个系统，有时很难找到所需的状态信息或信息缺失。

因此，一个包含所有信息的信息页面对站点管理员非常有帮助，特别是如果第三方开发者也可以将其安装的扩展的状态信息推送到那里。

在项目结束时，应该有一个或多个页面，提供有关Joomla的专用状态信息！健康是一种非常全面的方式。第三方开发者也可以增强此页面，以显示其扩展的状态。应该实现一个模块（和插件），在仪表板上提供一个简短的摘要，并在任何东西损坏时警告用户。

其他不同的基本信息目前在Joomla中不可用！应实现并显示，例如文件系统的状态（或有任何损坏、丢失的文件）和用户可能感兴趣的任何KPI。如果有什么需要用户注意，则应显示与问题的直接链接。

开发人员需要充分了解Joomla结构和需要额外注意的关键点。PHP和数据库知识是必须的，如果开发人员能够进行基本的前端开发（HTML、JS、CSS），这也是一个加分"
"目前Arthas里依赖的Async Profiler版本是2.6，但是Arthas的功能特性都是基于Async Profiler 1.8版本开发的。

1. 因此需要升级Arthas里依赖的Async Profiler到2.8版本
2. 适配最新版本的Async Profiler的功能和特性，提升或者增加Arthas产品特性

在arthas中适配新版本的Async Profiler

调整参数支持，支持Async Profiler新特性"
"应创建内容起草系统（可能通过工作流集成），以便在旧版本仍处于活动状态时起草（和查看）文章。

应解决以下挑战：

如果我正在起草一份草稿，但必须修复活动版本中的拼写错误，会发生什么？

我们可以使用版本控制系统进行绘图吗？

如何通过工作流实现这一点，以便草稿也可以通过确认流程运行

在项目结束时，应该可以为现有内容创建草稿，因此会创建更新，但不会在网站上发布。然后，该草稿可以随时转换为实时内容。在起草过程中，必须实施一个解决方案，也可以更改活动内容。建议使用版本控制和工作流等现有功能。

开发人员需要充分了解Joomla结构和需要额外注意的关键点。PHP和数据库知识是必须的，如果开发人员能够进行基本的前端开发（HTML、JS、CSS），这也是一个加分"
"中科大校内有一套网盘系统睿客网（英文指代暂规定为 recdrive），此系统目前仅有网页界面而没有命令行接口，因而无法轻松地将睿客网提供的云存储整合到其他系统中。我们计划在此次项目中，为睿客网实现一套 SDK，支持基础的文件 CURD 操作，然后将此 SDK 整合到云存储命令行工具 Rclone 中，提供给用户一份 Rclone plugin 或是直接合并至 Rclone 上游。

基础：提供一套 SDK 支持睿客网网盘文件的 CURD
需要保证 Go 中可用以满足下一阶段的条件
除 Go 外，可以使用 Rust/C/C++ 编写，只须提供 Go 中调用的方案即可
由我们提供测试帐号
进阶：对接 Rclone，提供一份睿客网的 Rclone plugin
Rclone 的各种子功能，如 cache 等，可以酬情对接，以可用为第一要义
开发者可以尝试将此功能提交到 Rclone 上游进行合并

掌握 Go 语言，或是掌握 Go 语言 FFI 并掌握另一门可 Go FFI 的语言
能理解文件系统语义，对 FUSE 等类似部件有一定了解
能阅读以 Rclone 为例的大型 Go 开源项目的源码并分析出扩展时需要对接的部分"
"Viterbi译码器大量用在短距通信，IOT通信芯片，卫星通信，以及3GPP控制信道，不同的应用场景，卷积码多项式不同，吞吐率要求不同，对成本功耗要求也不同，需要根据实际的应用场景定制最经济的电路规格。

实现Viterbi咬尾卷积译码算法

SpinalHDL
Chisel
Verilog
DSP"
"软件包安装器是桌面系统的重要程序，一个好的软件包安装器可提高桌面系统的易用性

1、 当前的软件包安装器使用dnf接口，需要增加rpm接口适配，保证在yum源无法使用时，软件包可以安装
2、 增加软件包批量安装功能
3、 优化qt调用dnf接口程序，使用python和c的混合编程接口，优化代码美观性（可选）

1、 语言要求python和qt
2、 熟练yum，rpm，linux的基本使用，熟悉yum，rpm接口文档"
"SLI(service level indicator)是度量服务可用性的指标，常见的SLI包括延迟、吞吐量、可用性和错误率等。
openGauss[1]是华为自研的一款企业级开源关系型数据库，RTT是其重点关注的SLI，且由于数据库的时延敏感性，对SLI的采集和上报需要在尽量低底噪的条件下进行。
openEuler gopher[2]是基于eBPF的低负载探针框架，致力于提供裸机/虚机/容器场景下的云原生观测引擎。
本项目要求基于openEuler gopher开发eBPF探针，实现openGauss场景的SLI测量和上报。

1、基于openEuler gopher开发eBPF探针，实现对openGauss服务端的SLI的测量和定期上报
2、代码合入指定仓库指定分支
3、提供测试报告，确定测试符合预期

1、熟悉linux内核ebpf机制
2、熟悉openGauss使用和通信协议
3、遵守linux代码规范"
"objtool是linux在x86静态分析&运行时推栈信息生成工具，为了实现arm64的可靠推栈，现在社区正在进行其移植工作。
协助社区进行arm64的可靠推栈的验证测试，保证objtool的移植可用性。

1、根据arm64推栈特性设计相应的测试用例，测试尽可能覆盖到特殊情况（irq、unconstructed frame）
2、实现测试用例，要求对stacktrace代码覆盖率达到80%以上
3、如果对objtool有相应的bugfix，可以合并推送到当前的社区邮件列表RFC patch

1、熟悉掌握Linux命令
2、熟悉掌握 C 编程语言
3、熟悉objtool静态分析工具的原理
4、熟悉arm64运行时栈内存分配原理"
"StratoVirt是计算产业中面向云数据中心的企业级虚拟化平台，实现了一套架构统一支持虚拟机、容器、 Serverless三种场景。StratoVirt在轻量低噪、软硬协同、Rust语言级安全等方面具备关键技术竞争优势。目前Stratovirt标准机型已经支持PCIe Native机制的热插拔，希望支持ACPI机制的PCI设备热插拔。

支持ACPI机制的PCI设备热插拔

熟悉Rust语言
了解ACPI机制
了解PCI设备的热插拔机制"
"Vineyard支持这两种方式来支持不同计算引擎之间的高效零拷贝数据共享，a. 内存映射，b. managed language（例如Java）可以通过高效的跨语言方法调用来访问对象的方法，并且这个过程中不会有特别多的跨语言调用的开销（众所周知，FFI（例如JNI）的执行效率一直是一个问题）。针对这个问题，Vineyard已经和FastFFI项目有很多共同的努力，并且也在实际应用中取得了一些比较好的结果。FastFFI将一部分JNI的JVM bytecode编译到UNSAFE代码和LLVM Bytecode来实现对JVM堆外对象（C++对象）的高效访问。

但现在已有的优化器仍然不能很好的处理一些复杂的情形，比如访问和操作一些复合数据类型的迭代器（例如`struct edge_iter { int vid, int offset}`）仍然不能被很好的inline。这个任务中，候选人需要改进fastffi中现有的优化器，将更多的常见的跨语言调用模式（比如iterator）翻译到更高效的bytecode来提升性能。这个题目是Vineyard项目与FastFFI项目的合作题目，一部分工作可能会需要在FastFFI (https://github.com/alibaba/fastFFI) 项目中完成。

提升跨语言访问复合数据类型的性能
通过在已有的一些测试集上验证实现的优化的效果

候选人需要有编写JNI代码的经验，并且对跨语言调用的低效等问题有一定程度的感知
候选人需要有一些编译器和性能评测方面的经验
候选人最好对JVM Bytecode和LLVM bytecode有一定程度的熟悉"
"在RT-Thread Smart上完成cyclone dds（https://github.com/eclipse-cyclonedds/cyclonedds）移植：以CMake方式进行移植，并可以在vscode + smart插件中进行编译，下载，调试。开发板可基于ART-Pi smart（32位单核），树莓派 4B（64位多核）等硬件开发板。

完成cyclone dds软件包，并移植到RT-Thread Smart的用户态下
移植cyclone dds的例程，并给出性能测试指标
提交cyclone dds软件包代码到RT-Thread的软件包中
给出基本的文档，覆盖cyclone dds的基本结构及一些主要场景的流程序列图

熟悉C语言，熟悉TCP/IP网络
熟悉git操作
熟悉操作系统"
"官网 https://maxkey.top/优化和国际化翻译

此项目需求为对官网进行优化调整，重新翻译英文版，对当前帮助文档进行国际化。具体为下面几点：

1. 官方网站内容优化调整
2. 官网网站英文版本翻译
3. 帮助文档国际化英文版

项目代码能合入仓库
官网网站英文版本翻译
帮助文档国际化
优化当前网站的内容

技术要求
熟悉前端知识html，css ，markdown
了解单点登录基本原理及相关单点登录协议
有一定的英文写基础
非技术要求
对开源抱有热情和强烈兴趣"
"为 EMQX Rule Engine 的 SQL 语法添加 Map/Reduce 语法。
 
1. 设计 Map/Reduce 语法，提交实现建议到 EIP审核。
2. 编码实现，合并到 https://github.com/emqx/rulesql
3. 完成此功能的文档编写

交付设计文档
完成设计文档，提交到 emqx/eip 并通过审核
设计文档规范工整
完成代码实现
完成编码并提交到 emqx/rulesql 项目
代码实现简单整洁
交付功能文档
完成功能文档并提交到 emqx/emqx-docs 项目
功能文档详细明了

能撰写规范的文档，保持代码整洁
使用过多种编程语言，并对语法设计有自己的见解
熟悉 Erlang 编程语言"
"Apache Wayang（孵化）使用不同的平台来执行查询。每个平台都有提供作业状态的工具，然而，这些信息不是集中的，也不人性化，它需要一些处理来创建一个可以帮助人类的真实可视化。我们的想法是使用underline平台提供的工具为Apache Wayang（孵化）生成一个监视UI，但对每个平台进行调整可以以相同的方式呈现信息，也是可以插入Wayang的新平台需要遵循的协议。

对社区的益处

社区的好处是提供了一种工具，可以更好地理解查询中的状态，并有助于调试的第一步，以及在优化时显示性能和Apache Wayang（孵化）决策。

可交付成果

预期的交付是一个功能用户界面，具有可接受的用户体验级别，用于监控正在运行的查询的状态。

预期步骤如下：

了解论文[1]将显示监控API中需要考虑的元素

进入阿帕奇瓦扬内部（孵化）

就如何继续提出意见

设计用于聚合不同平台的监控状态的解决方案

修改Apache Wayang的代码以支持监控

按照用户体验原则创建用户界面

进入阿帕奇瓦扬的内部（孵化）提出如何继续的想法

设计用于聚合不同平台的监控状态的解决方案

修改Apache Wayang的代码以支持监控，并按照用户体验原则创建用户界面

Java Javascript技术要求Postgres（非强制性）Apache Spark（非强制性）Web Framework，UI所需"
"StratoVirt是计算产业中面向云数据中心的企业级虚拟化平台，实现了一套架构统一支持虚拟机、容器、 Serverless三种场景。StratoVirt在轻量低噪、软硬协同、Rust语言级安全等方面具备关键技术竞争优势。目前Stratovirt已经支持轻量虚拟机与标准虚拟机。
为便于定位虚拟机内核本身的Bug，需要提供便捷的gdb通道。
【产出标准】：
支持虚拟机内核调测功能

1、支持stratovirt与gdb的对接
2、支持虚拟机db陷出获取与接管
3、支持虚拟机tcp端口重定向至gdb
4、可选择X86或ARM，或同时支持两个平台

熟悉Rust语言
了解debug机制
了解CPU DB寄存器相关功能
了解gdb
了解tcp与端口"
"基于JavaScript语言,使开源工具PDManer适配openGauss

1、参照PDManer适配openGauss数据库,包括设计、类型、生成java代码等。 2、代码改动尽量集中，满足社区编码规范，提供单元测试用例。 3、代码改动需合入PDManer项目(无法推动可以拉分支到openGauss社区)。 4、提供设计文档（包含修改说明）和测试文档。

1、了解PowerDesigner或类似软件的使用 2、了解openGauss数据库的常用SQL语法及类型 3、熟悉javascript和java编程语言,了解ORM框架。"
"交付openGauss的Ruby连接驱动，满足建连（sha256/md5/sm3）、DML操作(数据类型)、DDL、DCL、绑定参数操作、跨平台（win/arm/x86）等需求。

1、参照pg-ruby驱动实现openGauss的Ruby连接驱动。 2、代码改动尽量集中，满足社区编码规范，提供单元测试用例。 3、代码改动需合入openGauss社区。 4、提供设计文档（包含修改说明）和测试文档。

1、了解openGauss的基础功能 2、熟悉Ruby等常用的编程语言"
"openGauss支持isula容器部署

1、openGauss各版本均可以基于isula进行容器化部署，支持单机和一主多备形态部署，支持可选带om或CM
2、输出相关的镜像、镜像构建代码以及镜像使用方法相关文档
3、适配k8s部署

1、熟悉镜像构建和容器化部署，包括docker、isula
2、熟悉openGauss集群部署流程
3、熟悉shell脚本编写"
"目前 OpenMLDB 并没有一个图形化的运维界面。所有安装、部署、运维管理相关均通过命令行进行。其较为复杂的运维流程，通过命令行模式较容易产生误操作，并且非常不易用。在此项目中，我们期望你可以开发一个图形化的运维管理工具，包含核心的运维操作。

熟悉 OpenMLDB 的运维操作
开发可视化运维客户端，通过包装命令行，实现核心运维和管理功能，包括安装、升级、备份、恢复、扩缩容等（相关运维信息可参考 https://openmldb.ai/docs/zh/main/maintain/index.html）
开发者根据自己的能力经验来选择图形化工具需要实现的若干功能，并不要求实现所有完整的运维命令，但是其实现的框架具备可扩展性，方便以后其他开发者进行扩展
相关的测试代码
相关的产品文档

熟悉并且实践 OpenMLDB 相关的运维和管理命令
熟悉前端开发流程，有能力独立开发美观的前端界面，并且和后台相关命令整合"
"当数据库处于高负载时，可以通过在操作系统层面观察进程函数调用来辅助进行性能瓶颈的判断。类似于操作系统perf的Top. 本项目通过收集需要通过收集进程函数调用，通过GUI（或WEB GUI)实时（或准实时）给出进程函数调用的统计，包括Top调用、调用链等。目前业界已经有名为FlameGraph（火焰图）的实现，但属于手动运行并生成图像，本项目可参考FlameGraph，重点在于实现实时（或准实时）的展示，并可通过WebUI对性能数据收集进行过滤。

1, 实现数据收集通过WebUI进行选择性过滤 2，实现perf数据实时（准实时）收集并分析 3，实现火焰图实时（准实时）展示

1，熟悉HTML/Javasript画图 2，熟悉Python的数据处理和Web Server 3，对Linux操作系统进程函数调用有一定了解"
"Emacs，距今已经有45年的发展历史的“编辑器”，在这45年内，全世界最顶级的黑客在贡献自己的智慧和想象力，一起构建了Emacs这个伟大的开发者工具生态。Emacs的劣势也是因为它太古老了，导致在多线程和图形扩展能力已经无法跟上时代的步伐。EAF是在保留Emacs古老的黑客文化和庞大的开发者插件生态前提下扩展Emacs的多线程和图形渲染能力，实现Live In Emacs的理想。因此，本项目的目标是基于Knova Canvas这类NodeJS库拓展Emacs自身的图片处理能力，通过EAF将JavaScript与Emacs连接起来，需要同时了解Emacs，Python和Vue.js图形开发的黑客来报名参加。

基于Knova Canvas或类似npm库，通过EAF实现图片编辑和处理
在符合Emacs键盘操作习惯的前提下，用键盘控制图片处理指令
优先确保在Linux和Gnome/KDE能成功运行，时间允许下可以调试Windows/macOS平台

熟练使用Linux和GNU Emacs
熟悉ELisp或类似Lisp方言"
"目前xfs没有实现故障注入机制，某些文件系统实现过了，例如f2fs;可以参考f2fs的故障注入机制的框架在xfs上根据xfs的具体特点实现一套同样的机制

1、使能OLK-5.10中xfs故障输入机制，发现OLK-5.10中xfs的bug并提交issue和修复补丁
2、尝试将xfs故障注入特性推到xfs社区

1、熟练使用Linux kernel；
2、熟练C编程；
3、熟悉存储基本知识"
"RK3588采用 ARM 架构，是瑞芯微新一代旗舰级高端处理器。RK3588 凭借其高性能、低功耗、超强多媒体、丰富接口等特点，可广泛应用于高端平板、ARM PC、边缘计算、AR/VR 等领域。本项目的目标是将 openEuler 移植到 RK3588 上，并保证 RK3588的外设均可用。

1.openEuler 的 RK3588的镜像
a.基于 openEuler 20.03 LTS 内核 + openEuler 文件系统
b.镜像支持 DNF/YUM 安装软件源中的软件
c.USB口、WiFi、蓝牙等外设均可用
2.镜像制作脚本和文档
3.RK3588的 USB口、WiFi、蓝牙等外设的使用文档

基本的 Linux 命令
DNF/RPM 包管理
具备一种脚本语言，如 Python、Bash script 等"
"FUSE作为Linux提供的可以实现用户态文件系统的模块，与内核文件系统相比在提供灵活性的同时它也有两个劣势，多一次的内存拷贝和多一次的上下文切换导致性能问题。eBPF作为Linux的新技术提供了kernel space和user space共享数据的方式。本项目尝试将eBPF技术应用到FUSE模块中从而实现零拷贝。

1、实现FUSE 一次读/写请求的零拷贝

1、熟悉eBPF；
2、熟悉FUSE等相关Linux内核模块；
3、熟悉C语言"
"Rust for Linux是Rust语言为了在Linux内核里做开发而推出的项目，目前Linux内核社区也在常用基于Rust for Linux开发内核模块。函数式编程是近年来备受推崇的编程范式，函数式编程在复杂系统实现有独特的优势：代码量小、不容易出错、调试成本低。Rust语言本身也有不少函数式编程的特性。本项目要求为Rust for Linux增加函数式编程特性，使得基于Rust开发Linux内核模块可以采用函数式编程范式，诸如函数式IO、函数式多线程并发执行、函数式错误处理等等。

1、为Rust for Linux增加函数式编程特性；
2、基于为Rust for Linux所增加的函数式特性，实现内核模块。

1、Rust语言；
2、函数式编程；
3、Linux内核编程。"
