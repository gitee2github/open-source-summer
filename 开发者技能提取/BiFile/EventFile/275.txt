深度学习模型部署过程中，我们希望可以快速地对模型进行压缩和推理加速，离线量化是一种常用的压缩加速方法。

OpenPPL 团队一直致力于异构平台的推理加速，我们已经支持 Turing 系列显卡和多种 DSP 的 INT8 量化推理。面对大量模型的多平台量化部署需求，一款支持多平台量化部署的工具必不可少，OpenPPL Quantization Tool (PPQ) 应运而生。

本课题通过 OpenPPL QuantTool (PPQ) 离线量化工具完成视觉/语言模型多平台部署。

完成视觉/语言模型多平台量化部署，精度损失小于 0.5%，并产出对应 benchmark
视觉模型（分类，检测，分割，超分）/ 语言模型在 pplnn int8, TRT int8, snpe 上的部署

熟悉 Python, C++ 等编程语言，了解深度学习基本原理
了解视觉/语言模型基本原理；
了解模型多平台量化部署的流程